---
title: "Re: Cluster rebalancing"
description: ""
project: community
lastmod: 2014-07-07T05:54:58-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14467"
mailinglist_parent_id: "msg14462"
author_name: "John Daily"
project_section: "mailinglistitem"
sent_date: 2014-07-07T05:54:58-07:00
---


Weighted claim is indeed on the wishlist, but I don't believe it has yet
been assigned to any particular planned release.

-John


On Sun, Jul 6, 2014 at 9:09 AM, Thomas Santero  wrote:

&gt; Hi Chaim,
&gt;
&gt; Inline
&gt;
&gt; On Jul 6, 2014, at 1:13 AM, Chaim Solomon 
&gt; wrote:
&gt;
&gt; I don't think I was quite clear in what I asked for.
&gt;
&gt;
&gt; My apologies for misunderstanding your previous query.
&gt;
&gt;
&gt; I am not asking for the ability to influence the hashing algorithm. That
&gt; would be a mess.
&gt; But I would like to be able to have more influence on the distribution of
&gt; vnodes on the nodes - and that is something that RIAK already does.
&gt;
&gt; So a command to bump a vnode off a particular node or reduce the number of
&gt; vnodes on a node or set the target percentage on a node would be nice. It
&gt; seems like the current algorithm already does something similar - but I
&gt; didn't see how one can influence that.
&gt;
&gt; The other issue was that I would suggest taking the disk space into
&gt; consideration.
&gt; If you have nodes that have different storage then balancing the data
&gt; equally between nodes may not be the best option.
&gt; It may be better to take the available disk space into consideration and
&gt; move vnodes to nodes that have free space if a node runs low on space.
&gt;
&gt;
&gt; What you refer to here would be nice, and is something referred to as
&gt; "weighted claim." I know it's been discussed a bit in the past. Perhaps
&gt; someone from Basho can chime in and let us know if it's on the roadmap for
&gt; a future release?
&gt;
&gt;
&gt; One simple use case would be expanding a cluster with newer nodes (that
&gt; have more storage) and being able to utilise that storage.
&gt;
&gt; Another would be to be able to distribute larger partitions more evenly -
&gt; in particular if the size per partition is not evenly distributed.
&gt;
&gt; Chaim Solomon
&gt;
&gt;
&gt;
&gt; On Thu, Jul 3, 2014 at 8:51 PM, Tom Santero  wrote:
&gt;
&gt;&gt; responses inline
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Jul 3, 2014 at 2:45 AM, Chaim Solomon &gt; &gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Hi,
&gt;&gt;&gt;
&gt;&gt;&gt; I'm running a 2.0.0b cluster (small) and have been running out of space
&gt;&gt;&gt; on one node.
&gt;&gt;&gt; I had expected that adding a node would lead to freeing up of space on
&gt;&gt;&gt; other nodes - but it's not working too fast.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Keep in mind that the speed of transfers is bound by the bandwidth
&gt;&gt; available on the network as well as the speed at which you can actually
&gt;&gt; read the data off disk. Once the transfers complete you should see the disk
&gt;&gt; freed.
&gt;&gt;
&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; I would suggest to add to RIAK a way to have the distribution algorithm
&gt;&gt;&gt; take free space into consideration and to move data to empty nodes fast.
&gt;&gt;&gt; Another issue is that adding the node moved most nodes from 25% to 18.8% -
&gt;&gt;&gt; but one stayed on 25% in the planner.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; The algorithm Riak uses to determine vnode placement is
&gt;&gt; non-deterministic; if you don't like any given staged vnode distribution I
&gt;&gt; might suggest you run riak-admin cluster clear to undo any staged changed
&gt;&gt; and attempt to add the node again, until you're content with the new plan.
&gt;&gt;
&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; And I would also suggest adding some way to force a rebalancing of the
&gt;&gt;&gt; cluster to force nodes to take up more load if they don't have enough or
&gt;&gt;&gt; hand off load to others.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; The hashing algorithm used by Riak to determine object placement in the
&gt;&gt; ring is uniform--over time and with a greater number of total keys you'll
&gt;&gt; start to see a smoother distribution across all partitions.
&gt;&gt;
&gt;&gt; On the fly rebalancing would be incredibly expensive, especially for
&gt;&gt; users who have lots of nodes and petabytes of data stored in Riak. Ad-hoc
&gt;&gt; partition handoff would most likely be brittle and error-prone, given the
&gt;&gt; unreliability of the network.
&gt;&gt;
&gt;&gt; In my humble opinion the engineers at Basho work harder than most other
&gt;&gt; distributed systems developers, considering all the edge cases where
&gt;&gt; systems can fail unexpectedly; I say this not to boost their egos, but
&gt;&gt; rather to point out that their approach has the effect of making Riak more
&gt;&gt; robust and resilient than most other distributed datastores. But such
&gt;&gt; resiliency isn't free, and for these guarantees every user must pay the
&gt;&gt; price. Riak might not be the fastest database, and it may even underutilize
&gt;&gt; that really expensive hardware you might throw at it...but i'll be damned
&gt;&gt; if it doesn't lie to me, lose my data or pretend that failures like network
&gt;&gt; partitions don't happen.
&gt;&gt;
&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Chaim Solomon
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

