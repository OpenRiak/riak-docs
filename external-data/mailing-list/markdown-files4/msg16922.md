---
title: "Re: High CPU on a single node in production"
description: ""
project: community
lastmod: 2016-01-06T10:05:36-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16922"
mailinglist_parent_id: "msg16921"
author_name: "Josh Yudaken"
project_section: "mailinglistitem"
sent_date: 2016-01-06T10:05:36-08:00
---


Hi Luke,

We're planning on having a rather large cluster rather soon, which was
the reason for the large ring size. Your documentation indicates ring
resize is \*not\* possible with search 2.0 [1], although an issue I
found on github indicated it might be now? [2]

If the situation is resolved we might be open to resizing our ring
now, but given the trouble we're seeing with normal handoffs that
seems like a bad idea. Is the 4x ring size expected to completely
break Riak like we're seeing in production, or just a bit of extra
strain/latency?

I've been through the tuning list multiple times, and haven't seen any
changes. I migrated the machine seeing issues to a new host, and now
the new host is seeing similar problems. Heres a screenshot of `htop`
just before I stopped the node in order to bring our site back up [3].

Regards,
Josh

[1] 
http://docs.basho.com/riak/latest/ops/advanced/ring-resizing/#Feature-Incompatibility
[2] https://github.com/basho/basho\_docs/issues/1742
[3] https://slack-files.com/T031MU137-F0HRU4E94-c3ab1e776e

On Wed, Jan 6, 2016 at 6:39 AM, Luke Bakken  wrote:
&gt; Hi Josh,
&gt;
&gt; 1024 is too large of a ring size for 10 nodes. If it's possible to
&gt; rebuild your cluster using a ring size of 128 or 256 that would be
&gt; ideal 
&gt; (http://docs.basho.com/riak/latest/ops/building/planning/cluster/#Ring-Size-Number-of-Partitions).
&gt; Ring resizing is possible as well
&gt; (http://docs.basho.com/riak/latest/ops/advanced/ring-resizing/).
&gt;
&gt; Have all of our recommended performance tunings been applied to every
&gt; node in this cluster?
&gt; (http://docs.basho.com/riak/latest/ops/tuning/linux/) - these can have
&gt; a dramatic effect on cluster performance.
&gt;
&gt; --
&gt; Luke Bakken
&gt; Engineer
&gt; lbak...@basho.com
&gt;
&gt; On Tue, Jan 5, 2016 at 10:52 AM, Josh Yudaken  wrote:
&gt;&gt; Hi,
&gt;&gt;
&gt;&gt; We're attempting to use Riak as our primary key-value and search
&gt;&gt; database for an analytics-typed solution to blocking spam/fraud.
&gt;&gt;
&gt;&gt; As we expect to eventually be handling a huge amount of data, I
&gt;&gt; started with a ring size of 1024. We currently have 10 nodes on Google
&gt;&gt; Cloud n1-standard-16 instances [ 16 cores, 60gb RAM, 720gb local ssd.
&gt;&gt; ]. Disks are at about 60% usage [ roughly 175gb leveldb, 16gb yz, 45gb
&gt;&gt; anti\_entropy, 6gb yz\_anti\_entropy ], and request wise we're at about
&gt;&gt; 20k/min get, 4k/min set. Load average is usually around 6.
&gt;&gt;
&gt;&gt; I'm assuming most of the issues we're seeing are Yokozuna related, but
&gt;&gt; we're seeing a ton of tcp timeouts during handoffs, very slow get/set
&gt;&gt; queries, and a slew of other errors.
&gt;&gt;
&gt;&gt; Right now I'm trying to debug an issue where one of the 10 nodes
&gt;&gt; pegged all the cpu cores. Mostly with the `bean` process.
&gt;&gt;
&gt;&gt; # riak-admin top
&gt;&gt; Output server crashed: connection\_lost
&gt;&gt;
&gt;&gt; With few other options (as it was causing slow queries across the
&gt;&gt; cluster) I stopped the server and saw hundreds of the following
&gt;&gt; (interesting) messages in the log::
&gt;&gt;
&gt;&gt; 2016-01-05 18:28:28.573 [info]
&gt;&gt; &lt;0.4958.0&gt;@yz\_index\_hashtree:close\_trees:557 Deliberately marking YZ
&gt;&gt; hashtree {1458647141945490998441568260777384029383167049728,3} for
&gt;&gt; full rebuild on next restart
&gt;&gt;
&gt;&gt; As well as a ton of (I think related?):
&gt;&gt; 2016-01-05 18:28:31.153 [error] &lt;0.5982.0&gt;@yz\_kv:index\_internal:237
&gt;&gt; failed to index object
&gt;&gt; {{&lt;&lt;"features"&gt;&gt;,&lt;&lt;"features"&gt;&gt;},&lt;&lt;"0NKqMtj3O6\_"&gt;&gt;} with error
&gt;&gt; {noproc,{gen\_server,call,[yz\_entropy\_mgr,{get\_tree,1120389438774178506630754486017853682060456099840},infinity]}}
&gt;&gt; because 
&gt;&gt; [{gen\_server,call,3,[{file,"gen\_server.erl"},{line,188}]},{yz\_kv,get\_and\_set\_tree,1,[{file,"src/yz\_kv.erl"},{line,452}]},{yz\_kv,update\_hashtree,4,[{file,"src/yz\_kv.erl"},{line,340}]},{yz\_kv,index,7,[{file,"src/yz\_kv.erl"},{line,295}]},{yz\_kv,index\_internal,5,[{file,"src/yz\_kv.erl"},{line,224}]},{riak\_kv\_vnode,actual\_put,6,[{file,"src/riak\_kv\_vnode.erl"},{line,1619}]},{riak\_kv\_vnode,perform\_put,3,[{file,"src/riak\_kv\_vnode.erl"},{line,1607}]},{riak\_kv\_vnode,do\_put,7,[{file,"src/riak\_kv\_vnode.erl"},{line,1398}]}]
&gt;&gt;
&gt;&gt; For reference the TCP timeout error looks like:
&gt;&gt;
&gt;&gt; 2016-01-01 01:09:50.522 [error]
&gt;&gt; &lt;0.8430.6&gt;@riak\_core\_handoff\_sender:start\_fold:272 hinted transfer of
&gt;&gt; riak\_kv\_vnode from 'riak@riak25-2.c.authbox-api.internal'
&gt;&gt; 185542200051774784537577176028434367729757061120 to
&gt;&gt; 'riak@riak27-2.c.authbox-api.internal'
&gt;&gt; 185542200051774784537577176028434367729757061120 failed because of TCP
&gt;&gt; recv timeout
&gt;&gt;
&gt;&gt; Any suggestions about where to look?
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt; Josh

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

