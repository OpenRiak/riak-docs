---
title: "Re: No more disk space on a node of my Riak cluster"
description: ""
project: community
lastmod: 2013-03-22T09:51:43-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10561"
author_name: "Godefroy de Compreignac"
project_section: "mailinglistitem"
sent_date: 2013-03-22T09:51:43-07:00
---


Ok thanks Evan, I'll try that.

I just saw errors that I've never seen before (I certainly skipped them):

2013-03-22 12:02:18.719 [error] &lt;0.16959.2526&gt; gen\_server &lt;0.16959.2526&gt;
terminated with reason: no function clause matching
riak\_core\_pb:encode({ts,{1363,205559,674898}},
{{ts,{1363,205559,674898}},&lt;&lt;131,104,7,100,0,8,114,95,111,98,106,101,99,116,109,0,0,0,14,101,...&gt;&gt;})
line 40
2013-03-22 12:02:18.720 [error]
&lt;0.13316.2558&gt;@riak\_core\_handoff\_sender:start\_fold:215 hinted\_handoff
transfer of riak\_kv\_vnode from 'riak@5.135.137.208'
627988984790622347665645826557777860008408514560 to 'riak@5.39.74.57'
627988984790622347665645826557777860008408514560 failed because of
error:{badmatch,{error,{worker\_crash,{function\_clause,[{riak\_core\_pb,encode,[{ts,{1363,205559,674898}},{{ts,{1363,205559,674898}},&lt;&lt;131,104,7,100,0,8,114,95,111,98,106,101,99,116,109,0,0,0,14,101,107,108,97,98,108,111,103,45,99,97,99,104,101,109,0,0,0,35,45,45,45,109,90,71,85,99,120,51,84,99,78,101,108,122,72,75,90,80,115,85,85,51,121,87,85,64,56,48,48,120,54,48,48,108,0,0,0,1,104,3,100,0,9,114,95,99,111,110,116,101,110,116,104,9,100,0,4,100,105,99,116,97,6,97,16,97,16,97,8,97,80,97,48,104,16,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,104,1,104,16,106,106,108,0,0,0,1,108,0,0,0,1,109,0,0,0,5,76,105,110,107,115,106,106,106,106,106,106,106,106,106,108,0,0,0,2,108,0,0,0,11,109,0,0,0,12,99,111,110,116,101,110,116,45,116,121,112,101,97,105,97,109,97,97,97,103,97,101,97,47,97,106,97,112,97,101,97,103,106,108,0,0,0,23,109,0,0,0,11,88,45,82,105,97,107,45,86,84,97,103,97,49,97,55,97,109,97,110,97,117,97,66,97,56,97,116,97,108,97,114,97,72,97,82,97,55,97,115,97,114,97,88,97,73,97,73,97,78,97,79,97,67,97,85,106,106,108,0,0,0,1,108,0,0,0,1,109,0,0,0,5,105,110,100,101,120,106,106,106,108,0,0,0,1,108,0,0,0,1,109,0,0,0,20,88,45,82,105,97,107,45,76,97,115,116,45,77,111,100,105,102,105,101,100,104,3,98,0,0,5,83,98,0,3,34,247,98,0,10,75,84,106,106,108,0,0,0,1,108,0,0,0,1,109,0,0,0,11,88,45,82,105,97,107,45,77,101,116,97,106,106,109,0,4,54,114,255,216,255,224,0,16,74,70,73,70,0,1,1,1,1,44,1,44,0,0,255,219,0,67,0,3,2,2,2,2,2,3,2,2,2,3,3,3,3,4,6,4,4,4,4,4,8,6,6,5,6,9,8,10,10,9,8,9,9,10,12,15,12,10,11,14,11,9,9,13,17,13,14,15,16,16,17,16,10,12,18,19,18,16,19,15,16,16,16,255,219,0,67,1,3,3,3,4,3,4,8,4,4,8,16,11,9,11,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,255,192,0,17,8,2,88,3,32,3,1,33,0,2,17,1,3,17,1,255,196,0,29,0,0,3,0,3,1,1,1,1,0,0,0,0,0,0,0,0,4,5,6,2,3,7,1,8,0,9,255,196,0,70,...&gt;&gt;}],...},...]},...}}}
[{riak\_core\_handoff\_sender,start\_fold,5,[{file,"src/riak\_core\_handoff\_sender.erl"},{line,161}]}]
2013-03-22 12:02:18.722 [error] &lt;0.16959.2526&gt; CRASH REPORT Process
&lt;0.16959.2526&gt; with 0 neighbours exited with reason: no function clause
matching riak\_core\_pb:encode({ts,{1363,205559,674898}},
{{ts,{1363,205559,674898}},&lt;&lt;131,104,7,100,0,8,114,95,111,98,106,101,99,116,109,0,0,0,14,101,...&gt;&gt;})
line 40 in gen\_server:terminate/6 line 747
2013-03-22 12:02:18.725 [error] &lt;0.7442.164&gt; Supervisor poolboy\_sup had
child riak\_core\_vnode\_worker started with
{riak\_core\_vnode\_worker,start\_link,undefined} at &lt;0.16959.2526&gt; exit with
reason no function clause matching
riak\_core\_pb:encode({ts,{1363,205559,674898}},
{{ts,{1363,205559,674898}},&lt;&lt;131,104,7,100,0,8,114,95,111,98,106,101,99,116,109,0,0,0,14,101,...&gt;&gt;})
line 40 in context child\_terminated

2013-03-22 11:28:53.379 [error] &lt;0.28559.1189&gt; gen\_fsm &lt;0.28559.1189&gt; in
state active terminated with reason: no case clause matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059
2013-03-22 11:28:53.379 [error]
&lt;0.15853.1198&gt;@riak\_core\_handoff\_receiver:handle\_info:80 Handoff receiver
for partition 79925870791533753339264014289171727637433810944 exited
abnormally after processing 5337 objects:
{{{case\_clause,{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-laprovence"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-laprovence"}},{&lt;&lt;"storage-hotviber"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178727&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-hotviber"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-hotviber"}},{&lt;&lt;"storage-mwc"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178265&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-mwc"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-mwc"}},{&lt;&lt;"storage"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178239&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage"}}],&lt;&lt;"storage"&gt;&gt;}}},[{riak\_kv\_vnode,do\_diffobj\_put,3,[{file,"src/riak\_kv\_vnode.erl"},{line,1059}]},{riak\_kv\_vnode,handle\_handoff\_data,2,[{file,"src/riak\_kv\_vnode.erl"},{line,551}]},{riak\_core\_vnode,handle\_sync\_event,4,[{file,"src/riak\_core\_vnode.erl"},{line,472}]},{gen\_fsm,handle\_msg,7,[{file,"gen\_fsm.erl"},{line,494}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,227}]}]},{gen\_fsm,sync\_send\_all\_state\_event,[&lt;0.28559.1189&gt;,{handoff\_data,&lt;&lt;156,186,9,60,148,97,212,55,60,37,217,98,66,178,155,10,201,158,45,187,73,182,16,146,236,203,88,179,140,37,89,99,152,74,246,157,80,132,132,36,49,217,151,48,246,41,18,89,179,51,200,158,25,203,184,153,197,59,61,239,242,125,191,247,123,190,239,247,188,223,53,191,115,141,185,239,115,238,57,231,186,206,242,63,215,96,164,119,131,123,59,57,123,251,185,179,241,42,251,120,91,155,133,90,89,153,62,241,246,48,176,212,212,51,115,50,176,112,125,234,113,211,200,211,148,135,128,167,137,242,160,115,5,209,63,129,249,57,123,185,185,4,250,128,64,160,255,37,251,239,195,255,151,184,55,245,254,25,15,26,87,16,195,19,152,139,159,111,160,155,111,160,7,131,43,232,156,171,167,75,160,211,121,167,139,212,23,189,211,125,167,155,30,23,189,254,183,225,113,230,223,181,255,144,255,143,233,223,55,209,222,243,244,133,7,252,47,150,127,215,207,254,155,152,254,221,188,240,63,158,47,25,248,244,177,155,147,167,147,143,147,147,147,187,147,155,147,180,147,151,211,99,234,187,251,127,240,115,254,99,101,178,146,124,224,233,4,151,180,120,72,229,80,112,122,234,228,235,100,227,100,226,100,230,164,237,244,196,201,213,41,216,233,174,147,37,85,234,14,85,202,197,41,192,201,194,41,204,201,217,201,220,73,225,255,161,143,167,175,171,91,168,215,255,126,249,210,255,120,252,61,167,128,64,73,35,63,87,207,71,158,110,174,30,52,206,84,129,7,206,32,250,130,239,206,32,22,135,177,255,93,234,127,42,101,228,22,232,228,229,69,189,66,32,158,254,62,93,4,93,52,208,213,215,5,157,57,67,101,163,190,64,167,20,144,170,214,3,29,205,135,38,15,84,174,184,187,74,122,61,118,115,191,18,44,35,117,243,202,141,160,0,79,95,247,43,250,6,122,87,12,238,235,232,93,9,190,37,43,42,113,197,63,200,201,219,51,240,233,21,245,43,202,10,140,167,51,32,45,208,217,51,255,198,191,249,236,191,113,142,230,223,76,123,238,28,205,185,243,180,231,207,255,7,209,49,208,83,137,238,252,121,122,38,122,6,198,127,131,250,215,5,38,198,11,255,62,252,123,200,127,23,61,75,75,67,67,203,72,119,158,142,241,255,...&gt;&gt;},...]}}
2013-03-22 11:28:53.390 [error] &lt;0.28559.1189&gt; CRASH REPORT Process
&lt;0.28559.1189&gt; with 1 neighbours exited with reason: no case clause
matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059 in gen\_fsm:terminate/7 line 611
2013-03-22 11:28:53.397 [error] &lt;0.139.0&gt; Supervisor riak\_core\_vnode\_sup
had child undefined started with {riak\_core\_vnode,start\_link,undefined} at
&lt;0.28559.1189&gt; exit with reason no case clause matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059 in context child\_terminated
2013-03-22 11:28:53.400 [error] &lt;0.29144.1189&gt; gen\_fsm &lt;0.29144.1189&gt; in
state ready terminated with reason: no case clause matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059
2013-03-22 11:28:53.401 [error] &lt;0.29144.1189&gt; CRASH REPORT Process
&lt;0.29144.1189&gt; with 10 neighbours exited with reason: no case clause
matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059 in gen\_fsm:terminate/7 line 611
2013-03-22 11:28:53.402 [error] &lt;0.29145.1189&gt; Supervisor poolboy\_sup had
child riak\_core\_vnode\_worker started with
riak\_core\_vnode\_worker:start\_link([{worker\_args,[79925870791533753339264014289171727637433810944,[],worker\_props]},{worker\_callback\_mod,...},...])
at undefined exit with reason no case clause matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059 in context shutdown\_error
2013-03-22 11:28:53.404 [error] &lt;0.29145.1189&gt; gen\_server &lt;0.29145.1189&gt;
terminated with reason: no case clause matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059
2013-03-22 11:28:53.406 [error] &lt;0.29145.1189&gt; CRASH REPORT Process
&lt;0.29145.1189&gt; with 0 neighbours exited with reason: no case clause
matching
{error,bad\_crc,{state,[{&lt;&lt;"cache"&gt;&gt;,riak\_kv\_memory\_backend,{state,57458783,57450590,57442397,10737418240,31415183,43200}},{&lt;&lt;"storage-kazeo"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178788&gt;,"79925870791533753339264014289171727637433810944",[{data\_root,"/data/riak/bitcask/storage-kazeo"},{read\_write,true}],79925870791533753339264014289171727637433810944,"/data/riak/bitcask/storage-kazeo"}},{&lt;&lt;"storage-laprovence"&gt;&gt;,riak\_kv\_bitcask\_backend,{state,#Ref&lt;0.0.461.178779&gt;,"79925870791533753339...",...}},...],...}}
in riak\_kv\_vnode:do\_diffobj\_put/3 line 1059 in gen\_server:terminate/6 line
747



2013/3/21 Evan Vigil-McClanahan 

&gt; busy\_dist\_ports usually means that you're trying to push too much data
&gt; over your connections, but there are also other things that can
&gt; trigger it.
&gt;
&gt; you can tune the amount of buffer that distributed erlang provides by
&gt; adding
&gt; +zdbbl 
&gt;
&gt; where  is the buffer size \*in KB\* \*per other node in the
&gt; cluster\*. the default is 1024 (i.e. one megabyte), but raising it to
&gt; 8 or 16MB is often called for in busy clusters. If that doesn't help,
&gt; you may be affected by one of the other issues that I mentioned. That
&gt; said, I am not sure that this will help handoff, as it does not go
&gt; over distributed erlang.
&gt;
&gt;
&gt;
&gt; On Thu, Mar 21, 2013 at 12:22 PM, Godefroy de Compreignac
&gt;  wrote:
&gt; &gt; Ok thanks Evan.
&gt; &gt; I didn't post them before on this thread because I thought it was just
&gt; &gt; "info", but I have a lot of messages like these:
&gt; &gt;
&gt; &gt; 2013-03-21 20:13:23.945 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.29558.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.4656154&gt;,'riak@5.135.137.208'}
&gt; &gt; 2013-03-21 20:13:26.295 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.29046.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.21529382&gt;,'riak@5.39.74.57'}
&gt; &gt; 2013-03-21 20:13:27.807 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.29046.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{erlang,crc32,2}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.21529382&gt;,'riak@5.39.74.57'}
&gt; &gt; 2013-03-21 20:13:27.843 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.21168.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.6629407&gt;,'riak@5.39.74.55'}
&gt; &gt; 2013-03-21 20:13:30.626 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.29558.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.6629407&gt;,'riak@5.39.74.55'}
&gt; &gt; 2013-03-21 20:13:30.771 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.24361.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.4656154&gt;,'riak@5.135.137.208'}
&gt; &gt; 2013-03-21 20:13:34.447 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.29558.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.4656154&gt;,'riak@5.135.137.208'}
&gt; &gt; 2013-03-21 20:13:36.210 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.6726.946&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.4656154&gt;,'riak@5.135.137.208'}
&gt; &gt; 2013-03-21 20:13:36.501 [info]
&gt; &gt; &lt;0.12276.176&gt;@riak\_core\_sysmon\_handler:handle\_event:85 monitor
&gt; &gt; busy\_dist\_port &lt;0.32186.176&gt;
&gt; &gt;
&gt; [{initial\_call,{riak\_core\_vnode,init,1}},{almost\_current\_function,{gen\_fsm,loop,7}},{message\_queue\_len,0}]
&gt; &gt; {#Port&lt;0.6629407&gt;,'riak@5.39.74.55'}
&gt; &gt;
&gt; &gt; I guess I have a problem with my network config...
&gt; &gt;
&gt; &gt; I precise that the servers hosting my Riak cluster are also running
&gt; &gt; Couchebase, Nginx and Elasticsearch, so a lot of trafic and connections.
&gt; &gt; /proc/sys/net/netfilter/nf\_conntrack\_count = 30-100K
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; --
&gt; &gt; Godefroy de Compreignac
&gt; &gt;
&gt; &gt; Eklaweb CEO - www.eklaweb.com
&gt; &gt; EklaBlog CEO - www.eklablog.com
&gt; &gt;
&gt; &gt; +33(0)6 11 89 13 84
&gt; &gt; http://www.linkedin.com/in/godefroy
&gt; &gt; http://twitter.com/Godefroy
&gt; &gt;
&gt; &gt;
&gt; &gt; 2013/3/21 Evan Vigil-McClanahan 
&gt; &gt;&gt;
&gt; &gt;&gt; It could be a large number of things, unfortunately. To go through
&gt; &gt;&gt; them all it somewhat outside of my skill set. Maybe someone more
&gt; &gt;&gt; network savvy can provide some pointers?
&gt; &gt;&gt;
&gt; &gt;&gt; Perhaps checking with your network admin, or turning any software
&gt; &gt;&gt; firewalls on your nodes completely off, as a test?
&gt; &gt;&gt;
&gt; &gt;&gt; On Thu, Mar 21, 2013 at 11:44 AM, Godefroy de Compreignac
&gt; &gt;&gt;  wrote:
&gt; &gt;&gt; &gt; But I don't understand what could stop transfers. Maybe a kernel
&gt; &gt;&gt; &gt; setting?
&gt; &gt;&gt; &gt; How could I find out?
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; --
&gt; &gt;&gt; &gt; Godefroy de Compreignac
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; Eklaweb CEO - www.eklaweb.com
&gt; &gt;&gt; &gt; EklaBlog CEO - www.eklablog.com
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; +33(0)6 11 89 13 84
&gt; &gt;&gt; &gt; http://www.linkedin.com/in/godefroy
&gt; &gt;&gt; &gt; http://twitter.com/Godefroy
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; 2013/3/21 Evan Vigil-McClanahan 
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; Handoff is done by default on port 8099.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; I guess what I am getting at here is that this doesn't look like an
&gt; &gt;&gt; &gt;&gt; obvious riak problem, it's more likely that something on your network
&gt; &gt;&gt; &gt;&gt; or on your nodes is closing or interrupting those sockets; you'd most
&gt; &gt;&gt; &gt;&gt; likely get a different error if something internal to riak was
&gt; causing
&gt; &gt;&gt; &gt;&gt; the transfers to fail.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; On Thu, Mar 21, 2013 at 10:09 AM, Godefroy de Compreignac
&gt; &gt;&gt; &gt;&gt;  wrote:
&gt; &gt;&gt; &gt;&gt; &gt; The only limitation that I'd see is Haproy which have a time limit:
&gt; &gt;&gt; &gt;&gt; &gt; contimeout 5000
&gt; &gt;&gt; &gt;&gt; &gt; clitimeout 50000
&gt; &gt;&gt; &gt;&gt; &gt; srvtimeout 3600000
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; But Haproxy serves Riak on port 8098 and I configured Riak to use
&gt; &gt;&gt; &gt;&gt; &gt; port
&gt; &gt;&gt; &gt;&gt; &gt; 8097:
&gt; &gt;&gt; &gt;&gt; &gt; {pb\_port, 8087 }
&gt; &gt;&gt; &gt;&gt; &gt; {http, [ {"5.39.68.152", 8097 } ]}
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; So I guess Riak use only port 8097 internally, without any
&gt; &gt;&gt; &gt;&gt; &gt; limitation.
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; And by checking logs, I see that a vnode transfer fails after a
&gt; &gt;&gt; &gt;&gt; &gt; random
&gt; &gt;&gt; &gt;&gt; &gt; duration, sometimes a few minutes.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

