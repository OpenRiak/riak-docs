---
title: "Re: Bigger data than disk space?"
description: ""
project: community
lastmod: 2013-03-14T14:06:56-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10438"
mailinglist_parent_id: "msg10437"
author_name: "Mark Phillips"
project_section: "mailinglistitem"
sent_date: 2013-03-14T14:06:56-07:00
---


Kevin,

On Thu, Mar 14, 2013 at 1:56 PM, Kevin Burton  wrote:
&gt; So that is what I am missing. If each vnode keeps an entire copy of my data
&gt; and I have 4 physical node then there are 16 vnodes per physical node. That
&gt; would mean I have the data replicated 16 times per physical node. 10 GB
&gt; turns into 160GB etc. Right? So won’t I run out of disk space?
&gt;

Your raw data set is replicated 3 times by default. Three different
vnodes of your total (by default 64) will be responsible for each
replica. So, 10GB raw = 30GB replicated.

Mark

&gt;
&gt;
&gt; From: Alexander Sicular [mailto:sicul...@gmail.com]
&gt; Sent: Thursday, March 14, 2013 3:51 PM
&gt;
&gt;
&gt; To: Kevin Burton
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Bigger data than disk space?
&gt;
&gt;
&gt;
&gt; Each vnode keeps \_an entire copy\_ of your data. There is no striping, which
&gt; I think you are conflating with RAID. Default replication (also configured
&gt; in etc/app.config) is set to three. In which case, three entire copies of
&gt; your data are kept on three different vnodes and if you indeed have five
&gt; physical nodes in your cluster you are guaranteed to have each of those
&gt; three vnodes on different physical machines.
&gt;
&gt;
&gt; -Alexander Sicular
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt;
&gt;
&gt; On Mar 14, 2013, at 4:42 PM, "Kevin Burton" 
&gt; wrote:
&gt;
&gt;
&gt;
&gt; Thank you. Let me get it straight. I have a 4 node cluster (4 physical
&gt; machines). If I have not made any changes to the ring size then I have 16
&gt; (64/4) vnodes. Each physical node stores the actual data (the value) of
&gt; about ¼ of the data size. So when querying the data with a key given the
&gt; number of vnodes it can be determined which physical machine the data is on.
&gt; There must be enough redundancy built in so that if one or more of the
&gt; physical machines go down the remaining physical machines can reconstruct
&gt; the values lost by the lost vnodes. Correct so far? Now where does
&gt; replication some in? The documentation indicates that there are 3 copies of
&gt; the data (default) made. How is this changed and how can this replication of
&gt; the data be taken advantage of?
&gt;
&gt;
&gt;
&gt; From: Alexander Sicular [mailto:sicul...@gmail.com]
&gt; Sent: Thursday, March 14, 2013 3:28 PM
&gt; To: Kevin Burton
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Bigger data than disk space?
&gt;
&gt;
&gt;
&gt; Hi Kevin,
&gt;
&gt;
&gt;
&gt; The Riak distribution model is not based on "buckets" but rather the hash of
&gt; the bucket/key combination. That hash (and associated data) is then
&gt; allocated against a "vnode". A vnode, in turn, is one of n where n is the
&gt; ring\_creation\_size (default is 64, modify in etc/app.config). Each physical
&gt; machine in a Riak cluster claims an equal share of the ring. For example, a
&gt; cluster with five machines (the recommended minimum for a production
&gt; cluster) and the default ring\_creation\_size will have 64/5 vnodes per
&gt; physical machine (not sure if they round down or up but all machines will
&gt; have about the same number of vnodes). What you would do to make more data
&gt; available is either add a machine to the cluster whose available disk space
&gt; is equal or greater than the cluster member with the least amount of total
&gt; space or increase the space on all machines already in the cluster.
&gt;
&gt;
&gt;
&gt; tl;dr add a machine to your cluster.
&gt;
&gt;
&gt;
&gt;
&gt; -Alexander Sicular
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt;
&gt;
&gt; On Mar 14, 2013, at 3:41 PM, Kevin Burton  wrote:
&gt;
&gt;
&gt;
&gt;
&gt; I am relatively new to Riak so forgive me if this has been asked before. I
&gt; have a very thin understanding of a Riak cluster and understand somewhat
&gt; about replication. In planning I foresee a time when the amount of data
&gt; exceeds the disk space that is available to a single node. What facilities
&gt; are there to essentially “split” a bucket across several servers? How is
&gt; this handled?
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

