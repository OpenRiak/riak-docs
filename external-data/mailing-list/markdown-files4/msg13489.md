---
title: "Re: Data modeling a write-intensive comment storage cluster"
description: ""
project: community
lastmod: 2014-01-27T06:50:12-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13489"
mailinglist_parent_id: "msg13488"
author_name: "Jeremiah Peschka"
project_section: "mailinglistitem"
sent_date: 2014-01-27T06:50:12-08:00
---


---
Jeremiah Peschka - Founder, Brent Ozar Unlimited
MCITP: SQL Server 2008, MVP
Cloudera Certified Developer for Apache Hadoop


On Sun, Jan 26, 2014 at 10:27 PM, fxmy wang  wrote:

&gt; Thanks for the response, Jeremiah.
&gt;
&gt;
&gt;
&gt; &gt; &gt; Then here are my questions:
&gt; &gt; &gt; 1) To get better writing throughput, is it right to set the w=1?
&gt; &gt;
&gt; &gt; This will improve perceived throughput at the client, but it won't
&gt; improve throughput at the server.
&gt;
&gt; Thank you for clarifying this for me :D
&gt;
&gt; &gt; &gt; 2) What's the best way to query these comments? In this use case, I
&gt; don't need to retrieve all the comments in one bucket, but just the latest
&gt; few hundreds comments( if there are so many) based on the time they are
&gt; posted.
&gt; &gt; &gt;
&gt; &gt; &gt; Right now I'm thinking of using line-walking and keeping track of the
&gt; latest comment so I can trace backwards to get the latest 500 comments (
&gt; for example). And when new comment comes, point the line to the old latest,
&gt; then update new latest comment mark.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I wouldn't use link-walking. IIRC this uses MapReduce under the covers.
&gt; You could use a single key to store the most recent comment.
&gt;
&gt; What's bad about MapReduce?
&gt; Since there will be another cache layer lays on top of the cluster, so
&gt; the read operation is relatively quite infrequent. That's why I choose
&gt; to use link-walking.
&gt;

Even when you run a MapReduce query over a single bucket, MapReduce has to
contact a majority of nodes in the cluster to perform a coverage query. In
effect, you're scanning all of the keys to make sure you find only the keys
in a single bucket. MapReduce can work for limited scenarios (e.g. mutating
the state of a large number of objects or running batched analytics that
write to a separate set of buckets/keys) but people have reported
unsatisfactory results when trying to use MapReduce for live querying.

This sort of thing may be possible with the Riak Search 2.0 functionality
as well. I haven't played around with it enough to know whether it would be
a good fit or not.


&gt;
&gt; &gt; You can get the most recent n keys using secondary index queries on the
&gt; $bucket index, sorting, and pagination.
&gt; I'm not sure what you mean here =.=
&gt; How can I query most recent n keys using 2i ? Should I put timestamp
&gt; -----like by every hour----- in 2i on the coming comments , then when
&gt; it comes to queries, just try to query 2i by the hour segment? This
&gt; seems a little blind because some videos could be long time before got
&gt; commented again. Querying based on time segmentation seems like
&gt; shooting in the dark to me :\
&gt;

"Keys will consist of a timestamp and userID."

Sounds like you could sort on that to me.

The $bucket index is a special index that only contains a list of the keys
in a bucket. Querying $bucket is cheaper than a list keys operation.

There are a number of ways you can solve this problem that are all
implementation dependent.


&gt;
&gt; And doc says listing keys operation should not used in production, so
&gt; it's a no go either :\
&gt;

A list keys is not a $bucket index query. See "Retrieve all Bucket Keys via
$bucket Index" at http://docs.basho.com/riak/latest/dev/using/2i/

&gt;
&gt;
&gt; &gt; &gt; So in the scenario above, is it possible that after one client has
&gt; written on nodeA ,modified the latest-mark and another client on nodeB not
&gt; yet sees the change thus points the line to the old comment, resulting a
&gt; "branch" in the line?
&gt; &gt; &gt; If this could happen, then what can be done to avoid it? Are there any
&gt; better ways to store&query those comments? Any reply is appreciated.
&gt; &gt;
&gt; &gt; You can avoid siblings by serializing all of your writes through a
&gt; single writer. That's not a great idea since you lose many of Riak's
&gt; benefits.
&gt; &gt; You could also use a CRDT with a register type. These tend toward the
&gt; last writer.
&gt;
&gt; My goal is to form kind of a single-line-relationship based on
&gt; timestamp through the keys under high concurrent write pressure. And
&gt; through this relationship I can easily pick out the last
&gt; hundreds/thousands comments.
&gt; As Jeremiah said, serializing all of writes through a single writer
&gt; can avoid siblings totally. And note that we don't have key clashing
&gt; problems here ------ every comment holds an unique key. What we want
&gt; is single-line-relationship. So how about this:
&gt;
&gt; Multiple erlang-pb clients just do the writes and don't care about the
&gt; lining up.
&gt; Using post-commit hooks to notify one special global registered
&gt; process( which should be running in the riak cluster?) that "here
&gt; comes a new comment, line it up when it's appropriate".
&gt; Is this feasible? And if it is , how should i prepare for the cluster
&gt; partition & rejoin scenario when network fails?
&gt;

It sounds to me like you're doing an awful lot of work to do something that
a relational database handles remarkably well.


&gt;
&gt; &gt; The point is that you need to decide how you want to deal with this type
&gt; of scenario - it's going to happen. In a worst case; you lose a write
&gt; briefly.
&gt;
&gt; Hopefully the method above could avoid this :)
&gt;
&gt; Please everyone, share your thoughts please. \_(:3JZ)\_
&gt;
&gt; B.R.
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

