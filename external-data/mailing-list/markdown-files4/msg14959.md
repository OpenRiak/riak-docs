---
title: "Re: replacing node results in error with diag"
description: ""
project: community
lastmod: 2014-09-30T12:58:42-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14959"
mailinglist_parent_id: "msg14958"
author_name: "Sargun Dhillon"
project_section: "mailinglistitem"
sent_date: 2014-09-30T12:58:42-07:00
---


So, I don't have a ton of experience with Riaknostic, but taking a
casual glance at the source code, it appears that Riaknostic caches
some node-local data about the ring (see:
https://github.com/basho/riaknostic/blob/2.0.0/src/riaknostic\_node.erl#L192-L208).
You should be able to unset this by attaching to a node "riak attach"
and running application:unset\_env(riaknostic, local\_stats). --
although, it'd be nice to get a dump of your local env first for
debugging purposes, you can get that via io:format("Local env: ~p~n",
[application:get\_all\_env(riaknostic)]). (including the period).

If that clears one node, you can do it on all of your nodes by issuing
rpc:multicall(application, unset\_env, [riaknostic, local\_stats]). on
one node.

On Tue, Sep 30, 2014 at 12:39 PM, Max Vernimmen
 wrote:
&gt; Hi,
&gt;
&gt;
&gt;
&gt; Today I finished upgrading 2.0.0-pre20 to 2.0.0-1. Once that was done I did
&gt; a node replace according to the instructions at
&gt; http://docs.basho.com/riak/latest/ops/running/nodes/replacing/
&gt;
&gt; Once the replacing was done, our monitoring notified us about a problem with
&gt; the cluster. Our monitoring does a ‘riak-admin diag’ and each of the nodes
&gt; is now giving the output I’ve posted here:
&gt; https://gist.github.com/anonymous/a3133333a07b0cd1da1c
&gt;
&gt; There is a node being referenced in the diag, which is the replaced node. It
&gt; is no longer in the cluster. I confirmed the ring was settled and in the web
&gt; interface of the cluster the replaced node is no longer listed neither is it
&gt; in the `riak-admin status` output. Only a restart of the riak service on
&gt; each of the nodes resolves the problem. Doing a restart on only one node
&gt; fixes the diag status only for that node.
&gt;
&gt;
&gt;
&gt; To me it seems like there is some state left in the cluster nodes after a
&gt; node is replaced, causing the `riak-admin diag` command to fail. Has anyone
&gt; else seen this? Would this classify as a bug or did I simply do something
&gt; wrong ? J
&gt;
&gt;
&gt;
&gt; Best regards,
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; Max Vernimmen
&gt;
&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

