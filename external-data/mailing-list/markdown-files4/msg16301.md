---
title: "Re: Riak LevelDB Deletion Problem"
description: ""
project: community
lastmod: 2015-07-16T14:12:00-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16301"
mailinglist_parent_id: "msg16297"
author_name: "Antonio Teixeira"
project_section: "mailinglistitem"
sent_date: 2015-07-16T14:12:00-07:00
---


Timo,
After one hour it spitted the data we needed , for the record :
curl YOURIP:8098/buckets/YOURBUCKET/index/\$bucket/\_

Cheers,
Antonio

2015-07-15 21:51 GMT+01:00 Timo Gatsonides :

&gt; From: Antonio Teixeira 
&gt; To: Matthew Von-Maszewski 
&gt; Cc: riak-users 
&gt; Subject: Re: Riak LevelDB Deletion Problem
&gt; Message-ID:
&gt; 
&gt; Content-Type: text/plain; charset="utf-8"
&gt;
&gt; Hello Matthew,
&gt;
&gt; Space is reducing slooooowly , now we are faced with another problem :
&gt; Alot of applications store data on this node and we don't have the bucket
&gt; keys (they are uuid4) so :
&gt;
&gt; We are using listkeys ( I know its bad ) on the erlang client and we also
&gt; tried with curl using both blocking and stream methods.
&gt; And they are all returning {error, timeout}.
&gt;
&gt; We are 95 % sure that not all data has been migrated so , is there any way
&gt; to get the keys of the bucket, even if we have to shutdown the node (
&gt; Uptime/Availability not important for us ).
&gt;
&gt; We are currently looking at mapreduce ?!
&gt;
&gt;
&gt; What are you using to list keys? Are you using secondary indexes? You can
&gt; get all the keys for a bucket using the $bucket index, or do a range scan
&gt; on $key. See http://docs.basho.com/riak/latest/dev/using/2i/ . If your
&gt; cluster is healthy that should return the keys without throwing a timeout
&gt; error.
&gt;
&gt; Kind regards,
&gt; Timo
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

