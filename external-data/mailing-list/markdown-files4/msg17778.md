---
title: "Re: Riak CS: avoiding RAM overflow and OOM killer"
description: ""
project: community
lastmod: 2016-11-23T02:32:03-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg17778"
mailinglist_parent_id: "msg17776"
author_name: "Daniel Miller"
project_section: "mailinglistitem"
sent_date: 2016-11-23T02:32:03-08:00
---


Hi Alexander,

Thanks for responding.

&gt; How many nodes?

We currently have 9 nodes in our cluster.

&gt; How much ram per node?

Each node has 4GB of ram and 4GB of swap. The memory levels (ram + swap) on
each node are currently between 4GB and 5.5GB.

&gt; How many objects (files)? What is the average file size?

We currently have &gt;30 million objects, and I analyzed the average object
size before we migrated data into the cluster it was about 4KB/object, with
some objects being much larger (multiple MB). Is there an easy way to get
this information from a running cluster so I can give you more accurate
information?


On Tue, Nov 22, 2016 at 2:42 AM, Alexander Sicular 
wrote:

&gt; Hi Daniel,
&gt;
&gt; How many nodes?
&gt; -You should be using 5 minimum if you using the default config. There
&gt; are reasons.
&gt;
&gt; How much ram per node?
&gt; -As you noted, in Riak CS, 1MB file chunks are stored in bitcask.
&gt; Their key names and some overhead consume memory.
&gt;
&gt; How many objects (files)? What is the average file size?
&gt; -If your size distribution significantly skews &lt; 1MB that means you
&gt; will have a bunch of files in bitcask eating up ram.
&gt;
&gt; Kota was a former Basho engineer who worked on CS... That said, Basho
&gt; may not support a non standard deployment.
&gt;
&gt; -Alexander
&gt;
&gt; On Mon, Nov 21, 2016 at 2:45 PM, Daniel Miller  wrote:
&gt; &gt; I found a similar question from over a year ago
&gt; &gt; (http://lists.basho.com/pipermail/riak-users\_lists.
&gt; basho.com/2015-July/017327.html),
&gt; &gt; and it sounds like leveldb is the way to go, although possibly not well
&gt; &gt; tested. Has anything changed with regard to Basho's (or anyone else)
&gt; &gt; experience with using leveldb backend instead of the mutli backend for
&gt; CS?
&gt; &gt;
&gt; &gt; On Fri, Nov 4, 2016 at 11:48 AM, Daniel Miller 
&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Hi,
&gt; &gt;&gt;
&gt; &gt;&gt; I have a Riak CS cluster up and running, and am anticipating exponential
&gt; &gt;&gt; growth in the number of key/value pairs over the next few years. From
&gt; &gt;&gt; reading the documentation and experience, I've concluded that the
&gt; default
&gt; &gt;&gt; configuration of CS (with riak\_cs\_kv\_multi\_backend) keeps all keys in
&gt; RAM.
&gt; &gt;&gt; The OOM killer strikes when Riak uses too much RAM, which is not good
&gt; for my
&gt; &gt;&gt; sanity or sleep. Because of the amount of growth I am anticipating, it
&gt; seems
&gt; &gt;&gt; unlikely that I can allocate enough RAM to keep up with the load. Disk,
&gt; on
&gt; &gt;&gt; the other hand, is less constrained.
&gt; &gt;&gt;
&gt; &gt;&gt; A little background on the data set: I have a sparsely accessed key set.
&gt; &gt;&gt; By that I mean after a key is written, the more time passes with that
&gt; key
&gt; &gt;&gt; not being accessed, the less likely it is to be accessed any time soon.
&gt; At
&gt; &gt;&gt; any given time, most keys will be dormant. However, any given key
&gt; \_could\_ be
&gt; &gt;&gt; accessed at any time, so should be possible to retrieve it.
&gt; &gt;&gt;
&gt; &gt;&gt; I am currently running a smaller cluster (with smaller nodes: less RAM,
&gt; &gt;&gt; smaller disks) than I expect to use eventually. I am starting to hit
&gt; some
&gt; &gt;&gt; growth-related issues that are prompting me to explore more options
&gt; before
&gt; &gt;&gt; it becomes a dire situation.
&gt; &gt;&gt;
&gt; &gt;&gt; My question: Are there ways to tune Riak (CS) to support this scenario
&gt; &gt;&gt; gracefully? That is, are there ways to make Riak not load all keys into
&gt; RAM?
&gt; &gt;&gt; It looks like leveldb is just what I want, but I'm a little nervous
&gt; &gt;&gt; switching over to only leveldb when the default/recommended config uses
&gt; the
&gt; &gt;&gt; multi backend.
&gt; &gt;&gt;
&gt; &gt;&gt; As a stop-gap measure, I enabled swap (with swappiness = 0), which I
&gt; &gt;&gt; anticipated would kill performance, but was pleasantly surprised to see
&gt; it
&gt; &gt;&gt; return to effectively no-swap performance levels after a short period of
&gt; &gt;&gt; lower performance. I'm guessing this is not a good long-term solution
&gt; as my
&gt; &gt;&gt; dataset grows. The problem with using large amounts of swap is that each
&gt; &gt;&gt; time Riak starts it needs to read all keys into RAM. Long term, as our
&gt; &gt;&gt; dataset grows, the amount of time needed to read keys into RAM will
&gt; cause a
&gt; &gt;&gt; very long restart time (and thus period of unavailability), which could
&gt; &gt;&gt; endanger availability for a prolonged period if multiple nodes go down
&gt; at
&gt; &gt;&gt; once.
&gt; &gt;&gt;
&gt; &gt;&gt; Thanks!
&gt; &gt;&gt; Daniel Miller
&gt; &gt;&gt; Dimagi, Inc.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt; &gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

