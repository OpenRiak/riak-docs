---
title: "Re: Riak n00b questions"
description: ""
project: community
lastmod: 2011-03-15T05:32:49-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg02650"
mailinglist_parent_id: "msg02648"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2011-03-15T05:32:49-07:00
---


Ok, that's fair (you're basically describing a CQRS-style architecture). But I 
don't see anything in that chain of processing that requires your individual 
Map and Reduce functions to be written in PHP or Python. The munging you 
describe would probably be best done outside Riak, either via a custom system, 
or via something like Hadoop's streaming interface. One thing that might be of 
interest to you is Disco, which is written primarily in Python with some bits 
of Erlang, and is an alternative to Hadoop.

Sean Cribbs 
Developer Advocate
Basho Technologies, Inc.
http://basho.com/

On Mar 15, 2011, at 4:28 AM, Ishwar wrote:

&gt; Sean,
&gt; 
&gt; The use-case that we're looking at is a bit more complicated than that. 
&gt; Briefly, this is what we want to do.
&gt; 
&gt; 1. We get a whole bunch of data, say, blog posts from various sources which 
&gt; we index in Solr, and store in Riak in json format.
&gt; 
&gt; 2. Once the data is in riak, we need to run a whole bunch of analysis on 
&gt; selected groups of records. The scripts to do this analysis are in PHP and 
&gt; Python. The idea is to run MapReduce on a batch of records, and update Solr 
&gt; with the results of the analysis. On Riak, the results of the analysis will 
&gt; be updated on a different bucket, with links to the original record.
&gt; 
&gt; 
&gt; 3. At the serving end, it's going to be just key-value pair retrievals, or 
&gt; simple MapReduce.
&gt; 
&gt; Pre-processing the data is not an option as we won't be running this analysis 
&gt; on all the records. It will be run only on a subset of data.
&gt; 
&gt; Given these use-case, what do you suggest is the best way to use Riak?
&gt; 
&gt; 
&gt; --
&gt; Thanks,
&gt; Ishwar
&gt; 
&gt; 
&gt; 
&gt; 
&gt; ----- Original Message -----
&gt;&gt; From:Sean Cribbs 
&gt;&gt; To:Ishwar 
&gt;&gt; Cc:"riak-users@lists.basho.com" 
&gt;&gt; Sent:Monday, March 14, 2011 8:57 PM
&gt;&gt; Subject:Re: Riak n00b questions
&gt;&gt; 
&gt;&gt; 
&gt;&gt;&gt;&gt; It is not currently, but we are looking into the feasibility of 
&gt;&gt; supporting other languages. However, I might say that if you're already 
&gt;&gt; doing Python and PHP, it would be worth your while (and not difficult) to 
&gt;&gt; learn 
&gt;&gt; JavaScript.
&gt;&gt;&gt; 
&gt;&gt;&gt; We already have a whole bunch of processing on the data written in Python 
&gt;&gt; and PHP, and porting them to Javascript is (1) very tedious, and (2) 
&gt;&gt; Javascript 
&gt;&gt; does not support the required functionality. For example, we do a bunch of 
&gt;&gt; NLP 
&gt;&gt; analysis on the data.
&gt;&gt;&gt; 
&gt;&gt;&gt; Given these, is it advisable if I expose these processes as webservices and 
&gt;&gt; call them from javascript/erlang?
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; The other option of course, is to pre-process your data and just insert 
&gt;&gt; multiple 
&gt;&gt; copies in different formats, which is a pretty common pattern. The tradeoff 
&gt;&gt; is 
&gt;&gt; whether you want to pay the cost at query time or at write time. If you can 
&gt;&gt; pay 
&gt;&gt; that cost up-front, reads will likely be key-value or very simple MapReduce 
&gt;&gt; and 
&gt;&gt; thus very fast.
&gt;&gt; 
&gt;&gt; Sean Cribbs 
&gt;&gt; Developer Advocate
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; http://basho.com/
&gt; 


\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

