---
title: "Re: Slow performance using linkwalk, help wanted"
description: ""
project: community
lastmod: 2010-11-08T05:20:32-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01489"
mailinglist_parent_id: "msg01487"
author_name: "Kevin Smith"
project_section: "mailinglistitem"
sent_date: 2010-11-08T05:20:32-08:00
---


Jan - 

Which protocol (HTTP or protocol buffers) and client lib are you using?

--Kevin
On Nov 8, 2010, at 6:36 AM, Jan Buchholdt wrote:

&gt; We are evaluating Riak for a project, but having a hard time making it fast 
&gt; enough for our need.
&gt; 
&gt; Our model is very simple and looks like this:
&gt; 
&gt; --------------------- \* ---------------------
&gt; | Person | ------------------------&gt; | Document |
&gt; --------------------- ---------------------
&gt; 
&gt; We have a set of persons and each person can have many documents. 
&gt; 
&gt; Our typical queries are:
&gt; 
&gt; Get an overview of all the persons documents. This query returns the person 
&gt; along with a subset of data from all the persons documents.
&gt; Get document by id.
&gt; 
&gt; Our requirements are that these quires should be performed under in under 
&gt; 100millis when we have 10 requests per second or less load.
&gt; 
&gt; The size of the data:
&gt; A document is approximately 1 kb 
&gt; No data for a persons except the personidentifier
&gt; Around 6 million persons.
&gt; Each person has from from 0 to a couple of thousand documents.
&gt; All in all we have 120 mio documents.
&gt; Most persons don't have more than 1 to 10 documents, but then we have some 
&gt; few "heavy" persons having 500 to 1000 documents.
&gt; 
&gt; Riak setup:
&gt; 4 Nodes. 
&gt; Hardware configuration for each node:
&gt; HP ProLiant DL360 G7
&gt; 18 gb ram
&gt; SAS discs
&gt; Intel(R) Xeon(R) CPU E5620 @ 2.40GHz Proc 1
&gt; Solaris 10 update 9
&gt; 
&gt; We use the default bitcask storage engine
&gt; We replicate data to 3 machines when it is written.
&gt; Reads are read from just one machine
&gt; 
&gt; We tried implementing our datamodel using Riak links as described below:
&gt; 
&gt; Persons are stored in a person bucket using their person identifier as key 
&gt; /person/
&gt; {personid}
&gt; Documents are saved in another bucket 
&gt; /document/
&gt; {documented}
&gt; At each person we store links to the persons documents.
&gt; 
&gt; We are having problems with the query fetching all the documents for a 
&gt; person. Reading all the documents for a person is done using a link walk. 
&gt; The linkwalk start reading all the document keys using the personid. It then 
&gt; fetches all documents.
&gt; For persons with 1 - 5 documents the response times are often over 100 mills. 
&gt; And for the "heavy" persons with many documents response times are several 
&gt; seconds. But we are very new to Riak and are probably using a wrong approach.
&gt; 
&gt; Below are our thoughts (having almost no experience with Riak):
&gt; 
&gt; The chosen datamodel is good for writes. Writing a new document results in 3 
&gt; operations against Riak. Writing the document using its id as key. Reading 
&gt; the Person to get all the persons document links. Append the new document's 
&gt; key to the persons links and write back the person.
&gt; 
&gt; Reading, using linkwalk, is slow because it is expensive to fetch many 
&gt; documents even though the linkwalk can read their keys right away by reading 
&gt; the links for the person. Even though we have 4 nodes and linkwalks are 
&gt; parallelized many documents need to be retrieved from one node. Having to 
&gt; fetch for example 100 documents on one node (one disc) is expensive. We do 
&gt; not know how data is stored but are afraid Riak is doing a lot of disk seeks.
&gt; 
&gt; We are considering another more denormalized approach where we write all the 
&gt; documents for a person in one "blob". But then we are afraid our writes 
&gt; become slow, because when adding a new document the blob must be read, the 
&gt; new document inserted and the blob written back.
&gt; 
&gt; We could really need some input. Is our assumptions wrong? (we have not yet 
&gt; dug into the problems). Is there a good datamodel for our requirements? etc?.
&gt; We haven't looked at Riak search at all. Maybe it could solve some of our 
&gt; problems.
&gt; 
&gt; 
&gt; 
&gt; -- 
&gt; --
&gt; Jan Buchholdt
&gt; Software Pilot
&gt; Trifork A/S
&gt; Cell +45 50761121
&gt; 
&gt; 
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com


\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

