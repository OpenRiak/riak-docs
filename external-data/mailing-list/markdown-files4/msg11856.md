---
title: "Re: performance"
description: ""
project: community
lastmod: 2013-08-01T18:35:05-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11856"
mailinglist_parent_id: "msg11855"
author_name: "Paul Ingalls"
project_section: "mailinglistitem"
sent_date: 2013-08-01T18:35:05-07:00
---


I should add more details about the nodes that crashed. I ran this for the 
first time for all of 10 minutes.

Here is the log from the first one:

2013-08-02 00:09:44 =ERROR REPORT====
\*\* State machine &lt;0.2368.0&gt; terminating
\*\* Last event in was unregistered
\*\* When State == active
\*\* Data == 
{state,114179815416476790484662877555959610910619729920,riak\_kv\_vnode,{deleted,{state,114179815416476790484662877555959610910619729920,riak\_kv\_eleveldb\_backend,{state,&lt;&lt;&gt;&gt;,"/mnt/datadrive/riak/data/leveldb/114179815416476790484662877555959610910619729920",[{create\_if\_missing,true},{max\_open\_files,128},{use\_bloomfilter,true},{write\_buffer\_size,58858594}],[{add\_paths,[]},{allow\_strfun,false},{anti\_entropy,{on,[]}},{anti\_entropy\_build\_limit,{1,3600000}},{anti\_entropy\_concurrency,2},{anti\_entropy\_data\_dir,"/mnt/datadrive/riak/data/anti\_entropy"},{anti\_entropy\_expire,604800000},{anti\_entropy\_leveldb\_opts,[{write\_buffer\_size,4194304},{max\_open\_files,20}]},{anti\_entropy\_tick,15000},{create\_if\_missing,true},{data\_root,"/mnt/datadrive/riak/data/leveldb"},{fsm\_limit,50000},{hook\_js\_vm\_count,2},{http\_url\_encoding,on},{included\_applications,[]},{js\_max\_vm\_mem,8},{js\_thread\_stack,16},{legacy\_stats,true},{listkeys\_backpressure,true},{map\_js\_vm\_count,8},{mapred\_2i\_pipe,true},{mapred\_name,"mapred"},{max\_open\_files,128},{object\_format,v1},{reduce\_js\_vm\_count,6},{stats\_urlpath,"stats"},{storage\_backend,riak\_kv\_eleveldb\_backend},{use\_bloomfilter,true},{vnode\_vclocks,true},{write\_buffer\_size,58858594}],[],[],[{fill\_cache,false}],true,false},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},undefined,3000,1000,100,100,true,true,undefined}},riak@riak003,none,undefined,undefined,undefined,{pool,riak\_kv\_worker,10,[]},undefined,107615}
\*\* Reason for termination =
\*\* 
{badarg,[{eleveldb,close,[&lt;&lt;&gt;&gt;],[]},{riak\_kv\_eleveldb\_backend,stop,1,[{file,"src/riak\_kv\_eleveldb\_backend.erl"},{line,149}]},{riak\_kv\_vnode,terminate,2,[{file,"src/riak\_kv\_vnode.erl"},{line,836}]},{riak\_core\_vnode,terminate,3,[{file,"src/riak\_core\_vnode.erl"},{line,847}]},{gen\_fsm,terminate,7,[{file,"gen\_fsm.erl"},{line,586}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,227}]}]}
2013-08-02 00:09:44 =CRASH REPORT====
 crasher:
 initial call: riak\_core\_vnode:init/1
 pid: &lt;0.2368.0&gt;
 registered\_name: []
 exception exit: 
{{badarg,[{eleveldb,close,[&lt;&lt;&gt;&gt;],[]},{riak\_kv\_eleveldb\_backend,stop,1,[{file,"src/riak\_kv\_eleveldb\_backend.erl"},{line,149}]},{riak\_kv\_vnode,terminate,2,[{file,"src/riak\_kv\_vnode.erl"},{line,836}]},{riak\_core\_vnode,terminate,3,[{file,"src/riak\_core\_vnode.erl"},{line,847}]},{gen\_fsm,terminate,7,[{file,"gen\_fsm.erl"},{line,586}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,227}]}]},[{gen\_fsm,terminate,7,[{file,"gen\_fsm.erl"},{line,589}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,227}]}]}
 ancestors: [riak\_core\_vnode\_sup,riak\_core\_sup,&lt;0.139.0&gt;]
 messages: []
 links: [&lt;0.142.0&gt;]
 dictionary: [{random\_seed,{8115,23258,22987}}]
 trap\_exit: true
 status: running
 heap\_size: 196418
 stack\_size: 24
 reductions: 12124
 neighbours:
2013-08-02 00:09:44 =SUPERVISOR REPORT====
 Supervisor: {local,riak\_core\_vnode\_sup}
 Context: child\_terminated
 Reason: 
{badarg,[{eleveldb,close,[&lt;&lt;&gt;&gt;],[]},{riak\_kv\_eleveldb\_backend,stop,1,[{file,"src/riak\_kv\_eleveldb\_backend.erl"},{line,149}]},{riak\_kv\_vnode,terminate,2,[{file,"src/riak\_kv\_vnode.erl"},{line,836}]},{riak\_core\_vnode,terminate,3,[{file,"src/riak\_core\_vnode.erl"},{line,847}]},{gen\_fsm,terminate,7,[{file,"gen\_fsm.erl"},{line,586}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,227}]}]}
 Offender: 
[{pid,&lt;0.2368.0&gt;},{name,undefined},{mfargs,{riak\_core\_vnode,start\_link,undefined}},{restart\_type,temporary},{shutdown,300000},{child\_type,worker}]

The second one looks like it ran out of heap, I assume I have something miss 
configured here...

===== Fri Aug 2 00:51:28 UTC 2013
Erlang has closed
/home/fanzo/riak/rel/riak/bin/../lib/os\_mon-2.2.9/priv/bin/memsup: Erlang has 
closed.
^M
Crash dump was written to: ./log/erl\_crash.dump^M
eheap\_alloc: Cannot allocate 5568010120 bytes of memory (of type "heap").^M


Paul Ingalls
Founder & CEO Fanzo
p...@fanzo.me
@paulingalls
http://www.linkedin.com/in/paulingalls



On Aug 1, 2013, at 6:28 PM, Paul Ingalls  wrote:

&gt; Couple of questions.
&gt; 
&gt; I have migrated my system to use Riak on the back end. I have setup a 1.4 
&gt; cluster with 128 partitions on 7 nodes with LevelDB as the store. Each node 
&gt; looks like:
&gt; 
&gt; Azure Large instance (4CPU 7GB RAM)
&gt; data directory is on a RAID 0
&gt; max files is set to 128
&gt; async thread on the VM is 16
&gt; everything else is defaults
&gt; 
&gt; I'm using the 1.4.1 java client, connecting via the protocol buffer cluster.
&gt; 
&gt; With this setup, I'm seeing poor throughput on my service load. I ran a test 
&gt; for a bit and was seeing only a few gets/puts per second. And then when I 
&gt; stopped the client two of the nodes crashed.
&gt; 
&gt; I'm very new with Riak, so I figure I'm doing something wrong. I saw a note 
&gt; on the list earlier of someone getting well over 1000 puts per second, so I 
&gt; know it can move pretty fast. 
&gt; 
&gt; What is a good strategy for troubleshooting?
&gt; 
&gt; How many fetch/update/store loops per second should I expect to see on a 
&gt; cluster of this size?
&gt; 
&gt; Thanks!
&gt; 
&gt; Paul
&gt; 
&gt; Paul Ingalls
&gt; Founder & CEO Fanzo
&gt; p...@fanzo.me
&gt; @paulingalls
&gt; http://www.linkedin.com/in/paulingalls
&gt; 
&gt; 
&gt; 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

