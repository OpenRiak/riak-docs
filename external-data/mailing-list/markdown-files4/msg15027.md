---
title: "Re: Memory-backend TTL"
description: ""
project: community
lastmod: 2014-10-14T02:39:54-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg15027"
mailinglist_parent_id: "msg15023"
author_name: "Lucas Grijander"
project_section: "mailinglistitem"
sent_date: 2014-10-14T02:39:54-07:00
---


Hi Luke.

An update about the memory consumption in my 1 server "cluster" after about
10 hours after my last email. Remember, with max\_memory\_per\_vnode = 250MB
and ring\_size=16. Sadly, I had to restart the riak daemon:

# riak-admin diag -d debug
[debug] Local RPC: os:getpid([]) [5000]
[debug] Running shell command: ps -o pmem,rss -p 17521
[debug] Shell command output:
%MEM RSS
93.2 30599792


[debug] Local RPC: riak\_core\_ring\_util:check\_ring([]) [5000]
[debug] Cluster RPC: application:get\_env([riak\_search,enabled]) [5000]
[critical] Riak memory usage is HIGH: 93.2% of available RAM
[info] Riak process is using 93.2% of available RAM, totalling 30599792 KB
of real memory.

# riak-admin status|grep memory
memory\_total : 36546708552
memory\_processes : 410573688
memory\_processes\_used : 405268472
memory\_system : 36136134864
memory\_atom : 561761
memory\_atom\_used : 561285
memory\_binary : 14322847352
memory\_code : 14371292
memory\_ets : 21738236080

# riak-admin vnode-status

VNode: 1370157784997721485815954530671515330927436759040
Backend: riak\_kv\_multi\_backend
Status:
[{&lt;&lt;"one\_minute\_ttl"&gt;&gt;,
 [{mod,riak\_kv\_memory\_backend},
 {data\_table\_status,[{compressed,false},
 {memory,1366727},
 {owner,&lt;8343.9466.104&gt;},
 {heir,none},

 {name,riak\_kv\_1370157784997721485815954530671515330927436759040},
 {size,35042},
 {node,'riak@xxxxxxxxxx'},
 {named\_table,false},
 {type,ordered\_set},
 {keypos,1},
 {protection,protected}]},
 {index\_table\_status,[{compressed,false},
 {memory,89},
 {owner,&lt;8343.9466.104&gt;},
 {heir,none},

{name,riak\_kv\_1370157784997721485815954530671515330927436759040\_i},
 {size,0},
 {node,'riak@xxxxxxxxxxx'},
 {named\_table,false},
 {type,ordered\_set},
 {keypos,1},
 {protection,protected}]},
 {time\_table\_status,[{compressed,false},
 {memory,161493542},
 {owner,&lt;8343.9466.104&gt;},
 {heir,none},

 {name,riak\_kv\_1370157784997721485815954530671515330927436759040\_t},
 {size,5981239},
 {node,'riak@xxxxxxxxxxxx'},
 {named\_table,false},
 {type,ordered\_set},
 {keypos,1},
 {protection,protected}]}]}]

2014-10-14 2:02 GMT+02:00 Lucas Grijander :

&gt; Hi Luke.
&gt;
&gt; I really appreciate your efforts to attempt to reproduce the problem. I
&gt; think that the configs are right. I have been doing also a lot of tests and
&gt; with 1 server/node, the memory bucket works flawlessly, as your test. The
&gt; Riak cluster where we have the problem has a multi\_backend with 1 memory
&gt; backend, 2 bitcask backends and 2 leveldb backends. I have only changed the
&gt; parameter connection of the memory backend in our production code to
&gt; another new "cluster" with only 1 node, with the same config of Riak but
&gt; with only 1 memory backend under the multi configuration and, as I said,
&gt; all fine, the problem vanished. I deduce that the problem appears only with
&gt; more than 1 node and with a lot of requests.
&gt;
&gt; In my tests with the production cluster with the problem ( 4 nodes),
&gt; finally I realized that the TTL is working but, randomly and suddenly, KEYS
&gt; already deleted appear, and KEYS with correct TTL disappear :-? (Maybe
&gt; something related with the some ETS internal table? ) This is the moment
&gt; when I can obtain KEYS already expired.
&gt;
&gt; In summary:
&gt;
&gt; - With cluster with 4 nodes (config below): All OK for a while and
&gt; suddenly we lost the last 20 seconds approx. of keys and OLD keys appear in
&gt; the list: curl -X GET http://localhost:8098/buckets/ttl\_stg/keys?keys=true
&gt;
&gt; buckets.default.last\_write\_wins = true
&gt; bitcask.io\_mode = erlang
&gt; multi\_backend.ttl\_stg.storage\_backend = memory
&gt; multi\_backend.ttl\_stg.memory\_backend.ttl = 90s
&gt; multi\_backend.ttl\_stg.memory\_backend.max\_memory\_per\_vnode = 25MB
&gt; anti\_entropy = passive
&gt; ring\_size = 256
&gt;
&gt; - With 1 node: All OK
&gt;
&gt; buckets.default.n\_val = 1
&gt; buckets.default.last\_write\_wins = true
&gt; buckets.default.r = 1
&gt; buckets.default.w = 1
&gt; multi\_backend. ttl\_stg.storage\_backend = memory
&gt; multi\_backend. ttl\_stg.memory\_backend.ttl = 90s
&gt; multi\_backend. ttl\_stg.memory\_backend.max\_memory\_per\_vnode = 250MB
&gt; ring\_size = 16
&gt;
&gt;
&gt;
&gt; Another note: With this 1 node (32GB RAM) and only activated the memory
&gt; backend I have realized than the memory consumption grows without control:
&gt;
&gt;
&gt; # riak-admin status|grep memory
&gt; memory\_total : 17323130960
&gt; memory\_processes : 235043016
&gt; memory\_processes\_used : 233078456
&gt; memory\_system : 17088087944
&gt; memory\_atom : 561761
&gt; memory\_atom\_used : 561127
&gt; memory\_binary : 6737787976
&gt; memory\_code : 14370908
&gt; memory\_ets : 10295224544
&gt;
&gt; # # riak-admin diag -d debug
&gt; [debug] Local RPC: os:getpid([]) [5000]
&gt; [debug] Running shell command: ps -o pmem,rss -p 17521
&gt; [debug] Shell command output:
&gt; %MEM RSS
&gt; 60.5 19863800
&gt;
&gt; Wow 18.9GB when the max\_memory\_per\_vnode = 250MB. Is far away from the
&gt; value, 250\*16vnodes = 4000MB. Is it that correct?
&gt;
&gt; This is the riak-admin vnode-status of 1 vnode, the other 15 are with
&gt; similar data:
&gt;
&gt; VNode: 1370157784997721485815954530671515330927436759040
&gt; Backend: riak\_kv\_multi\_backend
&gt; Status:
&gt; [{&lt;&lt;"ttl\_stg"&gt;&gt;,
&gt; [{mod,riak\_kv\_memory\_backend},
&gt; {data\_table\_status,[{compressed,false},
&gt; {memory,1156673},
&gt; {owner,&lt;8343.9466.104&gt;},
&gt; {heir,none},
&gt;
&gt; {name,riak\_kv\_1370157784997721485815954530671515330927436759040},
&gt; {size,29656},
&gt; {node,'riak@xxxxxxxx'},
&gt; {named\_table,false},
&gt; {type,ordered\_set},
&gt; {keypos,1},
&gt; {protection,protected}]},
&gt; {index\_table\_status,[{compressed,false},
&gt; {memory,89},
&gt; {owner,&lt;8343.9466.104&gt;},
&gt; {heir,none},
&gt;
&gt; {name,riak\_kv\_1370157784997721485815954530671515330927436759040\_i},
&gt; {size,0},
&gt; {node,'riak@xxxxxxxxx'},
&gt; {named\_table,false},
&gt; {type,ordered\_set},
&gt; {keypos,1},
&gt; {protection,protected}]},
&gt; {time\_table\_status,[{compressed,false},
&gt; {memory,75968936},
&gt; {owner,&lt;8343.9466.104&gt;},
&gt; {heir,none},
&gt;
&gt; {name,riak\_kv\_1370157784997721485815954530671515330927436759040\_t},
&gt; {size,2813661},
&gt; {node,'riak@xxxxxxxxx'},
&gt; {named\_table,false},
&gt; {type,ordered\_set},
&gt; {keypos,1},
&gt; {protection,protected}]}]}]
&gt;
&gt; Thanks!
&gt;
&gt; 2014-10-13 22:30 GMT+02:00 Luke Bakken :
&gt;
&gt;&gt; Hi Lucas,
&gt;&gt;
&gt;&gt; I've tried reproducing this using a local Riak 2.0.1 node, however TTL
&gt;&gt; is working as expected.
&gt;&gt;
&gt;&gt; Here is the configuration I have in /etc/riak/riak.conf:
&gt;&gt;
&gt;&gt; storage\_backend = multi
&gt;&gt; multi\_backend.default = bc\_default
&gt;&gt;
&gt;&gt; multi\_backend.ttl\_stg.storage\_backend = memory
&gt;&gt; multi\_backend.ttl\_stg.memory\_backend.ttl = 90s
&gt;&gt; multi\_backend.ttl\_stg.memory\_backend.max\_memory\_per\_vnode = 4MB
&gt;&gt;
&gt;&gt; multi\_backend.bc\_default.storage\_backend = bitcask
&gt;&gt; multi\_backend.bc\_default.bitcask.data\_root = /var/lib/riak/bc\_default
&gt;&gt; multi\_backend.bc\_default.bitcask.io\_mode = erlang
&gt;&gt;
&gt;&gt; This translates to the following in
&gt;&gt; /var/lib/riak/generated.configs/app.2014.10.13.13.13.29.config:
&gt;&gt;
&gt;&gt; {multi\_backend\_default,&lt;&lt;"bc\_default"&gt;&gt;},
&gt;&gt; {multi\_backend,
&gt;&gt; [{&lt;&lt;"ttl\_stg"&gt;&gt;,riak\_kv\_memory\_backend,[{ttl,90},{max\_memory,4}]},
&gt;&gt; {&lt;&lt;"bc\_default"&gt;&gt;,riak\_kv\_bitcask\_backend,
&gt;&gt; [{io\_mode,erlang},
&gt;&gt; {expiry\_grace\_time,0},
&gt;&gt; {small\_file\_threshold,10485760},
&gt;&gt; {dead\_bytes\_threshold,134217728},
&gt;&gt; {frag\_threshold,40},
&gt;&gt; {dead\_bytes\_merge\_trigger,536870912},
&gt;&gt; {frag\_merge\_trigger,60},
&gt;&gt; {max\_file\_size,2147483648},
&gt;&gt; {open\_timeout,4},
&gt;&gt; {data\_root,"/var/lib/riak/bc\_default"},
&gt;&gt; {sync\_strategy,none},
&gt;&gt; {merge\_window,always},
&gt;&gt; {max\_fold\_age,-1},
&gt;&gt; {max\_fold\_puts,0},
&gt;&gt; {expiry\_secs,-1},
&gt;&gt; {require\_hint\_crc,true}]}]}]},
&gt;&gt;
&gt;&gt; I set the bucket properties to use the ttl\_stg backend:
&gt;&gt;
&gt;&gt; root@UBUNTU-12-1:~# cat ttl\_stg-props.json
&gt;&gt; {"props":{"name":"ttl\_stg","backend":"ttl\_stg"}}
&gt;&gt;
&gt;&gt; root@UBUNTU-12-1:~# curl -XPUT -H'Content-type: application/json'
&gt;&gt; localhost:8098/buckets/ttl\_stg/props --data-ascii @ttl\_stg-props.json
&gt;&gt;
&gt;&gt; root@UBUNTU-12-1:~# curl -XGET localhost:8098/buckets/ttl\_stg/props
&gt;&gt;
&gt;&gt; {"props":{"allow\_mult":false,"backend":"ttl\_stg","basic\_quorum":false,"big\_vclock":50,"chash\_keyfun":{"mod":"riak\_core\_util","fun":"chash\_std\_keyfun"},"dvv\_enabled":false,"dw":"quorum","last\_write\_wins":false,"linkfun":{"mod":"riak\_kv\_wm\_link\_walker","fun":"mapreduce\_linkfun"},"n\_val":3,"name":"ttl\_stg","notfound\_ok":true,"old\_vclock":86400,"postcommit":[],"pr":0,"precommit":[],"pw":0,"r":"quorum","rw":"quorum","small\_vclock":50,"w":"quorum","young\_vclock":20}}
&gt;&gt;
&gt;&gt;
&gt;&gt; And used the following statement to PUT test data:
&gt;&gt;
&gt;&gt; curl -XPUT localhost:8098/buckets/ttl\_stg/keys/1 -d "TEST $(date)"
&gt;&gt;
&gt;&gt; After 90 seconds, this is the response I get from Riak:
&gt;&gt;
&gt;&gt; root@UBUNTU-12-1:~# curl -XGET localhost:8098/buckets/ttl\_stg/keys/1
&gt;&gt; not found
&gt;&gt;
&gt;&gt; I would carefully check all of the app.config / riak.conf files in
&gt;&gt; your cluster, the output of "riak config effective" and the bucket
&gt;&gt; properties for those buckets you expect to be using the memory backend
&gt;&gt; with TTL. I also recommend using the localhost:8098/buckets/ endpoint
&gt;&gt; instead of the deprecated riak/ endpoint.
&gt;&gt;
&gt;&gt; Please let me know if you have additional questions.
&gt;&gt; --
&gt;&gt; Luke Bakken
&gt;&gt; Engineer / CSE
&gt;&gt; lbak...@basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt; On Fri, Oct 3, 2014 at 11:32 AM, Lucas Grijander
&gt;&gt;  wrote:
&gt;&gt; &gt; Hello,
&gt;&gt; &gt;
&gt;&gt; &gt; I have a memory backend in production with Riak 2.0.1, 4 servers and 256
&gt;&gt; &gt; vnodes. The servers have the same date and time.
&gt;&gt; &gt;
&gt;&gt; &gt; I have seen an odd performance with the ttl.
&gt;&gt; &gt;
&gt;&gt; &gt; This is the config:
&gt;&gt; &gt;
&gt;&gt; &gt; {&lt;&lt;"ttl\_stg"&gt;&gt;,riak\_kv\_memory\_backend,
&gt;&gt; &gt; [{ttl,90},{max\_memory,25}]},
&gt;&gt; &gt;
&gt;&gt; &gt; For example, see this GET response in one of the riak servers:
&gt;&gt; &gt;
&gt;&gt; &gt; &lt; HTTP/1.1 200 OK
&gt;&gt; &gt; &lt; X-Riak-Vclock: a85hYGBgzGDKBVIc4otdfgR/7bfIYEpkzGNlKI1efJYvCwA=
&gt;&gt; &gt; &lt; Vary: Accept-Encoding
&gt;&gt; &gt; \* Server MochiWeb/1.1 WebMachine/1.10.5 (jokes are better explained) is
&gt;&gt; not
&gt;&gt; &gt; blacklisted
&gt;&gt; &gt; &lt; Server: MochiWeb/1.1 WebMachine/1.10.5 (jokes are better explained)
&gt;&gt; &gt; &lt; Link: ; rel="up"
&gt;&gt; &gt; &lt; Last-Modified: Fri, 03 Oct 2014 17:40:05 GMT
&gt;&gt; &gt; &lt; ETag: "3c8bGoifWcOCSVn0otD5nI"
&gt;&gt; &gt; &lt; Date: Fri, 03 Oct 2014 17:47:50 GMT
&gt;&gt; &gt; &lt; Content-Type: application/json
&gt;&gt; &gt; &lt; Content-Length: 17
&gt;&gt; &gt;
&gt;&gt; &gt; If the TTL is 90 seconds, Why the GET doesn't return "not found" if the
&gt;&gt; &gt; difference between "Last-Modified" and "Date" (of the curl request) is
&gt;&gt; &gt; greater than the TTL?
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks in advance!
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt;
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

