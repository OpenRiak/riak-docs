---
title: "Re: why leaving riak cluster so slowly and how to accelerate the speed"
description: ""
project: community
lastmod: 2015-08-09T19:21:06-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16390"
mailinglist_parent_id: "msg16378"
author_name: "changmao wang"
project_section: "mailinglistitem"
sent_date: 2015-08-09T19:21:06-07:00
---


Is there any ideas to fix this issue?

Amao

On Fri, Aug 7, 2015 at 6:55 AM, changmao wang 
wrote:

&gt; Dmitri,
&gt;
&gt; Thanks for your quick reply.
&gt; my question are as below:
&gt; 1. what's the current status of the whole cluster? Is't doing data balance?
&gt; 2. there's so many errors during one of the node error log. how to handle
&gt; it?
&gt; 2015-08-05 01:38:59.717 [error]
&gt; &lt;0.23000.298&gt;@riak\_core\_handoff\_sender:start\_fold:262 ownership\_transfer
&gt; transfer of riak\_kv\_vnode from 'riak@10.21.136.81'
&gt; 525227150915793236229449236757414210188850757632 to 'riak@10.21.136.94'
&gt; 525227150915793236229449236757414210188850757632 failed because of enotconn
&gt; 2015-08-05 01:38:59.718 [error]
&gt; &lt;0.195.0&gt;@riak\_core\_handoff\_manager:handle\_info:289 An outbound handoff of
&gt; partition riak\_kv\_vnode 525227150915793236229449236757414210188850757632
&gt; was terminated for reason: {shutdown,{error,enotconn}}
&gt;
&gt; During the last 5 days, there's no changes of the "riak-admin member
&gt; status" output.
&gt; 3. how to accelerate the data balance?
&gt;
&gt;
&gt; On Fri, Aug 7, 2015 at 6:41 AM, Dmitri Zagidulin 
&gt; wrote:
&gt;
&gt;&gt; Ok, I think I understand so far. So what's the question?
&gt;&gt;
&gt;&gt; On Thursday, August 6, 2015, Changmao.Wang 
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Hi Riak users,
&gt;&gt;&gt;
&gt;&gt;&gt; Before adding new nodes, the cluster only have five nodes. The member
&gt;&gt;&gt; list are as below:
&gt;&gt;&gt; 10.21.136.66,10.21.136.71,10.21.136.76,10.21.136.81,10.21.136.86.
&gt;&gt;&gt; We did not setup http proxy for the cluster, only one node of the
&gt;&gt;&gt; cluster provide the http service. so the CPU load is always high on this
&gt;&gt;&gt; node.
&gt;&gt;&gt;
&gt;&gt;&gt; After that, I added four nodes (10.21.136.[91-94]) to those cluster.
&gt;&gt;&gt; During the ring/data balance progress, each node failed(riak stopped)
&gt;&gt;&gt; because of disk 100% full.
&gt;&gt;&gt; I used multi-disk path to "data\_root" parameter in
&gt;&gt;&gt; '/etc/riak/app.config'. Each disk is only 580MB size.
&gt;&gt;&gt; As you know, bitcask storage engine did not support multi-disk path.
&gt;&gt;&gt; After one of the disks is 100% full, it can not switch next idle disk. So
&gt;&gt;&gt; the "riak" service is down.
&gt;&gt;&gt;
&gt;&gt;&gt; After that, I removed the new add four nodes at active nodes with
&gt;&gt;&gt; "riak-admin cluster leave riak@'10.21.136.91'".
&gt;&gt;&gt; and then stop "riak" service on other active new nodes, reformat the
&gt;&gt;&gt; above new nodes with LVM disk management (bind 6 disk with virtual disk
&gt;&gt;&gt; group).
&gt;&gt;&gt; Replace the "data-root" parameter with one folder, and then start "riak"
&gt;&gt;&gt; service again. After that, the cluster began the data balance again.
&gt;&gt;&gt; That's the whole story.
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Amao
&gt;&gt;&gt;
&gt;&gt;&gt; ------------------------------
&gt;&gt;&gt; \*From: \*"Dmitri Zagidulin" 
&gt;&gt;&gt; \*To: \*"Changmao.Wang" 
&gt;&gt;&gt; \*Sent: \*Thursday, August 6, 2015 10:46:59 PM
&gt;&gt;&gt; \*Subject: \*Re: why leaving riak cluster so slowly and how to accelerate
&gt;&gt;&gt; the speed
&gt;&gt;&gt;
&gt;&gt;&gt; Hi Amao,
&gt;&gt;&gt;
&gt;&gt;&gt; Can you explain a bit more which steps you've taken, and what the
&gt;&gt;&gt; problem is?
&gt;&gt;&gt;
&gt;&gt;&gt; Which nodes have been added, and which nodes are leaving the cluster?
&gt;&gt;&gt;
&gt;&gt;&gt; On Tue, Jul 28, 2015 at 11:03 PM, Changmao.Wang &lt;
&gt;&gt;&gt; changmao.w...@datayes.com&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Hi Raik user group,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I'm using riak and riak-cs 1.4.2. Last weekend, I added four nodes to
&gt;&gt;&gt;&gt; cluster with 5 nodes. However, it's failed with one of disks 100% full.
&gt;&gt;&gt;&gt; As you know bitcask storage engine can not support multifolders.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; After that, I restarted the "riak" and leave the cluster with the
&gt;&gt;&gt;&gt; command "riak-admin cluster leave" and "riak-admin cluster plan", and the
&gt;&gt;&gt;&gt; commit.
&gt;&gt;&gt;&gt; However, riak is always doing KV balance after my submit leaving
&gt;&gt;&gt;&gt; command. I guess that it's doing join cluster progress.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Could you show us how to accelerate the leaving progress? I have tuned
&gt;&gt;&gt;&gt; the "transfer-limit" parameters on 9 nodes.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; below is some commands output:
&gt;&gt;&gt;&gt; riak-admin member-status
&gt;&gt;&gt;&gt; ================================= Membership
&gt;&gt;&gt;&gt; ==================================
&gt;&gt;&gt;&gt; Status Ring Pending Node
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt;&gt; leaving 6.3% 10.9% 'riak@10.21.136.91'
&gt;&gt;&gt;&gt; leaving 9.4% 10.9% 'riak@10.21.136.92'
&gt;&gt;&gt;&gt; leaving 6.3% 10.9% 'riak@10.21.136.93'
&gt;&gt;&gt;&gt; leaving 6.3% 10.9% 'riak@10.21.136.94'
&gt;&gt;&gt;&gt; valid 10.9% 10.9% 'riak@10.21.136.66'
&gt;&gt;&gt;&gt; valid 12.5% 10.9% 'riak@10.21.136.71'
&gt;&gt;&gt;&gt; valid 18.8% 10.9% 'riak@10.21.136.76'
&gt;&gt;&gt;&gt; valid 18.8% 12.5% 'riak@10.21.136.81'
&gt;&gt;&gt;&gt; valid 10.9% 10.9% 'riak@10.21.136.86'
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; riak-admin transfer\_limit
&gt;&gt;&gt;&gt; =============================== Transfer Limit
&gt;&gt;&gt;&gt; ================================
&gt;&gt;&gt;&gt; Limit Node
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt;&gt; 200 'riak@10.21.136.66'
&gt;&gt;&gt;&gt; 200 'riak@10.21.136.71'
&gt;&gt;&gt;&gt; 100 'riak@10.21.136.76'
&gt;&gt;&gt;&gt; 100 'riak@10.21.136.81'
&gt;&gt;&gt;&gt; 200 'riak@10.21.136.86'
&gt;&gt;&gt;&gt; 500 'riak@10.21.136.91'
&gt;&gt;&gt;&gt; 500 'riak@10.21.136.92'
&gt;&gt;&gt;&gt; 500 'riak@10.21.136.93'
&gt;&gt;&gt;&gt; 500 'riak@10.21.136.94'
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Any more details for your diagnosing the problem?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Amao
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; --
&gt; Amao Wang
&gt; Best & Regards
&gt;



-- 
Amao Wang
Best & Regards
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

