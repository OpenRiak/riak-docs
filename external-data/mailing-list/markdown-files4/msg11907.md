---
title: "Re: erlang go boom"
description: ""
project: community
lastmod: 2013-08-05T21:52:13-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11907"
mailinglist_parent_id: "msg11906"
author_name: "Paul Ingalls"
project_section: "mailinglistitem"
sent_date: 2013-08-05T21:52:13-07:00
---


I'm currently using the java client and its ConflictResolver and Mutator 
interfaces. In some cases I am just doing a store, and letting the client do 
an implicit fetch and the mutator to make the actual change. In other cases 
I'm doing an explicit fetch, modify the result, and then a store without fetch. 
 For both, I am using a ConflictResolver and I have added a field for the 
vclock and used the annotation in my beans.

I'll try pointing a local client at the cluster to see if I can see how many 
siblings there are. That is, if I can get the cluster running again...:)

Paul

Paul Ingalls
Founder & CEO Fanzo
p...@fanzo.me
@paulingalls
http://www.linkedin.com/in/paulingalls

On Aug 5, 2013, at 9:36 PM, Jeremy Ong  wrote:

&gt; On the client you could extract the value\_count of the objects you
&gt; read and just log them. Feel free to post code too, in particular, how
&gt; you are writing out updated values.
&gt; 
&gt; On Mon, Aug 5, 2013 at 9:20 PM, Paul Ingalls  wrote:
&gt;&gt; Interesting. I have sibling resolution code on the client side. Would
&gt;&gt; sibling explosion take out the entire cluster all at once? Within 5 minutes
&gt;&gt; of my last email, the rest of the cluster died.
&gt;&gt; 
&gt;&gt; Is there a way to quickly figure out whether the cluster is full of
&gt;&gt; siblings?
&gt;&gt; 
&gt;&gt; Paul Ingalls
&gt;&gt; Founder & CEO Fanzo
&gt;&gt; p...@fanzo.me
&gt;&gt; @paulingalls
&gt;&gt; http://www.linkedin.com/in/paulingalls
&gt;&gt; 
&gt;&gt; On Aug 5, 2013, at 8:07 PM, Evan Vigil-McClanahan 
&gt;&gt; wrote:
&gt;&gt; 
&gt;&gt; Given your leveldb settings, I think that compaction is an unlikely
&gt;&gt; culprit. But check this out:
&gt;&gt; 
&gt;&gt; 2013-08-05 18:01:15.878 [info] &lt;0.83.0&gt;@riak\_core\_sysmon\_
&gt;&gt; handler:handle\_event:92 monitor large\_heap &lt;0.14832.557&gt;
&gt;&gt; [{initial\_call,{riak\_kv\_get\_fsm,init,1}},{almost\_current\_function,{riak\_object,encode\_maybe\_binary,1}},{message\_queue\_len,1}]
&gt;&gt; [{old\_heap\_block\_size,0},{heap\_block\_size,116769640},{mbuf\_size,0},{stack\_size,52},{old\_heap\_size,0},{heap\_size,81956791}]
&gt;&gt; 
&gt;&gt; That's a 78MB heap in encode object... Unless your objects are big, I
&gt;&gt; would suspect sibling explosion caused by rapid updates at w = 1.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

