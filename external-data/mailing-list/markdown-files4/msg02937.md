---
title: "Re: Store() Performance"
description: ""
project: community
lastmod: 2011-04-08T09:23:43-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg02937"
mailinglist_parent_id: "msg02936"
author_name: "Gui Pinto"
project_section: "mailinglistitem"
sent_date: 2011-04-08T09:23:43-07:00
---


Hey Everyone, thanks for all of the recommendations.

I've tried importing using the example load\_data
scriptavailable
on the Fast Track, and have last tried the PHP library.

Both of these execute a straight-foward CURL -X PUT request.. which makes me
think Mark might have just guessed it..
Keep-alive not being used definitely explains the 200-writes/second cap.

I'm going to take a look into the PHP library and test this theory.

Gui Pinto
Software Engineer at Chitika


On Fri, Apr 8, 2011 at 10:01 AM, Mark Steele wrote:

&gt; If using HTTP, make sure you're using keep-alives. That will be a gigantic
&gt; speed boost.
&gt;
&gt; The protocol buffer API is much faster if you're client language supports
&gt; it.
&gt;
&gt;
&gt; Mark Steele
&gt; Bering Media Inc.
&gt;
&gt;
&gt;
&gt; On Thu, Apr 7, 2011 at 10:58 PM, matthew hawthorne 
&gt; wrote:
&gt;
&gt;&gt; Hi Gui,
&gt;&gt;
&gt;&gt; I recently pushed 70 million records of size 1K each into a 5-node
&gt;&gt; Riak cluster (which was replicating to another 5-node cluster) at
&gt;&gt; around 1000 writes/second using basho\_bench and the REST interface. I
&gt;&gt; probably could have pushed it further, but I wanted to confirm that it
&gt;&gt; could maintain the load for the entire data set, which it did.
&gt;&gt;
&gt;&gt; My point being that your speed-limit of 200 writes/second is likely
&gt;&gt; specific to your configuration.
&gt;&gt;
&gt;&gt; I wonder:
&gt;&gt; 1) what's your average write latency?
&gt;&gt; 2) how big is your connection pool?
&gt;&gt;
&gt;&gt; Because it's possible that you don't have enough connections available
&gt;&gt; to handle your desired load.
&gt;&gt;
&gt;&gt; -matt
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Apr 7, 2011 at 6:01 PM, Gui Pinto  wrote:
&gt;&gt; &gt; Hey guys,
&gt;&gt; &gt; I'm attempting to importing 300M+ objects into a Riak cluster, but have
&gt;&gt; &gt; quickly reached the REST API's speed-limit at 200-store()'s per second..
&gt;&gt; &gt; At the rate of 200/s, I'm looking at 20-days to import this data set!
&gt;&gt; That
&gt;&gt; &gt; can't be the fastest method to do this..
&gt;&gt; &gt;
&gt;&gt; &gt; Any recommendations?
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks!
&gt;&gt; &gt; Gui Pinto
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

