---
title: "Re: No more disk space on a node of my Riak cluster"
description: ""
project: community
lastmod: 2013-03-20T11:44:19-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10500"
mailinglist_parent_id: "msg10415"
author_name: "Godefroy de Compreignac"
project_section: "mailinglistitem"
sent_date: 2013-03-20T11:44:19-07:00
---


Any news? I still have the same problem, same data repartition...


2013/3/13 Godefroy de Compreignac 

&gt; I'm running Riak 1.2.1
&gt; I installed it with riak\_1.2.1-1\_amd64.deb
&gt;
&gt; Godefroy
&gt;
&gt;
&gt; 2013/3/13 Tom Santero 
&gt;
&gt;&gt; Godefroy,
&gt;&gt;
&gt;&gt; Which version of Riak are you running?
&gt;&gt;
&gt;&gt; Tom
&gt;&gt;
&gt;&gt;
&gt;&gt; On Wed, Mar 13, 2013 at 5:51 AM, Godefroy de Compreignac &lt;
&gt;&gt; godef...@eklablog.com&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Hi Mark,
&gt;&gt;&gt;
&gt;&gt;&gt; Thanks for your email.
&gt;&gt;&gt; The rebalancing doesn't seem to be working really good...
&gt;&gt;&gt; I still have approximately the same repartition as last week :
&gt;&gt;&gt;
&gt;&gt;&gt; # riak-admin member-status
&gt;&gt;&gt; Attempting to restart script through sudo -H -u riak
&gt;&gt;&gt; ================================= Membership
&gt;&gt;&gt; ==================================
&gt;&gt;&gt; Status Ring Pending Node
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt; valid 18.0% 25.0% 'riak@5.135.137.208'
&gt;&gt;&gt; valid 0.0% 0.0% 'riak@5.135.138.98'
&gt;&gt;&gt; valid 18.8% 25.0% 'riak@5.39.68.152'
&gt;&gt;&gt; valid 29.7% 25.0% 'riak@5.39.74.55'
&gt;&gt;&gt; valid 33.6% 25.0% 'riak@5.39.74.57'
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt; Valid:5 / Leaving:0 / Exiting:0 / Joining:0 / Down:0
&gt;&gt;&gt;
&gt;&gt;&gt; (the second node is waiting for the end of the rebalancing to join the
&gt;&gt;&gt; cluster and to begin a second rebalancing)
&gt;&gt;&gt; My servers are in the public network of OVH. No Vlan, but good iptables
&gt;&gt;&gt; rules. 1 Gbps network interface.
&gt;&gt;&gt;
&gt;&gt;&gt; If it can be useful:
&gt;&gt;&gt;
&gt;&gt;&gt; # riak-admin ring-status
&gt;&gt;&gt; Attempting to restart script through sudo -H -u riak
&gt;&gt;&gt; ================================== Claimant
&gt;&gt;&gt; ===================================
&gt;&gt;&gt; Claimant: 'riak@5.39.74.57'
&gt;&gt;&gt; Status: up
&gt;&gt;&gt; Ring Ready: true
&gt;&gt;&gt;
&gt;&gt;&gt; ============================== Ownership Handoff
&gt;&gt;&gt; ==============================
&gt;&gt;&gt; Owner: riak@5.39.68.152
&gt;&gt;&gt; Next Owner: riak@5.39.74.55
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 662242929415565384811044689824565743281594433536
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 799258707915337533392640142891717276374338109440
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 844930634081928249586505293914101120738586001408
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 890602560248518965780370444936484965102833893376
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt; Owner: riak@5.39.74.55
&gt;&gt;&gt; Next Owner: riak@5.135.137.208
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1004782375664995756265033322492444576013453623296
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1050454301831586472458898473514828420377701515264
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1096126227998177188652763624537212264741949407232
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1141798154164767904846628775559596109106197299200
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1187470080331358621040493926581979953470445191168
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1233142006497949337234359077604363797834693083136
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1278813932664540053428224228626747642198940975104
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1324485858831130769622089379649131486563188867072
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1415829711164312202009819681693899175291684651008
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt; Owner: riak@5.39.74.55
&gt;&gt;&gt; Next Owner: riak@5.39.68.152
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 924856504873462002925769308203272848376019812352
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 970528431040052719119634459225656692740267704320
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1016200357206643435313499610248040537104515596288
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1061872283373234151507364761270424381468763488256
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1107544209539824867701229912292808225833011380224
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1153216135706415583895095063315192070197259272192
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1198888061873006300088960214337575914561507164160
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1244559988039597016282825365359959758925755056128
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1290231914206187732476690516382343603290002948096
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1335903840372778448670555667404727447654250840064
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1381575766539369164864420818427111292018498732032
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1427247692705959881058285969449495136382746624000
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt; Owner: riak@5.39.74.57
&gt;&gt;&gt; Next Owner: riak@5.39.74.55
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 936274486415109681974235595958868809467081785344
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 981946412581700398168100746981252653831329677312
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1027618338748291114361965898003636498195577569280
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1073290264914881830555831049026020342559825461248
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1118962191081472546749696200048404186924073353216
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1210306043414653979137426502093171875652569137152
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1255977969581244695331291653115555720016817029120
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1301649895747835411525156804137939564381064921088
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1347321821914426127719021955160323408745312813056
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1392993748081016843912887106182707253109560705024
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt; Index: 1438665674247607560106752257205091097473808596992
&gt;&gt;&gt; Waiting on: [riak\_kv\_vnode]
&gt;&gt;&gt; Complete: [riak\_pipe\_vnode]
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; -------------------------------------------------------------------------------
&gt;&gt;&gt;
&gt;&gt;&gt; ============================== Unreachable Nodes
&gt;&gt;&gt; ==============================
&gt;&gt;&gt; All nodes are up and reachable
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Godefroy
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; 2013/3/13 Mark Phillips 
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Hi Godefroy,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Good to hear you managed to get the node running again. How is the
&gt;&gt;&gt;&gt; rebalancing going? Also, what's the network setup for the cluster?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Mark
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; On Fri, Mar 8, 2013 at 4:24 AM, Godefroy de Compreignac
&gt;&gt;&gt;&gt;  wrote:
&gt;&gt;&gt;&gt; &gt; Hi Mark,
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; Thanks for your answer.
&gt;&gt;&gt;&gt; &gt; To have the node running back, I moved a 39GB bitcask dir to another
&gt;&gt;&gt;&gt; disk
&gt;&gt;&gt;&gt; &gt; and made a symlink (ln -s). Rebalancing seems to be running, but
&gt;&gt;&gt;&gt; &gt; inequalities in data repartition stay huge and the node I added
&gt;&gt;&gt;&gt; yesterday
&gt;&gt;&gt;&gt; &gt; still has 0% of cluster data.
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; Godefroy
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; 2013/3/7 Mark Phillips 
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; Salut Godefroy
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; On Thu, Mar 7, 2013 at 6:50 AM, Godefroy de Compreignac
&gt;&gt;&gt;&gt; &gt;&gt;  wrote:
&gt;&gt;&gt;&gt; &gt;&gt; &gt; Hello,
&gt;&gt;&gt;&gt; &gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;&gt; &gt; I'm running a cluster of 4 nodes (1,8 TB on each) and I have a
&gt;&gt;&gt;&gt; problem
&gt;&gt;&gt;&gt; &gt;&gt; &gt; of
&gt;&gt;&gt;&gt; &gt;&gt; &gt; balancing. Current data repartition is 18%, 19%, 30%, 34%. The
&gt;&gt;&gt;&gt; node with
&gt;&gt;&gt;&gt; &gt;&gt; &gt; 34%
&gt;&gt;&gt;&gt; &gt;&gt; &gt; of cluster data is completely full and doesn't want to start
&gt;&gt;&gt;&gt; anymoe.
&gt;&gt;&gt;&gt; &gt;&gt; &gt; I don't know what to do. Do you have a solution for such a problem?
&gt;&gt;&gt;&gt; &gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; It looks like you need to increase storage capacity for the entire
&gt;&gt;&gt;&gt; &gt;&gt; cluster so you can move some data off of the full node. Do you have
&gt;&gt;&gt;&gt; &gt;&gt; the ability to another machine (or two) to the cluster?
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; The issue, of course, is that you'll need to get that Riak node
&gt;&gt;&gt;&gt; &gt;&gt; running before it can hand off a subset of its data to a new member.
&gt;&gt;&gt;&gt; I
&gt;&gt;&gt;&gt; &gt;&gt; assume the disk being full is the primary reason its failing to
&gt;&gt;&gt;&gt; start?
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; Mark
&gt;&gt;&gt;&gt; &gt;&gt;
&gt;&gt;&gt;&gt; &gt;&gt; &gt; Thank you in advance!
&gt;&gt;&gt;&gt; &gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;&gt; &gt; Godefroy
&gt;&gt;&gt;&gt; &gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt; &gt;&gt; &gt; riak-users mailing list
&gt;&gt;&gt;&gt; &gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; &gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt; &gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

