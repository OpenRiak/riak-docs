---
title: "Re: memory consumption"
description: ""
project: community
lastmod: 2013-08-07T08:18:43-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11932"
mailinglist_parent_id: "msg11913"
author_name: "Alexander Ilyin"
project_section: "mailinglistitem"
sent_date: 2013-08-07T08:18:43-07:00
---


Ok, thank you! Looking forward to the next release.

On 6 August 2013 17:32, Evan Vigil-McClanahan  wrote:

&gt; 11 + 4 + 16, so 31.
&gt;
&gt; 18 bytes there are the actual data, so that can't go away. Since the
&gt; allocation sized are going to be word aligned, the least overhead
&gt; there is going to be word aligning the entire structure, i.e. where
&gt; (key\_len + bucket\_len + 2 + 18) % 8 == 0, but that sort of
&gt; optimization only works with fixed length keys.
&gt;
&gt; Khash overheads are expected to be small-ish, but are
&gt; under-researched, at least by me. I suspect most of the overhead is
&gt; coming from the allocator. So moving to tcmalloc is a possible win
&gt; there, because it does a better job keeping amortized per-allocation
&gt; overheads low for small allocations than libc's malloc, but of course
&gt; with the caveats mentioned in my last email (tl;dr test
&gt; \*exhaustively\*, because we don't and likely won't).
&gt;
&gt; Another possible improvement would be to move to a fixed-length
&gt; structure (that points to an allocated location for oversized
&gt; key-bucket binaries, but that has a very bad pathological case where
&gt; someone selects all keys larger than your fixed size, where you have
&gt; the fixed len - 8 as an additional overhead.
&gt;
&gt; On Tue, Aug 6, 2013 at 2:56 AM, Alexander Ilyin 
&gt; wrote:
&gt; &gt; So if you will succeed with all your patches the memory overhead will
&gt; &gt; decrease by 22 (=16+4+2) bytes, am I right?
&gt; &gt;
&gt; &gt;
&gt; &gt; On 5 August 2013 16:38, Evan Vigil-McClanahan 
&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Before I'd done the research, I too thought that the overheads were a
&gt; &gt;&gt; much lower, near to what the calculator said, but not too far off.
&gt; &gt;&gt;
&gt; &gt;&gt; There are a few things that I plan on addressing this release cycle:
&gt; &gt;&gt; - 16b per-allocation overhead from using enif\_alloc. This allows us
&gt; &gt;&gt; a lot of flexibility about which allocator to use, but I suspect that
&gt; &gt;&gt; since allocation speed isn't a big bitcask bottleneck, this overhead
&gt; &gt;&gt; simply isn't worth it.
&gt; &gt;&gt; - 13b per value overhead from naive serialization of the bucket/key
&gt; &gt;&gt; value. I have a branch that reduced this by 11 bytes.
&gt; &gt;&gt; - 4b per value overhead from a single bit flag that is stored in an
&gt; &gt;&gt; int. No patch for this thus far.
&gt; &gt;&gt;
&gt; &gt;&gt; Additionally, I've found that running with tcmalloc using LD\_PRELOAD
&gt; &gt;&gt; reduces the cost for bitcask's many allocations, but a) I've never
&gt; &gt;&gt; done so in production and b) they say that it never releases memory,
&gt; &gt;&gt; which is worrying, although the paging system theoretically should
&gt; &gt;&gt; take care of it fairly easily as long as their page usages isn't
&gt; &gt;&gt; insane.
&gt; &gt;&gt;
&gt; &gt;&gt; My original notes looked like this:
&gt; &gt;&gt;
&gt; &gt;&gt; 1) ~32 bytes for the OS/malloc + khash overhead @ 50M keys
&gt; &gt;&gt; (amortized, so bigger for fewer keys, smaller for more keys).
&gt; &gt;&gt; 2) + 16 bytes of erlang allocator overhead
&gt; &gt;&gt; 3) + 22 bytes for the NIF C structure
&gt; &gt;&gt; 4) + 8 bytes for the entry pointer stored in the khash
&gt; &gt;&gt; 5) + 13 bytes of kv overhead
&gt; &gt;&gt;
&gt; &gt;&gt; tcmalloc does what it can for line 1.
&gt; &gt;&gt; My patches do what I can for lines 2, 3, and 5.
&gt; &gt;&gt;
&gt; &gt;&gt; 4 isn't amenable to anything other than a change in the way the keydir
&gt; &gt;&gt; is stored, which could also potentially help with 1 (fewer
&gt; &gt;&gt; allocations, etc). That, unfortunately, is not very likely to happen
&gt; &gt;&gt; soon.
&gt; &gt;&gt;
&gt; &gt;&gt; So things will get better relatively soon, but there are some
&gt; &gt;&gt; architectural limits that will be harder to address.
&gt; &gt;&gt;
&gt; &gt;&gt; On Mon, Aug 5, 2013 at 1:49 AM, Alexander Ilyin 
&gt; &gt;&gt; wrote:
&gt; &gt;&gt; &gt; Evan,
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; News about per key overhead of 91 bytes are quite frustrating. When we
&gt; &gt;&gt; &gt; were
&gt; &gt;&gt; &gt; choosing a key value storage per key metadata size was a crucial point
&gt; &gt;&gt; &gt; for
&gt; &gt;&gt; &gt; us. We have a simple use case but a lot of data (hundreds of millions
&gt; of
&gt; &gt;&gt; &gt; items) so we were looking for the ways to reduce memory consumption.
&gt; &gt;&gt; &gt; Here and here is stated a value of 40 bytes. 22 bytes in ram
&gt; calculator
&gt; &gt;&gt; &gt; seemed like a mistake because the following example obviously uses a
&gt; &gt;&gt; &gt; value
&gt; &gt;&gt; &gt; of 40.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; Anyway, thanks for your response.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; On 4 August 2013 04:39, Evan Vigil-McClanahan 
&gt; &gt;&gt; &gt; wrote:
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; Some responses inline.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; On Fri, Aug 2, 2013 at 3:11 AM, Alexander Ilyin &lt;
&gt; alexan...@rutarget.ru&gt;
&gt; &gt;&gt; &gt;&gt; wrote:
&gt; &gt;&gt; &gt;&gt; &gt; Hi,
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; I have a few questions about Riak memory usage.
&gt; &gt;&gt; &gt;&gt; &gt; We're using Riak 1.3.1 on a 3 node cluster. According to bitcask
&gt; &gt;&gt; &gt;&gt; &gt; capacity
&gt; &gt;&gt; &gt;&gt; &gt; calculator
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; (
&gt; http://docs.basho.com/riak/1.3.1/references/appendices/Bitcask-Capacity-Planning/
&gt; )
&gt; &gt;&gt; &gt;&gt; &gt; Riak should use about 30Gb of RAM for out data. Actually, it uses
&gt; &gt;&gt; &gt;&gt; &gt; about
&gt; &gt;&gt; &gt;&gt; &gt; 45Gb
&gt; &gt;&gt; &gt;&gt; &gt; and I can't figure out why. I'm looking at %MEM column in top on
&gt; each
&gt; &gt;&gt; &gt;&gt; &gt; node
&gt; &gt;&gt; &gt;&gt; &gt; for a beam.smp process.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; I've recently done some research on this and have filed bugs against
&gt; &gt;&gt; &gt;&gt; the calculator, it's a bit wrong and has been that way for a while:
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; https://github.com/basho/basho\_docs/issues/467
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; The numbers there look a bit closer to what you're seeing.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; The good news is that I am looking into reducing memory consumption
&gt; &gt;&gt; &gt;&gt; this development cycle and our next release should see some
&gt; &gt;&gt; &gt;&gt; improvements on that front. The bad news is that it may be a while.
&gt; &gt;&gt; &gt;&gt; If you want to watch the bitcask repo on github to see when these
&gt; &gt;&gt; &gt;&gt; changes go in, it's usually pretty easy to build a new bitcask and
&gt; &gt;&gt; &gt;&gt; replace the one that you're running.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; &gt; Disk usage is also about 1,5 times more than I have expected (270Gb
&gt; &gt;&gt; &gt;&gt; &gt; instead
&gt; &gt;&gt; &gt;&gt; &gt; of 180Gb). I rechecked that I have n\_val=2 (not 3), it seems
&gt; alright.
&gt; &gt;&gt; &gt;&gt; &gt; Why
&gt; &gt;&gt; &gt;&gt; &gt; this could happen?
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; There is definitely some overhead on the stored values, especially
&gt; &gt;&gt; &gt;&gt; when you're using bitcask. How big are your values? Overheads, if I
&gt; &gt;&gt; &gt;&gt; recall correctly, run to a few hundred bytes, but I'll have to ask
&gt; &gt;&gt; &gt;&gt; some people to refresh my memory.
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; &gt; Second question is about performance degradation when Riak uses
&gt; &gt;&gt; &gt;&gt; &gt; almost
&gt; &gt;&gt; &gt;&gt; &gt; all
&gt; &gt;&gt; &gt;&gt; &gt; available memory on the node. We see that 95/99 put percentiles
&gt; twice
&gt; &gt;&gt; &gt;&gt; &gt; as
&gt; &gt;&gt; &gt;&gt; &gt; large for nodes which don't have much free RAM. How much free
&gt; memory
&gt; &gt;&gt; &gt;&gt; &gt; I
&gt; &gt;&gt; &gt;&gt; &gt; should have to keep performance high?
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; I don't have a good answer for this; when I was working as a CSE we
&gt; &gt;&gt; &gt;&gt; generally urged people to start adding nodes when their most limited
&gt; &gt;&gt; &gt;&gt; resource (memory, disk, cpu, etc) was 70-80% utilized (as a grossly
&gt; &gt;&gt; &gt;&gt; oversimplified rule of thumb).
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; &gt; And the last question about memory\_total metric. riak-admin status
&gt; &gt;&gt; &gt;&gt; &gt; returns
&gt; &gt;&gt; &gt;&gt; &gt; value which is less than actual memory consumption as seen in the
&gt; &gt;&gt; &gt;&gt; &gt; top.
&gt; &gt;&gt; &gt;&gt; &gt; According to memory\_total description
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;&gt; &gt; (
&gt; http://docs.basho.com/riak/1.3.1/references/appendices/Inspecting-a-Node/)
&gt; &gt;&gt; &gt;&gt; &gt; they should be equal. Why they are not?
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; Top factors in OS/libc overheads that memory\_total cannot see. I'll
&gt; &gt;&gt; &gt;&gt; check out the docs and get them amended if they're wrong.
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

