---
title: "Re: Handoff stalled on 1.0.2 riak cluster"
description: ""
project: community
lastmod: 2012-06-03T19:43:48-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07599"
mailinglist_parent_id: "msg07598"
author_name: "Mark Phillips"
project_section: "mailinglistitem"
sent_date: 2012-06-03T19:43:48-07:00
---


Hi John,

Assuming things aren't back to normal... A few things:

Attach to any running node and run this:

rpc:multicall([node() | nodes()], riak\_core\_vnode\_manager, force\_handoffs, []).

This will attempt to force handoff. If this restarts handoff, you've
got new issue that we'll need to track down. Please report back if
this gets handoffs running again .

Another possible fix:

Take a look at https://github.com/basho/riak\_core/pull/153

This was fixed on 1.1, but it might be what's hitting you (though,
admittedly, your issue does seem like a perfect match for the issue
from the 1.0.2 release notes).

If this is what's ailing you, there's a work-around here:
https://github.com/basho/riak\_core/pull/153#issuecomment-4527706

If neither of these work, let us know and we'll take a deeper look.
Specifically:

a) any log files you could send along would be helpful
b) the output of the following diagnostic:

f(Members).
Members = riak\_core\_ring:all\_members(element(2,
riak\_core\_ring\_manager:get\_raw\_ring())).
[{N, rpc:call(N, riak\_core\_handoff\_manager, status, [])} || N &lt;- Members].

Thanks, John.

Mark



On Sun, Jun 3, 2012 at 5:06 AM, John Axel Eriksson  wrote:

&gt; Hi.
&gt;
&gt; We had an issue where one of the riak servers died (had to be force
&gt; removed from cluster). After we did that things got really bad and most
&gt; data was unreachable for hours. I added a new node to replace the old one
&gt; at one point as well - that never got any data and even now about a day
&gt; later it hasn't gotten any data.
&gt; What seems to be the issue now is that there are a few nodes are waiting
&gt; on handoff of 1 partition. When I look at ring\_status I see this:
&gt;
&gt; Attempting to restart script through sudo -u riak
&gt; ================================== Claimant
&gt; ===================================
&gt; Claimant: 'riak@r-001.x.x.x
&gt; Status: up
&gt; Ring Ready: true
&gt;
&gt; ============================== Ownership Handoff
&gt; ==============================
&gt; Owner: riak@r-004.x.x.x
&gt; Next Owner: riak@r-003.x.x.x
&gt;
&gt; Index: 930565495644285842450002452081070828921550798848
&gt; Waiting on: []
&gt; Complete: [riak\_kv\_vnode,riak\_pipe\_vnode,riak\_search\_vnode]
&gt;
&gt;
&gt; -------------------------------------------------------------------------------
&gt;
&gt; ============================== Unreachable Nodes
&gt; ==============================
&gt; All nodes are up and reachable
&gt;
&gt;
&gt; Ok, so it looks like the problem described in the Release Notes for 1.0.2
&gt; here https://github.com/basho/riak/blob/1.0.2-release/RELEASE-NOTES.org.
&gt; Unfortunately I've run that code (through riak attach) with no result.
&gt;
&gt; It's been in this state for 12 hours now I think. What can we do to fix
&gt; our cluster?
&gt;
&gt; I upgraded to 1.0.3 hoping it would fix our problems but that didn't help.
&gt; I cannot upgrade to 1.1.x because we mainly use Luwak for large object
&gt; support
&gt; and that's discontinued in 1.1.x as far as I know.
&gt;
&gt; Thanks for your help,
&gt; John
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

