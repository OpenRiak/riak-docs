---
title: "Performance Issues with LevelDB Backend on 1.0.0RC1"
description: ""
project: community
lastmod: 2011-09-26T11:17:58-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04878"
author_name: "Patrick Van Stee"
project_section: "mailinglistitem"
sent_date: 2011-09-26T11:17:58-07:00
---


We're running a small, 2 node riak cluster (on 2 m1.large boxes) using the 
LevelDB backend and have been trying to write ~250 keys a second at it. With a 
small dataset everything was running smoothly. However, after storing several 
hundred thousand keys some performance issues started to show up. 

\* We're running out of file descriptors which is causing nodes to crash with 
the following error:

2011-09-24 00:23:52.097 [error] &lt;0.110.0&gt; CRASH REPORT Process [] with 0 
neighbours crashed with reason: {error,accept\_failed}
2011-09-24 00:23:52.098 [error] &lt;0.121.0&gt; application: mochiweb, "Accept failed 
error", "{error,emfile}

Setting the max\_open\_files limit in the app.config doesn't seem to help.

\* Writes have slowed down by an order of magnitude. I even set the n\_val, w, 
and dw bucket properties to 1 without any noticeable difference. Also we 
switched to using protocol buffers to make sure there wasn't any extra overhead 
when using HTTP.

\* Running map reduce jobs that use a range query on a secondary index started 
returning an error, {"error":"map\_reduce\_error"}, once our dataset increased in 
size. Feeding a list of keys works fine, but querying the index for keys seems 
to be timing out:

2011-09-26 16:37:57.192 [error] &lt;0.136.0&gt; Supervisor riak\_pipe\_fitting\_sup had 
child undefined started with {riak\_pipe\_fitting,start\_link,undefined} at 
&lt;0.3497.0&gt; exit with reason 
{timeout,{gen\_server,call,[{riak\_pipe\_vnode\_master,'riak@10.206.105.52'},{return\_vnode,{'riak\_vnode\_req\_v1',502391187832497878132516661246222288006726811648,{raw,#Ref&lt;0.0.1.88700&gt;,&lt;0.3500.0&gt;},{cmd\_enqueue,{fitting,&lt;0.3499.0&gt;,#Ref&lt;0.0.1.88700&gt;,#Fun,#Fun},{&lt;&lt;"ip\_queries"&gt;&gt;,&lt;&lt;"uaukXZn5rZQ0LrSED3pi-fE-JjU"&gt;&gt;},infinity,[{502391187832497878132516661246222288006726811648,'riak@10.206.105.52'}]}}}]}}
 in context child\_terminated

Is anyone familiar with these problems or is there anything else I can try to 
increase the performance when using LevelDB?
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

