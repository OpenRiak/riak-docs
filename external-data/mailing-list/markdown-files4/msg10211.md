---
title: "Re: Understanding read_repairs"
description: ""
project: community
lastmod: 2013-02-22T10:57:39-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10211"
mailinglist_parent_id: "msg10210"
author_name: "Jared Morrow"
project_section: "mailinglistitem"
sent_date: 2013-02-22T10:57:39-08:00
---


Belai,

One other option is to use our "basho-patches" functionality. We use it to
run new code on current installations where sending a new .beam file is
easier than remaking the packages or compiling from source. On your ubuntu
system using our packages, the folder should be in
/usr/lib/riak/lib/basho-patches.

To do this you just need the one file changed in the PR pointed to by
Russell.

Here are the steps to make that happen:

 - Install Erlang R15B01:
 http://docs.basho.com/riak/latest/tutorials/installation/Installing-Erlang/
 - Get riak\_kv: git clone git://github.com/basho/riak\_kv.git
 - compile riak\_kv with just 'make'
 - copy the resulting .beam file in the ebin folder to the machines you
 need the new file: scp ebin/riak\_kv\_vnode.beam user@myriaknode
 :/usr/lib/riak/lib/basho-patches
 - stop each node and restart them one at a time
 - If you want to convince yourself you are using the new code, you can
 do a 'riak attach' to attach to the node and run
 code:which('riak\_kv\_vnode'). (Don't forget the '.' at the end)

For example on my dev install here is the command before the file is in
basho-patches:

(dev2@127.0.0.1)1&gt; code:which('riak\_kv\_vnode').
".../lib/riak\_kv-1.3.0/ebin/riak\_kv\_vnode.beam"

Here is the command after I put the .beam in the basho-patches directory:

(dev2@127.0.0.1)1&gt; code:which('riak\_kv\_vnode').
".../lib/basho-patches/riak\_kv\_vnode.beam"

Notice the path of the code changed from .../riak\_kv-1.3.0/... to
.../basho-patches/...

That might seem like a lot of work, but it is a really handy and useful
trick/skill that you might use quite a bit down the road.

Hope that helps,
Jared


On Fri, Feb 22, 2013 at 10:25 AM, Belai Beshah wrote:

&gt; Thanks Russel, that looks like exactly the problem we saw. I have never
&gt; built riak from source before but I will give it a try it this weekend.
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; From: Russell Brown [russell.br...@me.com]
&gt; Sent: Friday, February 22, 2013 1:24 AM
&gt; To: Belai Beshah
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Understanding read\_repairs
&gt;
&gt; Hi,
&gt; Thanks for trying Riak.
&gt;
&gt; On 21 Feb 2013, at 23:48, Belai Beshah  wrote:
&gt;
&gt; &gt; Hi All,
&gt; &gt;
&gt; &gt; We are evaluating Riak to see if it can be used to cache large blobs of
&gt; data. Here is our test cluster setup:
&gt; &gt;
&gt; &gt; • six Ubuntu LTS 12.04 dedicated nodes with 8 core 2.6 Ghz CPU, 32
&gt; GB RAM, 3.6T disk
&gt; &gt; • {pb\_backlog, 64},
&gt; &gt; • {ring\_creation\_size, 256},
&gt; &gt; • {default\_bucket\_props, [{n\_val, 2},
&gt; {allow\_mult,false},{last\_write\_wins,true}]},
&gt; &gt; • using bitcask as the backend
&gt; &gt;
&gt; &gt; Everything else default except the above. There is an HAProxy load
&gt; balancer infront of the nodes that the clients talk too configured
&gt; according to the basho wiki. Due to the nature of the application we are
&gt; integrating we do about 1200/s writes of approximately 40-50KB each and
&gt; read them back almost immediately. We noticed a lot of read repairs and
&gt; since that was one of the things that could indicate performance problem we
&gt; go worried. So we wrote a simple java client application that simulates our
&gt; use case. The test program is dead simple:
&gt; &gt; • generate keys using random UUID and value using Apache commons
&gt; RandomStringUtils
&gt; &gt; • create a thread pool of 5 and store key/value using
&gt; “bucket.store()”
&gt; &gt; • read the values back using “bucket.fetch()” multiple times
&gt; &gt; I could provide the spike code if needed. What we noticed is that we get
&gt; a lot of read repairs all over the place. We even made it use a single
&gt; thread to read/write, played with the write/read quorum and even put a
&gt; delay of 5 minutes between the writes before the reads start to give the
&gt; cluster time to be eventually consistent. Nothing helps, we always see a
&gt; lot of read repairs, sometime as many as the number of inserts.
&gt;
&gt;
&gt; It sounds like you are experiencing this bug
&gt; https://github.com/basho/riak\_kv/pull/334
&gt;
&gt; It is fixed in master, but it doesn't look like it made it into 1.3.0. If
&gt; you're ok with building from source, I tried it and a patch from
&gt; 8895d2877576af2441bee755028df1a6cf2174c7 goes cleanly onto 1.3.0.
&gt;
&gt; Cheers
&gt;
&gt; Russell
&gt;
&gt;
&gt; &gt; The good thing is that in all of these tests we have not seen any read
&gt; failures. Performance is also not bad, a few maxs here and there we don't
&gt; like but 90% looks good. Even when we killed a node, the reads are still
&gt; successful.
&gt; &gt;
&gt; &gt; We are wondering what the expected ratio of read repairs is and what is
&gt; a reasonable time for the cluster not to restore to read\_repair to fulfill
&gt; a read request or is there something we are missing in our setup.
&gt; &gt;
&gt; &gt; Thanks
&gt; &gt; Belai
&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

