---
title: "Re: EC2 and RIAK"
description: ""
project: community
lastmod: 2011-04-01T08:52:12-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg02836"
mailinglist_parent_id: "msg02827"
author_name: "David Dawson"
project_section: "mailinglistitem"
sent_date: 2011-04-01T08:52:12-07:00
---


Mathias and Alexander,

 Thanks for both of your replies they were very informative and really 
have helped me to make my mind up, but to summarise:

 - If you want good predictable performance but you are happy to live 
with the risk of loosing some of your data ( in the event of a cluster failure 
where the number of nodes that fail &gt; than your n\_val ) then run with the local 
ephemeral storage in RAID 5 or 10 and take snapshots of the data periodically 
or run in dual DC mode with replication.
 - If you want 100% assurance that your data is available and you are 
happy with unpredictable performance then use EBS.
 - If you want 100% assurance that your data is available and also has 
predictable performance then Amazon EC2 is not the most optimal choice.

 In our scenario we are doing a equal amount of reads and writes, and 
will need to guarantee about 32K ops/sec from a RIAK cluster over a 2 hour 
period with minimal risks of a outage or drop in performance, hence I am 
guessing that maybe EC2 is not the right choice for us. We are going to look at 
Joyent as an alternative, that said has anyone else used other solutions e.g. 
RackSpace cloud?

Dave


On 1 Apr 2011, at 14:21, Mathias Meyer wrote:

&gt; Hi David,
&gt; 
&gt; Alexander already gave you a good rundown on EC2 and Riak, but let me add 
&gt; some of my own experiences running databases on EC2 in general. 
&gt; 
&gt; The short answer is, Riak is certainly successfully used in production on 
&gt; EC2, so nothing should hold you back from testing a setup on EC2. But there's 
&gt; a whole bunch of things you should keep in mind.
&gt; 
&gt; First, it's probably a good idea to avoid using ephemeral storage as 
&gt; persistent storage. Even though it rarely happens, instances can crash on EC2 
&gt; for any kind of reason, mostly a hardware failure of the underlying host of 
&gt; course.
&gt; 
&gt; Cluster compute instances offer especially high CPU power, but what you 
&gt; really want is really fast and reliable storage I/O, persisted for eternity 
&gt; if need be. CC instances are certainly a lot better than any other instance 
&gt; in that terms of general I/O (see [2] for a comparison), but fall prey to 
&gt; similar limitations in terms of network storage I/O as other instance types, 
&gt; see below.
&gt; 
&gt; The RAID 0'd ephemeral storage on the cluster compute instances may sound 
&gt; good in theory in terms of performance, but in practice it takes away data 
&gt; durability in case of a single disk failure. One disk fails, and the data on 
&gt; that node is gone. Depending on what kinds of seek your doing, an EBS setup 
&gt; may even turn out to be faster. See [6] and [4] for a comparison and some 
&gt; initial and extended measurements, and [7] for another comparison. But 
&gt; certainly, the cluster compute instance's ephemeral storage can achieve a 
&gt; good amount of throughput, see [5] for some pretty graphs comparing both RAID 
&gt; and non-RAID setups.
&gt; 
&gt; As Alexander pointed out, multiple instance failures can make this scenario a 
&gt; real killer, though you end up with the same risks as running on raw iron 
&gt; servers. Both ephemeral storage and EBS don't make the problem of a proper 
&gt; backup disappear. You could e.g. run off ephemeral storage, relying on both 
&gt; Riak's replication and a good backup e.g. to an EBS volume or to S3.
&gt; 
&gt; EBS on the other hand is prone to a large variance in network latency, making 
&gt; performance at any point unpredictable and unreliable. Every measurement you 
&gt; take is likely to be different an hour later. This may sound extreme, but it 
&gt; turns out to be a very big issue for databases where there's lots of disk I/O 
&gt; involved to read and write data, as is the case with Riak's Bitcask storage.
&gt; 
&gt; You can increase the performance and reliability of EBS by using a RAID of 
&gt; volumes. Preferrably go for a RAID 5 or RAID 10 to add redundancy. There's 
&gt; mixed opinions on whether that's really necessary on EBS, with Amazon keeping 
&gt; the data redundant on their end as well, but in general, it's a good tradeoff 
&gt; between increased performance through striping and increased redundancy 
&gt; through mirroring. [1] has a good summary of when it's better to choose RAID 
&gt; 5 vs. 10.
&gt; 
&gt; RAID 0 will obviously bring the best performance, it's certainly a valid 
&gt; setup. We've been running RAID 0 setups with 4 volumes, and got great 
&gt; improvements over a single volume. You're also likely to achieve more 
&gt; throughput on bigger instances with a setup like this. The caveat once again 
&gt; is that one corrupted volume is enough to make a RAID 0 setup unusable.
&gt; 
&gt; Another crazy thought is to setup a RAID striping across a bunch of ephemeral 
&gt; drives and EBS volumes, maximizing throughput on both local and network 
&gt; storage. But know what you're getting yourself into with this kind of setup, 
&gt; especially when your write load is a lot heavier then the available network 
&gt; bandwidth can handle, a scenario where your network volumes will never be 
&gt; able to catch up with the local storage.
&gt; 
&gt; All that said, EBS I/O sure is reasonably fast, but it depends on your 
&gt; particular use case and performance requirements. It's also worth noting that 
&gt; the I/O capabilities of EBS increase with the instance size. The bigger your 
&gt; instance, the more throughput you'll achieve (see [3]). Bigger instances tend 
&gt; to have better network throughput in general, with cluster compute instances 
&gt; obviously having some of the highest bandwidth available.
&gt; 
&gt; All this turns out to be much less of a problem when data can be held in 
&gt; memory very easily, e.g. with Innostore, where you can read and write to/from 
&gt; cache buffers first and then have InnoDB take care of flushing to disk.
&gt; 
&gt; Personally, I don't think you're overcomplicating things in regard to 
&gt; multiple availability zones, it's a good idea to do that, when highest 
&gt; availability possible is your goal, as when it's usually just a single 
&gt; availability zone that's affected by increased latency or network timeouts, 
&gt; but as Alexander said, you should think about having cross-datacenter 
&gt; replication in that scenario, as availability zones are data centers located 
&gt; in different physical locations. Usually they're not that far apart, but far 
&gt; enough to increase latency considerably. But as always, it depends on your 
&gt; particular use case.
&gt; 
&gt; Now, after all this realtalk, here's the kicker. Riak's way of replicating 
&gt; data can make both scenarios work. When it's ensured that your data is 
&gt; replicated on more than one node, it can work in both ways. You could use 
&gt; both ephemeral storage and be somewhat safe because data will reside on 
&gt; multiple nodes. The same is true for EBS volumes, as potential variances in 
&gt; I/O or even minutes of total unavailabilities (as seen on the recent Reddit 
&gt; outage) can be recovered a lot easier thanks to handoff and read repairs. You 
&gt; can increase the number of replicas (n\_val) to increase your tolerance of 
&gt; instance failure, just make sure that n\_val is less than the number of nodes 
&gt; in your cluster.
&gt; 
&gt; Don't get me wrong, I love EC2 and EBS, being able to spin up servers at any 
&gt; time and to attache more storage to a running instance is extremely powerful, 
&gt; when you can handle the downsides. But if very low latency is what you're 
&gt; looking for, raw iron with lots of memory and SSD as storage device thrown on 
&gt; top is hard to beat.
&gt; 
&gt; When in doubt, start with a RAID 0 setup on EBS with 4 volumes, and compare 
&gt; it with a RAID 5 in terms of performance. They're known to give a good enough 
&gt; performance in a lot of cases. If you decide to go with a RAID, be sure to 
&gt; add LVM on top for simpler snapshotting, which will be quite painful if not 
&gt; impossible to get consistent snapshots using just EBS snapshots on a bunch of 
&gt; striped volumes.
&gt; 
&gt; Let us know if you have more questions, there's lots of details involved when 
&gt; you're going under the hood, but this should cover the most important bases.
&gt; 
&gt; Mathias Meyer
&gt; Developer Advocate, Basho Technologies
&gt; 
&gt; [1] 
&gt; http://en.wikipedia.org/wiki/RAID#RAID\_10\_versus\_RAID\_5\_in\_Relational\_Databases
&gt; [2] http://blog.cloudharmony.com/2010/09/benchmarking-of-ec2s-new-cluster.html
&gt; [3] http://blog.cloudharmony.com/2010/06/disk-io-benchmarking-in-cloud.html
&gt; [4] 
&gt; http://blog.bioteam.net/2010/07/boot-ephemeral-ebs-storage-performance-on-amazon-cc1-4xlarge-instance-types/
&gt; [5] 
&gt; http://blog.bioteam.net/2010/07/local-storage-performance-of-aws-cluster-compute-instances/
&gt; [6] 
&gt; http://blog.bioteam.net/2010/07/preliminary-ebs-performance-tests-on-amazon-compute-cluster-cc1-4xlarge-instance-types/
&gt; [7] http://victortrac.com/EC2\_Ephemeral\_Disks\_vs\_EBS\_Volumes
&gt; 
&gt; On Mittwoch, 30. MÃ¤rz 2011 at 18:29, David Dawson wrote: 
&gt;&gt; I am not sure if this has already been discussed, but I am looking at the 
&gt;&gt; feasibility of running RIAK in a EC2 cloud, as we have a requirement that 
&gt;&gt; may require us to scale up and down quite considerably on a month by month 
&gt;&gt; basis. After some initial testing and investigation we have come to the 
&gt;&gt; conclusion that there are 2 solutions although both have their downsides in 
&gt;&gt; my opinion:
&gt;&gt; 
&gt;&gt; 1. Run multiple cluster compute( cc1.4xlarge ) instances ( 23 GB RAM, 10 
&gt;&gt; Gigabit ethernet, 2 x 845 GB disks running RAID 0 )
&gt;&gt; 2. Same as above but using EBS as the storage instead of the local disks.
&gt;&gt; 
&gt;&gt; The problems I see are as follows with solution 1: 
&gt;&gt; 
&gt;&gt; - A instance failure results in complete loss of data on that machine, as 
&gt;&gt; the disks are ephemeral storage ( e.g. they only exist whilst the machine is 
&gt;&gt; up ).
&gt;&gt; 
&gt;&gt; The problems I see are as follows with solution 2:
&gt;&gt; 
&gt;&gt; - EBS is slower than the local disks and from what I have read is 
&gt;&gt; susceptible to latency depending on factors out of your control.
&gt;&gt; - There has been a bit of press lately about availability problems with EBS, 
&gt;&gt; so we would have to use multiple availability zones although there are only 
&gt;&gt; 4 in total and it just seems as though I am over complicating things.
&gt;&gt; 
&gt;&gt; Has anyone used EC2 and RIAK in production and if so what are their 
&gt;&gt; experiences?
&gt;&gt; 
&gt;&gt; Otherwise has anyone used RackSpace or Joyent? as these are alternatives 
&gt;&gt; although the Joyent solution seems very expensive, and what are their 
&gt;&gt; experiences?
&gt;&gt; 
&gt;&gt; Dave
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt; 


\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

