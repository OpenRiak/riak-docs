---
title: "Re: Fun with Unicode"
description: ""
project: community
lastmod: 2013-02-01T08:12:33-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg09963"
mailinglist_parent_id: "msg09962"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2013-02-01T08:12:33-08:00
---


For what it's worth, the underlying transports don't (read: shouldn't)
care about the encoding of the payload. They just want a chunk of
bytes. Is there an equivalent to "hey, I know this is probably a
unicode or string object, but just give me the equivalent bytearray
without transcoding anything"? If there is, we should be using that.

On Fri, Feb 1, 2013 at 9:57 AM, Anton  wrote:
&gt; Adam, you should be able to write to any transport if you first
&gt; .encode('utf-8') the result there, right? ensure\_ascii=False will feed
&gt; you unicode objects (if and only if there's something non-ASCII in the
&gt; input to .dumps). They of course will cause anything that attempts to
&gt; coerce them to a string to go wrong, as it'll attempt to do that by
&gt; encoding to ASCII.
&gt;
&gt; On 1 February 2013 16:45, Adam Lindsay  wrote:
&gt;&gt; Anton, Sean,
&gt;&gt;
&gt;&gt; Anton brings up a pretty interesting problem.
&gt;&gt;
&gt;&gt; At first, I thought it might be easy to remedy with:
&gt;&gt;
&gt;&gt; import json
&gt;&gt; import functools
&gt;&gt; antonjson = functools.partial(json.dumps, ensure\_ascii=False)
&gt;&gt;
&gt;&gt; from riak import RiakClient
&gt;&gt; R = RiakClient()
&gt;&gt; R.set\_encoder('application/json', antonjson)
&gt;&gt;
&gt;&gt; â€¦however, upon testing this out, it's seems likely that the underlying
&gt;&gt; transport channels use the default encoding, 'ascii,' and choke on the 8-bit
&gt;&gt; data we now pass it, in socket.py (for the HTTP client) or
&gt;&gt; protobuf.internal.type\_checkers (for PBC).
&gt;&gt;
&gt;&gt; Maybe that's a suitable hint for Anton's further investigation, but I'll try
&gt;&gt; to spend some time with it to see what I can find, as well.
&gt;&gt;
&gt;&gt; As to the OP's question: Yes, you've summarized the state of affairs quite
&gt;&gt; nicely. IMHO it was a reasonable default (you can't be sure other Riak
&gt;&gt; clients are as good as Python at 8-bit/Unicode!), but the underlying
&gt;&gt; implementation definitely shows a bug that (again, IMHO) should and can be
&gt;&gt; fixed.
&gt;&gt; --
&gt;&gt; Adam Lindsay
&gt;&gt;
&gt;&gt; On Friday, 1 February 2013 at 14:27, Sean Cribbs wrote:
&gt;&gt;
&gt;&gt; Anton,
&gt;&gt;
&gt;&gt; I don't see any reason why this can't be fixed. However, since I'm not
&gt;&gt; familiar with the specifics of the JSON implementation, I'll need
&gt;&gt; assistance. Please open an issue or pull-request on the Python client:
&gt;&gt; https://github.com/basho/riak-python-client/issues. We are open to
&gt;&gt; major, breaking changes for the next release.
&gt;&gt;
&gt;&gt; On Fri, Feb 1, 2013 at 8:06 AM, Anton  wrote:
&gt;&gt;
&gt;&gt; Let's talk python and Unicode (yey!)
&gt;&gt;
&gt;&gt; The objects that I want to store will have non-ASCII strings in them.
&gt;&gt; Potentially a lot. How much is a lot? "Very many millions" should be a
&gt;&gt; good estimate.
&gt;&gt;
&gt;&gt; Now, the default behaviour for storing a python object (ok, a dict of
&gt;&gt; stuff), using the PBC transport is to pass them to json and encode
&gt;&gt; them. I'm ok with that, I like JSON and the fact that I can read out
&gt;&gt; an object in JSON, using a browser, helps a lot. It's really great for
&gt;&gt; developing project-specific tools, say debugging tools.
&gt;&gt;
&gt;&gt; But here is where the fun part starts. The JSON encoder in python is
&gt;&gt; not a simple thing, and takes a lot of parameters. And by default it
&gt;&gt; works. So well that people rarely look at what's going on. When you
&gt;&gt; look at what's going on, however, things get more entertaining.
&gt;&gt;
&gt;&gt; The JSON encoder works on unicode objects, not strings. When you pass
&gt;&gt; it unicode objects, it's happy. When you pass it strings, it decodes
&gt;&gt; them, using a specified encoding. By default this is set to 'utf-8'
&gt;&gt; which makes everything quite ok. So far so good. However, there's
&gt;&gt; another option - 'ensure\_ascii'. This is set to True by default and it
&gt;&gt; means that the JSON encoder will spew out an ASCII-encoded string.
&gt;&gt; That is, in the result, every unicode code-point is encoded as \u0123,
&gt;&gt; or a total of 6 bytes.
&gt;&gt;
&gt;&gt; Now, this is not good. For one, the JSON RFCs expect Unicode, encoded
&gt;&gt; using UTF-\*. Also, even if much of the data will require 3bytes in
&gt;&gt; UTF-8, that's still only half the bytes that the python default would
&gt;&gt; take.
&gt;&gt;
&gt;&gt; Now, consider this elementary example. It already gives a significant
&gt;&gt; (in bytes) difference for a short string:
&gt;&gt; http://pastie.org/6011147
&gt;&gt;
&gt;&gt;
&gt;&gt; Please tell me I'm not going crazy and all this is the state of
&gt;&gt; affairs and it is, in fact, wrong and can/should be fixed.
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; Sean Cribbs 
&gt;&gt; Software Engineer
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; http://basho.com/
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;&gt;



-- 
Sean Cribbs 
Software Engineer
Basho Technologies, Inc.
http://basho.com/

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

