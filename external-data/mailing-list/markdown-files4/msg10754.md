---
title: "Re: Map phase timeout"
description: ""
project: community
lastmod: 2013-04-08T08:12:43-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10754"
mailinglist_parent_id: "msg10746"
author_name: "Dmitri Zagidulin"
project_section: "mailinglistitem"
sent_date: 2013-04-08T08:12:43-07:00
---


Matt,

My recommendation to you is - don't use MapReduce for this use case. Fetch
the objects via regular Riak GETs (using connection pooling and
multithreading, preferably).

I'm assuming that you have a list of keys (either by keeping track of them
externally to Riak, or via a Secondary Index query or a Search query), and
you want to back up those objects.

The natural inclination, once you know the keys, is to want to fetch all of
those objects via a single query, and MapReduce immediately comes to mind.
(And to most developers, writing the MR function in Javascript is easier
and more familiar than in Erlang). Unfortunately, as Christian mentioned,
it's very easy for the JS VMs to run out of resources and crash or time
out. In addition, I've found that rewriting the MapReduce in Erlang affords
only a bit more resources -- once you hit a certain number of keys that you
want to fetch, or a certain object size threshold, even Erlang MR jobs can
time out (keep in mind, while the Map phase can happen in parallel on all
of the nodes in a cluster, all the object values have to be serialized on
the single coordinating node, which becomes the bottleneck).

The workaround for this, even though it might seem counter-intuitive, is --
if you know the list of keys, fetch them using GETs. Even a naive
single-threaded "while loop" way of fetching the objects can often be
faster than a MapReduce job (for this use case), and it doesn't time out.
Add to that connection-pooling and multiple worker threads, and this method
is invariably faster.

Dmitri

On Mon, Apr 8, 2013 at 4:27 AM, Christian Dahlqvist wrote:

&gt; Hi Matt,
&gt;
&gt; If you have a complicated mapreduce job containing multiple phases
&gt; implemented in JavaScript, you will most likely see a lot of contention for
&gt; the JavaScript VMs which will cause problems. While you can tune the
&gt; configuration [1], you may find that you will need a very large pool size
&gt; in order to properly support your job, especially for map phases as these
&gt; run in parallel.
&gt;
&gt; The best way to speed up the mapreduce job and get around the VM pool
&gt; contention is to implement the mapreduce functions in Erlang.
&gt;
&gt; Best regards,
&gt;
&gt; Christian
&gt;
&gt; [1]
&gt; http://docs.basho.com/riak/1.2.0/references/appendices/MapReduce-Implementation/#Configuration-Tuning-for-Javascript
&gt;
&gt;
&gt;
&gt; --------------------
&gt; Christian Dahlqvist
&gt; Client Services Engineer
&gt; Basho Technologies
&gt; EMEA Office
&gt; E-mail: christ...@basho.com
&gt; Skype: c.dahlqvist
&gt; Mobile: +44 7890 590 910
&gt;
&gt; On 8 Apr 2013, at 08:20, Matt Black  wrote:
&gt;
&gt; Thanks for the reply, Christian.
&gt;
&gt; I didn't explain well enough in my first post - the map reduce operation
&gt; is merely loading a bunch of objects, and a Python script which makes the
&gt; connection to Riak then will write these objects to disk. (It's probably
&gt; obvious, but I'm using javascript and riak python client.)
&gt;
&gt; The query itself has many map phases where a composite object is built up
&gt; from related objects spread across many buckets.
&gt;
&gt; I was hoping there may be some kind of timeout I could adjust on a per-map
&gt; phase basis - clutching at straws really.
&gt;
&gt; Cheers
&gt; Matt
&gt;
&gt;
&gt; On 8 April 2013 17:14, Christian Dahlqvist  wrote:
&gt;
&gt;&gt; Hi,
&gt;&gt;
&gt;&gt; Without having access to the mapreduce functions you are running, I would
&gt;&gt; assume that a mapreduce job both writing data to disk as well as deleting
&gt;&gt; the written record from Riak might be quite slow. This is not really a use
&gt;&gt; case mapreduce was designed for, and when a mapreduce job crashes or times
&gt;&gt; out it is difficult to know how far along the processing of different
&gt;&gt; records it got.
&gt;&gt;
&gt;&gt; I would therefore recommend considering running this type of archiving
&gt;&gt; and delete job as an external batch process instead as it will give you
&gt;&gt; better control over the execution and avoid timeout problems.
&gt;&gt;
&gt;&gt; Best regards,
&gt;&gt;
&gt;&gt; Christian
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On 8 Apr 2013, at 00:49, Matt Black  wrote:
&gt;&gt;
&gt;&gt; &gt; Dear list,
&gt;&gt; &gt;
&gt;&gt; &gt; I'm currently getting a timeout during a single phase of a multi-phase
&gt;&gt; map reduce query. Is there anything I can do to assist this in running?
&gt;&gt; &gt;
&gt;&gt; &gt; It's purpose is to backup and remove objects from Riak, so it will run
&gt;&gt; periodically during quiet times moving old data out of Riak into file
&gt;&gt; storage.
&gt;&gt; &gt;
&gt;&gt; &gt; Traceback (most recent call last):
&gt;&gt; &gt; File "./tools/rolling\_backup.py", line 185, in 
&gt;&gt; &gt; main()
&gt;&gt; &gt; File "./tools/rolling\_backup.py", line 181, in main
&gt;&gt; &gt; args.func(\*\*kwargs)
&gt;&gt; &gt; File "/srv/backup/tools/mapreduce.py", line 295, in do\_map\_reduce
&gt;&gt; &gt; raise e
&gt;&gt; &gt; Exception:
&gt;&gt; {"phase":2,"error":"timeout","input":"[&lt;&lt;\"cart-products\"&gt;&gt;,&lt;&lt;\"cd67d7f6e2688bc2089e6fa79506ac05-2\"&gt;&gt;,{struct,[{&lt;&lt;\"uid\"&gt;&gt;,&lt;&lt;\"cd67d7f6e2688bc2089e6fa79506ac05\"&gt;&gt;},{&lt;&lt;\"cart\"&gt;&gt;,{struct,[{&lt;&lt;\"expired\_ts\"&gt;&gt;,&lt;&lt;\"2013-03-05T19:12:23.906228\"&gt;&gt;},{&lt;&lt;\"last\_updated\"&gt;&gt;,&lt;&lt;\"2013-03-05T19:12:23.906242\"&gt;&gt;},{&lt;&lt;\"tags\"&gt;&gt;,{struct,[{&lt;&lt;\"type\"&gt;&gt;,&lt;&lt;\"AB\"&gt;&gt;}]}},{&lt;&lt;\"completed\"&gt;&gt;,false},{&lt;&lt;\"created\"&gt;&gt;,&lt;&lt;\"2013-03-04T02:10:18.638413\"&gt;&gt;},{&lt;&lt;\"products\"&gt;&gt;,[{struct,[{&lt;&lt;\"cost\"&gt;&gt;,0},{&lt;&lt;\"bundleName\"&gt;&gt;,&lt;&lt;\"Product\"&gt;&gt;},...]},...]},...]}},...]}]","type":"exit","stack":"[{riak\_kv\_w\_reduce,'-js\_runner/1-fun-0-',3,[{file,\"src/riak\_kv\_w\_reduce.erl\"},{line,283}]},{riak\_kv\_w\_reduce,reduce,3,[{file,\"src/riak\_kv\_w\_reduce.erl\"},{line,206}]},{riak\_kv\_w\_reduce,maybe\_reduce,2,[{file,\"src/riak\_kv\_w\_reduce.erl\"},{line,157}]},{riak\_pipe\_vnode\_worker,process\_input,3,[{file,\"src/riak\_pipe\_vnode\_worker.erl\"},{line,444}]},{riak\_pipe\_vnode\_worker,wait\_for\_input,2,[{file,\"src/riak\_pipe\_vnode\_worker.erl\"},{line,376}]},{gen\_fsm,handle\_msg,7,[{file,\"gen\_fsm.erl\"},{line,494}]},{proc\_lib,...}]"}
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

