---
title: "Re: May allow_mult cause DoS?"
description: ""
project: community
lastmod: 2013-12-19T21:15:33-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13302"
mailinglist_parent_id: "msg13268"
author_name: "Jason Campbell"
project_section: "mailinglistitem"
sent_date: 2013-12-19T21:15:33-08:00
---


Can anyone familiar with Riak internals describe how siblings are handled in Level DB? I think part of this issue is a misunderstanding of how that works and false expectations. As far as I understand, siblings are light at write time and resolved at read time.Meaning if I had an object with 100 siblings, it would result in 100 GETs from the Level DB backend when reading that object. Also an additional sibling would only require writing the new data to an additional object.Am I correct in this, or does Riak do some special merging in the backend on write to make reads more efficient? Also, how does it handle siblings since Level DB doesn't support them? Is there an intermediate object that stores links to all siblings?I think this information would allow people to better utilise siblings and understand why certain workloads can crash Riak or make it dreadfully slow.Thanks,Jason Campbell From: Rune Skou LarsenSent: Thursday, 19 December 2013 7:10 AMTo: Viable Nisei; riak-users@lists.basho.comSubject: SV: May allow\_mult cause DoS?Save the transaction list inside the customer object keyed by customerid. Index this object with 2i on storeids for each contained tx.If some customer objects grow too big, you can move old txs into archive objects keyed by customerid\_seqno. For your low latency customer reads, you probably only need the newest txs anyway.That's just one idea. Trifork will be happy to help you find a suitable model for your use cases.We usually do this by stress-testing a simulation with realistic data sizes/shapes and access patterns. It's fastest if we come onsite for a couple of days and work with you to set it up, but we can also help you offsite.Write me if you're interested, then we can do a call.Rune Skou LarsenTrifork, Denmark----- Reply message -----Fra: "Viable Nisei" Til: "riak-users@lists.basho.com" Emne: May allow\_mult cause DoS?Dato: ons., dec. 18, 2013 20:13---------- Forwarded message ----------From: Viable Nisei &gt;Date: Thu, Dec 19, 2013 at 2:11 AMSubject: Re: May allow\_mult cause DoS?To: Russell Brown &gt;Hi.Thank you for your descriptive and so informative answer very much.On Wed, Dec 18, 2013 at 3:29 PM, Russell Brown &gt; wrote:Hi,Can you describe your use case a little? Maybe it would be easier for us to help.Yeah, let me describe some abstract case equivalent to our. Let we have CUSTOMER object, STORE object and TRANSACTION object, each TRANSACTION has one tribool attribute STATE={ACTIVE, COMPLETED, ROLLED\_BACK}.We should be able to list all the TRANSACTIONs of given CUSTOMER, for example (so we should establish 1-many relation, this list should not be long, 10^2-10^3 records, but we should be able to obtain this list fast enough). Also we should be able to list all the TRANSACTIONs of given STATE made in given STORE (lists may be very long, up to 10^8 records), but these list may be computed with some latency. Predictable latency is surely preferred but is not show-stopper. So, that's all.Another pain is races and/or operations atomicity, but it's not so important at current time.On 18 Dec 2013, at 04:32, Viable Nisei &gt; wrote:&gt; On Wed, Dec 18, 2013 at 8:32 AM, Erik Søe Sørensen &gt; wrote:&gt; It really is not a good idea to use siblings to represent 1-to-many relations. That's not what it's intended for, nor what it's optimized for...&gt; Ok, understood.&gt;&gt; Can you tell us exactly why you need Bitcask rather than LevelDB? 2i would probably do it.&gt; 1) According to http://docs.basho.com/riak/latest/ops/running/backups/#LevelDB-Backups , it's real pain to implement backups with leveldb.&gt; 2) According to http://docs.basho.com/riak/latest/ops/advanced/backends/leveldb/ , reads may be slower comparing to bitcask, it's critical for us&gt;&gt; Otherwise, storing a list of items under each key could be a solution, depending of course on the number of items per key. (But do perform conflict resolution.)&gt; Why any conflict resolving is required? As far as I understood, with allow\_mult=true riak should just collect all the values written to key without anything additional work? What design decision leads to exponential slowdown and crashes when multiple values allowed for any single key?.. So, what's the REAL purpose of allow\_mult=true if it's bad idea to use it for unlimited values per single key?The real purpose of allow\_mult=true is so that writes are never dropped. In the case where your application concurrently writes to the same key on two different nodes, or on two partitioned nodes, Riak keeps both values. Other data stores will lose one of the writes based on timestamp, serialise your writes (slow) or simply refuse to accept one or more of them.Ok, but documentation doesn't make points really clear.It is the job of the client to aggregate those multiple writes into a single value when it detects the conflict on read. Conflict resolution is required because your data is opaque to Riak. Riak doesn’t know that you’re storing lists of values, or JPEGs or JSON. It can’t possibly know how to resolve two conflicting values unless it knows the semantics of the values. Riak \_does\_ collect all the values written to a key, but it does so as a temporary measure, it expects your application to resolve them to a single value. How many are you writing per Key?As I said before, we need really many values in our 1-many sets - up to 10^8Also why not to implement separate bucket mode allowing just to collect all the values writing? Anyway, current allow\_mult implementation looks like very dangerous. Also documentation should be more clear - in "sibling explosion" paragraph some statement should be added pointing that this relates to allow\_mult=true too.Riak’s sweetspot is highly write available applications. If you have the time read the Amazon Dynamo paper[1], as it explains the \_problems\_ Riak solves as well as the way in which it solves them. If you don’t have these problems, maybe Riak is not the right datastore for you. Solving these problems comes with some developer complexity costs. You’ve run into one of them. We have many customers who think the trade-off is worth it: that the high availability and low-latency makes up for having eventual consistency.Yeah, ok, but what riak&lt;2.0 really allows? FTS looks unscalable (am I right? is any way to speed-up it available?), list of all bucket keys is not for production, 2i is not implemented for bitcask (anyway, we'll try them on leveldb), links "implemented as hacks in java driver". So, riak&lt;2.0 with bitcask is only good distributed 1-1 hashmap with mapred support.&gt;&gt; Ok, documentation contains the following paragraph:&gt;&gt; &gt; Sibling explosion occurs when an object rapidly collects siblings without being reconciled. This can lead to a myriad of issues. Having an enormous object in your node can cause reads of that object to crash the entire node. Other issues are increased cluster latency as the object is replicated and out of memory errors.&gt;&gt; But there is no point if it related to allow\_mult=false or both cases.Sorry, but I don’t understand what you mean by this statement. The point of allow\_mult=true is so that writes are not arbitrarily dropped. It allows Riak nodes to continue to be available to take writes even if they can’t communicate with each other. Have a look at Kyle Kingsbury’s Jepsen[2] post on Riak.I'm just speaking about that this paragraph should contain something like "don't write multiple values into single key in bucket with allow\_mult=true, this will cause dramatic slowdowns/crashes". It's not really obvious that siblings explosion is related to bucket with allow\_mult=true.&gt;&gt; So, the only solution is leveldb+2i?Maybe. Or maybe just use the client as it is intended to resolve sibling values and send that value and a vector clock back to Riak.Not a solution for big sets of 10^8 elementsOr maybe roll your own indexes like in this blog post[3]. It's not an option to use some custom "indexes" on client side for long lists, so the only option is to write some erlang piece of code?..With Riak 2.0 there are a few data types added to Riak that are not opaque. Maybe Riak’s Sets would suit your purpose (depending on the size of your Set.) What are you meaning by "depending size of Set"?Will I be able to store 10^8 values and enumerate/add new values fast enough?You’re fighting the database at the moment, rather than working with it. The properties of Riak buy you some wonderful things (high availability, partition tolerance, low latency) but you have to want / need those properties, and then you have to accept that there is a data modelling / developer complexity price to pay. We don’t think that price is too high. We have many customers who agree. We’re always working to lower that price (see Strong Consistency, Yokozuna, Data Types etc in Riak 2.0[4].)We've built 2.0 TP but it like to crash frequently and 2.0 driver still is not ready, but according to docs it looks like significantly better. But questions about maximum Set size and FTS scalability still looks actual.You seem to have had a very negative first experience of Riak (and Basho.) I think that is because you misunderstand what it is for and how it should be used. I'm very keen to fix that. If it turns out that Riak is just not for you, that is fine too.It's not negative experience, it's just WTFZOMG state. Everything looked good until loading/scalability tests...In response to your earlier mail, I think Basho’s consulting costs sound incredibly low. I think you got that answer because you reached out to Basho through that channel, rather than ask the list. We’re still trying to track down who you spoke to and when, if you could provide me details of that conversation directly (rather than to the list) I’d be very grateful.I think it's not really important for now, I think we've incorrectly emphasized our questions/thoughts.Anyway for now looks like there is no silver bullet priced for $5k - all the possible approaches to solve our problem was already listed in this thread. And the only way I've missed in op message was custom indexing on server side (implemented as precommit hook, am I right? such as FTS?)I’m not sure if it is just a cultural / language thing, but you’re very negative right now, and you sound like you're attacking Basho and Riak. I don’t think that is warranted at this point as we’re just trying to help you figure out if Riak is the datastore you want / need.As I said before, I'm not negative. This picture http://tinyurl.com/p5zntks excellently describes thoughts of our dev team after set of loading tests. We got 100 writes/sec on single core i3 host. Ok, we got up to 500 writes (but we need 10k+) on single cc2.8xlarge host, but with 5 cc2.8xlarge nodes we got lesser with latency significantly increased. We changed our approach to using allow\_mult - and got only 100 for some first seconds, then exponentially dropping to zero, then total crash of all the cluster... Also you are right - english is not my native language. What about subject of our thread - take it like like some yellow press headline (but I still think that it's not so good idea to allow client code to do SUCH BAD THINGS WITH WHOLE CLUSTER)CheersRussell[1] http://dl.acm.org/citation.cfm?id=1294281[2] http://aphyr.com/posts/285-call-me-maybe-riak[3] http://basho.com/index-for-fun-and-for-profit/[4] http://basho.com/technical-preview-of-riak-2-0/&gt;&gt;&gt;&gt; On Wed, Dec 18, 2013 at 8:32 AM, Erik Søe Sørensen &gt; wrote:&gt; It really is not a good idea to use siblings to represent 1-to-many relations. That's not what it's intended for, nor what it's optimized for...&gt; Can you tell us exactly why you need Bitcask rather than LevelDB? 2i would probably do it.&gt; Otherwise, storing a list of items under each key could be a solution, depending of course on the number of items per key. (But do perform conflict resolution.)&gt; /Erik&gt;&gt;&gt;&gt; -------- Oprindelig meddelelse --------&gt; Fra: Viable Nisei &gt;&gt; Dato:&gt; Til: riak-users@lists.basho.com&gt; Emne: May allow\_mult cause DoS?&gt;&gt;&gt; Hi.&gt;&gt; Recently we've described that something is going unexpectedly. We are using Riak 1.4.2 with some buckets with allow\_mult=true.&gt; We've tried our app under load then found that... concurrently writes into bucket with allow\_mult turning Riak into irresponsible slowpoke and even crash it.&gt;&gt; Core i3 with 4GB RAM performs only 20 writes/sec with 5 client threads writing 20 short strings into 20 keys in bucket with allow\_mult=true, search=false. With 40 values per 40 keys it performs only 6 writes/sec. 60x60 cause riak crash?&gt; Throughput drops drastically. Ok, we've not chaged concurrency factor (5) and increased our data set 4x, but why throughput drops?&gt; Ok, we increase our dataset linear, 20 strings \* 20 keys, 40 strings\*20 keys, 60 strings\*20 keys... Results will be same - exponential throughput drop with crash at end.&gt;&gt; Cluster of five Amazon EC2 cc2.8xlarge nodes becomes irresponsibly with throughput 1-5 writes/sec with only 80-100 values per 1-10 keys.&gt;&gt; So, we think it is very strange.&gt;&gt; Here you can check our code sample (in java) reproducing this behavior: https://bitbucket.org/vsnisei/riak-allow\_mult\_wtf&gt;&gt; So, we have asked Basho about this, but they said that "we think SQLish" and asked us for $5k for 2-days consultation to resolve our problem.&gt; So, I've decided to ask here if we are really so stupid and not able to understood some simple things or Basho didn't understood us correctly?..&gt;&gt; Anyway, looks like that some DoS/DDoS attack approach utilizing this behavior may be proposed. We should only know that some service/appliation/website is using Riak with allow\_mult buckets then provoke concurrent writes into them...&gt;&gt; Actually our question to Basho was broader. Our application needs to implement 1-many bindings. Riak allows the following approaches to simultate such bindings, according to documentation:&gt;&gt; 1. Riak search - but we've found that it's VERY slow (20x performance drop when search enabled, even for simple objects like {source\_id: xxx, target\_id: yyy}, also we've found that search is not really scalable - adding new nodes into cluster not increasing throughput, but even slows cluster down...&gt; 2. secondary indexes. But, according to docs, they are working only on LevelDb, but we need Bitcask&gt; 3. Link walking. But, according to docs, it's "rest only operation" and in java driver it's implemented as a hack&gt; 4. allow\_mult. But we've found that it's just a nightmare. So we told Basho about this and given link to our example, but they didn't given us any feedback&gt; 5. Bucket keys enumeration. But, according to docs, this operation causes full keys scan on each node and must not be used in production&gt; 6. Mapred queries. Ok, we didn't tried them yet, maybe it's silver bullet, really. But according to docs (and common sense) mapred causes full-scan (for bucket at least. Or for all keys?) and it's operation with unpredictable latency.&gt;&gt; So, where we are wrong? Is everything ok with behavior I've described? Are we misunderstood Riak completely and should pay $5k for some mind-expansion, or there is no any hidden mystical knowledge and they will not say us anything excepting approaches listed above?&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_&gt; riak-users mailing list&gt; riak-users@lists.basho.com&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_riak-users mailing listriak-users@lists.basho.comhttp://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

