---
title: "Re: Error while importing data"
description: ""
project: community
lastmod: 2011-11-23T02:50:20-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05716"
mailinglist_parent_id: "msg05684"
author_name: "Nitish Sharma"
project_section: "mailinglistitem"
sent_date: 2011-11-23T02:50:20-08:00
---


So far I've figured out that this error has nothing to do with Python.
After couple of million iterations, one of the nodes (any random node) in
the cluster crashes and thus python threads time out.
I am trying to make sense out of error and crash logs.

Cheers
Nitish

On Sat, Nov 19, 2011 at 10:16 PM, Erik Søe Sørensen  wrote:

&gt; A timeout... Do you know what the timeout threshold is? Have you tried
&gt; increasing it (if possible; I don't know the Python client) or simply
&gt; retrying once or twice on timeout?
&gt; Also, what backend is Riak configured with? - I believe eleveldb has
&gt; occasional lower throughput/higher latency because of file compaction.
&gt;
&gt; ----- Reply message -----
&gt; Fra: "Nitish Sharma" 
&gt; Dato: lør., nov. 19, 2011 13:22
&gt; Emne: Error while importing data
&gt; Til: "riak-users" 
&gt;
&gt; Hi,
&gt; To give my Riak setup a good stress testing, I decided to import a large
&gt; dataset (consisting of around 160 million records). But before importing
&gt; the whole thing, I tested the import python script (using protocol buffers)
&gt; using 1 million records, which was successful with ~2200 writes/sec. The
&gt; script, essentially, puts the data into a queue and couple of threads gets
&gt; the data from the queue and store it in Riak.
&gt; When started with full dataset, after storing several million objects, I
&gt; get thread exception with timeout errors.
&gt; Following is the traceback:
&gt;
&gt; File "/usr/lib/python2.7/threading.py", line 552, in \_\_bootstrap\_inner
&gt; self.run()
&gt; File "/usr/lib/python2.7/threading.py", line 505, in run
&gt; self.\_\_target(\*self.\_\_args, \*\*self.\_\_kwargs)
&gt; File "python\_load\_data.py", line 23, in worker
&gt; new\_obj.store()
&gt; File
&gt; "/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/riak\_object.py",
&gt; line 296, in store
&gt; Result = t.put(self, w, dw, return\_body)
&gt; File
&gt; "/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/transports/pbc.py",
&gt; line 188, in put
&gt; msg\_code, resp = self.recv\_msg()
&gt; File
&gt; "/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/transports/pbc.py",
&gt; line 370, in recv\_msg
&gt; raise Exception(msg.errmsg)
&gt; Exception: timeout
&gt;
&gt; The cluster consists of 3 nodes (Ubuntu 10.04). The nodes have enough disk
&gt; space; number of file handles used (~2500) are also within limit (32768);
&gt; number of concurrent ports 32768. I cant figure out what else could be the
&gt; possible reason for the exceptions.
&gt;
&gt; Any Suggestions?
&gt;
&gt; Cheers
&gt; Nitish
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

