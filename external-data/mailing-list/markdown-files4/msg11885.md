---
title: "Re: memory consumption"
description: ""
project: community
lastmod: 2013-08-05T05:46:02-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11885"
mailinglist_parent_id: "msg11884"
author_name: "Evan Vigil-McClanahan"
project_section: "mailinglistitem"
sent_date: 2013-08-05T05:46:02-07:00
---


Before I'd done the research, I too thought that the overheads were a
much lower, near to what the calculator said, but not too far off.

There are a few things that I plan on addressing this release cycle:
 - 16b per-allocation overhead from using enif\_alloc. This allows us
a lot of flexibility about which allocator to use, but I suspect that
since allocation speed isn't a big bitcask bottleneck, this overhead
simply isn't worth it.
 - 13b per value overhead from naive serialization of the bucket/key
value. I have a branch that reduced this by 11 bytes.
 - 4b per value overhead from a single bit flag that is stored in an
int. No patch for this thus far.

Additionally, I've found that running with tcmalloc using LD\_PRELOAD
reduces the cost for bitcask's many allocations, but a) I've never
done so in production and b) they say that it never releases memory,
which is worrying, although the paging system theoretically should
take care of it fairly easily as long as their page usages isn't
insane.

My original notes looked like this:

1) ~32 bytes for the OS/malloc + khash overhead @ 50M keys
(amortized, so bigger for fewer keys, smaller for more keys).
2) + 16 bytes of erlang allocator overhead
3) + 22 bytes for the NIF C structure
4) + 8 bytes for the entry pointer stored in the khash
5) + 13 bytes of kv overhead

tcmalloc does what it can for line 1.
My patches do what I can for lines 2, 3, and 5.

4 isn't amenable to anything other than a change in the way the keydir
is stored, which could also potentially help with 1 (fewer
allocations, etc). That, unfortunately, is not very likely to happen
soon.

So things will get better relatively soon, but there are some
architectural limits that will be harder to address.

On Mon, Aug 5, 2013 at 1:49 AM, Alexander Ilyin  wrote:
&gt; Evan,
&gt;
&gt; News about per key overhead of 91 bytes are quite frustrating. When we were
&gt; choosing a key value storage per key metadata size was a crucial point for
&gt; us. We have a simple use case but a lot of data (hundreds of millions of
&gt; items) so we were looking for the ways to reduce memory consumption.
&gt; Here and here is stated a value of 40 bytes. 22 bytes in ram calculator
&gt; seemed like a mistake because the following example obviously uses a value
&gt; of 40.
&gt;
&gt; Anyway, thanks for your response.
&gt;
&gt;
&gt; On 4 August 2013 04:39, Evan Vigil-McClanahan  wrote:
&gt;&gt;
&gt;&gt; Some responses inline.
&gt;&gt;
&gt;&gt; On Fri, Aug 2, 2013 at 3:11 AM, Alexander Ilyin 
&gt;&gt; wrote:
&gt;&gt; &gt; Hi,
&gt;&gt; &gt;
&gt;&gt; &gt; I have a few questions about Riak memory usage.
&gt;&gt; &gt; We're using Riak 1.3.1 on a 3 node cluster. According to bitcask
&gt;&gt; &gt; capacity
&gt;&gt; &gt; calculator
&gt;&gt; &gt;
&gt;&gt; &gt; (http://docs.basho.com/riak/1.3.1/references/appendices/Bitcask-Capacity-Planning/)
&gt;&gt; &gt; Riak should use about 30Gb of RAM for out data. Actually, it uses about
&gt;&gt; &gt; 45Gb
&gt;&gt; &gt; and I can't figure out why. I'm looking at %MEM column in top on each
&gt;&gt; &gt; node
&gt;&gt; &gt; for a beam.smp process.
&gt;&gt;
&gt;&gt; I've recently done some research on this and have filed bugs against
&gt;&gt; the calculator, it's a bit wrong and has been that way for a while:
&gt;&gt;
&gt;&gt; https://github.com/basho/basho\_docs/issues/467
&gt;&gt;
&gt;&gt; The numbers there look a bit closer to what you're seeing.
&gt;&gt;
&gt;&gt; The good news is that I am looking into reducing memory consumption
&gt;&gt; this development cycle and our next release should see some
&gt;&gt; improvements on that front. The bad news is that it may be a while.
&gt;&gt; If you want to watch the bitcask repo on github to see when these
&gt;&gt; changes go in, it's usually pretty easy to build a new bitcask and
&gt;&gt; replace the one that you're running.
&gt;&gt;
&gt;&gt; &gt; Disk usage is also about 1,5 times more than I have expected (270Gb
&gt;&gt; &gt; instead
&gt;&gt; &gt; of 180Gb). I rechecked that I have n\_val=2 (not 3), it seems alright.
&gt;&gt; &gt; Why
&gt;&gt; &gt; this could happen?
&gt;&gt;
&gt;&gt; There is definitely some overhead on the stored values, especially
&gt;&gt; when you're using bitcask. How big are your values? Overheads, if I
&gt;&gt; recall correctly, run to a few hundred bytes, but I'll have to ask
&gt;&gt; some people to refresh my memory.
&gt;&gt;
&gt;&gt; &gt; Second question is about performance degradation when Riak uses almost
&gt;&gt; &gt; all
&gt;&gt; &gt; available memory on the node. We see that 95/99 put percentiles twice as
&gt;&gt; &gt; large for nodes which don't have much free RAM. How much free memory I
&gt;&gt; &gt; should have to keep performance high?
&gt;&gt;
&gt;&gt; I don't have a good answer for this; when I was working as a CSE we
&gt;&gt; generally urged people to start adding nodes when their most limited
&gt;&gt; resource (memory, disk, cpu, etc) was 70-80% utilized (as a grossly
&gt;&gt; oversimplified rule of thumb).
&gt;&gt;
&gt;&gt; &gt; And the last question about memory\_total metric. riak-admin status
&gt;&gt; &gt; returns
&gt;&gt; &gt; value which is less than actual memory consumption as seen in the top.
&gt;&gt; &gt; According to memory\_total description
&gt;&gt; &gt;
&gt;&gt; &gt; (http://docs.basho.com/riak/1.3.1/references/appendices/Inspecting-a-Node/)
&gt;&gt; &gt; they should be equal. Why they are not?
&gt;&gt;
&gt;&gt; Top factors in OS/libc overheads that memory\_total cannot see. I'll
&gt;&gt; check out the docs and get them amended if they're wrong.
&gt;
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

