---
title: "Re: Riak Search and Yokozuna Backup Strategy"
description: ""
project: community
lastmod: 2014-01-23T12:59:02-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13468"
mailinglist_parent_id: "msg13464"
author_name: "Dave Martorana"
project_section: "mailinglistitem"
sent_date: 2014-01-23T12:59:02-08:00
---


I like that HyperDex provides direct backup support instead of simply
suggesting a stop-filecopy-start-catchup scenario. Are there any plans at
Basho to make backups a core function of Riak (or as a separate but
included utility) - it would certainly be nice to have something Basho
provides help ensure things are done properly each time, all the time.

Cheers,

Dave


On Thu, Jan 23, 2014 at 1:42 PM, Joe Caswell  wrote:

&gt; Apologies, clicked send in the middle of an incomplete thought. It should
&gt; have read:
&gt;
&gt; Backing up the LevelDB data files while the node is stopped would remove
&gt; the necessity of using the LevelDB repair process upon restoring to make
&gt; the vnode self-consistent.
&gt;
&gt; From: Joe Caswell 
&gt; Date: Thursday, January 23, 2014 1:25 PM
&gt; To: Sean McKibben , Elias Levy &lt;
&gt; fearsome.lucid...@gmail.com&gt;
&gt;
&gt; Cc: "riak-users@lists.basho.com" 
&gt; Subject: Re: Riak Search and Yokozuna Backup Strategy
&gt;
&gt; Backing up LevelDB data files can be accomplished while the node is
&gt; running if the sst\_x directories are backed up in numerical order. The
&gt; undesirable side effects of that could be duplicated data, inconsistent
&gt; manifest, or incomplete writes, which necessitates running the leveldb
&gt; repair process upon restoration for any vnode backed up while the node was
&gt; running. Since the data is initially written to the recovery log before
&gt; being appended to level 0, and any compaction operation fully writes the
&gt; data to its new location before removing it from its old location, if any
&gt; of these operations are interrupted, the data can be completely recovered
&gt; by leveldb repair.
&gt;
&gt; The only incomplete write that won't be recovered by the LevelDB repair
&gt; process is the initial write to the recovery log, limiting exposure to the
&gt; key being actively written at the time of the snapshot/backup. As long as
&gt; 2 vnodes in the same preflist are not backed up while simultaneously
&gt; writing the same key to the recovery log (i.e. rolling backups are good),
&gt; this key will be recovered by AAE/read repair after restoration.
&gt;
&gt; Backing up the LevelDB data files while the node is stopped would remove
&gt; the necessity of repairing the
&gt;
&gt; Backing up Riak Search data, on the other hand, is a dicey proposition.
&gt; There are 3 bits to riak search data: the document you store, the output
&gt; of the extractor, and the merge index.
&gt;
&gt; When you put a document in &lt;&lt;"key"&gt;&gt; in a &lt;&lt;"bucket"&gt;&gt; with search
&gt; enabled, Riak uses the pre-defined extractor to parse the document into
&gt; terms, possibly flattening the structure, and stores the result in
&gt; &lt;&lt;"\_rsid\_bucket"&gt;&gt;/&lt;&lt;"key"&gt;&gt;, which is used during update operations to
&gt; remove stale entries before adding new ones, and would most likely be
&gt; stored in a different vnode, possibly on a different node entirely. The
&gt; document id/link is inserted into the merge index entry for each term
&gt; identified by the extractor, any or all of which may reside on different
&gt; nodes. Since the document, its index document, and the term indexes could
&gt; not be guaranteed to be captured in any single backup operation, it is a
&gt; very real probability that these would be out of sync in the event that a
&gt; restore is required.
&gt;
&gt; If restore is only required for a single node, consistency could be
&gt; restored by running a repair operation for each riak\_kv vnode and
&gt; riak\_search vnode stored on the node, which would repair the data from
&gt; other nodes in the cluster. If more than one node is restored, it is quite
&gt; likely that they both stored replicas of the same data, for some subset of
&gt; the full data set. The only way to ensure consistency is fully restored in
&gt; the latter case is to reindex the data set. This can be accomplished by
&gt; reading and rewriting all of the data, or by reindexing via MapReduce as
&gt; suggested in this earlier mailing list post:
&gt; http://lists.basho.com/pipermail/riak-users\_lists.basho.com/2012-October/009861.html
&gt;
&gt; In either restore case, having a backup of the merge\_index data files is
&gt; not helpful, so there does not appear to be any point in backing them up.
&gt;
&gt; Joe Caswell
&gt; From: Sean McKibben 
&gt; Date: Tuesday, January 21, 2014 1:04 PM
&gt; To: Elias Levy 
&gt; Cc: "riak-users@lists.basho.com" 
&gt; Subject: Re: Riak Search and Yokozuna Backup Strategy
&gt;
&gt; +1 LevelDB backup information is important to us
&gt;
&gt;
&gt; On Jan 20, 2014, at 4:38 PM, Elias Levy 
&gt; wrote:
&gt;
&gt; Anyone from Basho care to comment?
&gt;
&gt;
&gt; On Thu, Jan 16, 2014 at 10:19 AM, Elias Levy 
&gt; wrote:
&gt;
&gt;&gt;
&gt;&gt; Also, while LevelDB appears to be largely an append only format, the
&gt;&gt; documentation currently does not recommend live backups, presumably because
&gt;&gt; there are some issues that can crop up if restoring a DB that was not
&gt;&gt; cleanly shutdown.
&gt;&gt;
&gt;&gt; I am guessing those issues are the ones documented as edge cases here:
&gt;&gt; https://github.com/basho/leveldb/wiki/repair-notes
&gt;&gt;
&gt;&gt; That said, it looks like as of 1.4 those are largely cleared up, at least
&gt;&gt; from what I gather from that page, and that one must only ensure that data
&gt;&gt; is copied in a certain order and that you run the LevelDB repair algorithm
&gt;&gt; when retiring the files.
&gt;&gt;
&gt;&gt; So is the backup documentation on LevelDB still correct? Will Basho will
&gt;&gt; enable hot backups on LevelDB backends any time soon?
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On Thu, Jan 16, 2014 at 10:05 AM, Elias Levy &gt; &gt; wrote:
&gt;&gt;
&gt;&gt;&gt; How well does Riak Search play with backups? Can you backup the Riak
&gt;&gt;&gt; Search data without bringing the node down?
&gt;&gt;&gt;
&gt;&gt;&gt; The Riak documentation backup page is completely silent on Riak Search
&gt;&gt;&gt; and its merge\_index backend.
&gt;&gt;&gt;
&gt;&gt;&gt; And looking forward, what is the backup strategy for Yokozuna? Will it
&gt;&gt;&gt; make use of Solr's Replication Handler, or something more lower level?
&gt;&gt;&gt; Will the node need to be offline to backup it up?
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

