---
title: "Re: Performance Issues with LevelDB Backend on 1.0.0RC1"
description: ""
project: community
lastmod: 2011-09-26T11:54:55-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04883"
mailinglist_parent_id: "msg04879"
author_name: "Jon Meredith"
project_section: "mailinglistitem"
sent_date: 2011-09-26T11:54:55-07:00
---


Hi Patrick,

I suggested increasing ports as you had an emfile on a socket accept call.
Erlang uses ports for things like network sockets and file handles when
opened by \*erlang\* processes. However, the leveldb library manages it's own
sockets as it is a C++ library dynamically loaded by the emulator and so
doesn't count towards ports.

Is it possible that Riak started getting more client load if request latency
increased? Changing max\_open\_files will keep the number of process-level
file handles lower, but will cause more opening and closing of files to
search them. If you have a nice modern OS with lots of file handles
available, you may be able to increase max\_open\_files for increased
performance.

If you want to check how many ports you are using you can run this from the
riak console.

 (dev1@127.0.0.1)7&gt; length(erlang:ports()).
 39

Try increasing your max\_open\_ports and checking how many file handles are in
use using a tool like lsof and check the number of ports you have opened.

Cheers, Jon.

On Mon, Sep 26, 2011 at 12:44 PM, Patrick Van Stee
wrote:

&gt; Thanks for the quick response Jon. I bumped it from 4096 up to the max I
&gt; have set in /etc/riak/defaults and writes actually slowed down a little bit
&gt; (~10 less writes per second). Shouldn't the max\_open\_files setting keep the
&gt; total amount of fd's pretty low? Maybe I'm misunderstanding what that option
&gt; is used for.
&gt;
&gt; Patrick
&gt;
&gt; On Sep 26, 2011, at 2:34 PM, Jon Meredith wrote:
&gt;
&gt; Hi Patrick,
&gt;
&gt; You may be running out of ports which erlang uses for TCP sockets - try
&gt; increasing ERL\_MAX\_PORTS in etc/vm.args
&gt;
&gt; Cheers, Jon
&gt; Basho Technologies.
&gt;
&gt; On Mon, Sep 26, 2011 at 12:17 PM, Patrick Van Stee  &gt; wrote:
&gt;
&gt;&gt; We're running a small, 2 node riak cluster (on 2 m1.large boxes) using the
&gt;&gt; LevelDB backend and have been trying to write ~250 keys a second at it. With
&gt;&gt; a small dataset everything was running smoothly. However, after storing
&gt;&gt; several hundred thousand keys some performance issues started to show up.
&gt;&gt;
&gt;&gt; \* We're running out of file descriptors which is causing nodes to crash
&gt;&gt; with the following error:
&gt;&gt;
&gt;&gt; 2011-09-24 00:23:52.097 [error] &lt;0.110.0&gt; CRASH REPORT Process [] with 0
&gt;&gt; neighbours crashed with reason: {error,accept\_failed}
&gt;&gt; 2011-09-24 00:23:52.098 [error] &lt;0.121.0&gt; application: mochiweb, "Accept
&gt;&gt; failed error", "{error,emfile}
&gt;&gt;
&gt;&gt; Setting the max\_open\_files limit in the app.config doesn't seem to help.
&gt;&gt;
&gt;&gt; \* Writes have slowed down by an order of magnitude. I even set the n\_val,
&gt;&gt; w, and dw bucket properties to 1 without any noticeable difference. Also we
&gt;&gt; switched to using protocol buffers to make sure there wasn't any extra
&gt;&gt; overhead when using HTTP.
&gt;&gt;
&gt;&gt; \* Running map reduce jobs that use a range query on a secondary index
&gt;&gt; started returning an error, {"error":"map\_reduce\_error"}, once our dataset
&gt;&gt; increased in size. Feeding a list of keys works fine, but querying the index
&gt;&gt; for keys seems to be timing out:
&gt;&gt;
&gt;&gt; 2011-09-26 16:37:57.192 [error] &lt;0.136.0&gt; Supervisor riak\_pipe\_fitting\_sup
&gt;&gt; had child undefined started with {riak\_pipe\_fitting,start\_link,undefined} at
&gt;&gt; &lt;0.3497.0&gt; exit with reason
&gt;&gt; {timeout,{gen\_server,call,[{riak\_pipe\_vnode\_master,'riak@10.206.105.52
&gt;&gt; '},{return\_vnode,{'riak\_vnode\_req\_v1',502391187832497878132516661246222288006726811648,{raw,#Ref&lt;0.0.1.88700&gt;,&lt;0.3500.0&gt;},{cmd\_enqueue,{fitting,&lt;0.3499.0&gt;,#Ref&lt;0.0.1.88700&gt;,#Fun,#Fun},{&lt;&lt;"ip\_queries"&gt;&gt;,&lt;&lt;"uaukXZn5rZQ0LrSED3pi-fE-JjU"&gt;&gt;},infinity,[{502391187832497878132516661246222288006726811648,'
&gt;&gt; riak@10.206.105.52'}]}}}]}} in context child\_terminated
&gt;&gt;
&gt;&gt; Is anyone familiar with these problems or is there anything else I can try
&gt;&gt; to increase the performance when using LevelDB?
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

