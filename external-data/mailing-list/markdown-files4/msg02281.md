---
title: "Re: Is Riak right for me?"
description: ""
project: community
lastmod: 2011-02-11T11:14:00-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg02281"
mailinglist_parent_id: "msg02280"
author_name: "Mike Stoddart"
project_section: "mailinglistitem"
sent_date: 2011-02-11T11:14:00-08:00
---


Cool - some very useful information. Much appreciated. I need to
digest this a bit before replying with more questions. I'm still
trying to understand map/reduce so I'm struggling to get my head
around how to apply it to my requirements. I'm obviously used to
indexing. :)

Thanks
Mike

On Fri, Feb 11, 2011 at 9:23 AM, Sean Cribbs  wrote:
&gt; Mike,
&gt;
&gt; Sounds like an interesting project. Here are some things to think about 
&gt; (corresponding to your bullet points):
&gt;
&gt; 1) What seems fairly natural and obvious for key choice is the timestamp, 
&gt; since so many of your operations are time-oriented.
&gt; 2) For playback of historical data, consider using MapReduce to grab more 
&gt; than just single seconds of data... maybe 30 at a time.  You could even put 
&gt; some of your preprocessing into the map or reduce phase.  Make sure to 
&gt; generate the key list (since you'll know them) instead of trying to do a 
&gt; full-bucket query with filtering.
&gt; 3) Beware of race-conditions and the possibility of not all clients seeing 
&gt; the data right away.  This can be somewhat alleviated by using DW=W=quorum 
&gt; when writing, but you're still talking about dogpiling a bunch of requests on 
&gt; the same key. An in-memory write-through cache of the "latest second" might 
&gt; be what you need here.
&gt; 4) This is another case where you could use MapReduce to crunch the data. 60 
&gt; items is not very much, so I think you'll have good results here. The 
&gt; internal MapReduce cache will also reduce the pain of multiple computations 
&gt; on the same data.
&gt;
&gt; All in all, I think Riak will be a good fit for your application, with the 
&gt; possible exception of the polling-every-second thing.  A couple of tips to 
&gt; make sure you have a good experience with Riak:
&gt;
&gt; First, benchmark your usage pattern as best you can to make sure that Riak 
&gt; will meet your performance needs.  For example, I might create some 
&gt; basho\_bench tests with appropriate key and value generators that have:
&gt;
&gt; a) 1 write per second (the snapshot data)
&gt; b) X reads per second (where X is the number of expected clients)
&gt; c) 1-5 historical replays per second (via MapReduce)
&gt; d) X roll-up reports per minute (X = number of clients again)
&gt;
&gt; I'd then run them concurrently, and in different combinations to simulate the 
&gt; load.
&gt;
&gt; Second, make sure you start with at least 3 nodes (even in your local 
&gt; developer setup).  Because Riak is designed to be distributed, there are 
&gt; certain things that are sub-optimal when the number of nodes is less than the 
&gt; replication factor (N value, default 3).
&gt;
&gt; Let us know if there's anything else we can help you with.
&gt;
&gt; Sean Cribbs 
&gt; Developer Advocate
&gt; Basho Technologies, Inc.
&gt; http://basho.com/
&gt;
&gt; On Feb 11, 2011, at 8:49 AM, Mike Stoddart wrote:
&gt;
&gt;&gt; Riak is very appealing for several reasons; scalability, durability,
&gt;&gt; open-source, performance etc. I'm currently using PostgreSQL for all
&gt;&gt; my storage needs, but I'm investigating nosql (can I use that name?)
&gt;&gt; solutions for scalability and to experiment with map/reduce
&gt;&gt; functionality for statistics and reporting.
&gt;&gt;
&gt;&gt; I have a few requirements that nosql solutions might not be able to meet.
&gt;&gt;
&gt;&gt; 1) Every second I take a snapshot of my data and store it in the
&gt;&gt; database in one record. Each recorded snapshot includes the timestamp
&gt;&gt; it was taken.
&gt;&gt;
&gt;&gt; 2) I have a playback feature that lets me retrieve historical data.
&gt;&gt; During playback, the browser requests a recorded snapshot every
&gt;&gt; second:
&gt;&gt;
&gt;&gt;   2011-01-01 08:00:00
&gt;&gt;   2011-01-01 08:00:01
&gt;&gt;   2011-01-01 08:00:02
&gt;&gt;   2011-01-01 08:00:03 ...
&gt;&gt;
&gt;&gt; Currently it takes less than 75ms for the server to retrieve the data
&gt;&gt; from PostgreSQL and to return it to the browser. Some processing is
&gt;&gt; done before the response is sent.
&gt;&gt;
&gt;&gt; 3) Every second each client's browser requests the current data
&gt;&gt; snapshot (i.e. not in playback mode). The same comment for timing and
&gt;&gt; processing applies from 2).
&gt;&gt;
&gt;&gt; 4) Every minute I retrieve statistics and a report for a specific type
&gt;&gt; of data to present on the browser. Currently with PostgreSQL this
&gt;&gt; takes about 2-3s for the web server to retrieve the data, process it
&gt;&gt; and return it to the browser.
&gt;&gt;
&gt;&gt; The only primary key I use is a serial integer, only because that's
&gt;&gt; the default. I don't see anything in my data that would be useful as a
&gt;&gt; key when using a key/value database. My data is a good fit for storing
&gt;&gt; as a 'document' though.
&gt;&gt;
&gt;&gt; I know there might not be enough information here but do you think
&gt;&gt; Riak is a good fit?
&gt;&gt;
&gt;&gt; Thanks
&gt;&gt; Mike
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

