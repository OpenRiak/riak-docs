---
title: "Re: Riak replication: can nodes replicate from clean to operational	state without re-adding them to cluster?"
description: ""
project: community
lastmod: 2014-04-03T01:05:22-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13982"
mailinglist_parent_id: "msg13973"
author_name: "Seth Thomas"
project_section: "mailinglistitem"
sent_date: 2014-04-03T01:05:22-07:00
---


Responses inline.

On Wed, Apr 2, 2014 at 3:42 AM, Igor Kukushkin  wrote:

&gt; Hi all.
&gt;
&gt; Here's a simple scenario that we're planning to test: a cluster of 4
&gt; nodes, 2 are normal eleveldb'backend nodes and 2 are stored on RAM
&gt; (with same eleveldb backend).
&gt;

Going to put this out here right now, this is a very non-standard setup.
Riak treats all nodes equally, keys are consistently hashed across the
cluster, and there is no in-built weighting. I'd either make faster LevelDB
nodes (maybe with SSDs) or go full in on the RAM angle and just have enough
machines for failover. Spitting the difference doesn't really get you any
advantages with Riak. You're also still below the 5 node threshold so there
is still unrealized performance being left on the table before even getting
to the physical node attributes.

&gt;
&gt; We plan to use RAM nodes as a fast "frontend".
&gt;
&gt;
&gt; Question A:
&gt; RAM disks are completely volatile, so nodes will restart with no data
&gt; stored.
&gt; So, what will happen at restart? If a Riak node is restarted in a
&gt; "clean" state (no data, same state as it was on creation), will it
&gt; receive the state from disk nodes? Or it's required to re-add it to
&gt; cluster?
&gt;

If you have AAE[1] enabled then the node would begin rebuilding itself if
already a member of the cluster. Depending on the amount of data rebuild
times may not be ideal.

&gt;
&gt; Question B: due to huge speed difference between on-disk and on-RAM
&gt; backend, should any replication side-effects be expected?
&gt;
 Latency profiles are going to be weird - if you make a request (Assuming
default N/R/W) then Riak will still have to query 2 nodes minimum on a GET
and as keys are consistently hashed there is no controlling where they
live. So you could on any given query completely negate the speed advantage
of running the RAM backed nodes.

&gt;
&gt; Quesion C: should we use memory\_backend + leveldb\_backend nodes
&gt; together instead of building that? Does Riak networking topology
&gt; allows for mixed backends?
&gt;
It depends on what you're trying to achieve but it's entirely possible.
Riak support multi-backends per node, in fact that is how Riak CS works, so
running memory and levelDB on each node is a viable option. So yes, Riak
definitely supports running multiple backends per node. It's worth noting
that Riak will "happily" run with different/mixed backends on each node
(say 3 nodes levelDB and 1 Bitcask) and still mostly work as it's largely
agnostic to the specific backend unless doing an operation specific to that
backend (like a 2i query).

&gt; --
&gt; Igor
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

