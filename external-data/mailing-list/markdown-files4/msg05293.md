---
title: "RE: Join a Riak-1.0 node to a Riak-0.14 cluster"
description: ""
project: community
lastmod: 2011-10-25T02:49:07-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05293"
mailinglist_parent_id: "msg05281"
author_name: "Tomer Naor"
project_section: "mailinglistitem"
sent_date: 2011-10-25T02:49:07-07:00
---


Thanks for the answer.

Far as I see the read-repair is not so applicable for us. It requires to know 
beforehand all the keys that is written in the system and due to the fact that 
we have more than 180,000,000 keys it makes the read-repair not so relevant 
(not for list-keys operation and not for read requests).

I saw the 'Raplacing-a-Node' instruction on wiki which might be a good solution 
but I still fears from troubles with this approach.
http://wiki.basho.com/Replacing-a-Node.html

this are the steps as described on wiki:

 1. Tar up your data directory on the node in question (which should be found 
at riak/data).
 2. Download and install Riak on the new node you wish to bring into the 
cluster. Don't start it just yet.
 3. Copy the data from the node you're decommissioning to the new machine and 
untar it. Also make sure to copy the existing ring file to the new node.
 4. Run reip on the new node.
 5. Stop the old node using riak stop.
 6. Start the new machine with riak start.


Few questions:
- About step 2: If I already started the node and 'reip' it before I begin the 
replacing process, will it prevent me from doing the 'Replacing' operation?
- About step 3: I understand this steps as: copy the 'bitcask' directory and 
the 'ring' directory, what about the 'kv\_node' directory?

-After a success replacing operation, do we still need to expect to replicas 
problems which will require us to do read-repair?

Thanks,
Tomer.



-----Original Message-----
From: Joseph Blomstedt [mailto:j...@basho.com] 
Sent: Monday, October 24, 2011 22:06
To: Tomer Naor
Cc: Sean Cribbs; riak-users@lists.basho.com
Subject: Re: Join a Riak-1.0 node to a Riak-0.14 cluster

Tomer,

The issues you encountered aren't related to having a mixed 0.14/1.0
cluster, or the overall upgrade cycle. They're issues with 0.14 Riak.

In pre-1.0 Riak, GETs would sometimes return 404s when adding/removing
nodes to a cluster. The situation would be transient, and would sort
itself out after the cluster stabilized, but there would be a period
in which this behavior could occur. This has been fixed in Riak 1.0.
However, the new protocol that fixes this does not take effect until
the entire cluster is 1.0 nodes.

Likewise, in 0.14 Riak there are instances in which a node would not
finish handing off all its data before leaving. This has also been
fixed in Riak 1.0. This behavior should be extremely rare, however,
and isn't something that will normally happen. Your best bet is to
rely on read-repair to restore your lost replicas. Simply re-reading
your entire dataset using HEAD requests will ensure lost replicas are
restored. There is also a manual approach you can consider, but I
would only recommend that on a production server for users with a
support contract who can get immediate help if things run awry:
https://help.basho.com/entries/20580987-node-left-cluster-before-handing-off-all-data-how-can-i-resolve

Read-repair is likely the safest route.

Again, all of these issue were resolved in Riak 1.0. But, until you
have a full 1.0 cluster, you may still run into them.

The issue Mark Smith brought up is related to replica restoration when
handoff didn't occur. Such as using 'riak-admin remove' rather than
'riak-admin leave'. If you remove a node without handoff (say, a
failed node), Riak won't automatically restore replicas (yet). But, in
normal cases, 'riak-admin leave' (which is different than remove),
will ensure handoff of replicas before shutting down. It just so
happens that 0.14 nodes sometimes would leave prematurely. Read-repair
works for both cases because the problem is fundamentally lost
replicas. However, in the premature leave case, there's also the
manual approach to consider.

-Joe

On Mon, Oct 24, 2011 at 11:06 AM, Tomer Naor  wrote:
&gt; Well, it caused us some problems.
&gt;
&gt;
&gt;
&gt; The situation is as follows:
&gt;
&gt; we have a production cluster with five 0.14 nodes and which we want to
&gt; replace with three new Riak 1.0.1 servers.
&gt;
&gt;
&gt;
&gt; This is what we did:
&gt;
&gt; 1.       join each of the 1.0 nodes to the 0.14 cluster.
&gt;
&gt; 2.       after that all the three 1.0 nodes were part of the ring members
&gt; and handoff was over we did 'admin-riak leave' on one of the 0.14 nodes
&gt; (eventually we'll need to leave them all).
&gt;
&gt;
&gt;
&gt; The problem is that it looks like not all the data from the 0.14 node were
&gt; handoff in the leaving process and it seems like we've lost some data.
&gt;
&gt; (Don't know if it's matter but the bitcask of the 0.14 node that we tried to
&gt; 'riak-admin leave' was reduced from 120GB to 55GB)
&gt;
&gt;
&gt;
&gt; Another problem that we noticed is that the basic get api not always
&gt; returned a consistent response, it sometimes returned the required data and
&gt; sometimes returned 404 status code.
&gt;
&gt;
&gt;
&gt; what is the best/right/safe way to do it without losing data and without
&gt; experience significant downtime as a result of the join and leave process.
&gt;
&gt;
&gt;
&gt; Thanks,
&gt;
&gt; Tomer.
&gt;
&gt;
&gt;
&gt; From: Sean Cribbs [mailto:s...@basho.com]
&gt; Sent: Wednesday, October 12, 2011 14:37
&gt; To: Tomer Naor
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Join a Riak-1.0 node to a Riak-0.14 cluster
&gt;
&gt;
&gt;
&gt; It is possible but requires a slight modification from the directions
&gt; in http://wiki.basho.com/Rolling-Upgrades.html.  When adding the new 1.0
&gt; node, make sure these settings are in the 'riak\_kv' section of its
&gt; app.config:
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; {legacy\_keylisting, true},
&gt;
&gt; {mapred\_system, legacy},
&gt;
&gt; {vnode\_vclocks, false}
&gt;
&gt; This will ensure that it does not try to use functionality that is
&gt; unavailable on the 0.14.2 nodes.
&gt;
&gt;
&gt;
&gt; On Wed, Oct 12, 2011 at 6:30 AM, Tomer Naor  wrote:
&gt;
&gt; Hi,
&gt;
&gt;
&gt;
&gt; Is it possible to join a Riak-1.0 node (not from rolling upgrade - new
&gt; server with fresh 1.0.0 installation) to a cluster with Riak-0.14 nodes
&gt; without any unexpected problems?
&gt;
&gt;
&gt;
&gt; Thanks,
&gt;
&gt; Tomer.
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
&gt;
&gt; --
&gt; Sean Cribbs 
&gt;
&gt; Developer Advocate
&gt;
&gt; Basho Technologies, Inc.
&gt;
&gt; http://www.basho.com/
&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;



-- 
Joseph Blomstedt 
Software Engineer
Basho Technologies, Inc.
http://www.basho.com/

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

