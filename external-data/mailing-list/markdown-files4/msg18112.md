---
title: "Re: RiakTS Query Question"
description: ""
project: community
lastmod: 2017-03-31T05:15:46-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg18112"
mailinglist_parent_id: "msg18110"
author_name: "Andrei Zavada"
project_section: "mailinglistitem"
sent_date: 2017-03-31T05:15:46-07:00
---


Hi Joe,

First of all, updates in Riak TS are not safe. There are write-once
optimizations which take shortcuts in the logic that ensures your
writes are consistent. In the simplest scenario of a single client
doing the writes at one and the same node of a cluster that completes
the writing faster than the client issues a new request, and no
partitions occur, data will be successfully overwritten. If any of the
above conditions are not met, you may see old values in subsequent
reads.

That said, there is no difference, in terms of amount of data going
from coordinator to the leveldb nodes, between initial (clean) writes
and overwrites. If you do a deletion before writing, however, the full
record will be read (but not delivered from the eleveldb node to the
coordinator). The latter issue was fixed in
https://github.com/basho/riak\_kv/pull/1630 and should be gone in 1.6.

Regards,
Andrei

On Thu, Mar 30, 2017 at 5:06 PM, Joe Olson  wrote:
&gt;&gt;So no, the 1M blobs will be read from the leveldb backend, and they will
&gt;&gt; hog the bandwidth between storage and coordinator nodes.
&gt;
&gt;
&gt; Ok that is what I thought. Thanks for the info.
&gt;
&gt;
&gt; One more question...what is the penalty for doing an in place update (i.e.
&gt; an insert of the same exact keys) of the BLOB in the same situation? I have
&gt; a new blob, and I want to overwrite the BLOB field with a new one. Obviously
&gt; I'll have to pay to shuffle the new blob around the cluster. Am I paying the
&gt; same as it were a clean, new insert? Do I get to re-use the existing
&gt; (already sorted in its correct place) record, and just update the object
&gt; component? Or when I do a duplicate insert, am I paying the price for a
&gt; delete + insert?
&gt;
&gt;
&gt; Thanks again!
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; From: Andrei Zavada 
&gt; Sent: Wednesday, March 29, 2017 3:14:58 PM
&gt; To: Alexander Sicular
&gt; Cc: Joe Olson; riak-users@lists.basho.com
&gt; Subject: Re: RiakTS Query Question
&gt;
&gt; Joe,
&gt;
&gt; TS records in a given table all have the same structure and are stored
&gt; and retrieved as single objects (in Riak KV sense); the backend cannot
&gt; introspect them and only extract some fields.
&gt;
&gt; Full records are read from backend and these are delivered, in chunks,
&gt; to the coordinator node (the node your client has connected to). On
&gt; receipt, columns not appearing in the SELECT clause are dropped; thus,
&gt; only the relevant columns are kept while the coordinator collects the
&gt; remaining chunks. From there, records are shipped to the client (via
&gt; temp tables if the query had an ORDER BY or LIMIT clause).
&gt;
&gt; So no, the 1M blobs will be read from the leveldb backend, and they
&gt; will hog the bandwidth between storage and coordinator nodes. They
&gt; will not appear in the traffic going from the coordinator to the
&gt; client, though.
&gt;
&gt; Andrei
&gt;
&gt; On Wed, Mar 29, 2017 at 10:17 PM, Alexander Sicular 
&gt; wrote:
&gt;&gt; I'm not 100% certain but I do not believe that is the case. Part of the
&gt;&gt; reason for structured data is efficient retrieval. I believe the data is
&gt;&gt; read but only the data selected leaves the leveldb backend, unselected
&gt;&gt; data
&gt;&gt; never leaves leveldb so there's no overhead when passing data from level
&gt;&gt; to
&gt;&gt; Riak or on the network.
&gt;&gt;
&gt;&gt; I defer to the engineering folks working on TS tho.
&gt;&gt;
&gt;&gt; -Alexander
&gt;&gt;
&gt;&gt; @siculars
&gt;&gt; http://siculars.posthaven.com
&gt;&gt;
&gt;&gt; Sent from my iRotaryPhone
&gt;&gt;
&gt;&gt; On Mar 29, 2017, at 15:08, Joe Olson  wrote:
&gt;&gt;
&gt;&gt; Suppose I have the following table in RiakTS:
&gt;&gt;
&gt;&gt;
&gt;&gt; CREATE TABLE T1 (
&gt;&gt;
&gt;&gt; id VARCHAR NOT NULL,
&gt;&gt;
&gt;&gt; eventtime TIMESTAMP NOT NULL,
&gt;&gt;
&gt;&gt; field2 SINT64,
&gt;&gt;
&gt;&gt; data BLOB NOT NULL,
&gt;&gt;
&gt;&gt; primary key (id, QUANTUM(eventtime, 365, 'd')),id)
&gt;&gt;
&gt;&gt; )
&gt;&gt;
&gt;&gt;
&gt;&gt; Assume the BLOB field is close to the max size for a RiakTS BLOB value
&gt;&gt; (~1MB)
&gt;&gt;
&gt;&gt;
&gt;&gt; Suppose I want to execute the following query:
&gt;&gt;
&gt;&gt;
&gt;&gt; Select id, eventtime, field2 from T1 where ((id = ID1) and (eventtime &gt;=
&gt;&gt; T1
&gt;&gt; and eventtime &lt; T2))
&gt;&gt;
&gt;&gt;
&gt;&gt; I only want the SINT64 field, not the 1MB BLOB.
&gt;&gt;
&gt;&gt;
&gt;&gt; Am I paying for the bandwidth for the RiakTS cluster to pass around
&gt;&gt; (internally) the 1MB BLOB field just to get the SINT64 field?
&gt;&gt;
&gt;&gt;
&gt;&gt; If so, is there a way to avoid this, besides creating a second table
&gt;&gt; without
&gt;&gt; the BLOB field?
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

