---
title: "Re: Have Riak servers in separate cluster behind a load balancer,	or on same machines as web server?"
description: ""
project: community
lastmod: 2011-10-04T16:04:38-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05039"
mailinglist_parent_id: "msg05037"
author_name: "Jeremiah Peschka"
project_section: "mailinglistitem"
sent_date: 2011-10-04T16:04:38-07:00
---


The only thing I have to add is that I'd avoid option B like the plague. 
Spinning up and spinning down nodes in a cluster is going to result in a lot of 
gossip around the ring, especially when we already know that comms in AWS are a 
bit spotty.

I'm assuming that you're not talking about elastic load balancers - those don't 
work for communication within AWS.

You could also use a virtual private cloud for your setup to minimize traffic 
from the outside world.
---
Jeremiah Peschka - Founder, Brent Ozar PLF, LLC
Microsoft SQL Server MVP

On Oct 4, 2011, at 3:59 PM, Greg Stein wrote:

&gt; I'm with Kyle on this one. Even better, my 'newhttp' branch on Github
&gt; enables this kind of multiple-connection and automatic fail-over.
&gt; 
&gt; That branch does have a basic sketch for automatic addition/removal of
&gt; Riak nodes as you manipulate your cluster. I'll need it one day, but
&gt; not "now", so I haven't finished it yet (the monitor.py background
&gt; thread).
&gt; 
&gt; Regarding security: it is the same for option A and B and C (you're
&gt; just shifting stuff around, but it is pretty much all the same). Put
&gt; your webservers in one security group, and the Riak nodes in another.
&gt; Open the Riak ports \*only\* to the webserver security group and to each
&gt; other.
&gt; 
&gt; Avoiding two services on one machine (e.g web + riak) is also much
&gt; easier to manage/maintain. Just have web machines and riak machines.
&gt; 
&gt; Cheers,
&gt; -g
&gt; 
&gt; On Tue, Oct 4, 2011 at 17:09, Aphyr  wrote:
&gt;&gt; Option C: Deploy your web servers with a list of hosts to connect to. Have
&gt;&gt; the clients fail over when a riak node goes down. Lower latency without
&gt;&gt; sacrificing availability. If you're using protobufs, this may not be as big
&gt;&gt; of an issue.
&gt;&gt; 
&gt;&gt; --Kyle
&gt;&gt; 
&gt;&gt; On 10/04/2011 02:04 PM, O'Brien-Strain, Eamonn wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt; I am contemplating two different architectures for deploying Riak nodes
&gt;&gt;&gt; and web servers.
&gt;&gt;&gt; 
&gt;&gt;&gt; Option A: Riak nodes are in their own cluster of dedicated machines
&gt;&gt;&gt; behind a load balancer. Web servers talk to the Riak nodes via the load
&gt;&gt;&gt; balancer. (See diagram http://eamonn.org/i/riak-arch-A.png )
&gt;&gt;&gt; 
&gt;&gt;&gt; Option B: Each web server machine also has a Riak node, and there are also
&gt;&gt;&gt; some Riak-only machines. Each web server only talks to its own localhost
&gt;&gt;&gt; Riak node. (See diagram http://eamonn.org/i/riak-arch-B.png )
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; All machines will deployed as elastic cloud instances. I will want to
&gt;&gt;&gt; spin up and spin down instances, particularly the web servers, as demand
&gt;&gt;&gt; varies. Both load balancers are non-sticky. Web servers are currently
&gt;&gt;&gt; talking to Riak via HTTP (though might change that to protocol buffers in
&gt;&gt;&gt; the future). Currently Riak is configured with the default options.
&gt;&gt;&gt; 
&gt;&gt;&gt; Here is my thinking of the comparative advantages:
&gt;&gt;&gt; 
&gt;&gt;&gt; Option A:
&gt;&gt;&gt; 
&gt;&gt;&gt; - Better for security, because can lock down the Riak load balancer to
&gt;&gt;&gt; only open a single port and only for connections from the web servers.
&gt;&gt;&gt; - Less churn for Riak of nodes entering and leaving the Riak cluster (as
&gt;&gt;&gt; web servers spin up and down)
&gt;&gt;&gt; - More flexibility in scaling storage and web tiers independently of each
&gt;&gt;&gt; other
&gt;&gt;&gt; 
&gt;&gt;&gt; Option B:
&gt;&gt;&gt; 
&gt;&gt;&gt; - Faster localhost connection from web server to Riak
&gt;&gt;&gt; 
&gt;&gt;&gt; I think availability is similar for the two options.
&gt;&gt;&gt; 
&gt;&gt;&gt; The web server response time is the primary metric I want to optimize.
&gt;&gt;&gt; Most web server requests will cause several requests to Riak.
&gt;&gt;&gt; 
&gt;&gt;&gt; What other factors should I take into account? What measurements could I
&gt;&gt;&gt; make to help me decide between the architectures? Are there other
&gt;&gt;&gt; architectures I should consider? Should I add memcached? Does anyone have
&gt;&gt;&gt; any experiences they could share in deploying such systems?
&gt;&gt;&gt; 
&gt;&gt;&gt; Thanks.
&gt;&gt;&gt; \_\_
&gt;&gt;&gt; Eamonn
&gt;&gt;&gt; 
&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; 
&gt; 
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com


\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

