---
title: "Re: Recommended way to delete keys"
description: ""
project: community
lastmod: 2015-06-05T07:39:06-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16215"
mailinglist_parent_id: "msg16198"
author_name: "Matthew Brender"
project_section: "mailinglistitem"
sent_date: 2015-06-05T07:39:06-07:00
---


There are a few follow-ups on my mind:

Peter, it's good that you found an easy fix for now. I'd still love to
have a better answer on hand for you in the future.

John, could you share this rig you mention with me? I'll fork it to
Basho Labs [1] if you have it on GitHub already or help clean up and
post it to GitHub. I'm glad to give you credit and maintainer status
and it'd be good for others to find your solution.

Lastly, I'm also curious if anyone built a gradual deletion process on
Erlang. It'd be cool if (a) I can fork this as well or (b) Peter can
pair up with someone else to program it.

Thank you all - this thread has been really thoughtful.

[1] https://github.com/basho-labs/

Matt Brender | Developer Advocacy Lead
Basho Technologies
t: @mjbrender


On Thu, Jun 4, 2015 at 5:54 PM, John O'Brien  wrote:
&gt;
&gt; We've got an expiry worker rig I can likely pass over offline. Its not overly 
&gt; clever.
&gt;
&gt; Basic idea stream a feed of keys into a pool of workers that spin off delete 
&gt; calls.
&gt; We feed this based on continuous search's of an expiry TTL field in all keys.
&gt;
&gt; It'd likely be better to run this from with the Erlang riak layer... But then 
&gt; there's that whole Erlang thing.
&gt;
&gt; J
&gt;
&gt; On Jun 4, 2015 1:49 PM, "Peter Herndon"  wrote:
&gt;&gt;
&gt;&gt; Mmm, I think we’re looking at deleting about 50 million keys per day. That’s 
&gt;&gt; a completely back-of-envelope estimate, I haven’t done the actual math yet.
&gt;&gt;
&gt;&gt; —Peter
&gt;&gt;
&gt;&gt; &gt; On Jun 4, 2015, at 3:28 AM, Daniel Abrahamsson 
&gt;&gt; &gt;  wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Hi Peter,
&gt;&gt; &gt;
&gt;&gt; &gt; What is "large-scale" in your case? How many keys do you need to delete, 
&gt;&gt; &gt; and how often?
&gt;&gt; &gt;
&gt;&gt; &gt; //Daniel
&gt;&gt; &gt;
&gt;&gt; &gt; On Wed, Jun 3, 2015 at 9:54 PM, Peter Herndon  wrote:
&gt;&gt; &gt; Interesting thought. It might work for us, it might not, I’ll have to 
&gt;&gt; &gt; check with our CTO to see whether the expense makes sense under our 
&gt;&gt; &gt; circumstances.
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks!
&gt;&gt; &gt;
&gt;&gt; &gt; —Peter
&gt;&gt; &gt; &gt; On Jun 3, 2015, at 2:21 PM, Drew Kerrigan  wrote:
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; Another idea for a large-scale one-time removal of data, as well as an 
&gt;&gt; &gt; &gt; opportunity for a fresh start, would be to:
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; 1. set up multi-data center replication between 2 clusters
&gt;&gt; &gt; &gt; 2. implement a recv/2 hook on the sink which refuses data from the 
&gt;&gt; &gt; &gt; buckets / keys you would like to ignore / delete
&gt;&gt; &gt; &gt; 3. trigger a full sync replication
&gt;&gt; &gt; &gt; 4. start using the sync as your new source of data sans the ignored data
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; Obviously this is costly, but it should have a fairly minimal impact to 
&gt;&gt; &gt; &gt; existing production users other than the moment that you switch traffic 
&gt;&gt; &gt; &gt; from the old cluster to the new one.
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; Caveats: Not all Riak features are supported with MDC (search indexes 
&gt;&gt; &gt; &gt; and strong consistency in particular).
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; On Wed, Jun 3, 2015 at 2:11 PM Peter Herndon  wrote:
&gt;&gt; &gt; &gt; Sadly, this is a production cluster already using leveldb as the 
&gt;&gt; &gt; &gt; backend. With that constraint in mind, and rebuilding the cluster not 
&gt;&gt; &gt; &gt; really being an option to enable multi-backends or bitcask, what would 
&gt;&gt; &gt; &gt; our best approach be?
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; Thanks!
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; —Peter
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; On Jun 3, 2015, at 12:09 PM, Alexander Sicular  
&gt;&gt; &gt; &gt; &gt; wrote:
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; We are actively investigating better options for deletion of large 
&gt;&gt; &gt; &gt; &gt; amounts of keys. As Sargun mentioned, deleting the data dir for an 
&gt;&gt; &gt; &gt; &gt; entire backend via an operationalized rolling restart is probably the 
&gt;&gt; &gt; &gt; &gt; best approach right now for killing large amounts of keys.
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; But if your key space can fit in memory the best way to kill keys is 
&gt;&gt; &gt; &gt; &gt; to use bitcask ttl if that's an option. 1. If you can even use bitcask 
&gt;&gt; &gt; &gt; &gt; in your environment due to the memory overhead and 2. If your use case 
&gt;&gt; &gt; &gt; &gt; allows for ttls which it may considering you may already be using time 
&gt;&gt; &gt; &gt; &gt; bound buckets....
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; -Alexander
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; @siculars
&gt;&gt; &gt; &gt; &gt; http://siculars.posthaven.com
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; Sent from my iRotaryPhone
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt; On Jun 3, 2015, at 09:54, Sargun Dhillon  wrote:
&gt;&gt; &gt; &gt; &gt;
&gt;&gt; &gt; &gt; &gt;&gt; You could map your keys to a given bucket, and that bucket to a given 
&gt;&gt; &gt; &gt; &gt;&gt; backend using multi\_backend. There is some cost to having lots of 
&gt;&gt; &gt; &gt; &gt;&gt; backends (memory overhead, FDs, etc...). When you want to do a mass 
&gt;&gt; &gt; &gt; &gt;&gt; drop, you could down the node, and delete that given backend, and 
&gt;&gt; &gt; &gt; &gt;&gt; bring it up. Caveat: AAE, MDC, nor mutable data play well with this 
&gt;&gt; &gt; &gt; &gt;&gt; scenario.
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; On Wed, Jun 3, 2015 at 10:43 AM, Peter Herndon  
&gt;&gt; &gt; &gt; &gt;&gt; wrote:
&gt;&gt; &gt; &gt; &gt;&gt; Hi list,
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; We’re looking for the best way to handle large scale expiration of 
&gt;&gt; &gt; &gt; &gt;&gt; no-longer-useful data stored in Riak. We asked a while back, and the 
&gt;&gt; &gt; &gt; &gt;&gt; recommendation was to store the data in time-segmented buckets 
&gt;&gt; &gt; &gt; &gt;&gt; (bucket per day or per month), query on the current buckets, and use 
&gt;&gt; &gt; &gt; &gt;&gt; the streaming list keys API to handle slowly deleting the buckets 
&gt;&gt; &gt; &gt; &gt;&gt; that have aged out.
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; Is that still the best approach for doing this kind of task? Or is 
&gt;&gt; &gt; &gt; &gt;&gt; there a better approach?
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; Thanks!
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; —Peter Herndon
&gt;&gt; &gt; &gt; &gt;&gt; Sr. Application Engineer
&gt;&gt; &gt; &gt; &gt;&gt; @Bitly
&gt;&gt; &gt; &gt; &gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; &gt; &gt;&gt; riak-users mailing list
&gt;&gt; &gt; &gt; &gt;&gt; riak-users@lists.basho.com
&gt;&gt; &gt; &gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt; &gt; &gt;&gt;
&gt;&gt; &gt; &gt; &gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; &gt; &gt;&gt; riak-users mailing list
&gt;&gt; &gt; &gt; &gt;&gt; riak-users@lists.basho.com
&gt;&gt; &gt; &gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt;
&gt;&gt; &gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; &gt; riak-users mailing list
&gt;&gt; &gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

