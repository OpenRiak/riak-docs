---
title: "Re: May allow_mult cause DoS?"
description: ""
project: community
lastmod: 2013-12-18T21:20:05-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13297"
mailinglist_parent_id: "msg13292"
author_name: "Viable Nisei"
project_section: "mailinglistitem"
sent_date: 2013-12-18T21:20:05-08:00
---


Hi

On Thu, Dec 19, 2013 at 3:07 AM, Rune Skou Larsen  wrote:

&gt; Save the transaction list inside the customer object keyed by customerid.
&gt; Index this object with 2i on storeids for each contained tx.
&gt;
&gt; Not so good idea. Transactions may be running in parallel, but there is no
atomic operations in Riak, or lock managers or UPDATE operation knowing
about blob structure. Risk of race condition is not so high but it exists.


&gt; If some customer objects grow too big, you can move old txs into archive
&gt; objects keyed by customerid\_seqno. For your low latency customer reads, you
&gt; probably only need the newest txs anyway.
&gt;
&gt; Yeah, we've considered approaches similar to this, but rejected this due
to race conditions. Also we've considered some kind of DLM (like
ZooKeeper), but if we need DLM, we'll just use hadoop/cassandra/hbase...

That's just one idea. Trifork will be happy to help you find a suitable
&gt; model for your use cases.
&gt;
&gt; Ok, but such idea doesn't look as something mind-blowing...we have
considered this idea and many other approaches. Also what may be anwser for
STORE-TRANSACTION binding? Just mapred?..


&gt; We usually do this by stress-testing a simulation with realistic data
&gt; sizes/shapes and access patterns.

Same for us. We using tsung (scripts are generated, tsung is slightly
automated with some pieces of erlang code) and some custom multithreaded
scenarios like I've mentioned in op-message.


&gt; It's fastest if we come onsite for a couple of days and work with you to
&gt; set it up, but we can also help you offsite.
&gt;

Write me if you're interested, then we can do a call.
&gt;
I'm interested, but for now it looks like that there is no prefect solution
(the only untested approach left is custom indexing on riak side), so I
don't really sure if we should pay to just confirm that there is no real
solution...


On Thu, Dec 19, 2013 at 3:07 AM, Rune Skou Larsen  wrote:

&gt; Save the transaction list inside the customer object keyed by customerid.
&gt; Index this object with 2i on storeids for each contained tx.
&gt;
&gt; If some customer objects grow too big, you can move old txs into archive
&gt; objects keyed by customerid\_seqno. For your low latency customer reads, you
&gt; probably only need the newest txs anyway.
&gt;
&gt; That's just one idea. Trifork will be happy to help you find a suitable
&gt; model for your use cases.
&gt;
&gt; We usually do this by stress-testing a simulation with realistic data
&gt; sizes/shapes and access patterns. It's fastest if we come onsite for a
&gt; couple of days and work with you to set it up, but we can also help you
&gt; offsite.
&gt;
&gt; Write me if you're interested, then we can do a call.
&gt;
&gt; Rune Skou Larsen
&gt; Trifork, Denmark
&gt;
&gt;
&gt; ----- Reply message -----
&gt; Fra: "Viable Nisei" 
&gt; Til: "riak-users@lists.basho.com" 
&gt; Emne: May allow\_mult cause DoS?
&gt; Dato: ons., dec. 18, 2013 20:13
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; ---------- Forwarded message ----------
&gt; From: Viable Nisei &gt;
&gt; Date: Thu, Dec 19, 2013 at 2:11 AM
&gt; Subject: Re: May allow\_mult cause DoS?
&gt; To: Russell Brown &gt;
&gt;
&gt;
&gt; Hi.
&gt;
&gt; Thank you for your descriptive and so informative answer very much.
&gt;
&gt; On Wed, Dec 18, 2013 at 3:29 PM, Russell Brown  &gt; wrote:
&gt; Hi,
&gt;
&gt; Can you describe your use case a little? Maybe it would be easier for us
&gt; to help.
&gt; Yeah, let me describe some abstract case equivalent to our. Let we have
&gt; CUSTOMER object, STORE object and TRANSACTION object, each TRANSACTION has
&gt; one tribool attribute STATE={ACTIVE, COMPLETED, ROLLED\_BACK}.
&gt;
&gt; We should be able to list all the TRANSACTIONs of given CUSTOMER, for
&gt; example (so we should establish 1-many relation, this list should not be
&gt; long, 10^2-10^3 records, but we should be able to obtain this list fast
&gt; enough). Also we should be able to list all the TRANSACTIONs of given STATE
&gt; made in given STORE (lists may be very long, up to 10^8 records), but these
&gt; list may be computed with some latency. Predictable latency is surely
&gt; preferred but is not show-stopper. So, that's all.
&gt;
&gt; Another pain is races and/or operations atomicity, but it's not so
&gt; important at current time.
&gt;
&gt;
&gt; On 18 Dec 2013, at 04:32, Viable Nisei  vsni...@gmail.com&gt;&gt; wrote:
&gt;
&gt; &gt; On Wed, Dec 18, 2013 at 8:32 AM, Erik Søe Sørensen  &gt; wrote:
&gt; &gt; It really is not a good idea to use siblings to represent 1-to-many
&gt; relations. That's not what it's intended for, nor what it's optimized for...
&gt; &gt; Ok, understood.
&gt; &gt;
&gt; &gt; Can you tell us exactly why you need Bitcask rather than LevelDB? 2i
&gt; would probably do it.
&gt; &gt; 1) According to
&gt; http://docs.basho.com/riak/latest/ops/running/backups/#LevelDB-Backups ,
&gt; it's real pain to implement backups with leveldb.
&gt; &gt; 2) According to
&gt; http://docs.basho.com/riak/latest/ops/advanced/backends/leveldb/ , reads
&gt; may be slower comparing to bitcask, it's critical for us
&gt; &gt;
&gt; &gt; Otherwise, storing a list of items under each key could be a solution,
&gt; depending of course on the number of items per key. (But do perform
&gt; conflict resolution.)
&gt; &gt; Why any conflict resolving is required? As far as I understood, with
&gt; allow\_mult=true riak should just collect all the values written to key
&gt; without anything additional work? What design decision leads to exponential
&gt; slowdown and crashes when multiple values allowed for any single key?.. So,
&gt; what's the REAL purpose of allow\_mult=true if it's bad idea to use it for
&gt; unlimited values per single key?
&gt;
&gt; The real purpose of allow\_mult=true is so that writes are never dropped.
&gt; In the case where your application concurrently writes to the same key on
&gt; two different nodes, or on two partitioned nodes, Riak keeps both values.
&gt; Other data stores will lose one of the writes based on timestamp, serialise
&gt; your writes (slow) or simply refuse to accept one or more of them.
&gt; Ok, but documentation doesn't make points really clear.
&gt;
&gt;
&gt; It is the job of the client to aggregate those multiple writes into a
&gt; single value when it detects the conflict on read. Conflict resolution is
&gt; required because your data is opaque to Riak. Riak doesn’t know that you’re
&gt; storing lists of values, or JPEGs or JSON. It can’t possibly know how to
&gt; resolve two conflicting values unless it knows the semantics of the values.
&gt; Riak \_does\_ collect all the values written to a key, but it does so as a
&gt; temporary measure, it expects your application to resolve them to a single
&gt; value. How many are you writing per Key?
&gt; As I said before, we need really many values in our 1-many sets - up to
&gt; 10^8
&gt; Also why not to implement separate bucket mode allowing just to collect
&gt; all the values writing? Anyway, current allow\_mult implementation looks
&gt; like very dangerous. Also documentation should be more clear - in "sibling
&gt; explosion" paragraph some statement should be added pointing that this
&gt; relates to allow\_mult=true too.
&gt;
&gt;
&gt; Riak’s sweetspot is highly write available applications. If you have the
&gt; time read the Amazon Dynamo paper[1], as it explains the \_problems\_ Riak
&gt; solves as well as the way in which it solves them. If you don’t have these
&gt; problems, maybe Riak is not the right datastore for you. Solving these
&gt; problems comes with some developer complexity costs. You’ve run into one of
&gt; them. We have many customers who think the trade-off is worth it: that the
&gt; high availability and low-latency makes up for having eventual consistency.
&gt;
&gt; Yeah, ok, but what riak&lt;2.0 really allows? FTS looks unscalable (am I
&gt; right? is any way to speed-up it available?), list of all bucket keys is
&gt; not for production, 2i is not implemented for bitcask (anyway, we'll try
&gt; them on leveldb), links "implemented as hacks in java driver". So, riak&lt;2.0
&gt; with bitcask is only good distributed 1-1 hashmap with mapred support.
&gt;
&gt; &gt;
&gt; &gt; Ok, documentation contains the following paragraph:
&gt; &gt;
&gt; &gt; &gt; Sibling explosion occurs when an object rapidly collects siblings
&gt; without being reconciled. This can lead to a myriad of issues. Having an
&gt; enormous object in your node can cause reads of that object to crash the
&gt; entire node. Other issues are increased cluster latency as the object is
&gt; replicated and out of memory errors.
&gt; &gt;
&gt; &gt; But there is no point if it related to allow\_mult=false or both cases.
&gt;
&gt; Sorry, but I don’t understand what you mean by this statement. The point
&gt; of allow\_mult=true is so that writes are not arbitrarily dropped. It allows
&gt; Riak nodes to continue to be available to take writes even if they can’t
&gt; communicate with each other. Have a look at Kyle Kingsbury’s Jepsen[2] post
&gt; on Riak.
&gt;
&gt; I'm just speaking about that this paragraph should contain something like
&gt; "don't write multiple values into single key in bucket with
&gt; allow\_mult=true, this will cause dramatic slowdowns/crashes". It's not
&gt; really obvious that siblings explosion is related to bucket with
&gt; allow\_mult=true.
&gt;
&gt; &gt;
&gt; &gt; So, the only solution is leveldb+2i?
&gt;
&gt; Maybe. Or maybe just use the client as it is intended to resolve sibling
&gt; values and send that value and a vector clock back to Riak.
&gt; Not a solution for big sets of 10^8 elements
&gt;
&gt; Or maybe roll your own indexes like in this blog post[3].
&gt; It's not an option to use some custom "indexes" on client side for long
&gt; lists, so the only option is to write some erlang piece of code?..
&gt;
&gt; With Riak 2.0 there are a few data types added to Riak that are not
&gt; opaque. Maybe Riak’s Sets would suit your purpose (depending on the size of
&gt; your Set.)
&gt;
&gt; What are you meaning by "depending size of Set"?
&gt; Will I be able to store 10^8 values and enumerate/add new values fast
&gt; enough?
&gt;
&gt; You’re fighting the database at the moment, rather than working with it.
&gt; The properties of Riak buy you some wonderful things (high availability,
&gt; partition tolerance, low latency) but you have to want / need those
&gt; properties, and then you have to accept that there is a data modelling /
&gt; developer complexity price to pay. We don’t think that price is too high.
&gt; We have many customers who agree. We’re always working to lower that price
&gt; (see Strong Consistency, Yokozuna, Data Types etc in Riak 2.0[4].)
&gt; We've built 2.0 TP but it like to crash frequently and 2.0 driver still is
&gt; not ready, but according to docs it looks like significantly better. But
&gt; questions about maximum Set size and FTS scalability still looks actual.
&gt;
&gt;
&gt; You seem to have had a very negative first experience of Riak (and Basho.)
&gt; I think that is because you misunderstand what it is for and how it should
&gt; be used. I'm very keen to fix that. If it turns out that Riak is just not
&gt; for you, that is fine too.
&gt; It's not negative experience, it's just WTFZOMG state. Everything looked
&gt; good until loading/scalability tests...
&gt;
&gt;
&gt; In response to your earlier mail, I think Basho’s consulting costs sound
&gt; incredibly low. I think you got that answer because you reached out to
&gt; Basho through that channel, rather than ask the list. We’re still trying to
&gt; track down who you spoke to and when, if you could provide me details of
&gt; that conversation directly (rather than to the list) I’d be very grateful.
&gt; I think it's not really important for now, I think we've incorrectly
&gt; emphasized our questions/thoughts.
&gt; Anyway for now looks like there is no silver bullet priced for $5k - all
&gt; the possible approaches to solve our problem was already listed in this
&gt; thread. And the only way I've missed in op message was custom indexing on
&gt; server side (implemented as precommit hook, am I right? such as FTS?)
&gt;
&gt;
&gt; I’m not sure if it is just a cultural / language thing, but you’re very
&gt; negative right now, and you sound like you're attacking Basho and Riak. I
&gt; don’t think that is warranted at this point as we’re just trying to help
&gt; you figure out if Riak is the datastore you want / need.
&gt;
&gt; As I said before, I'm not negative. This picture
&gt; http://tinyurl.com/p5zntks excellently describes thoughts of our dev team
&gt; after set of loading tests. We got 100 writes/sec on single core i3 host.
&gt; Ok, we got up to 500 writes (but we need 10k+) on single cc2.8xlarge host,
&gt; but with 5 cc2.8xlarge nodes we got lesser with latency significantly
&gt; increased. We changed our approach to using allow\_mult - and got only 100
&gt; for some first seconds, then exponentially dropping to zero, then total
&gt; crash of all the cluster... Also you are right - english is not my native
&gt; language. What about subject of our thread - take it like like some yellow
&gt; press headline (but I still think that it's not so good idea to allow
&gt; client code to do SUCH BAD THINGS WITH WHOLE CLUSTER)
&gt;
&gt; Cheers
&gt;
&gt; Russell
&gt;
&gt; [1] http://dl.acm.org/citation.cfm?id=1294281
&gt; [2] http://aphyr.com/posts/285-call-me-maybe-riak
&gt; [3] http://basho.com/index-for-fun-and-for-profit/
&gt; [4] http://basho.com/technical-preview-of-riak-2-0/
&gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; On Wed, Dec 18, 2013 at 8:32 AM, Erik Søe Sørensen  &gt; wrote:
&gt; &gt; It really is not a good idea to use siblings to represent 1-to-many
&gt; relations. That's not what it's intended for, nor what it's optimized for...
&gt; &gt; Can you tell us exactly why you need Bitcask rather than LevelDB? 2i
&gt; would probably do it.
&gt; &gt; Otherwise, storing a list of items under each key could be a solution,
&gt; depending of course on the number of items per key. (But do perform
&gt; conflict resolution.)
&gt; &gt; /Erik
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; -------- Oprindelig meddelelse --------
&gt; &gt; Fra: Viable Nisei &gt;
&gt; &gt; Dato:
&gt; &gt; Til: riak-users@lists.basho.com
&gt; &gt; Emne: May allow\_mult cause DoS?
&gt; &gt;
&gt; &gt;
&gt; &gt; Hi.
&gt; &gt;
&gt; &gt; Recently we've described that something is going unexpectedly. We are
&gt; using Riak 1.4.2 with some buckets with allow\_mult=true.
&gt; &gt; We've tried our app under load then found that... concurrently writes
&gt; into bucket with allow\_mult turning Riak into irresponsible slowpoke and
&gt; even crash it.
&gt; &gt;
&gt; &gt; Core i3 with 4GB RAM performs only 20 writes/sec with 5 client threads
&gt; writing 20 short strings into 20 keys in bucket with allow\_mult=true,
&gt; search=false. With 40 values per 40 keys it performs only 6 writes/sec.
&gt; 60x60 cause riak crash?
&gt; &gt; Throughput drops drastically. Ok, we've not chaged concurrency factor
&gt; (5) and increased our data set 4x, but why throughput drops?
&gt; &gt; Ok, we increase our dataset linear, 20 strings \* 20 keys, 40 strings\*20
&gt; keys, 60 strings\*20 keys... Results will be same - exponential throughput
&gt; drop with crash at end.
&gt; &gt;
&gt; &gt; Cluster of five Amazon EC2 cc2.8xlarge nodes becomes irresponsibly with
&gt; throughput 1-5 writes/sec with only 80-100 values per 1-10 keys.
&gt; &gt;
&gt; &gt; So, we think it is very strange.
&gt; &gt;
&gt; &gt; Here you can check our code sample (in java) reproducing this behavior:
&gt; https://bitbucket.org/vsnisei/riak-allow\_mult\_wtf
&gt; &gt;
&gt; &gt; So, we have asked Basho about this, but they said that "we think SQLish"
&gt; and asked us for $5k for 2-days consultation to resolve our problem.
&gt; &gt; So, I've decided to ask here if we are really so stupid and not able to
&gt; understood some simple things or Basho didn't understood us correctly?..
&gt; &gt;
&gt; &gt; Anyway, looks like that some DoS/DDoS attack approach utilizing this
&gt; behavior may be proposed. We should only know that some
&gt; service/appliation/website is using Riak with allow\_mult buckets then
&gt; provoke concurrent writes into them...
&gt; &gt;
&gt; &gt; Actually our question to Basho was broader. Our application needs to
&gt; implement 1-many bindings. Riak allows the following approaches to
&gt; simultate such bindings, according to documentation:
&gt; &gt;
&gt; &gt; 1. Riak search - but we've found that it's VERY slow (20x performance
&gt; drop when search enabled, even for simple objects like {source\_id: xxx,
&gt; target\_id: yyy}, also we've found that search is not really scalable -
&gt; adding new nodes into cluster not increasing throughput, but even slows
&gt; cluster down...
&gt; &gt; 2. secondary indexes. But, according to docs, they are working only on
&gt; LevelDb, but we need Bitcask
&gt; &gt; 3. Link walking. But, according to docs, it's "rest only operation"
&gt; and in java driver it's implemented as a hack
&gt; &gt; 4. allow\_mult. But we've found that it's just a nightmare. So we told
&gt; Basho about this and given link to our example, but they didn't given us
&gt; any feedback
&gt; &gt; 5. Bucket keys enumeration. But, according to docs, this operation
&gt; causes full keys scan on each node and must not be used in production
&gt; &gt; 6. Mapred queries. Ok, we didn't tried them yet, maybe it's silver
&gt; bullet, really. But according to docs (and common sense) mapred causes
&gt; full-scan (for bucket at least. Or for all keys?) and it's operation with
&gt; unpredictable latency.
&gt; &gt;
&gt; &gt; So, where we are wrong? Is everything ok with behavior I've described?
&gt; Are we misunderstood Riak completely and should pay $5k for some
&gt; mind-expansion, or there is no any hidden mystical knowledge and they will
&gt; not say us anything excepting approaches listed above?
&gt; &gt;
&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

