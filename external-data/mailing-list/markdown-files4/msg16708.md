---
title: "Re: Ownership handoff timed out"
description: ""
project: community
lastmod: 2015-10-27T08:36:03-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16708"
mailinglist_parent_id: "msg16705"
author_name: "Vladyslav Zakhozhai"
project_section: "mailinglistitem"
sent_date: 2015-10-27T08:36:03-07:00
---


Hi,

Jon thank you for the answer. During approval of my mail to this list I've
troubleshoot my issue more deep. And yes, your are right. Neither {error,
enotconn} nor max\_concurrency is my problem.

I'm going to migrate my cluster entierly to eleveldb only, i.e. I need to
refuse using bitcask. I have a talk with basho support and they said that
it is tricky to tune bitcask on servers with 32 GB RAM (and I guess that it
is not tricky, but it is impossible, because bitcask loads all keys in
memory regardless of free available RAM). With LevelDB I have opportunity
to tune using RAM on servers.

So I have 15 nodes with multibackend (bitcask for data and leveldb for
metadata). 2 additional servers are without multibackend - only with
leveldb. Now I'm not sure do I need still use mutibackend with levedb-only
backend.

And my problem is (as I mentioned earlier) the following. On leveldb-only
nodes I see handoffs timedout and no further progress.

On multibackend hosts I have configuration:

{riak\_kv, [
 {add\_paths, ["/usr/lib/riak-cs/lib/riak\_cs-1.5.0/ebin"]},
 {storage\_backend, riak\_cs\_kv\_multi\_backend},
 {multi\_backend\_prefix\_list, [{&lt;&lt;"0b:"&gt;&gt;, be\_blocks}]},
 {multi\_backend\_default, be\_default},
 {multi\_backend, [
 {be\_default, riak\_kv\_eleveldb\_backend, [
 {max\_open\_files, 50},
 {data\_root, "/var/lib/riak/leveldb"}
 ]},
 {be\_blocks, riak\_kv\_bitcask\_backend, [
 {data\_root, "/var/lib/riak/bitcask"}
 ]}
 ]},

And for hosts with leveldb-only backend:

{riak\_kv, [
 {storage\_backend, riak\_kv\_eleveldb\_backend},
...
{eleveldb, [
 {data\_root, "/var/lib/riak/leveldb"}
(default values for leveldb)

In leveldb logs I see nothing that could help me (no errors in logs).


On Mon, Oct 26, 2015 at 3:57 PM Jon Meredith  wrote:

&gt; Hi,
&gt;
&gt; I suspect your {error,enotconn} messages are unrelated - that's likely to
&gt; be caused by an HTTP client closing the connection while Riak looks up
&gt; some networking information about the requestor.
&gt;
&gt; The max\_concurrency message you are seeing is related to the handoff
&gt; transfer limit - it should be labelled as informational. When a node has
&gt; data to handoff it starts the handoff sender process and if there are
&gt; either too many local handoff processes or too many on the remote side it
&gt; exits with max\_concurrency. You could increase with riak-admin
&gt; transfer-limit but that probably won't help if you're timing out.
&gt;
&gt; As you're using the multi-backend you're transferring data from bitcask
&gt; and leveldb. The next place I would look is in the leveldb LOG files to
&gt; see if there are any leveldb vnodes that are having problems that's
&gt; preventing repair.
&gt;
&gt; Jon
&gt;
&gt; On Mon, Oct 26, 2015 at 7:15 AM Vladyslav Zakhozhai &lt;
&gt; v.zakhoz...@smartweb.com.ua&gt; wrote:
&gt;
&gt;&gt; Hello,
&gt;&gt;
&gt;&gt; I have a problem with persistent timeouts during ownership handoffs. I've
&gt;&gt; tried to surf over Internet and current mail list but no success.
&gt;&gt;
&gt;&gt; I have Riak 1.4.12 cluster with 17 nodes. Almost all nodes use
&gt;&gt; multibackend with bitcask and eleveldb as storage backends (we need
&gt;&gt; multiple backend for Riak CS 1.5.0 integration).
&gt;&gt;
&gt;&gt; Now I'm working to migrate Riak cluster to eleveldb as primary and only
&gt;&gt; backend. For now I have 2 nodes with eleveldb backend in the same cluster.
&gt;&gt;
&gt;&gt; During ownership handoff process I permanently see errors of timed out
&gt;&gt; handoff receivers and sender.
&gt;&gt;
&gt;&gt; Here is partial output of riak-admin transfers:
&gt;&gt; ...
&gt;&gt; transfer type: ownership\_transfer
&gt;&gt; vnode type: riak\_kv\_vnode
&gt;&gt; partition: 331121464707782692405522344912282871640797216768
&gt;&gt; started: 2015-10-21 08:32:55 [46.66 min ago]
&gt;&gt; last update: no updates seen
&gt;&gt; total size: unknown
&gt;&gt; objects transferred: unknown
&gt;&gt;
&gt;&gt; unknown
&gt;&gt; riak@taipan.pleiad.uaprom =======&gt; r...@eggeater.pleiad.uapr
&gt;&gt; om
&gt;&gt; | | 0%
&gt;&gt; unknown
&gt;&gt;
&gt;&gt; transfer type: ownership\_transfer
&gt;&gt; vnode type: riak\_kv\_vnode
&gt;&gt; partition: 336830455478606531929755488790080852186328203264
&gt;&gt; started: 2015-10-21 08:32:54 [46.68 min ago]
&gt;&gt; last update: no updates seen
&gt;&gt; total size: unknown
&gt;&gt; objects transferred: unknown
&gt;&gt; ...
&gt;&gt;
&gt;&gt; Some of partition handoffs state never updates, some of them terminates
&gt;&gt; after partial handoff objects and never starts again.
&gt;&gt;
&gt;&gt; I see nothing in logs but following:
&gt;&gt;
&gt;&gt; On receiver side:
&gt;&gt;
&gt;&gt; 2015-10-21 11:33:55.131 [error]
&gt;&gt; &lt;0.25390.1266&gt;@riak\_core\_handoff\_receiver:handle\_info:105 Handoff receiver
&gt;&gt; for partition 331121464707782692405522344912282871640797216768 timed out
&gt;&gt; after processing 0 objects.
&gt;&gt;
&gt;&gt; On sender side:
&gt;&gt;
&gt;&gt; 2015-10-21 11:01:58.879 [error] &lt;0.13177.1401&gt; CRASH REPORT Process
&gt;&gt; &lt;0.13177.1401&gt; with 0 neighbours crashed with reason: no function clause
&gt;&gt; matching webmachine\_request:peer\_from\_peername({error,enotconn},
&gt;&gt; {webmachine\_request,{wm\_reqstate,#Port&lt;0.50978116&gt;,[],undefined,undefined,undefined,{wm\_reqdata,...},...}})
&gt;&gt; line 150
&gt;&gt; 2015-10-21 11:32:50.055 [error] &lt;0.207.0&gt; Supervisor
&gt;&gt; riak\_core\_handoff\_sender\_sup had child riak\_core\_handoff\_sender started
&gt;&gt; with {riak\_core\_handoff\_sender,start\_link,undefined} at &lt;0.22312.1090&gt; exit
&gt;&gt; with reason max\_concurrency in context child\_terminated
&gt;&gt;
&gt;&gt; {error, enotconn} - seems to be network issue. But I have no any problems
&gt;&gt; with network. All hosts resolve their neighbors correctly and /etc/hosts on
&gt;&gt; each node are correct.
&gt;&gt;
&gt;&gt; I've tried to increase handoff\_timeout and handoff\_receive\_timeout. But
&gt;&gt; no success.
&gt;&gt;
&gt;&gt; Forcing handoff helped me but for short period of time:
&gt;&gt;
&gt;&gt; rpc:multicall([node() | nodes()], riak\_core\_vnode\_manager, force\_handoffs, 
&gt;&gt; []).
&gt;&gt;
&gt;&gt;
&gt;&gt; I see progress of handoffs (riak-admin transfers) but then I see handoff 
&gt;&gt; timed out again.
&gt;&gt;
&gt;&gt;
&gt;&gt; A week ago I've joined 4 nodes with bitcask. And there was no such problems.
&gt;&gt;
&gt;&gt;
&gt;&gt; I'm confused a little bit and need to understand my next steps in 
&gt;&gt; troubleshooting this issue.
&gt;&gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

