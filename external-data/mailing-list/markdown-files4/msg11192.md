---
title: "Re: Riak CS 1.3 S3 access does not seem to mark s3 deleted file as	truly deleted"
description: ""
project: community
lastmod: 2013-05-29T11:25:01-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11192"
author_name: "Kelly McLaughlin"
project_section: "mailinglistitem"
sent_date: 2013-05-29T11:25:01-07:00
---


Idan,

I did some investigation and I believe that the problem is just that
bitcask has not fully merged all of the old data. I ran a test similar to
what you described and afterwards saw a similar usage of data by bitcask. I
then wrote a small erlang module [1] to trigger a merge on all of the
bitcask data directories. After the merging was complete my disk usage was
back to the same amount as after the first batch of 48 uploads that I ran.
I have not done any further digging into the bitcask merging behavior and I
was just using the default merge settings for this test. I believe that
eventually bitcask would merge and free up all of the used space, but we
probably should investigate if there are ways to make this happen in a more
timely and predictable manner when used with Riak CS.

[1] : https://gist.github.com/kellymclaughlin/5672447

Kelly


On Thu, May 23, 2013 at 5:31 PM, Kelly McLaughlin  wrote:

&gt; Idan,
&gt;
&gt; I'll investigate this a bit and see if I can replicate similar behavior
&gt; and hopefully I can get back to you with more information. Thanks for
&gt; sharing the info.
&gt;
&gt; Kelly
&gt;
&gt;
&gt; On Wed, May 22, 2013 at 3:23 AM, Idan Shinberg 
&gt; wrote:
&gt;
&gt;&gt; Hey Kelly
&gt;&gt;
&gt;&gt; Thanks for getting back to me ...
&gt;&gt;
&gt;&gt; You were right to bring up the point - these setting were indeed
&gt;&gt; applied gradually .
&gt;&gt;
&gt;&gt; I have thus started from scratch with the same settings mentioned above
&gt;&gt; in place
&gt;&gt;
&gt;&gt; I made 3 batch of 48 uploads of the same 32 MB files to 48 different keys
&gt;&gt; in s3
&gt;&gt; I Wound up with 48 keys in the S3 ( uploads overwrote old data ) , each
&gt;&gt; is 32 MB of size , for a total of 144 uploads
&gt;&gt;
&gt;&gt; BTW , I also forgot to mention n\_val is set to 1 in default\_bucket\_props .
&gt;&gt; Bitcask dir was around 5.5 GB and after merges kicked in it shrunk to
&gt;&gt; 3.4 GB
&gt;&gt;
&gt;&gt; still , actual data-set size should be 48 x 32 MB , which is 1.5 GB .
&gt;&gt; I also noticed each time I upload a file , 2x of it's size is
&gt;&gt; automatically used , And I'm guessing that's related :-)
&gt;&gt;
&gt;&gt; The Single Riak node is running on CentOS 6.3 with 1.3.1 packaged
&gt;&gt; version...
&gt;&gt;
&gt;&gt;
&gt;&gt; Thanks
&gt;&gt;
&gt;&gt; Idan Shinberg
&gt;&gt; idomoo
&gt;&gt;
&gt;&gt;
&gt;&gt; On Wed, May 22, 2013 at 2:26 AM, Kelly McLaughlin wrote:
&gt;&gt;
&gt;&gt;&gt; Idan,
&gt;&gt;&gt;
&gt;&gt;&gt; Bitcask can sometimes be slow to reclaim space after deleting objects
&gt;&gt;&gt; from Riak CS. Are the settings you included the settings that have been in
&gt;&gt;&gt; place during all of your uploads and deletions? I am surprised that just a
&gt;&gt;&gt; few tens of uploads of 32 MB objects used up 15 GB of space. Can you be
&gt;&gt;&gt; more specific on a count of uploads? Also do you have any error output in
&gt;&gt;&gt; the riak or riak cs log files that may be related? Finally, which packages
&gt;&gt;&gt; are you using for your testing?
&gt;&gt;&gt;
&gt;&gt;&gt; Kelly
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Tue, May 21, 2013 at 2:18 PM, Idan Shinberg &gt;&gt; &gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thus , I fear Riak never treats their data as "dead-bytes" and they
&gt;&gt;&gt;&gt; never get merged
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I created 2 buckets using s3cmd and made several tens of uploads of
&gt;&gt;&gt;&gt; 32mb sized files , deleting them right afterwards ( with proper s3cmd
&gt;&gt;&gt;&gt; commands , of course) .
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I ended up with no buckets and no keys in my riak s3 database ,
&gt;&gt;&gt;&gt; however , directory /var/lib/riak/bitcask/ 64 partitions now occupy
&gt;&gt;&gt;&gt; 15GB worth of space
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; several riak restarts did not trigger any merges , and my merge
&gt;&gt;&gt;&gt; settings are set to impose very though merge triggering criterias , So I'm
&gt;&gt;&gt;&gt; guessing the only reason the data is not being cleared is the fact that
&gt;&gt;&gt;&gt; it's still in use ...
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Relevant riak-cs config :
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \* %% == Garbage Collection ==\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% The number of seconds to retain the block\*
&gt;&gt;&gt;&gt; \* %% for an object after it has been deleted.\*
&gt;&gt;&gt;&gt; \* %% This leeway time is set to give the delete\*
&gt;&gt;&gt;&gt; \* %% indication time to propogate to all replicas.\*
&gt;&gt;&gt;&gt; \* %% 86400 is 24-hours.\*
&gt;&gt;&gt;&gt; \* {leeway\_seconds, 30},\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% How often the garbage collection daemon\*
&gt;&gt;&gt;&gt; \* %% waits in-between gc batches.\*
&gt;&gt;&gt;&gt; \* %% 900 is 15-minutes.\*
&gt;&gt;&gt;&gt; \* {gc\_interval, 60},\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% How long a move to the garbage\*
&gt;&gt;&gt;&gt; \* %% collection to do list can remain\*
&gt;&gt;&gt;&gt; \* %% failed, before we retry it.\*
&gt;&gt;&gt;&gt; \* %% 21600 is 6-hours.\*
&gt;&gt;&gt;&gt; \* {gc\_retry\_interval,300},\*
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Relevant Riak Config
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \*{riak\_kv, [\*
&gt;&gt;&gt;&gt; \* %% Storage\_backend specifies the Erlang module defining
&gt;&gt;&gt;&gt; the storage\*
&gt;&gt;&gt;&gt; \* %% mechanism that will be used on this node.\*
&gt;&gt;&gt;&gt; \* {add\_paths,
&gt;&gt;&gt;&gt; ["/usr/lib64/riak-cs/lib/riak\_cs-1.3.1/ebin"]},\*
&gt;&gt;&gt;&gt; \* {storage\_backend, riak\_cs\_kv\_multi\_backend},\*
&gt;&gt;&gt;&gt; \* {multi\_backend\_prefix\_list, [{&lt;&lt;"0b:"&gt;&gt;, be\_blocks}]},
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* {multi\_backend\_default, be\_default},\*
&gt;&gt;&gt;&gt; \* {multi\_backend, [\*
&gt;&gt;&gt;&gt; \* {be\_default, riak\_kv\_eleveldb\_backend, [\*
&gt;&gt;&gt;&gt; \* {max\_open\_files, 50},\*
&gt;&gt;&gt;&gt; \* {data\_root, "/var/lib/riak/leveldb"}\*
&gt;&gt;&gt;&gt; \* ]},\*
&gt;&gt;&gt;&gt; \* {be\_blocks, riak\_kv\_bitcask\_backend, [\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* {max\_file\_size, 16#4000000}, %% 64MB\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% Trigger a merge if any of the following
&gt;&gt;&gt;&gt; are true:\*
&gt;&gt;&gt;&gt; \* {frag\_merge\_trigger, 10}, %% fragmentation &gt;=
&gt;&gt;&gt;&gt; 10%\*
&gt;&gt;&gt;&gt; \* {dead\_bytes\_merge\_trigger, 33554432}, %% dead
&gt;&gt;&gt;&gt; bytes &gt; 32 MB\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% Conditions that determine if a file will
&gt;&gt;&gt;&gt; be examined during a merge:\*
&gt;&gt;&gt;&gt; \* {frag\_threshold, 5}, %% fragmentation &gt;= 5%\*
&gt;&gt;&gt;&gt; \* {dead\_bytes\_threshold, 8388608}, %% dead
&gt;&gt;&gt;&gt; bytes &gt; 8 MB\*
&gt;&gt;&gt;&gt; \* {small\_file\_threshold, 16#80000000}, %% file
&gt;&gt;&gt;&gt; is &lt; 2GB\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* {data\_root, "/var/lib/riak/bitcask"}\*
&gt;&gt;&gt;&gt; \* ]}\*
&gt;&gt;&gt;&gt; \* ]},\*
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; ...
&gt;&gt;&gt;&gt; ...
&gt;&gt;&gt;&gt; ...
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \* {bitcask, [\*
&gt;&gt;&gt;&gt; \* %% Configure how Bitcask writes data to disk.\*
&gt;&gt;&gt;&gt; \* %% erlang: Erlang's built-in file API\*
&gt;&gt;&gt;&gt; \* %% nif: Direct calls to the POSIX C API\*
&gt;&gt;&gt;&gt; \* %%\*
&gt;&gt;&gt;&gt; \* %% The NIF mode provides higher throughput for certain\*
&gt;&gt;&gt;&gt; \* %% workloads, but has the potential to negatively impact\*
&gt;&gt;&gt;&gt; \* %% the Erlang VM, leading to higher worst-case latencies\*
&gt;&gt;&gt;&gt; \* %% and possible throughput collapse.\*
&gt;&gt;&gt;&gt; \* {io\_mode, erlang},\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* {max\_file\_size, 16#4000000}, %% 64MB\*
&gt;&gt;&gt;&gt; \* {merge\_window, always}, %% Span of hours during which
&gt;&gt;&gt;&gt; merge is acceptable.\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% Trigger a merge if any of the following are true:\*
&gt;&gt;&gt;&gt; \* {frag\_merge\_trigger, 10}, %% fragmentation &gt;= 10%\*
&gt;&gt;&gt;&gt; \* {dead\_bytes\_merge\_trigger, 33554432}, %% dead bytes &gt; 32
&gt;&gt;&gt;&gt; MB\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* %% Conditions that determine if a file will be examined
&gt;&gt;&gt;&gt; during a merge:\*
&gt;&gt;&gt;&gt; \* {frag\_threshold, 5}, %% fragmentation &gt;= 5%\*
&gt;&gt;&gt;&gt; \* {dead\_bytes\_threshold, 8388608}, %% dead bytes &gt; 8 MB\*
&gt;&gt;&gt;&gt; \* {small\_file\_threshold, 16#80000000}, %% file is &lt; 2GB\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* {data\_root, "/var/lib/riak/bitcask"}\*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \*
&gt;&gt;&gt;&gt; \* ]},\*
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I do see merges taking place in riak's console.log , they're just not
&gt;&gt;&gt;&gt; making that much of a difference ...
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Any idea what I might be missing here ?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Idan Shinberg
&gt;&gt;&gt;&gt; idomoo
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

