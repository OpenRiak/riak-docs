---
title: "Re: How to best store arbitrarily large Java objects"
description: ""
project: community
lastmod: 2016-07-21T08:38:31-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg17552"
mailinglist_parent_id: "msg17551"
author_name: "Alex Moore"
project_section: "mailinglistitem"
sent_date: 2016-07-21T08:38:31-07:00
---


Hi Henning,

Responses inline:

...

&gt; However, depending on the size of the `TreeMap`, the serialization
&gt; output can become rather large, and this limits the usefulness of my
&gt; object. In our tests, dealing with Riak-objects &gt;2MB proved to be
&gt; significantly slower than dealing with objects &lt;200kB.


Yes. We usually recommend keeping objects &lt; 100kB for the best
performance; and Riak can usually withstand objects up to 1MB with the
understanding that everything will be a little slower with the larger
objects going around the system.


&gt; My idea was to use a converter that splits the serialized JSON into
&gt; chunks during \_write\_, and uses links to point from one chunk to the
&gt; next. During \_fetch\_ the links would be traversed, the JSON string
&gt; concatenated from chunks, deserialized and the object would be
&gt; returned. Looking at `com.basho.riak.client.api.convert.Converter`, it
&gt; seems this is not going to work.


Linkwalking was deprecated in Riak 2.0 so I wouldn't do it that way.

I'm beginning to think that I'll need to remodel my data and use CRDTs
&gt; for individual fields such as the `TreeMap`. Would that be a better
&gt; way?


This sounds like a plausible idea. If you do a lot of possibly conflicting
updates to the Tree, then a CRDT map would be the way to go. You could
reuse the key from the main object, and just put it in the new
buckettype/bucket.

If you don't need to update the tree much, you could also just serialize
the tree into it's own object - split up the static data and the often
updated data, and put them in different buckets that share the same key.

Thanks,
Alex


On Thu, Jul 21, 2016 at 9:36 AM, Henning Verbeek 
wrote:

&gt; I have a Java class, which is being stored in Riak. The class contains
&gt; a `TreeMap` field, amongst other fields. Out of the box, Riak is
&gt; converting the object to/from JSON. Everything works fine.
&gt;
&gt; However, depending on the size of the `TreeMap`, the serialization
&gt; output can become rather large, and this limits the usefulness of my
&gt; object. In our tests, dealing with Riak-objects &gt;2MB proved to be
&gt; significantly slower than dealing with objects &lt;200kB.
&gt;
&gt; So, in order to store/fetch instances of my class with arbitrary
&gt; sizes, but with reliable performance, I believe I need to split the
&gt; output into separate Riak-objects after serialization, and reassemble
&gt; before deserialization.
&gt;
&gt; My idea was to use a converter that splits the serialized JSON into
&gt; chunks during \_write\_, and uses links to point from one chunk to the
&gt; next. During \_fetch\_ the links would be traversed, the JSON string
&gt; concatenated from chunks, deserialized and the object would be
&gt; returned. Looking at `com.basho.riak.client.api.convert.Converter`, it
&gt; seems this is not going to work.
&gt;
&gt; I'm beginning to think that I'll need to remodel my data and use CRDTs
&gt; for individual fields such as the `TreeMap`. Would that be a better
&gt; way?
&gt;
&gt; Any other recommendations would be much appreciated.
&gt;
&gt; Thanks,
&gt; Henning
&gt; --
&gt; My other signature is a regular expression.
&gt; http://www.pray4snow.de
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

