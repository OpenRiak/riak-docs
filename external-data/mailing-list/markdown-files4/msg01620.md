---
title: "Re: upgrade process?"
description: ""
project: community
lastmod: 2010-11-23T20:28:21-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01620"
mailinglist_parent_id: "msg01611"
author_name: "John D. Rowell"
project_section: "mailinglistitem"
sent_date: 2010-11-23T20:28:21-08:00
---


2010/11/23 David Smith 

&gt; On Tue, Nov 23, 2010 at 8:58 AM, Colin Surprenant
&gt;  wrote:
&gt; &gt;
&gt; &gt; Would upgrading (rolling or offline) sequentially from 0.10 to 0.11 to
&gt; &gt; 0.12 be "easier" to manage potential compatibility issues?
&gt;
&gt; As on of my colleagues (Grant) just pointed out to me, a rolling
&gt; upgrade of 0.10 -&gt; 0.13 won't work due to some internal messaging
&gt; changes; you'll need to take the whole cluster down after all.
&gt; However, I do not know of any major changes to the storage formats
&gt; (particularly with innostore), so you should be able to just upgrade
&gt; in place and bring the cluster back up.
&gt;
&gt; As I said before, though, testing it would be a wise idea. :) (Yes,
&gt; there's a pattern here...:))
&gt;
&gt; &gt; I'm using innostore, with a 3 nodes cluster holding ~250GB of data
&gt; &gt; each. Using the riak-admin backup/restore is just too slow to be
&gt; &gt; usable in my environment. Would innodump/innoload be any faster? Could
&gt; &gt; I consider setting up a new 0.13 ring, use innodump on my 0.10 nodes
&gt; &gt; and innoload on the 0.13??
&gt;
&gt; innodump is going to be much faster than riak-admin backup, I believe,
&gt; since it's dumping data at a much lower-level.
&gt;
&gt; Yes, you could setup a whole new cluster...but that really shouldn't
&gt; be necessary. If I were backing up your cluster, here's what I would
&gt; do (off the cuff):
&gt;
&gt; 1. Take down one node at a time and innodump the data so I have a
&gt; known good backup
&gt;


If you're taking each node down, why not simply backup the filesystem
instead of using innodump? Restoring the filesystem should work just as
well, right? That way you'd have a backend agnostic procedure that would
also be faster and you'd always backup the ring state (less steps).

-jd




&gt; 2. For each node, backup the ring and any other config info
&gt; 3. Take down cluster; upgrade in place (i.e. try to use the existing
&gt; config, ring and data)
&gt; 4. Bring cluster back up
&gt; 4a. If there are problems when bringing cluster back up, revert to
&gt; previous version/config. Data \_should\_ be ok, but if push comes to
&gt; shove you'll have to reload via innoload.
&gt;
&gt; As noted before, test..test..test before doing this in a production
&gt; environment. :)
&gt;
&gt; D.
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

