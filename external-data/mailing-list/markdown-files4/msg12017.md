---
title: "Re: Practical Riak cluster choices in AWS (number of nodes? AZ's?)"
description: ""
project: community
lastmod: 2013-08-13T20:52:47-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12017"
mailinglist_parent_id: "msg12015"
author_name: "Matthew Dawson"
project_section: "mailinglistitem"
sent_date: 2013-08-13T20:52:47-07:00
---


On August 13, 2013 10:20:48 PM Brady Wetherington wrote:
&gt; One thing that I \*think\* I've figured out is that the number of "how many
&gt; replicas can you lose and stay up" is actually n-w for writes, and n-r for
&gt; reads -
&gt; 
&gt; So with n=3 and r=2 and w=2, the loss of two replicas due to AZ failure
&gt; means that I still \*have\* my data ("durability") but I might lose \_access\_
&gt; to it ("availability") for a little bit. And with that weird feature that
&gt; Riak has (the feature's name escapes me for now?) I might even be able to
&gt; write new data if my cluster figures out that the downed nodes are actually
&gt; down; I think it just stores the writes on the remaining boxen, and
&gt; eventually it gets distributed back once the nodes come back. Neat stuff.
&gt; 
Actually, that is sort of true. If you lose two nodes, when you request a 
read, it will initially fail as it can only preform the read against one node, 
and the two fall over vnodes won't have the data. However, the cluster will 
recognize that there is data missing in the fallover vnodes, and initiate 
read-repair. So the next read will in fact work just fine. If you build your 
app to assume reads may transiently fail, then you shouldn't have an issue.
Write will also continue to work in the same way (like you mentioned).
-- 
Matthew

smime.p7s
Description: S/MIME cryptographic signature
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

