---
title: "Re: cloned machines issues"
description: ""
project: community
lastmod: 2013-04-29T05:33:04-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10988"
mailinglist_parent_id: "msg10987"
author_name: "Pieter Breed"
project_section: "mailinglistitem"
sent_date: 2013-04-29T05:33:04-07:00
---


Thanks,

I actually went with shutting down both clusters completely and deleting
everything in the /var/lib/riak folders on all of the machines . Then
setting up the clusters again from scratch.

The nature of our solution means that our data is transient anyway, so it
worked for us.

Pieter
&gt;
&gt; On 29 Apr 2013 12:58, "Shane McEwan"  wrote:
&gt;&gt;
&gt;&gt; On 27/04/13 10:56, Pieter Breed wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; I'm trying to get two cloned machines to form a new cluster but I'm
&gt;&gt;&gt; struggling to get rid of the old cluster config.
&gt;&gt;
&gt;&gt;
&gt;&gt; I went through the same issue when trying to clone our production
cluster to use as a staging cluster.
&gt;&gt;
&gt;&gt; The trick is to configure the new cluster completely independently of
the one you're cloning and only copy the data directories (for LevelDB,
anyway. I don't know if it works with other backends.). Don't copy any of
the configuration files from the original cluster.
&gt;&gt;
&gt;&gt; Here is how I did it:
&gt;&gt;
&gt;&gt; \* Create a new, empty cluster on the staging servers.
&gt;&gt; \* Shut down Riak on the new cluster.
&gt;&gt; \* If possible, shut down Riak on the production cluster to ensure a
clean copy.
&gt;&gt; \* Copy the Production "leveldb" data directory to the staging servers.
NOTE: To avoid unnecessary handoffs between staging nodes make sure you
clone the nodes in the same order as the 'ringready' command lists them.
First production node to first staging node, etc.
&gt;&gt; \* Start Riak on the staging cluster.
&gt;&gt; \* Riak will start using the leveldb data as if it was its own. There's
nothing in the leveldb data directories that ties the data to a particular
node name.
&gt;&gt; \* Monitor the Riak logs for errors or handoffs. Excessive handoffs means
you've cloned one or more production nodes to the wrong staging nodes. Riak
will fix it but it's inefficient.
&gt;&gt;
&gt;&gt; I now automatically update our staging nodes every night with an rsync
of our production snapshot backups. This has two advantages: First, it
gives us a test platform with real, almost current, production data; and
second, it tests our backup system ensuring that our snapshots actually
work when loaded into Riak.
&gt;&gt;
&gt;&gt; Shane.
&gt;&gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

