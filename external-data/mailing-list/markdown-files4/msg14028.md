---
title: "Re: RIAK 1.4.6 - Mass key deletion"
description: ""
project: community
lastmod: 2014-04-08T09:20:03-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14028"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2014-04-08T09:20:03-07:00
---


Edgar,

The test I have running currently has reach 1 Billion keys. It is running 
against a single node with N=1. It has 42G of AAE data. Here is my 
extrapolation to compare your numbers:

You have ~2.5 Billion keys. I assume you are running N=3 (the default). AAE 
therefore is actually tracking ~7.5 Billion keys. You have six nodes, 
therefore tracking ~1.25 Billion keys per node.

Raw math would suggest that my 42G of AAE data for 1 billion keys would 
extrapolate to 52.5G of AAE data for you. Yet you have ~120G of AAE data. Is 
something wrong? No. My data is still loading and has experience zero 
key/value updates/edits.

AAE hashes get rewritten every time a user updates the value of a key. AAE's 
leveldb is just like the user leveldb, all prior values of a key accumulate in 
the .sst table files until compaction removes duplicates. Similarly, a user 
delete of a key causes a delete tombstone in the AAE hash tree. Those delete 
tombstones have to await compactions too before leveldb recovers the disk space.

AAE's hash trees rebuild weekly. I am told that the rebuild operation will 
actually destroy the existing files and start over. That is when you should 
see AAE space usage dropping dramatically.

Matthew


On Apr 8, 2014, at 9:31 AM, Edgar Veiga  wrote:

&gt; Thanks a lot Matthew!
&gt; 
&gt; A little bit of more info, I've gathered a sample of the contents of 
&gt; anti-entropy data of one of my machines:
&gt; - 44 folders with the name equal to the name of the folders in level-db dir 
&gt; (i.e. 393920363186844927172086927568060657641638068224/)
&gt; - each folder has a 5 files (log, current, log, etc) and 5 sst\_\* folders.
&gt; - The biggest sst folder is sst\_3 with 4.3G
&gt; - Inside sst\_3 folder there are 1219 files name 00\*\*\*\*.sst.
&gt; - Each of the 00\*\*\*\*\*.sst files has ~3.7M
&gt; 
&gt; Hope this info gives you some more help! 
&gt; 
&gt; Best regards, and again, thanks a lot
&gt; Edgar
&gt; 
&gt; 
&gt; On 8 April 2014 13:24, Matthew Von-Maszewski  wrote:
&gt; Argh. Missed where you said you had upgraded. Ok it will proceed with getting 
&gt; you comparison numbers. 
&gt; 
&gt; Sent from my iPhone
&gt; 
&gt; On Apr 8, 2014, at 6:51 AM, Edgar Veiga  wrote:
&gt; 
&gt;&gt; Thanks again Matthew, you've been very helpful!
&gt;&gt; 
&gt;&gt; Maybe you can give me some kind of advise on this issue I'm having since 
&gt;&gt; I've upgraded to 1.4.8.
&gt;&gt; 
&gt;&gt; Since I've upgraded my anti-entropy data has been growing a lot and has only 
&gt;&gt; stabilised in very high values... Write now my cluster has 6 machines each 
&gt;&gt; one with ~120G of anti-entropy data and 600G of level-db data. This seems to 
&gt;&gt; be quite a lot no? My total amount of keys is ~2.5 Billions.
&gt;&gt; 
&gt;&gt; Best regards,
&gt;&gt; Edgar
&gt;&gt; 
&gt;&gt; On 6 April 2014 23:30, Matthew Von-Maszewski  wrote:
&gt;&gt; Edgar,
&gt;&gt; 
&gt;&gt; This is indirectly related to you key deletion discussion. I made changes 
&gt;&gt; recently to the aggressive delete code. The second section of the following 
&gt;&gt; (updated) web page discusses the adjustments:
&gt;&gt; 
&gt;&gt; https://github.com/basho/leveldb/wiki/Mv-aggressive-delete
&gt;&gt; 
&gt;&gt; Matthew
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Apr 6, 2014, at 4:29 PM, Edgar Veiga  wrote:
&gt;&gt; 
&gt;&gt;&gt; Matthew, thanks again for the response!
&gt;&gt;&gt; 
&gt;&gt;&gt; That said, I'll wait again for the 2.0 (and maybe buy some bigger disks :)
&gt;&gt;&gt; 
&gt;&gt;&gt; Best regards
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On 6 April 2014 15:02, Matthew Von-Maszewski  wrote:
&gt;&gt;&gt; Edgar,
&gt;&gt;&gt; 
&gt;&gt;&gt; In Riak 1.4, there is no advantage to using empty values versus deleting.
&gt;&gt;&gt; 
&gt;&gt;&gt; leveldb is a "write once" data store. New data for a given key never 
&gt;&gt;&gt; physically overwrites old data for the same key. New data "hides" the old 
&gt;&gt;&gt; data by being in a lower level, and therefore picked first.
&gt;&gt;&gt; 
&gt;&gt;&gt; leveldb's compaction operation will remove older key/value pairs only when 
&gt;&gt;&gt; the newer key/value is pair is part of a compaction involving both new and 
&gt;&gt;&gt; old. The new and the old key/value pairs must have migrated to adjacent 
&gt;&gt;&gt; levels through normal compaction operations before leveldb will see them in 
&gt;&gt;&gt; the same compaction. The migration could take days, weeks, or even months 
&gt;&gt;&gt; depending upon the size of your entire dataset and the rate of incoming 
&gt;&gt;&gt; write operations.
&gt;&gt;&gt; 
&gt;&gt;&gt; leveldb's "delete" object is exactly the same as your empty JSON object. 
&gt;&gt;&gt; The delete object simply has one more flag set that allows it to also be 
&gt;&gt;&gt; removed if and only if there is no chance for an identical key to exist on 
&gt;&gt;&gt; a higher level.
&gt;&gt;&gt; 
&gt;&gt;&gt; I apologize that I cannot give you a more useful answer. 2.0 is on the 
&gt;&gt;&gt; horizon.
&gt;&gt;&gt; 
&gt;&gt;&gt; Matthew
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On Apr 6, 2014, at 7:04 AM, Edgar Veiga  wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Hi again!
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Sorry to reopen this discussion, but I have another question regarding the 
&gt;&gt;&gt;&gt; former post.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; What if, instead of doing a mass deletion (We've already seen that it will 
&gt;&gt;&gt;&gt; be non profitable, regarding disk space) I update all the values with an 
&gt;&gt;&gt;&gt; empty JSON object "{}" ? Do you see any problem with this? I no longer 
&gt;&gt;&gt;&gt; need those millions of values that are living in the cluster... 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; When the version 2.0 of riak runs stable I'll do the update and only then 
&gt;&gt;&gt;&gt; delete those keys!
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Best regards
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On 18 February 2014 16:32, Edgar Veiga  wrote:
&gt;&gt;&gt;&gt; Ok, thanks a lot Matthew.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On 18 February 2014 16:18, Matthew Von-Maszewski  
&gt;&gt;&gt;&gt; wrote:
&gt;&gt;&gt;&gt; Riak 2.0 is coming. Hold your mass delete until then. The "bug" is 
&gt;&gt;&gt;&gt; within Google's original leveldb architecture. Riak 2.0 sneaks around to 
&gt;&gt;&gt;&gt; get the disk space freed.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On Feb 18, 2014, at 11:10 AM, Edgar Veiga  wrote:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; The only/main purpose is to free disk space..
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; I was a little bit concerned regarding this operation, but now with your 
&gt;&gt;&gt;&gt;&gt; feedback I'm tending to don't do nothing, I can't risk the growing of 
&gt;&gt;&gt;&gt;&gt; space... 
&gt;&gt;&gt;&gt;&gt; Regarding the overhead I think that with a tight throttling system I 
&gt;&gt;&gt;&gt;&gt; could control and avoid overloading the cluster.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Mixed feelings :S
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; On 18 February 2014 15:45, Matthew Von-Maszewski  
&gt;&gt;&gt;&gt;&gt; wrote:
&gt;&gt;&gt;&gt;&gt; Edgar,
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; The first "concern" I have is that leveldb's delete does not free disk 
&gt;&gt;&gt;&gt;&gt; space. Others have executed mass delete operations only to discover they 
&gt;&gt;&gt;&gt;&gt; are now using more disk space instead of less. Here is a discussion of 
&gt;&gt;&gt;&gt;&gt; the problem:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; https://github.com/basho/leveldb/wiki/mv-aggressive-delete
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; The link also describes Riak's database operation overhead. This is a 
&gt;&gt;&gt;&gt;&gt; second "concern". You will need to carefully throttle your delete rate 
&gt;&gt;&gt;&gt;&gt; or the overhead will likely impact your production throughput.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; We have new code to help quicken the actual purge of deleted data in Riak 
&gt;&gt;&gt;&gt;&gt; 2.0. But that release is not quite ready for production usage.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; What do you hope to achieve by the mass delete?
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; On Feb 18, 2014, at 10:29 AM, Edgar Veiga  wrote:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Sorry, forgot that info!
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; It's leveldb.
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Best regards
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; On 18 February 2014 15:27, Matthew Von-Maszewski  
&gt;&gt;&gt;&gt;&gt;&gt; wrote:
&gt;&gt;&gt;&gt;&gt;&gt; Which Riak backend are you using: bitcask, leveldb, multi?
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; On Feb 18, 2014, at 10:17 AM, Edgar Veiga  wrote:
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; Hi all!
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; I have a fairly trivial question regarding mass deletion on a riak 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; cluster, but firstly let me give you just some context. My cluster is 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; running with riak 1.4.6 on 6 machines with a ring of 256 nodes and 1Tb 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; ssd disks.
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; I need to execute a massive object deletion on a bucket, I'm talking 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; of ~1 billion keys (The object average size is ~1Kb). I will not 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; retrive the keys from riak because a I have a file with all of them. 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; I'll just start a script that reads them from the file and triggers an 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; HTTP DELETE for each one.
&gt;&gt;&gt;&gt;&gt;&gt; &gt; The cluster will continue running on production with a quite high load 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; serving all other applications, while running this deletion.
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; My question is simple, do I need to have any kind of extra concerns 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; regarding this action? Do you advise me on taking special attention to 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; any kind of metrics regarding riak or event the servers where it's 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; running?
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; Best regards!
&gt;&gt;&gt;&gt;&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak-users mailing list
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt;&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt; 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

