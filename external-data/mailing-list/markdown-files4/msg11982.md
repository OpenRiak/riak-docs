---
title: "Re: Practical Riak cluster choices in AWS (number of nodes? AZ's?)"
description: ""
project: community
lastmod: 2013-08-12T12:08:39-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11982"
mailinglist_parent_id: "msg11980"
author_name: "Hector Castro"
project_section: "mailinglistitem"
sent_date: 2013-08-12T12:08:39-07:00
---


On Mon, Aug 12, 2013 at 2:38 PM, Dave Martorana  wrote:
&gt; Jared - thanks for the links. I'm in the same boat with Brady with weighing
&gt; deployment options in AWS.
&gt;
&gt; Jeremiah - isn't EBS the only option once your data starts reaching into the
&gt; hundreds-of-gigs?

Several instances give you &gt; 1TB of instance store if you combine the
volumes. [0]

It may also be worth noting that if you flip the EBS-optimized bit on
instances that support it, you can get 500Mbps-1000Mbps between your
instance and EBS. [1]

&gt; Dave

[0] 
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#StorageOnInstanceTypes
[1] 
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#EBSOptimized

&gt; On Sun, Aug 11, 2013 at 8:57 PM, Jared Morrow  wrote:
&gt;&gt;
&gt;&gt; +1 to what Jeremiah said, putting a 4 or 5 node cluster in each US West
&gt;&gt; and US East using MDC between them would be the optimum solution. I'm also
&gt;&gt; not buying consistent latencies between AZ's, but I've also not tested it
&gt;&gt; personally in a production environment. We have many riak-users members on
&gt;&gt; AWS, so hopefully more experienced people will chime in.
&gt;&gt;
&gt;&gt; If you haven't seen them already, here's what I have in my "Riak on AWS"
&gt;&gt; bookmark folder:
&gt;&gt;
&gt;&gt; http://media.amazonwebservices.com/AWS\_NoSQL\_Riak.pdf
&gt;&gt; http://docs.basho.com/riak/latest/ops/tuning/aws/
&gt;&gt; http://basho.com/riak-on-aws-deployment-options/
&gt;&gt;
&gt;&gt; -Jared
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On Sun, Aug 11, 2013 at 6:11 PM, Jeremiah Peschka
&gt;&gt;  wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; I'd be wary of using EBS backed nodes for Riak - with only a single
&gt;&gt;&gt; ethernet connection, it wil be very easy to saturate the max of 1000mbps
&gt;&gt;&gt; available in a single AWS NIC (unless you're using cluster compute
&gt;&gt;&gt; instances). I'd be more worried about temporarily losing contact with a node
&gt;&gt;&gt; through network saturation than through AZ failure, truthfully.
&gt;&gt;&gt;
&gt;&gt;&gt; The beauty of Riak is that a node can drop and you can replace it with
&gt;&gt;&gt; minimal fuss. Use that to your advantage and make every node in the cluster
&gt;&gt;&gt; disposable.
&gt;&gt;&gt;
&gt;&gt;&gt; As far as doubling up in one AZ goes - if you're worried about AZ
&gt;&gt;&gt; failure, you should treat each AZ as a separate data center and design your
&gt;&gt;&gt; failure scenarios accordingly. Yes, Amazon say you should put one Riak node
&gt;&gt;&gt; in each AZ; I'm not buying that. With no guarantee around latency, and no
&gt;&gt;&gt; control around between DCs, you need to be very careful how much of that
&gt;&gt;&gt; latency you're willing to introduce into your application.
&gt;&gt;&gt;
&gt;&gt;&gt; Were I in your position, I'd stand up a 5 node cluster in US-WEST-2 and
&gt;&gt;&gt; be done with it. I'd consider Riak EE for my HA/DR solution once the
&gt;&gt;&gt; business decides that off-site HA/DR is something it wants/needs.
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt; Jeremiah Peschka - Founder, Brent Ozar Unlimited
&gt;&gt;&gt; MCITP: SQL Server 2008, MVP
&gt;&gt;&gt; Cloudera Certified Developer for Apache Hadoop
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Sun, Aug 11, 2013 at 1:52 PM, Brady Wetherington
&gt;&gt;&gt;  wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Hi all -
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I have some questions about how I want my Riak stuff to work - I've
&gt;&gt;&gt;&gt; already asked these questions of some Basho people and gotten some answers,
&gt;&gt;&gt;&gt; but thought I would toss it out into the wider world to see what you all
&gt;&gt;&gt;&gt; have to say, too:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; First off - I know 5 instances is the "magic number" of instances to
&gt;&gt;&gt;&gt; have. If I understand the thinking here, it's that at the default 
&gt;&gt;&gt;&gt; redundancy
&gt;&gt;&gt;&gt; level ('n'?) of 3, it is most likely to start getting me some scaling 
&gt;&gt;&gt;&gt; (e.g.,
&gt;&gt;&gt;&gt; performance &gt; just that of a single node), and yet also have redundancy;
&gt;&gt;&gt;&gt; whereby I can lose one box and not start to take a performance hit.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; My question is - I think I can only do 4 in a way that makes sense. I
&gt;&gt;&gt;&gt; only have 4 AZ's that I can use right now; AWS won't let me boot instances
&gt;&gt;&gt;&gt; in 1a. My concern is if I try to do 5, I will be "doubling up" in one AZ -
&gt;&gt;&gt;&gt; and in AWS you're almost as likely to lose an entire AZ as you are a single
&gt;&gt;&gt;&gt; instance. And so, if I have instances doubled-up in one AZ (let's say
&gt;&gt;&gt;&gt; us-east-1e), and then I lose 1e, I've now lost two instances. What are the
&gt;&gt;&gt;&gt; chances that all three of my replicas of some chunk of my data are on those
&gt;&gt;&gt;&gt; two instances? I know that it's not guaranteed that all replicas are on
&gt;&gt;&gt;&gt; separate nodes.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; So is it better for me to ignore the recommendation of 5 nodes, and just
&gt;&gt;&gt;&gt; do 4? Or to ignore the fact that I might be doubling-up in one AZ? Also,
&gt;&gt;&gt;&gt; another note. These are designed to be 'durable' nodes, so if one should go
&gt;&gt;&gt;&gt; down I would expect to bring it back up \*with\* its data - or, if I 
&gt;&gt;&gt;&gt; couldn't,
&gt;&gt;&gt;&gt; I would do a force-replace or replace and rebuild it from the other
&gt;&gt;&gt;&gt; replicas. I'm definitely not doing instance-store. So I don't know if that
&gt;&gt;&gt;&gt; mitigates my need for a full 5 nodes. I would also consider losing one node
&gt;&gt;&gt;&gt; to be "degraded" and would probably seek to fix that problem as soon as
&gt;&gt;&gt;&gt; possible, so I wouldn't expect to be in that situation for long. I would
&gt;&gt;&gt;&gt; probably tolerate a drop in performance during that time, too. (Not a
&gt;&gt;&gt;&gt; super-severe one, but 20-30 percent? Sure.)
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; What do you folks think?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; -B.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

