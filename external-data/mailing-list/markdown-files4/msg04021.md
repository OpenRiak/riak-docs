---
title: "Re: riaksearch performace when numFound is high"
description: ""
project: community
lastmod: 2011-07-15T13:01:32-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04021"
mailinglist_parent_id: "msg04018"
author_name: "Greg Pascale"
project_section: "mailinglistitem"
sent_date: 2011-07-15T13:01:32-07:00
---


Ryan,

Thanks for the detailed reply.

We're a node.js shop and we're hitting riak via the riak-js library, which
AFAIK just uses the http client.

We haven't actually scaled out to the point where we're seeing huge #s of
results returned, but if we extrapolate from the numbers we are seeing, it's
clear that we'll start to hit these limits. We have a lot of #2 type queries
because we support full text search, and unfortunately our "text" tends to
be a lot longer than 140 characters, so I really don't think inlining it is
practical.

-- Greg
Clipboard  is hiring
!


On Fri, Jul 15, 2011 at 11:49 AM, Ryan Zezeski  wrote:

&gt; Greg,
&gt;
&gt; I'm curious to know how you are querying search (i.e. which client/API) and
&gt; what your setup looks like (i.e. # of nodes, disk, network between them,
&gt; etc). How many of these #2 query types are you seeing and what's the
&gt; average # of results being returned? Is your search instance opened up to
&gt; user queries?
&gt;
&gt; Ignoring any other inefficiencies in the Search code I'd say that there are
&gt; two main points working against you in query #2
&gt;
&gt; 1.) Search uses a \_global index\_ [1] which means that, as Rusty would say,
&gt; it's partitioned by term (as opposed to a \_local index\_ which would
&gt; partition by document). It has been found, in cases where the query
&gt; contains less terms than the processor count, that a global index scales out
&gt; better as it has better concurrency characteristics [1]. However, a local
&gt; index can balance load better and in the case of #2 could possibly drop
&gt; latency times. When you perform that "text:guitar AND date:07/14/11" each
&gt; term is queried by one, and only one, vnode. These results are then
&gt; combined by a coordinator (called a broker in [1]). How much using a local
&gt; index would change your observed latency is unknown to me, but it would have
&gt; other effects that may offset any latency drops.
&gt;
&gt; 2.) Search is not limiting the results returned. Instead of sorting the
&gt; results based on relevance and only taking the top N from each query term
&gt; it's getting all data from each query, passing it to the coordinator and
&gt; saying "hey, you figure this out." When you run that #2 query, as you said,
&gt; you are bounded by your largest result set because that's the only way for
&gt; search to know it's correctly answered the query. Said another way, you may
&gt; only have 10 entries for the 14th but you still need to search all 100K
&gt; guitar entries to determine which ones fall on that date. Performing some
&gt; sort of relevance calculation beforehand and limiting the result
&gt; would certainly help but it also means you won't get the full result set. I
&gt; don't think there's any way to have your cake and eat it too unless you can
&gt; afford to put everything in memory.
&gt;
&gt; At this point in time I think inline fields will be your best bet. Inline
&gt; fields help dramatically here because you are essentially bringing part of
&gt; your document into each term entry in the index. This means you can query
&gt; on high cardinality terms and filter on lower ones, i.e. low latency (high
&gt; and low being relative here). If you're worried about disk space then you
&gt; can make use of the `only` value for the inline attribute. This tells
&gt; Search to store this field's value inline but \_don't\_ index it. If you're
&gt; only using the `text` field to filter results then this is exactly what you
&gt; should do. In fact, I would recommend you do that because any search
&gt; against the `text` field for a corpus of tweets is probably going to have a
&gt; large result set.
&gt;
&gt;
&gt; HTH,
&gt; -Ryan
&gt;
&gt; [1]: C.S. Badue. Distributed query processing using partitioned inverted
&gt; files. Master's thesis, Federal University of Minas Gerais, Belo Horizonte,
&gt; Minas Gerias, Brazil, March 2001.
&gt;
&gt; On Thu, Jul 14, 2011 at 6:20 PM, Greg Pascale  wrote:
&gt;
&gt;&gt; Hi Ryan,
&gt;&gt;
&gt;&gt; Yes we are using 14.2.
&gt;&gt;
&gt;&gt; I think I get what you are saying about inline fields. It looks like it
&gt;&gt; will fix some of our problems, but not all of them. If you'll indulge me in
&gt;&gt; a little contrived example, I think I can explain what I mean.
&gt;&gt;
&gt;&gt; Let's say I'm implementing a simple twitter clone. In my system, tweets
&gt;&gt; have a user, text, date and can be either public or private - so one might
&gt;&gt; look like
&gt;&gt;
&gt;&gt; {
&gt;&gt; username: greg,
&gt;&gt; public: true,
&gt;&gt; text: "I bought a new guitar!",
&gt;&gt; date: 07/14/11
&gt;&gt; }
&gt;&gt;
&gt;&gt; Let's say that my service is popular - I have 100k users, each of whom has
&gt;&gt; published exactly 100 tweets, and exactly half of the tweets are public, the
&gt;&gt; rest are private. So I have 10 million tweets total and 5 million of them
&gt;&gt; are public.
&gt;&gt;
&gt;&gt; Query 1: "username:greg AND public:false" - this finds all tweets by greg
&gt;&gt; that are private. In this case "username:greg" matches 100 results and
&gt;&gt; "public:false" matches 5 million. My tests have shown that the performance
&gt;&gt; of this compound query will be roughly equivalent to the worse of the two
&gt;&gt; ("public:false") - so this query will be way too slow.
&gt;&gt; However, since "public" values are nice and small, I can inline it for a
&gt;&gt; big win.
&gt;&gt;
&gt;&gt; Query 2: "text:guitar AND date:07/14/11" - this finds all tweets from
&gt;&gt; today that contain "guitar". Suppose there are 100k tweets that contain
&gt;&gt; "guitar", but it's early in the day so there have only been 1k tweets in
&gt;&gt; total on 07/14/11. My result set is therefore no bigger than 1k (probably
&gt;&gt; much smaller unless all my users bought new guitars today), but this query
&gt;&gt; is still bounded by the "text:guitar" piece which matches 100k results. In
&gt;&gt; this case, inlining date wouldn't help because it's not the slow part, and
&gt;&gt; indexing on the text field isn't practical - it's too big.
&gt;&gt;
&gt;&gt; If you could follow that, am I understanding this correctly? In our
&gt;&gt; system, we have some queries like #1 above, but since we support full text
&gt;&gt; search, many like #2 as well. Do you have any suggestions for what we could
&gt;&gt; do to make queries like #2 performant?
&gt;&gt;
&gt;&gt; Thanks,
&gt;&gt; -Greg
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On Wed, Jul 13, 2011 at 7:19 PM, Ryan Zezeski  wrote:
&gt;&gt;
&gt;&gt;&gt; Greg,
&gt;&gt;&gt;
&gt;&gt;&gt; I'm assuming you are using 14.2.
&gt;&gt;&gt;
&gt;&gt;&gt; 1) There is a bug in 14.2 that will cause a (potentially very fast
&gt;&gt;&gt; growing) memory leak when using AND. This is unfortunate, sorry. The good
&gt;&gt;&gt; news I have since patched it [1].
&gt;&gt;&gt;
&gt;&gt;&gt; 2) This is your best course of action, and you were so close but you've
&gt;&gt;&gt; actually crossed your fields. That is, the inline field should be the one
&gt;&gt;&gt; that contains the more common term (i.e. the 'text' field). So you should
&gt;&gt;&gt; perform a range query on your date with a filter on the text inline field.
&gt;&gt;&gt; Obviously, the more terms in this field the more the index will inflate
&gt;&gt;&gt; (space-wise), but if you can live with that then it should reduce your
&gt;&gt;&gt; latency substantially (famous last words). Please try this and get back to
&gt;&gt;&gt; me.
&gt;&gt;&gt;
&gt;&gt;&gt; 3) That is a very well written article, props to the author. However, I
&gt;&gt;&gt; would leave this as a last resort. Try what I mentioned in #2, and if
&gt;&gt;&gt; that's not enough to get you by then let's brainstorm.
&gt;&gt;&gt;
&gt;&gt;&gt; [1]:
&gt;&gt;&gt; https://github.com/basho/riak\_search/commit/cd910c2519f94e9d7e8a8e21894db9d0eecdd5b4
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Wed, Jul 6, 2011 at 2:43 PM, Greg Pascale  wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Hi,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I'm looking at ways to improve riaksearch queries that produce a lot of
&gt;&gt;&gt;&gt; matches.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; In my use case, I only ever want the top 20 results for any query, and
&gt;&gt;&gt;&gt; results should be ordered by date (which is encoded in the key). For
&gt;&gt;&gt;&gt; searches with few matches (numFound &lt; ~1000), performance is great. For
&gt;&gt;&gt;&gt; searches with more matches (numFound &gt; ~10000), performance starts to lag
&gt;&gt;&gt;&gt; even though I only ever want the top 20. I assume this is because the 
&gt;&gt;&gt;&gt; system
&gt;&gt;&gt;&gt; needs to fetch and sort all of the results to know what the top 20 are, but
&gt;&gt;&gt;&gt; I'm hoping I can exploit the constraints of my use case in some way to
&gt;&gt;&gt;&gt; increase performance. I've looked at the following approaches.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; 1) AND the "text:" term with a small date range (e.g. text:
&gt;&gt;&gt;&gt; AND date:[]). This reduces the result set, but
&gt;&gt;&gt;&gt; performance does not improve. At best, the performance is as good as simply
&gt;&gt;&gt;&gt; doing the "text:" search without the date range, and in some
&gt;&gt;&gt;&gt; cases worse.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; 2) Same as above, but make the date an inline field. From what I could
&gt;&gt;&gt;&gt; find on the topic, it sounded like this is exactly what inline fields or
&gt;&gt;&gt;&gt; for, but I was disappointed to discover it performed far worse than even 
&gt;&gt;&gt;&gt; the
&gt;&gt;&gt;&gt; compound query above.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; 3) In this article ,
&gt;&gt;&gt;&gt; which I was linked to from somewhere on the basho site, the author 
&gt;&gt;&gt;&gt; describes
&gt;&gt;&gt;&gt; a technique in which he calls search\_fold directly and stops after he's
&gt;&gt;&gt;&gt; received enough results. He claims this is possible in his case because
&gt;&gt;&gt;&gt; results are returned in key order, and he's chosen his keys to match the
&gt;&gt;&gt;&gt; desired ordering of his results. My keys have the same property, as I'm
&gt;&gt;&gt;&gt; already using the presort=key option. Is this behavior of search\_fold a
&gt;&gt;&gt;&gt; lucky side-effect, or is this actually guaranteed to work?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Am I simply expecting too much of riaksearch here, or is there a way to
&gt;&gt;&gt;&gt; make this work? If all else fails, I suppose I could divide my data into
&gt;&gt;&gt;&gt; more buckets, but I'm hoping to avoid that as it would make querying much
&gt;&gt;&gt;&gt; more complex.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks,
&gt;&gt;&gt;&gt; -Greg
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

