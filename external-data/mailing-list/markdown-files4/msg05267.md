---
title: "Re: Key Filter Timeout"
description: ""
project: community
lastmod: 2011-10-24T07:23:37-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05267"
author_name: "Mark Steele"
project_section: "mailinglistitem"
sent_date: 2011-10-24T07:23:37-07:00
---


Just curious Kyle, you using the 1.0 series?

I've done some informal testing on a 3 node 1.0 cluster and key listing was 
working just peachy on 60 million keys using bitcask as the backend.

Cheers,

Mark

On Sunday 23 October 2011 12:26:35 Aphyr wrote:
&gt; On 10/23/2011 12:11 PM, Jim Adler wrote:
&gt; &gt; I will be loosening the key filter criterion after I get the basics
&gt; &gt; working, which I thought would be a simple equality check. 8M keys
&gt; &gt; isn't really a large data set, is it? I thought that keys were stored
&gt; &gt; in memory and key filters just operated on those memory keys and not
&gt; &gt; data.
&gt; &gt;
&gt; &gt; Jim
&gt; 
&gt; That's about where we started seeing timeouts in list-keys. Around 25
&gt; million keys, list-keys started to take down the cluster. (6 nodes, 1024
&gt; partitions). You may not encounter these problems, but were I in your
&gt; position and planning to grow... I would prepare to stop using key
&gt; filters, bucket listing, and key listing early.
&gt; 
&gt; Our current strategy is to store the keys in Redis, and synchronize them
&gt; with post-commit hooks and a process that reads over bitcask. With
&gt; ionice 3, it's fairly low-impact. https://github.com/aphyr/bitcask-ruby
&gt; may be useful.
&gt; 
&gt; --Kyle
&gt; 
&gt; # Simplified code, extracted from our bitcask scanner:
&gt; def run
&gt; `renice 10 #{Process.pid}`
&gt; `ionice -c 3 -p #{Process.pid}`
&gt; 
&gt; begin
&gt; bitcasks\_dir = '/var/lib/riak/bitcask'
&gt; dirs = Dir.entries(bitcasks\_dir).select do |dir|
&gt; dir =~ /^\d+$/
&gt; end.map do |dir|
&gt; File.join(bitcasks\_dir, dir)
&gt; end
&gt; 
&gt; dirs.each do |dir|
&gt; scan dir
&gt; GC.start
&gt; end
&gt; log.info "Completed run"
&gt; rescue =&gt; e
&gt; log.error "#{e}\n#{e.backtrace.join "\n"}"
&gt; sleep 10
&gt; end
&gt; end
&gt; end
&gt; 
&gt; def scan(dir)
&gt; log.info "Loading #{dir}"
&gt; b = Bitcask.new dir
&gt; b.load
&gt; 
&gt; log.info "Updating #{dir}"
&gt; b.keydir.each do |key, e|
&gt; bucket, key = BERT.decode(key).map { |x|
&gt; Rack::Utils.unescape x
&gt; }
&gt; # Handle determines what to do with this particular bucket/key
&gt; # combo; e.g. insert into redis.
&gt; handle bucket, key, e
&gt; end
&gt; end
&gt; 
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

