---
title: "Re: Very (very) slow handoff, how to investigate?"
description: ""
project: community
lastmod: 2012-05-24T12:23:15-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07533"
mailinglist_parent_id: "msg06467"
author_name: "Matthew Tovbin"
project_section: "mailinglistitem"
sent_date: 2012-05-24T12:23:15-07:00
---


Guys,

Thanks for the tips!! Helpful indeed.

-Matthew



On Tue, Jan 31, 2012 at 2:32 AM, Gal Barnea  wrote:

&gt; Guys
&gt; Thanks a lot for the helpful pointers
&gt;
&gt; I decided to focus more on speeding the process of joining servers to the
&gt; cluster, where it is easier to monitor disk space during the handoff
&gt; ("&gt;watch df -B M" and "dstat -dn -D") and deduct the actual handoff
&gt; progress (When partitions are big enough, there is very little indication
&gt; of their handoff progress in riak's logs)
&gt;
&gt; Increasing the handoff\_cuncurrency did indeed help push the handoff rate
&gt; much higher
&gt; Also, running on EC2 I was able to setup RAID0 on multiple ephemeral
&gt; drives which helped me reach rates of around 35-40 MB/s - practically the
&gt; IO limit set by amazon
&gt;
&gt; Thanks guys!
&gt;
&gt;
&gt; On Fri, Jan 27, 2012 at 9:26 PM, Joseph Blomstedt  wrote:
&gt;
&gt;&gt; Gal,
&gt;&gt;
&gt;&gt; 0.5 to 1 MB/s is indeed painfully slow.
&gt;&gt;
&gt;&gt; A few questions:
&gt;&gt; What backend are you running: bitcask,leveldb, etc?
&gt;&gt; Are you using the local ephemeral storage, or running off EBS?
&gt;&gt; Are you running any software RAID?
&gt;&gt; What filesystem are you running?
&gt;&gt; Which OS are you using?
&gt;&gt; Have you changed any of Riak's default settings?
&gt;&gt;
&gt;&gt; Also, any chance you could provide the output of "iostat -x" during
&gt;&gt; one of these long handoff sessions? Preferably on both the sending and
&gt;&gt; receiving nodes.
&gt;&gt;
&gt;&gt; The more information we have, the better we can try to help out here.
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt; Joe
&gt;&gt;
&gt;&gt; On Fri, Jan 27, 2012 at 7:44 AM, Ian Plosker  wrote:
&gt;&gt; &gt; Gal,
&gt;&gt; &gt;
&gt;&gt; &gt; You could try using `riak attach` and running the following to increase
&gt;&gt; the
&gt;&gt; &gt; handoff\_concurrency from 1 to 4:
&gt;&gt; &gt;
&gt;&gt; &gt; application:set\_env(riak\_core, handoff\_concurrency, 4).
&gt;&gt; &gt;
&gt;&gt; &gt; You will need to do this on all nodes. This will only remain in effect
&gt;&gt; as
&gt;&gt; &gt; long as the nodes remain running. If you wish to permanently increase
&gt;&gt; the
&gt;&gt; &gt; handoff concurrency you will have to do so in the app.config.
&gt;&gt; &gt;
&gt;&gt; &gt; --
&gt;&gt; &gt; Ian Plosker 
&gt;&gt; &gt; Developer Advocate
&gt;&gt; &gt; Basho Technologies
&gt;&gt; &gt;
&gt;&gt; &gt; On Friday, January 27, 2012 at 7:45 AM, Gal Barnea wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Hi Ian
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks for the informative answer, I am using 1.0.3 indeed.
&gt;&gt; &gt;
&gt;&gt; &gt; A day later, the cluster is making progress, but than I saw this in the
&gt;&gt; &gt; console.log:
&gt;&gt; &gt; 2012-01-27 08:51:32.643 [info]
&gt;&gt; &gt; &lt;0.30733.2881&gt;@riak\_core\_handoff\_sender:start\_fold:87 Handoff of
&gt;&gt; partition
&gt;&gt; &gt; riak\_kv\_vnode 50239118783249787813
&gt;&gt; &gt; 2516661246222288006726811648 from
&gt;&gt; &gt; 'r...@ec2-107-21-156-59.compute-1.amazonaws.com' to
&gt;&gt; &gt; 'r...@ec2-leaving.compute-1.amazonaws.com' completed: sent 5100479
&gt;&gt; objects
&gt;&gt; &gt; in 10596.49 seconds
&gt;&gt; &gt;
&gt;&gt; &gt; so we've dropped 50% in rate and are now less than 500 records/second !
&gt;&gt; &gt;
&gt;&gt; &gt; Frankly, I think this is problematic any way you look at it...If I need
&gt;&gt; to
&gt;&gt; &gt; wait days every time I manually remove a server from the cluster, it
&gt;&gt; isn't
&gt;&gt; &gt; really a valid solution from my perspective.
&gt;&gt; &gt;
&gt;&gt; &gt; Any thoughts?
&gt;&gt; &gt;
&gt;&gt; &gt; Regards
&gt;&gt; &gt; Gal
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; On Thu, Jan 26, 2012 at 11:35 PM, Ian Plosker  wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Gal,
&gt;&gt; &gt;
&gt;&gt; &gt; The limiting factor on EC2 will likely be IOPs (i.e. Disk throughput).
&gt;&gt; EC2
&gt;&gt; &gt; is a IOPs constrained environment, especially if you're using EBS.
&gt;&gt; Further,
&gt;&gt; &gt; doing a leave can induce a large number of ownership changes to ensure
&gt;&gt; that
&gt;&gt; &gt; preflists maintain the appropriate n\_vals. The number of partitions that
&gt;&gt; &gt; need to be shuffled can exceed 80% of all partitions. In short, it can
&gt;&gt; take
&gt;&gt; &gt; a while for the rebalance to complete. Assuming you're using a &gt;=1.0
&gt;&gt; &gt; release, you're cluster should still correctly respond to all incoming
&gt;&gt; &gt; requests.
&gt;&gt; &gt;
&gt;&gt; &gt; Which version of Riak are you using? As of Riak 1.0.3,
&gt;&gt; &gt; `handoff\_concurrency`, the number of outgoing handoffs per node, is set
&gt;&gt; to
&gt;&gt; &gt; 1. This will reduce the rate at which the rebalance occurs, but it
&gt;&gt; reduces
&gt;&gt; &gt; the impact of the rebalance on your cluster.
&gt;&gt; &gt;
&gt;&gt; &gt; --
&gt;&gt; &gt; Ian Plosker 
&gt;&gt; &gt; Developer Advocate
&gt;&gt; &gt; Basho Technologies, Inc.
&gt;&gt; &gt;
&gt;&gt; &gt; On Thursday, January 26, 2012 at 3:43 PM, Gal Barnea wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Ok, so now I can see in the "leaving" node logs:
&gt;&gt; &gt; 2012-01-26 19:18:23.015 [info]
&gt;&gt; &gt; &lt;0.32148.2873&gt;@riak\_core\_handoff\_sender:start\_fold:39 Starting handoff
&gt;&gt; of
&gt;&gt; &gt; partition riak\_kv\_vnode 685078892498860742907977265335757665463718379520
&gt;&gt; &gt; from 'r...@ec2-leaving.compute-1.amazonaws.com' to
&gt;&gt; &gt; 'r...@ec2-othernode.compute-1.amazonaws.com'
&gt;&gt; &gt; 2012-01-26 19:24:17.798 [info] &lt;0.31620.2873&gt; alarm\_handler:
&gt;&gt; &gt; {set,{system\_memory\_high\_watermark,[]}}
&gt;&gt; &gt; 2012-01-26 20:23:28.991 [info]
&gt;&gt; &gt; &lt;0.32148.2873&gt;@riak\_core\_handoff\_sender:start\_fold:87 Handoff of
&gt;&gt; partition
&gt;&gt; &gt; riak\_kv\_vnode 685078892498860742907977265335757665463718379520 from
&gt;&gt; &gt; 'r...@leaving.compute-1.amazonaws.com' to
&gt;&gt; &gt; 'r...@ec2-othernode.compute-1.amazonaws.com' completed: sent 5110665
&gt;&gt; objects
&gt;&gt; &gt; in 3905.97 seconds
&gt;&gt; &gt;
&gt;&gt; &gt; so things \*are\* moving but at a rate of 1308 records per second.
&gt;&gt; &gt; This sounds very slow to me, accounting for the small record size, the
&gt;&gt; high
&gt;&gt; &gt; bw rate inside ec2 and practically 0% load on the servers
&gt;&gt; &gt;
&gt;&gt; &gt; any thoughts?
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; On Thu, Jan 26, 2012 at 10:12 PM, Gal Barnea 
&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; Hi all
&gt;&gt; &gt;
&gt;&gt; &gt; I have a 6 server cluster running on ec2 (m1.large) - this is an
&gt;&gt; evaluation
&gt;&gt; &gt; environment, so practically no load besides the existing data
&gt;&gt; &gt; (~200 million records, ~1k each)
&gt;&gt; &gt;
&gt;&gt; &gt; after running "riak-admin leave" on one of the node, I noticed that for
&gt;&gt; more
&gt;&gt; &gt; than 3 hours
&gt;&gt; &gt; 1 - member\_status showed that there is one "leaving" node and pending
&gt;&gt; data
&gt;&gt; &gt; to handoff on the rest but the numbers never changed
&gt;&gt; &gt; 2 - riak-admin transfers - showed handoffs waiting, but nothing changed
&gt;&gt; &gt;
&gt;&gt; &gt; at this point, I restarted the "leaving" node, so now the status is
&gt;&gt; &gt; 1 - member\_status - still stuck with the same numbers
&gt;&gt; &gt; 2 - transfers - are slowly changing
&gt;&gt; &gt;
&gt;&gt; &gt; The leaving server's logs are showing that a single handoff started
&gt;&gt; after
&gt;&gt; &gt; the restart,but nothing since (roughly an hour ago)
&gt;&gt; &gt;
&gt;&gt; &gt; Interestingly, the leaving server is pretty idle while the remaining
&gt;&gt; servers
&gt;&gt; &gt; are working hard at 50%-60% cpu
&gt;&gt; &gt;
&gt;&gt; &gt; so, the question now is where should I dig around to try and understand
&gt;&gt; &gt; what's going on. Any thoughts?
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks
&gt;&gt; &gt; Gal
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; Joseph Blomstedt 
&gt;&gt; Software Engineer
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; http://www.basho.com/
&gt;&gt;
&gt;
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

