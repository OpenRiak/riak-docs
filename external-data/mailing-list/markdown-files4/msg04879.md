---
title: "Re: Performance Issues with LevelDB Backend on 1.0.0RC1"
description: ""
project: community
lastmod: 2011-09-26T11:34:20-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04879"
mailinglist_parent_id: "msg04878"
author_name: "Jon Meredith"
project_section: "mailinglistitem"
sent_date: 2011-09-26T11:34:20-07:00
---


Hi Patrick,

You may be running out of ports which erlang uses for TCP sockets - try
increasing ERL\_MAX\_PORTS in etc/vm.args

Cheers, Jon
Basho Technologies.

On Mon, Sep 26, 2011 at 12:17 PM, Patrick Van Stee
wrote:

&gt; We're running a small, 2 node riak cluster (on 2 m1.large boxes) using the
&gt; LevelDB backend and have been trying to write ~250 keys a second at it. With
&gt; a small dataset everything was running smoothly. However, after storing
&gt; several hundred thousand keys some performance issues started to show up.
&gt;
&gt; \* We're running out of file descriptors which is causing nodes to crash
&gt; with the following error:
&gt;
&gt; 2011-09-24 00:23:52.097 [error] &lt;0.110.0&gt; CRASH REPORT Process [] with 0
&gt; neighbours crashed with reason: {error,accept\_failed}
&gt; 2011-09-24 00:23:52.098 [error] &lt;0.121.0&gt; application: mochiweb, "Accept
&gt; failed error", "{error,emfile}
&gt;
&gt; Setting the max\_open\_files limit in the app.config doesn't seem to help.
&gt;
&gt; \* Writes have slowed down by an order of magnitude. I even set the n\_val,
&gt; w, and dw bucket properties to 1 without any noticeable difference. Also we
&gt; switched to using protocol buffers to make sure there wasn't any extra
&gt; overhead when using HTTP.
&gt;
&gt; \* Running map reduce jobs that use a range query on a secondary index
&gt; started returning an error, {"error":"map\_reduce\_error"}, once our dataset
&gt; increased in size. Feeding a list of keys works fine, but querying the index
&gt; for keys seems to be timing out:
&gt;
&gt; 2011-09-26 16:37:57.192 [error] &lt;0.136.0&gt; Supervisor riak\_pipe\_fitting\_sup
&gt; had child undefined started with {riak\_pipe\_fitting,start\_link,undefined} at
&gt; &lt;0.3497.0&gt; exit with reason
&gt; {timeout,{gen\_server,call,[{riak\_pipe\_vnode\_master,'riak@10.206.105.52
&gt; '},{return\_vnode,{'riak\_vnode\_req\_v1',502391187832497878132516661246222288006726811648,{raw,#Ref&lt;0.0.1.88700&gt;,&lt;0.3500.0&gt;},{cmd\_enqueue,{fitting,&lt;0.3499.0&gt;,#Ref&lt;0.0.1.88700&gt;,#Fun,#Fun},{&lt;&lt;"ip\_queries"&gt;&gt;,&lt;&lt;"uaukXZn5rZQ0LrSED3pi-fE-JjU"&gt;&gt;},infinity,[{502391187832497878132516661246222288006726811648,'
&gt; riak@10.206.105.52'}]}}}]}} in context child\_terminated
&gt;
&gt; Is anyone familiar with these problems or is there anything else I can try
&gt; to increase the performance when using LevelDB?
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

