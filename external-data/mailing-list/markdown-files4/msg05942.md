---
title: "Re: Open ticket for configurable R-value in MapReduce?"
description: ""
project: community
lastmod: 2011-12-14T14:34:56-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05942"
mailinglist_parent_id: "msg05941"
author_name: "Elias Levy"
project_section: "mailinglistitem"
sent_date: 2011-12-14T14:34:56-08:00
---


On Wed, Dec 14, 2011 at 12:58 PM, Mark Phillips  wrote:

&gt; Hmmm. Perhaps I'm not following here, but I don't see how R=1 on M/R
&gt; would make it unreliable in the face of node failure or node addition.
&gt; Assuming you have at least three nodes (the Basho Recommended
&gt; Minimumâ„¢) and standard defaults, you should have three copies of any
&gt; key you're trying to use in a M/R job. If you lose one node (or one
&gt; copy), you can still satisfy the R=1 requirement.
&gt;

If you add a node, that node will be empty. If MR chooses the new node,
the choice of R=1 will cause it to think there is no data to process. As
time goes on that node will gain new data or be populated by read-repair,
but it will still not have a complete data set until either all previous
data has been read, updated, or deleted.

In the case of node failure, the sample applies if you have to bring up a
new empty node to replace the downed node.

I forgot that if a node goes down temporary other nodes will accept updates
on its behalf and hand them over when it comes back up, so that type of
failure is not of a concern.

We did some major work in Riak 1.x to ensure that node additions
&gt; didn't result in 404's, and riak\_pipe does some work to ensure that
&gt; jobs are processed, too. More specifically:
&gt;
&gt; \* riak\_core will compute a new claim when a node is added, and then
&gt; periodically ask a vnode to start handing off data as appropriate.
&gt; Vnodes can choose not to handoff given its current state. In any case,
&gt; whenever all vnode modules associated with an index (kv, pipe, search,
&gt; etc) finish handoff, that's when the ownership is actually
&gt; transferred. Otherwise, the prior owner remains in effect. Thus, a new
&gt; node is not reflected as the owner of a partition until after it has
&gt; all data associated with that partition.
&gt;

Just to confirm, you are saying that existing KV and Search data will be
redistributed within a cluster when you add a new node?

If so, then that is great. I was under the impression that was not the
case. The only the vnode ownership transfered, and not the data from the
underlaying store.

I'm curious - have you tested node addition? Where did that 50% error
&gt; number come from? Also, what version of Riak are you running?
&gt;

I have not. We are just planning for it at the moment. The 50% came just
from my (apparently half-assed) understanding of the state of rebalancing
 within a cluster.

Elias
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

