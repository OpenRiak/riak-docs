---
title: "Re: Alternative to Post-Commit in EDS"
description: ""
project: community
lastmod: 2012-04-05T11:40:37-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07149"
mailinglist_parent_id: "msg07140"
author_name: "Bogunov"
project_section: "mailinglistitem"
sent_date: 2012-04-05T11:40:37-07:00
---


Isn't riak-eds replication based on merkle-trees? Can`t riak provide some
hook which triggers then some leaf-node becomes synchronized ? So anybody
can just parse synchronized binary and retrieve keys from it ?

On Thu, Apr 5, 2012 at 1:37 AM, Anthony Molinaro &lt;
antho...@alumni.caltech.edu&gt; wrote:

&gt; Okay, so here's what I'm thinking now after reading through some of
&gt; the M/R docs. Suppose I did this.
&gt;
&gt; 1. Create 2 buckets
&gt; - one for K/V pairs
&gt; - one for changed keys keyed by a timestamp or bin or something
&gt; (run in post-commit on source colo).
&gt; 2. Replicate both buckets to remote colo
&gt; 2. Use a key filter with M/R to get keys changed from some time in the past
&gt; 3. Run M/R regularly to publish key changes (probably to a rabbit queue)
&gt; 4. Have local consumer read key changes then grab updated Values from first
&gt; bucket
&gt;
&gt; I think this will all work, I'm not totally sure on the key filtering, but
&gt; it seems like a second bucket with time based keys would work best. I plan
&gt; to serialize all writes to each bucket as that is a requirement for
&gt; auditing
&gt; so just having a single integer key with the time the entry was written
&gt; will probably work, then a key filter with a simple greater than. I can
&gt; even overlap times to pick up any late additions caused by backups in
&gt; replication, since I only keep track of changed keys, and always read
&gt; the most current. I guess you could end up with the timestamp based
&gt; bucket replicating faster and thus data drift, hmm, that could be an issue.
&gt;
&gt; Maybe a secondary index with time might work better. I believe I need
&gt; some sort of secondary index as otherwise iterating over all the entries
&gt; in a bucket would be costly. I don't know exact numbers but I would guess
&gt; I'm looking at worst case several million K/V pairs per bucket so maybe M/R
&gt; on that isn't so bad. Is there any speed up with 2i and a key filter (can
&gt; you even create a key filter based on 2i?).
&gt;
&gt; Anyway, still searching for a way to do this efficiently,
&gt;
&gt; -Anthony
&gt;
&gt; On Wed, Apr 04, 2012 at 09:20:04AM -0700, Anthony Molinaro wrote:
&gt; &gt;
&gt; &gt; On Wed, Apr 04, 2012 at 08:10:29AM -0600, Jon Meredith wrote:
&gt; &gt; &gt; Riak does have a last modified field, but it's last modified by client
&gt; so
&gt; &gt; &gt; is deliberately left untouched on replication. Similarly the vclock is
&gt; not
&gt; &gt; &gt; incremented either (the vclocks/siblings from both sides are resolved
&gt; using
&gt; &gt; &gt; the two vclocks).
&gt; &gt;
&gt; &gt; That's great, as I'd want to know on the far end when the client modified
&gt; &gt; it.
&gt; &gt;
&gt; &gt; &gt; There are no obvious mechanisms for doing what you want currently.
&gt; I'll
&gt; &gt; &gt; think about options and somebody will get back to you.
&gt; &gt;
&gt; &gt; Is it not possible to use the last modified filed in a Map/Reduce? I've
&gt; &gt; not actually played with M/R in Riak yet (as I've only ever used it
&gt; &gt; previously as a Key/Value store). I'll try to dig into it a bit today
&gt; &gt; but I assumed I could do something to map over all records in a bucket
&gt; &gt; checking last modified, and return the set modified since a certain
&gt; &gt; time (or better yet put them in a rabbit queue to be consumed by my
&gt; &gt; systems which will cache the data).
&gt; &gt;
&gt; &gt; Alternatively, I could maybe have a second bucket representing the
&gt; changed
&gt; &gt; keys, where each time a key is changed in the primary bucket, I could
&gt; &gt; add an entry to the other bucket. I could then replicate that bucket
&gt; &gt; and just list keys on the remote side (maybe also deleting so subsequent
&gt; &gt; list keys only get changes, but then I think the replicator will replace
&gt; &gt; those keys, so I'd have to have some sort of bidirectional replication
&gt; &gt; for those buckets, sounds messy).
&gt; &gt;
&gt; &gt; Anyway, hopefully someone will have an idea,
&gt; &gt;
&gt; &gt; -Anthony
&gt; &gt;
&gt; &gt; --
&gt; &gt; ------------------------------------------------------------------------
&gt; &gt; Anthony Molinaro 
&gt; &gt;
&gt; &gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt; --
&gt; ------------------------------------------------------------------------
&gt; Anthony Molinaro 
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;



-- 
email: bogu...@gmail.com
skype: i.bogunov
phone: +7 903 131 8499
Regards, Bogunov Ilya
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

