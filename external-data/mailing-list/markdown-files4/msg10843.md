---
title: "Re: Riak 2i http query much faster than python api?"
description: ""
project: community
lastmod: 2013-04-10T19:26:40-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10843"
mailinglist_parent_id: "msg10836"
author_name: "Jeff Peck"
project_section: "mailinglistitem"
sent_date: 2013-04-10T19:26:40-07:00
---


As a follow-up to this thread and my thread from earlier today, I am basically 
looking for a simple way to extract the value of a single field from 
approximately 900,000 documents (which happens to be indexed). I have been 
trying many options including a map-reduce function that executes entirely over 
http (taking out any python client bottlenecks). I let that run for over an 
hour before I stopped it. It did not return any output.

I also have tried grabbing a list of the 900k keys from a secondary index (very 
fast, about 11 seconds) and then trying to fetch each key in parallel (using 
curl and gnu parallel). That was also too slow to be feasible.

Is there something basic that I am missing?

One idea that I though of was to have a secondary index that is intended to 
split all of my data into segments. I would use the first three characters of 
the md5 of the document's key in hexadecimal format. So, the index would 
contain strings like "ae1", "2f4", "5ee", etc. Then, I can run my map-reduce 
query against \*each\* segment individually and possibly even in parallel.

I have observed that map-reduce is very fast with small sets of data (i.e. 
5,000 objects), but with 900,000 objects it does not appear to run in a 
proportionately fast time. So, the idea is to divide the data into segments 
that can be better handled by map-reduce.

Before I implement this, I want to ask: Does this seem like the appropriate way 
to handle this type of operation? And, is there any better way to do this in 
the current version of Riak?


On Apr 10, 2013, at 6:10 PM, Shuhao Wu  wrote:

&gt; There are some inefficiencies in the python client... I've been profiling it 
&gt; recently and found that it occasionally takes the python client longer when 
&gt; you're on the same machine.
&gt; 
&gt; Perhaps Sean could comment?
&gt; 
&gt; Shuhao
&gt; Sent from my phone.
&gt; 
&gt; On 2013-04-10 4:04 PM, "Jeff Peck"  wrote:
&gt; Thanks Evan. I tried doing it in python like this (realizing that the 
&gt; previous way I did it uses MapReduce) and I had better results. It finished 
&gt; in 3.5 minutes, but nowhere close to the 15 seconds from the straight http 
&gt; query:
&gt; 
&gt; import riak
&gt; from pprint import pprint
&gt; 
&gt; bucket\_name = "mybucket"
&gt; 
&gt; client = riak.RiakClient(port=8087,transport\_class=riak.RiakPbcTransport)
&gt; bucket = client.bucket(bucket\_name)
&gt; results = bucket.get\_index('status\_bin', 'PERSISTED')
&gt; 
&gt; print len(results)
&gt; 
&gt; 
&gt; On Apr 10, 2013, at 4:00 PM, Evan Vigil-McClanahan  
&gt; wrote:
&gt; 
&gt; &gt; get\_index() is the right function there, I think.
&gt; &gt;
&gt; &gt; On Wed, Apr 10, 2013 at 2:53 PM, Jeff Peck  wrote:
&gt; &gt;&gt; I can grab over 900,000 keys from an indexs, using an http query in about 
&gt; &gt;&gt; 15 seconds, whereas the same operation in python times out after 5 
&gt; &gt;&gt; minutes. Does this indicate that I am using the python API incorrectly? 
&gt; &gt;&gt; Should I be relying on an http request initially when I need to grab this 
&gt; &gt;&gt; many keys?
&gt; &gt;&gt;
&gt; &gt;&gt; (Note: This is tied to the question that I asked earlier, but is also a 
&gt; &gt;&gt; general question to help understand the proper usage of the python API.)
&gt; &gt;&gt;
&gt; &gt;&gt; Thanks! Examples are below.
&gt; &gt;&gt;
&gt; &gt;&gt; - Jeff
&gt; &gt;&gt;
&gt; &gt;&gt; ---
&gt; &gt;&gt;
&gt; &gt;&gt; HTTP:
&gt; &gt;&gt;
&gt; &gt;&gt; $ time curl -s 
&gt; &gt;&gt; http://localhost:8098/buckets/mybucket/index/status\_bin/PERSISTED | grep 
&gt; &gt;&gt; -o , | wc -l
&gt; &gt;&gt; 926047
&gt; &gt;&gt;
&gt; &gt;&gt; real 0m14.583s
&gt; &gt;&gt; user 0m2.500s
&gt; &gt;&gt; sys 0m0.270s
&gt; &gt;&gt;
&gt; &gt;&gt; ---
&gt; &gt;&gt;
&gt; &gt;&gt; Python:
&gt; &gt;&gt;
&gt; &gt;&gt; import riak
&gt; &gt;&gt;
&gt; &gt;&gt; bucket = "my bucket"
&gt; &gt;&gt; client = riak.RiakClient(port=8098)
&gt; &gt;&gt; results = client.index(bucket, 'status\_bin', 
&gt; &gt;&gt; 'PERSISTED').run(timeout=5\*60\*1000) # 5 minute timeout
&gt; &gt;&gt; print len(results)
&gt; &gt;&gt;
&gt; &gt;&gt; (times out after 5 minutes)
&gt; &gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; &gt;&gt; riak-users mailing list
&gt; &gt;&gt; riak-users@lists.basho.com
&gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt; 
&gt; 
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

