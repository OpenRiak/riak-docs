---
title: "Re: Corrupted Erlang binary term inside LevelDB"
description: ""
project: community
lastmod: 2013-07-26T08:11:04-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11770"
mailinglist_parent_id: "msg11761"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-07-26T08:11:04-07:00
---


Vladimir,

I have created a branch off the 1.3.2 release tag: mv-error-logging-hack

This has two changes:

- removes a late fix for database level locking that was added in 1.3.2 (to see 
if that was the problem source prior to its fix)

- add test of all background file operations and log errors to syslog (since 
LOG handle not available)


When I build new version of leveldb, I make sure eleveldb also rebuilds. I do 
this via "rm eleveldb/c\_src/\*.o" followed by "cd eleveldb/c\_src/leveldb; make 
clean" There is a pull request from another community user that makes the 
entire process cleaner. I just have not had time to review and approve it.

I typically "grep beam /var/log/syslog" on my Debian system. The exact system 
log may vary due to your Linux implementation.

Let me know if this finds in any bugs. 

Matthew


On Jul 25, 2013, at 8:12 PM, Vladimir Shabanov  wrote:

&gt; I prefer second option since it will show are the corrupted blocks related to 
&gt; race condition. First option needs to be run for a long time to be completely 
&gt; sure that it really fixes the issue.
&gt; 
&gt; 
&gt; 2013/7/26 Matthew Von-Maszewski 
&gt; Vladimir,
&gt; 
&gt; I apologize for not recognizing your name and previous contribution. I just 
&gt; tend to think in terms of code and performance bottlenecks, not people.
&gt; 
&gt; Your June contribution resulted in changes that were released in 1.4 and 
&gt; 1.3.2. I and the team thank you. However, we have not isolated the source 
&gt; of the corruption. We only know today that it does not happen very often. 
&gt; We have a second, high transaction site, that has seen the same issue.
&gt; 
&gt; I can offer you two non-release options:
&gt; 
&gt; - I have a branch to 1.4.0 that fixes a potential, but unproven, race 
&gt; condition. Details are here:
&gt; 
&gt; https://github.com/basho/leveldb/wiki/mv-sst-fadvise
&gt; 
&gt; You would have to build eleveldb locally and copy it into your executable 
&gt; tree. The 1.4 leveldb and eleveldb work fine with Riak 1.3.x. should you 
&gt; desire to limit changes to your production environment.
&gt; 
&gt; 
&gt; - I have code, soon to be a branch against 1.3.2, that only adds syslog error 
&gt; messages to prove / disprove the race condition. You could take this code 
&gt; and see if it reports problems. This route would help the community and 
&gt; mostly me know the root cause is within the race condition addressed by the 
&gt; mv-sst-fadvise branch.
&gt; 
&gt; 
&gt; The two options above are what I currently have to offer. I am actively 
&gt; working to find the corruption source. The good news is that Riak will 
&gt; naturally recover from a "bad CRC" when detected. The bad news is that the 
&gt; Google defaults let some bad CRCs become good CRCs. Riak 1.4 and 1.3.2 
&gt; cannot identify those bad CRCs that became good CRCs.
&gt; 
&gt; Matthew
&gt; 
&gt; 
&gt; 
&gt; 
&gt; On Jul 25, 2013, at 4:32 PM, Vladimir Shabanov  wrote:
&gt; 
&gt;&gt; Good. Will wait for doctor.
&gt;&gt; 
&gt;&gt; A month ago I mailed about segmentation fault
&gt;&gt; http://lists.basho.com/pipermail/riak-users\_lists.basho.com/2013-June/012245.html
&gt;&gt; After looking at core dumps you have found this problem with CRC checks 
&gt;&gt; being skipped. I enabled paranoid\_checks and got my node up an running.
&gt;&gt; 
&gt;&gt; I've also found that lost/BLOCKS.bad sometimes appears in partitions and 
&gt;&gt; have sent you these blocks for further analysis.
&gt;&gt; 
&gt;&gt; It's very interesting why corrupted data appears in the first place. Nodes 
&gt;&gt; didn't crashed, hardware didn't failed. As I mentioned previously all my 
&gt;&gt; machines are with ECC memory and Riak data is kept on ZFS filesystem (which 
&gt;&gt; also checks CRC for all the data and doesn't report any CRC errors). So it 
&gt;&gt; looks that data is somehow corrupted by Riak itself.
&gt;&gt; 
&gt;&gt; lost/BLOCKS.bad are usually small 2-8kb and appears very infrequently (once 
&gt;&gt; a week, once a month or never for many partitions). I found these BLOCKS.bad 
&gt;&gt; in both data/leveldb and data/anti\_entropy. So I have suspicion that there 
&gt;&gt; is a bug in LevelDB.
&gt;&gt; 
&gt;&gt; Looking at LOGs they are created during compactions:
&gt;&gt; "Moving corrupted block to lost/BLOCKS.bad (size 2393)"
&gt;&gt; but there is no more information. What kind of block is it, where it was 
&gt;&gt; found.
&gt;&gt; 
&gt;&gt; Is it possible to somehow find source of those BLOCKS.bad files? I'm 
&gt;&gt; building Riak from sources, maybe it's possible to enable some additional 
&gt;&gt; logging to find what these BLOCKS.bad are?
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 2013/7/25 Matthew Von-Maszewski 
&gt;&gt; Vladimir,
&gt;&gt; 
&gt;&gt; I can explain what happened, but not how to correct the problem. The 
&gt;&gt; gentleman that can walk you through a repair is tied up on another project, 
&gt;&gt; but he intends to respond as soon as he is able.
&gt;&gt; 
&gt;&gt; We recently discovered / realized that Google's leveldb code does not check 
&gt;&gt; the CRC of each block rewritten during a compaction. This means that blocks 
&gt;&gt; with bad CRCs get read without being flagged as bad, then rewritten to a new 
&gt;&gt; file with a new, valid CRC. The corruption is now hidden.
&gt;&gt; 
&gt;&gt; A more thorough discussion of the problem is found here:
&gt;&gt; 
&gt;&gt; https://github.com/basho/leveldb/wiki/mv-verify-compactions
&gt;&gt; 
&gt;&gt; 
&gt;&gt; We added code to the 1.3.2 and 1.4 Riak releases to have the block CRC 
&gt;&gt; checked during both read (Get) requests and compaction rewrites. This 
&gt;&gt; prevents future corruption hiding. Unfortunately, it does NOTHING for 
&gt;&gt; blocks already corrupted and rewritten with valid CRCs. You are 
&gt;&gt; encountering this latter condition. We have a developer advocate / client 
&gt;&gt; services person that has walked others through a fix via the Riak data 
&gt;&gt; replicas … 
&gt;&gt; 
&gt;&gt; … please hold and the doctor will be with you shortly.
&gt;&gt; 
&gt;&gt; Matthew
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Jul 24, 2013, at 9:39 PM, Vladimir Shabanov  wrote:
&gt;&gt; 
&gt;&gt;&gt; Hello,
&gt;&gt;&gt; 
&gt;&gt;&gt; Recently I've started expanding my Riak cluster and found that handoffs 
&gt;&gt;&gt; were continuously retried for one partition.
&gt;&gt;&gt; 
&gt;&gt;&gt; Here are logs from two nodes
&gt;&gt;&gt; https://gist.github.com/vshabanov/41282e622479fbe81974
&gt;&gt;&gt; 
&gt;&gt;&gt; The most interesting parts of logs are
&gt;&gt;&gt; "Handoff receiver for partition ... exited abnormally after processing 
&gt;&gt;&gt; 2860338 objects: {{badarg,[{erlang,binary\_to\_term,..."
&gt;&gt;&gt; and
&gt;&gt;&gt; "bad argument in call to erlang:binary\_to\_term(&lt;&lt;131,104,...."
&gt;&gt;&gt; 
&gt;&gt;&gt; Both nodes are running Riak 1.3.2 (old one was running 1.3.1 previously).
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; When I've printed corrupted binary string I found that it corresponds to 
&gt;&gt;&gt; one value.
&gt;&gt;&gt; 
&gt;&gt;&gt; When I've tried to "get" it, it was read OK but node with corrupted value 
&gt;&gt;&gt; shown the same binary\_to\_term error.
&gt;&gt;&gt; 
&gt;&gt;&gt; When I've tried to delete corrupted value I've got timeout.
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; I'm running machines with ECC memory and ZFS filesystem (which doesn't 
&gt;&gt;&gt; report any checksum failures) so I doubt data was silently corrupted on 
&gt;&gt;&gt; disk.
&gt;&gt;&gt; 
&gt;&gt;&gt; LOG from corresponding LevelDB partition doesn't show any errors. But there 
&gt;&gt;&gt; is a lost/BLOCKS.bad file in this partition (7kb, created more than a month 
&gt;&gt;&gt; ago and looks like it doesn't contain corrupted value).
&gt;&gt;&gt; 
&gt;&gt;&gt; At the moment I've stopped handoffs using "risk-admin transfer-limit 0".
&gt;&gt;&gt; 
&gt;&gt;&gt; Why the value was corrupted? It there any way to remove it or fix it?
&gt;&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;&gt; 
&gt;&gt; 
&gt; 
&gt; 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

