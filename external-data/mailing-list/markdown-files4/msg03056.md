---
title: "Re: \"Failed to compact\" in RiakSearch"
description: ""
project: community
lastmod: 2011-04-15T01:27:45-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg03056"
mailinglist_parent_id: "msg03042"
author_name: "Morten Siebuhr"
project_section: "mailinglistitem"
sent_date: 2011-04-15T01:27:45-07:00
---


Hi Rusty,

On Thu, Apr 14, 2011 at 8:00 PM, Rusty Klophaus  wrote:
&gt; Hi Morten,
&gt; Thanks for sending the log files. I was able to figure out, at least
&gt; partially, what's going on here.

Fantastic - thanks!

&gt; The "Failed to compact" message is a result of trying to index a token
&gt; that's greater than 32kb in size. (The index storage engine, called
&gt; merge\_index, assumes tokens sizes smaller than 32kb.) I was able to decode
&gt; part of the term in question by pulling data from the log file, and it looks
&gt; like you may be indexing HTML with base64 encoded inline images, ie: ![]() src="data:image/jpeg;base64,iVBORw0KG..."&gt; The inline image is being treated
&gt; as a single token, and it's greater than 32kb.

That's odd - in the search schema, I asked it to ignore everything
besides a few specific fields:

{
 schema,
 [
 {version, "0.1"},
 {default\_field, "\_owner"},
 {n\_val, 1}
 ],
 [
 %% Don't parse \_id and \_owner, just treat it as single token
 {field, [
 {name, "id"},
 {required, true},
 {analyzer\_factory, {erlang, text\_analyzers, 
noop\_analyzer\_factory}}
 ]},
 {field, [
 {name, "\_owner"},
 {required, true},
 {analyzer\_factory, {erlang, text\_analyzers, 
noop\_analyzer\_factory}}
 ]},

 %% Parse Name fields for full-text indexing
 {field, [
 {name, "displayName"},
 {aliases, ["nickname", "preferredUsername", 
"name\_formatted",
"name\_displayName"]},
 {analyzer\_factory, {erlang, text\_analyzers, 
standard\_analyzer\_factory}}
 ]},

 {field, [
 {name, "emails\_value"},
 {analyzer\_factory, {erlang, text\_analyzers, 
standard\_analyzer\_factory}}
 ]},

 %% Add modification dates
 {field, [
 {name, "published"},
 {aliases, ["updated"]},
 {type, date}
 ]},

 %% Skip all else...
 {dynamic\_field, [
 {name, "\*"},
 {skip, true}
 ]}
 ]
}.

(We're indexing Portable Contacts, where the user images reside in a
'image'-field.)

&gt; The short term workaround is to either:
&gt; 1) Preprocess your data to avoid this situation.
&gt; 2) Or, create a custom analyzer that limits the size of terms
&gt; (See http://wiki.basho.com/Riak-Search---Schema.html for more information
&gt; about analyzers and custom analyzers.)
&gt; The long term solution is for us to increase the maximum token size in
&gt; merge\_index. I've filed a bugzilla issue for this, trackable
&gt; here: https://issues.basho.com/show\_bug.cgi?id=1069
&gt; Still investigating the "Too many db tables" error. This is being caused by
&gt; the system opening too many ETS tables. It \*may\* be related to the
&gt; compaction error described above, but I'm not sure.
&gt; Search (specifically merge\_index) uses ETS tables heavily, and the number of
&gt; tables is affected by a few different factors. Can you send me some more
&gt; information to help debug, specifically:
&gt;
&gt; How many partitions (vnodes) are in your cluster? (If you haven't changed
&gt; any settings, then the default is 64.)

It's 64 (no defaults changed at all).

&gt; How many machines are in your cluster?

Four.

&gt; How many segments are on the node where you are seeing these errors?
&gt; (Run: "find DATAPATH/merge\_index/\*/\*.data | wc -l", replacing DATAPATH with
&gt; the path to your Riak data directory for that node.)

foreach srv ( nosql1 nosql2 nosql4 nosql5 )
echo -n "$srv "; ssh $srv sh -c 'find
/var/lib/riaksearch/merge\_index/\*/\*.data | wc -l'
end
nosql1 32434
nosql2 14170
nosql4 15480
nosql5 13501

(nosql1 is the one the error log is lifted from - but the errors
seemed to come of all of the servers.)

&gt; Approximately how much data are you loading (# Docs and # MB), and how
&gt; quickly are you trying to load it?

~17m records, weighing in just shy of four GB.

While I didn't do the loading, I believe we did it with 25 concurrent
threads, using the four machines in round-robin fashion.

/Siebuhr

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

