---
title: "Re: Having to raise VM number-of-processes limit"
description: ""
project: community
lastmod: 2013-04-02T07:32:41-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10637"
mailinglist_parent_id: "msg10635"
author_name: "Dave Brady"
project_section: "mailinglistitem"
sent_date: 2013-04-02T07:32:41-07:00
---


It happened again today, though I was not available to watch it at the time.

Three nodes each showed riak\_kv being stopped for one minute:

2013-04-02 11:10:57.923 [info] &lt;0.2833.1447&gt;@riak\_kv\_app:check\_kv\_health:239 
Disabling riak\_kv due to large message queues. Offending vnodes: 
[{319703483166135013357056057156686910549735243776,5798}]
2013-04-02 11:11:57.924 [info] &lt;0.3589.1447&gt;@riak\_kv\_app:check\_kv\_health:242 
Re-enabling riak\_kv after successful health check

--
Dave Brady

----- Original Message -----
From: "Dave Brady" 
To: "Evan Vigil-McClanahan" 
Cc: riak-users@lists.basho.com
Sent: Monday, April 1, 2013 11:15:47 AM GMT +01:00 Amsterdam / Berlin / Bern / 
Rome / Stockholm / Vienna
Subject: Re: Having to raise VM number-of-processes limit

Hi Evan,

Thanks for the suggestions!

I did not think that raising that limit was normal. Glad to have confirmation.

I'll go through the logs again, and run 'riak-admin top ...' the next time it 
happens.

--
Dave Brady

----- Original Message -----
From: "Evan Vigil-McClanahan" 
To: "Dave Brady" 
Cc: riak-users@lists.basho.com
Sent: Saturday, March 30, 2013 11:03:30 PM GMT +01:00 Amsterdam / Berlin / Bern 
/ Rome / Stockholm / Vienna
Subject: Re: Having to raise VM number-of-processes limit

Dave,

If you're seeing the process count go that high, it suggests to me
that something else is wrong. Typically, even for heavily loaded
clusters, hundreds of thousands of processes isn't normal. Is there
anything else in the logs?

When a node sees this sort of behavior start, does riak-admin top
-sort msg\_q look like?

On Sat, Mar 30, 2013 at 2:07 PM, Dave Brady  wrote:
&gt; Hello,
&gt;
&gt; I have run into a situation whereby I started seeing:
&gt;
&gt; [error] emulator Too many processes
&gt;
&gt; when some of our new jobs ran. These jobs are in perl using Net::Riak,
&gt; communicating to the cluster via PBC. They fire tens of thousands of fetchs
&gt; and stores over the course of about 20 minutes.
&gt;
&gt; Our cluster has five nodes with 1.3, using eLevelDB.
&gt;
&gt; I have been raising the limit (+P in vm.args) in increments from the default
&gt; of 32768. Currently at 524288, and that is still not high enough.
&gt;
&gt; Have any of you had to increase this limit?
&gt;
&gt; Thanks!
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

