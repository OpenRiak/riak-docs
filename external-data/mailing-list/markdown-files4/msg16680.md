---
title: "Re: Using Bucket Data Types slowed insert performance"
description: ""
project: community
lastmod: 2015-10-20T11:53:29-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16680"
mailinglist_parent_id: "msg16679"
author_name: "Christopher Mancini"
project_section: "mailinglistitem"
sent_date: 2015-10-20T11:53:29-07:00
---


Hi Mark / Dennis,

Can you provide the snippet of the code that puts a 5k record onto Riak as
a map?

Chris

On Tue, Oct 20, 2015 at 11:30 AM Mark Schmidt  wrote:

&gt; Hi folks, sorry for the confusion.
&gt;
&gt;
&gt;
&gt; Our scenario is as follows:
&gt;
&gt;
&gt;
&gt; We have a 6 node development cluster running on its own network segment
&gt; using HAProxy to facilitate load-balancing across the nodes. A single
&gt; Riak-dot-NET client service is performing the insert operations from
&gt; dedicated hardware located within the same network segment. We have basic
&gt; network throughput capabilities of 100 Mbit with an average speed
&gt; achievable of 75 Mbit.
&gt;
&gt;
&gt;
&gt; The data we are attempting to insert is composed of phone call record
&gt; receipts from telephone carriers. These records are batched and written to
&gt; a flat file for incorporation into our reporting engine. 1) Our Riak client
&gt; process takes a flat file (In this case, a 40MB collection of records, each
&gt; record being approximately 5k in size) and parses the entire file so each
&gt; record can be added to a local .NET queue.
&gt;
&gt; 2) Once the entire file has been parsed and each record loaded into the
&gt; local queue, 20 threads are spawned and connections are opened to our Riak
&gt; nodes via the HAProxy.
&gt;
&gt; 3) Each thread will pull a 5k record from the queue on a first come first
&gt; served basis and perform a put to the Riak environment.
&gt;
&gt;
&gt;
&gt; When first testing our client insert process, we were pushing the 5K
&gt; records as whole strings into the Riak environment. Network throughput
&gt; topped out at around 80 Mbits with a total load time of 90 seconds for 149k
&gt; records. When the client process was modified (same queuing and de-queuing
&gt; methods) so that a map datatype bucket would be created and keys stored as
&gt; registers, we saw network throughput drop to around 10 Mbit with total
&gt; upload time increase to around 270 seconds for the 149k records.
&gt;
&gt;
&gt;
&gt; It appears as though we’ve either encountered a potential bottleneck
&gt; unrelated to network throughput, or we’re just seeing an expected
&gt; processing penalty for our use of Riak datatypes. Please note, we’re
&gt; configuring Zabbix so we can monitor disk IO on each node as processor and
&gt; memory resources don’t appear to be the culprit either.
&gt;
&gt;
&gt;
&gt; If the reduction in processing speed is a natural consequence to utilizing
&gt; Riak data types, is the inter-node network the optimum place to increase
&gt; resources? Our eventual datacenter implementation will support speeds of
&gt; over 40 Gbit for inter-node communication. We’re just trying to identify
&gt; which levers from an operational standpoint we can throw to boost
&gt; performance, or if our client implementation is suspect.
&gt;
&gt;
&gt;
&gt; You bring up some excellent points regarding our use of CRDTs. In our
&gt; case, the call data records are mutable as they are subject to changes by
&gt; phone carriers for billing error corrections, incorrect data and a host of
&gt; other reasons. We may be better served by treating the records as immutable
&gt; and performing wide scale record removal and “reprocessing” in the event
&gt; changes to existing records are received/requested.
&gt;
&gt;
&gt;
&gt; Thank you,
&gt;
&gt;
&gt;
&gt; Mark Schmidt
&gt;
&gt;
&gt;
&gt; \*From:\* Alexander Sicular [mailto:sicul...@gmail.com]
&gt; \*Sent:\* Tuesday, October 20, 2015 10:55 AM
&gt; \*To:\* Dennis Nicolay 
&gt; \*Cc:\* Christopher Mancini ; riak-users@lists.basho.com;
&gt; Mark Schmidt 
&gt;
&gt;
&gt; \*Subject:\* Re: Using Bucket Data Types slowed insert performance
&gt;
&gt;
&gt;
&gt; Let's talk about Riak data types for a moment. Riak data types are
&gt; collectively implementations of what academia refer to as CRDT's
&gt; (convergent or conflict free replicated data types.) The key benefit a CRDT
&gt; offers, over a traditional KV by contrast, is in automatic conflict
&gt; resolution. The various CRDT's provided in Riak have specific conflict
&gt; resolution strategies. This does not come for free. There is a
&gt; computational cost associated with CRDT's. If your use case requires
&gt; automated conflict resolution strategies than CRDT's are a good fit.
&gt; Internally CRDT's rely on vector clocks (see DVV's in the documentation) to
&gt; resolve conflict.
&gt;
&gt;
&gt;
&gt; Considering your ETL use case I'm going to presume that your data is
&gt; immutable (I could very well be wrong here.) If your data is immutable I
&gt; would consider simply using a KV and not paying the CRDT computational
&gt; penalty (and possibly even the write once bucket.) The CRDT penalty you pay
&gt; is obviously subjective to your use case, configuration, hw deployment etc.
&gt;
&gt;
&gt;
&gt; Hope that helps!
&gt; -Alexander
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt; http://siculars.posthaven.com
&gt;
&gt;
&gt;
&gt; Sent from my iRotaryPhone
&gt;
&gt;
&gt; On Oct 20, 2015, at 12:39, Dennis Nicolay  wrote:
&gt;
&gt; Hi Alexander,
&gt;
&gt;
&gt;
&gt; I’m parsing the file and storing each row with own key in a map datatype
&gt; bucket and each column is a register.
&gt;
&gt;
&gt;
&gt; Thanks,
&gt;
&gt; Dennis
&gt;
&gt;
&gt;
&gt; \*From:\* Alexander Sicular [mailto:sicul...@gmail.com ]
&gt;
&gt; \*Sent:\* Tuesday, October 20, 2015 10:34 AM
&gt; \*To:\* Dennis Nicolay
&gt; \*Cc:\* Christopher Mancini; riak-users@lists.basho.com
&gt; \*Subject:\* Re: Using Bucket Data Types slowed insert performance
&gt;
&gt;
&gt;
&gt; Hi Dennis,
&gt;
&gt;
&gt;
&gt; It's a bit unclear what you are trying to do here. Are you 1. uploading
&gt; the entire file and saving it to one key with the value being the file? Or
&gt; are you 2. parsing the file and storing each row as a register in a map?
&gt;
&gt;
&gt;
&gt; Either of those approaches are not appropriate in Riak KV. For the first
&gt; case I would point you to Riak S2 which is designed to manage large binary
&gt; object storage. You can keep the large file as a single addressable entity
&gt; and access it via Amazon S3 or Swift protocol. For the second case I would
&gt; consider maintaining one key (map) per row in the file and have a register
&gt; per column in the row. Or not use Riak data types (maps, sets, registers,
&gt; flags and counters) and simply keep each row in the file as a KV in Riak
&gt; either as a raw string or as a serialized json string. ETL'ing out of
&gt; relational databases and into Riak is a very common use case and often
&gt; implemented in the fashion I described.
&gt;
&gt;
&gt;
&gt; As Chris mentioned, soft upper bound on value size should be 1MB. I say
&gt; soft because we won't enforce it although there are settings in the config
&gt; that can be changed to enforce it (default 5MB warning, 50MB reject I
&gt; believe.)
&gt;
&gt; Best,
&gt;
&gt; Alexander
&gt;
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt; http://siculars.posthaven.com
&gt;
&gt;
&gt;
&gt; Sent from my iRotaryPhone
&gt;
&gt;
&gt; On Oct 20, 2015, at 10:22, Christopher Mancini  wrote:
&gt;
&gt; Hi Dennis,
&gt;
&gt; I am not the most experienced, but what I do know is that a file that size
&gt; causes a great deal of network chatter because it has to handoff that data
&gt; to the other nodes in the network and will cause delays in Riak's ability
&gt; to send and confirm consistency across the ring. Typically we recommend
&gt; that you try to structure your objects to around 1mb or less to ensure
&gt; consistent performance. That max object size can vary of course based on
&gt; your network / server specs and configuration.
&gt;
&gt; I hope this helps.
&gt;
&gt; Chris
&gt;
&gt;
&gt;
&gt; On Tue, Oct 20, 2015 at 8:18 AM Dennis Nicolay 
&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt;
&gt;
&gt; I’m using .net RiakClient 2.0 to insert a 44mb delimited file with 139k
&gt; rows of data into riak. I switched to a map bucket data type with
&gt; registers. It is taking about 3 times longer to insert into this bucket
&gt; vs non data typed bucket. Any suggestions?
&gt;
&gt;
&gt;
&gt; Thanks in advance,
&gt;
&gt; Dennis
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt;
&gt;
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

