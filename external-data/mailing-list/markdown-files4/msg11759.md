---
title: "Re: Corrupted Erlang binary term inside LevelDB"
description: ""
project: community
lastmod: 2013-07-25T16:23:55-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11759"
mailinglist_parent_id: "msg11758"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-07-25T16:23:55-07:00
---


Vladimir,

I apologize for not recognizing your name and previous contribution. I just 
tend to think in terms of code and performance bottlenecks, not people.

Your June contribution resulted in changes that were released in 1.4 and 1.3.2. 
 I and the team thank you. However, we have not isolated the source of the 
corruption. We only know today that it does not happen very often. We have a 
second, high transaction site, that has seen the same issue.

I can offer you two non-release options:

- I have a branch to 1.4.0 that fixes a potential, but unproven, race 
condition. Details are here:

https://github.com/basho/leveldb/wiki/mv-sst-fadvise

You would have to build eleveldb locally and copy it into your executable tree. 
 The 1.4 leveldb and eleveldb work fine with Riak 1.3.x. should you desire to 
limit changes to your production environment.


- I have code, soon to be a branch against 1.3.2, that only adds syslog error 
messages to prove / disprove the race condition. You could take this code and 
see if it reports problems. This route would help the community and mostly me 
know the root cause is within the race condition addressed by the 
mv-sst-fadvise branch.


The two options above are what I currently have to offer. I am actively 
working to find the corruption source. The good news is that Riak will 
naturally recover from a "bad CRC" when detected. The bad news is that the 
Google defaults let some bad CRCs become good CRCs. Riak 1.4 and 1.3.2 cannot 
identify those bad CRCs that became good CRCs.

Matthew




On Jul 25, 2013, at 4:32 PM, Vladimir Shabanov  wrote:

&gt; Good. Will wait for doctor.
&gt; 
&gt; A month ago I mailed about segmentation fault
&gt; http://lists.basho.com/pipermail/riak-users\_lists.basho.com/2013-June/012245.html
&gt; After looking at core dumps you have found this problem with CRC checks being 
&gt; skipped. I enabled paranoid\_checks and got my node up an running.
&gt; 
&gt; I've also found that lost/BLOCKS.bad sometimes appears in partitions and have 
&gt; sent you these blocks for further analysis.
&gt; 
&gt; It's very interesting why corrupted data appears in the first place. Nodes 
&gt; didn't crashed, hardware didn't failed. As I mentioned previously all my 
&gt; machines are with ECC memory and Riak data is kept on ZFS filesystem (which 
&gt; also checks CRC for all the data and doesn't report any CRC errors). So it 
&gt; looks that data is somehow corrupted by Riak itself.
&gt; 
&gt; lost/BLOCKS.bad are usually small 2-8kb and appears very infrequently (once a 
&gt; week, once a month or never for many partitions). I found these BLOCKS.bad in 
&gt; both data/leveldb and data/anti\_entropy. So I have suspicion that there is a 
&gt; bug in LevelDB.
&gt; 
&gt; Looking at LOGs they are created during compactions:
&gt; "Moving corrupted block to lost/BLOCKS.bad (size 2393)"
&gt; but there is no more information. What kind of block is it, where it was 
&gt; found.
&gt; 
&gt; Is it possible to somehow find source of those BLOCKS.bad files? I'm building 
&gt; Riak from sources, maybe it's possible to enable some additional logging to 
&gt; find what these BLOCKS.bad are?
&gt; 
&gt; 
&gt; 2013/7/25 Matthew Von-Maszewski 
&gt; Vladimir,
&gt; 
&gt; I can explain what happened, but not how to correct the problem. The 
&gt; gentleman that can walk you through a repair is tied up on another project, 
&gt; but he intends to respond as soon as he is able.
&gt; 
&gt; We recently discovered / realized that Google's leveldb code does not check 
&gt; the CRC of each block rewritten during a compaction. This means that blocks 
&gt; with bad CRCs get read without being flagged as bad, then rewritten to a new 
&gt; file with a new, valid CRC. The corruption is now hidden.
&gt; 
&gt; A more thorough discussion of the problem is found here:
&gt; 
&gt; https://github.com/basho/leveldb/wiki/mv-verify-compactions
&gt; 
&gt; 
&gt; We added code to the 1.3.2 and 1.4 Riak releases to have the block CRC 
&gt; checked during both read (Get) requests and compaction rewrites. This 
&gt; prevents future corruption hiding. Unfortunately, it does NOTHING for blocks 
&gt; already corrupted and rewritten with valid CRCs. You are encountering this 
&gt; latter condition. We have a developer advocate / client services person that 
&gt; has walked others through a fix via the Riak data replicas … 
&gt; 
&gt; … please hold and the doctor will be with you shortly.
&gt; 
&gt; Matthew
&gt; 
&gt; 
&gt; On Jul 24, 2013, at 9:39 PM, Vladimir Shabanov  wrote:
&gt; 
&gt;&gt; Hello,
&gt;&gt; 
&gt;&gt; Recently I've started expanding my Riak cluster and found that handoffs were 
&gt;&gt; continuously retried for one partition.
&gt;&gt; 
&gt;&gt; Here are logs from two nodes
&gt;&gt; https://gist.github.com/vshabanov/41282e622479fbe81974
&gt;&gt; 
&gt;&gt; The most interesting parts of logs are
&gt;&gt; "Handoff receiver for partition ... exited abnormally after processing 
&gt;&gt; 2860338 objects: {{badarg,[{erlang,binary\_to\_term,..."
&gt;&gt; and
&gt;&gt; "bad argument in call to erlang:binary\_to\_term(&lt;&lt;131,104,...."
&gt;&gt; 
&gt;&gt; Both nodes are running Riak 1.3.2 (old one was running 1.3.1 previously).
&gt;&gt; 
&gt;&gt; 
&gt;&gt; When I've printed corrupted binary string I found that it corresponds to one 
&gt;&gt; value.
&gt;&gt; 
&gt;&gt; When I've tried to "get" it, it was read OK but node with corrupted value 
&gt;&gt; shown the same binary\_to\_term error.
&gt;&gt; 
&gt;&gt; When I've tried to delete corrupted value I've got timeout.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; I'm running machines with ECC memory and ZFS filesystem (which doesn't 
&gt;&gt; report any checksum failures) so I doubt data was silently corrupted on disk.
&gt;&gt; 
&gt;&gt; LOG from corresponding LevelDB partition doesn't show any errors. But there 
&gt;&gt; is a lost/BLOCKS.bad file in this partition (7kb, created more than a month 
&gt;&gt; ago and looks like it doesn't contain corrupted value).
&gt;&gt; 
&gt;&gt; At the moment I've stopped handoffs using "risk-admin transfer-limit 0".
&gt;&gt; 
&gt;&gt; Why the value was corrupted? It there any way to remove it or fix it?
&gt;&gt; \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
&gt; 
&gt; 

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

