---
title: "Map reduce error on large bucket"
description: ""
project: community
lastmod: 2010-09-13T11:06:22-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01069"
author_name: "SKester"
project_section: "mailinglistitem"
sent_date: 2010-09-13T11:06:22-07:00
---


I am trying to run a map-reduce job against all keys in a bucket. The job
is working fine on buckets with ~60,000 or less entries. However on buckets
with > 63,000 keys I get the following error every time:

Input:

curl -X POST -H "content-type: application/json"
http://testdw0b01.be.weather.com:8098/mapred?chunked=true --data @-
{"inputs":"profile\_63000","query":[{"map":{"language":"javascript","source":
"function(v) {var data = Riak.mapValuesJson(v)[0]; var r=[];for(var i in
data.locations){ var
o = {}; o[data.locations[i]] = 1; r.push(o); } return r;
}"}},{"reduce":{"language":"javascript","source":"function(v) { var r = {};
for (var i in v) { for(var w in v[i])
 { if (w in r) r[w] += v[i][w]; else r[w] = v[i][w]; } } return
[r];}"}}],"timeout": 600000}

Output:

{"error":"map\_reduce\_error"}

Any ideas? I am running on a 4 box Centos cluster with Riak installed via
64bit RPMÂ¹s, and default settings.

Thanks,
Scott

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

