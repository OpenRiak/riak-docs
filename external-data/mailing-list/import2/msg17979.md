---
title: "Re: Truncated bit-cask files"
description: ""
project: community
lastmod: 2017-02-14T07:43:41-0800
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg17979"
mailinglist_parent_id: "msg17978"
author_name: "Magnus Kessler"
project_section: "mailinglistitem"
sent_date: 2017-02-14T07:43:41-0800
---


On 14 February 2017 at 14:46, Arun Rajagopalan  wrote:

> Hi Magnus
>
> RIAK crashes on startup when I have trucated bitcask file
>
> It also crashes when the AAE files are bad too I think. Example below
>
> 2017-02-13 21:18:30 =CRASH REPORT====
>
> crasher:
>
> initial call: riak\_kv\_index\_hashtree:init/1
>
> pid: <0.6037.0>
>
> registered\_name: []
>
> exception exit: {{{badmatch,{error,{db\_open,"Corruption: truncated
> record at end of file"}}},[{hashtree,new\_segment\_
>
> store,2,[{file,"src/hashtree.erl"},{line,675}]},{hashtree,
> new,2,[{file,"src/hashtree.erl"},{line,246}]},{riak\_kv\_index\_h
>
> ashtree,do\_new\_tree,3,[{file,"src/riak\_kv\_index\_hashtree.
> erl"},{line,610}]},{lists,foldl,3,[{file,"lists.erl"},{line,124
>
> 8}]},{riak\_kv\_index\_hashtree,init\_trees,3,[{file,"src/riak\_
> kv\_index\_hashtree.erl"},{line,474}]},{riak\_kv\_index\_hashtree,
>
> init,1,[{file,"src/riak\_kv\_index\_hashtree.erl"},{line,
> 268}]},{gen\_server,init\_it,6,[{file,"gen\_server.erl"},{line,304}]}
>
> ,{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,
> 239}]}]},[{gen\_server,init\_it,6,[{file,"gen\_server.erl"},{line
>
> ,328}]},{proc\_lib,init\_p\_do\_apply,3,[{file,"proc\_lib.erl"},{line,239}]}]}
>
> ancestors: [<0.715.0>,riak\_core\_vnode\_sup,riak\_core\_sup,<0.160.0>]
>
> messages: []
>
> links: []
>
> dictionary: []
>
> trap\_exit: false
>
> status: running
>
> heap\_size: 1598
>
> stack\_size: 27
>
> reductions: 889
>
> neighbours:
>
>
>
> Regards
> Arun
>
>
Hi Arun,

The crash log you provided shows that there is a corrupted file in the AAE
(anti\_entropy) backend. Entries in console.log should have more information
about which partition is affected. Please post output from the affected
node at around 2017-02-13T21:18:30. As this is AAE data, it is safe to
remove the directory named after the affected partition from the
active\_entropy directory before restarting the node. You may find that
there is more than one affected partition, the next of which will be
encountered after the attempted restart only. If this is the case, simply
identify the next partition in the same way and remove it, too, until the
node starts up successfully again.

Is there a reason why the nodes aren't shut down in the regular way?

Kind Regards,

Magnus



-- 
Magnus Kessler
Client Services Engineer
Basho Technologies Limited

Registered Office - 8 Lincolnâ€™s Inn Fields London WC2A 3BP Reg 07970431
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

