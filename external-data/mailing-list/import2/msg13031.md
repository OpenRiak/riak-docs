---
title: "Re: Riak Search Map Reduce error"
description: ""
project: community
lastmod: 2013-11-20T08:46:49-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13031"
mailinglist_parent_id: "msg13009"
author_name: "Roger Diller"
project_section: "mailinglistitem"
sent_date: 2013-11-20T08:46:49-08:00
---


I could dig up all our nitty gritty Riak details but I don't think that
will help really.

The point I think is this: Using search map reduce is not a viable way to
do real time search queries. Especially ones that may have 2000+ plus
results each. Couple that with search requests coming in every few seconds
from 300+ customer app instances and you literally bring Riak to it's
knees.

Not that Riak is the problem really, it's just we are using it in a way it
was not designed for. In essence, we are using Riak as a search engine for
our application data. Correct me if I'm wrong but Riak is more for storing
large amounts of KV data, but not really for finding that data in a search
sense.

Am I missing something here? Is there a viable way for doing real time
search queries on a bucket with 1 million keys?


On Mon, Nov 18, 2013 at 5:29 PM, Alexander Sicular wrote:

> More info please...
>
> Version
> Current config
> Hardware
> Data size
> Search Schema
> Etc.
>
> But I would probably say that your search is returning too many keys to
> your mr. More inline.
>
> @siculars
> http://siculars.posthaven.com
>
> Sent from my iRotaryPhone
>
> On Nov 18, 2013, at 13:59, Roger Diller 
> wrote:
>
> Using the Riak Java client, I am executing a search map reduce like this:
>
> MapReduceResult result = riakClient.mapReduce(SEARCH\_BUCKET,
> search).execute();
>
>
> ^is this part a typo. Cause otherwise it looks like you do a s>mr, set the
> search and then another s>mr.
>
>
> String search = "systemId:" + systemName + " AND indexId:" + indexId;
>
> MapReduceResult result = riakClient.mapReduce(SEARCH\_BUCKET,
> search).execute();
>
> This worked fine when the bucket contained a few thousand keys. Now that
> we have far more data stored in the bucket (at least 250K keys), it's
> throwing this generic error:
>
> com.basho.riak.client.RiakException: java.io.IOException:
> {"error":"map\_reduce\_error"}
>
> We've also noticed that storing new key/values in the bucket has slowed
> WAY down.
>
> Any idea what's going on?
>
>
> Your data set is incorrectly sized to your production config.
>
> Are there limitations to Search Map Reduce?
>
>
> Certainly
>
> Are there configuration options that need changed?
>
>
> Possibly
>
> Any help would be greatly appreciated.
>
>
> --
> Roger Diller
> Flex Rental Solutions, LLC
> Email: ro...@flexrentalsolutions.com
> Skype: rogerdiller
> Time Zone: Eastern Time
>
> \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> riak-users mailing list
> riak-users@lists.basho.com
> http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
>
>


-- 
Roger Diller
Flex Rental Solutions, LLC
Email: ro...@flexrentalsolutions.com
Skype: rogerdiller
Time Zone: Eastern Time
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

