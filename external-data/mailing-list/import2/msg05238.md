---
title: "Re: Search failure: stream_timeout"
description: ""
project: community
lastmod: 2011-10-21T14:44:50-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05238"
mailinglist_parent_id: "msg05237"
author_name: "Elias Levy"
project_section: "mailinglistitem"
sent_date: 2011-10-21T14:44:50-07:00
---


On Fri, Oct 21, 2011 at 2:23 PM, Elias Levy wrote:

> I found that if I limited the timestamps to a range that covers a
> reasonable number of records the query succeeds. But if the query is of the
> form 'ts:[0 TO 1319228408]', then Riak generates that error and the client
> connection it shutdown. I am guessing that that queries covers too many
> records, which is causing the nodes to take longer than expected to respond,
> and that some timeout is being reached and Riak kills the query. Is that
> correct?
>

I should have probably mentioned that the are other terms in the query that
limit the results. I am now wondering if this is caused by the fact that
Riak Search is sharded by term, rather than document, causing it to search
for each term in the query independently and then creating an intersection
of matches to return as the query result.

If that is the case, then a single query term that select a large portion of
the index will cause trouble, even if other terms limit the results, as the
system will need return a good portion of the keys in the bucket, before
they can be whittled down by other query terms.

If so, it would seem the only solution is to break up the query into
smaller, more manageable chunks and aggregate them on the client side. Is
this correct?
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

