---
title: "Re: Issue with Riak partition allocation"
description: ""
project: community
lastmod: 2014-09-09T10:08:26-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14880"
mailinglist_parent_id: "msg14879"
author_name: "Peter Bakkum"
project_section: "mailinglistitem"
sent_date: 2014-09-09T10:08:26-07:00
---


Hey Luke,

Here you go. Last night I believe we had ~70 partitions still to transfer.

[root@192.168.72.19 ~] #
[root@192.168.72.19 ~] #
[root@192.168.72.19 ~] # riak-admin transfers
'xxxx\_prod\_cluster@192.168.72.74' waiting to handoff 2 partitions
'xxxx\_prod\_cluster@192.168.72.7' waiting to handoff 2 partitions
'xxxx\_prod\_cluster@192.168.72.19' waiting to handoff 21 partitions

Active Transfers:

transfer type: ownership\_transfer
vnode type: riak\_kv\_vnode
partition: 422465317040964124793252646957050560369293000704
started: 2014-09-09 16:15:11 [48.93 min ago]
last update: 2014-09-09 17:04:06 [887.56 ms ago]
total size: 47814241779 bytes
objects transferred: 326825

 111 Objs/s
xxxx\_prod\_cluster =======> xxxx\_prod\_cluster
@192.168.72.176 @192.168.72.19
 |=================== | 45%
 7.13 MB/s

transfer type: hinted\_handoff
vnode type: riak\_kv\_vnode
partition: 1004782375664995756265033322492444576013453623296
started: 2014-09-09 16:36:37 [27.50 min ago]
last update: 2014-09-09 17:04:07 [411.93 ms ago]
total size: 47179582874 bytes
objects transferred: 213001

 129 Objs/s
xxxx\_prod\_cluster =======> xxxx\_prod\_cluster
@192.168.72.19 @192.168.72.7
 |============= | 31%
 8.48 MB/s



On Tue, Sep 9, 2014 at 7:22 AM, Luke Bakken  wrote:

> Hi Peter,
>
> Could you please provide the output of "riak-admin transfers" ?
> --
> Luke Bakken
> Engineer / CSE
> lbak...@basho.com
>
>
> On Mon, Sep 8, 2014 at 10:01 AM, Peter Bakkum  wrote:
> > Hey all,
> >
> > Looking for some guidance on a problem we're seeing in production right
> now.
> > We're not Riak experts so please bear with us.
> >
> > We had a member of our 6-node Riak cluster appear to fall out (riak-admin
> > member status on that node only showed itself). So I ran a riak-admin
> join
> > and riak-admin commit to get the node back in the cluster. Node discovery
> > appears to work now, but for some reason that node is now using a huge
> > amount of disk space. It appears that the partition balancing process is
> > creating this condition, and still hasn't completed after ~16 hours. The
> > cluster is still functional and serving our production traffic, and
> taking
> > the entire cluster offline isn't an option for us.
> >
> > Most of our nodes use about 450GB of space, this node in particular is
> using
> > around 1.2TB, which is pushing the limit of its disk.
> >
> > Questions:
> > Whats happening here? Is this expected?
> >
> > Whats the best course of action? Should we clear out this node and
> attempt
> > to join the cluster again?
> >
> > Here are some stats from the node in question. Let me know if anything
> else
> > would be helpful.
> >
> > Thanks for your help.
> >
> >
> > [root@192.168.72.19 /data/lib/riak] # riak-admin member-status
> > ================================= Membership
> > ==================================
> > Status Ring Pending Node
> >
> -------------------------------------------------------------------------------
> > valid 20.3% 16.4% 'xxxx\_prod\_cluster@192.168.72.135'
> > valid 18.0% 17.2% 'xxxx\_prod\_cluster@192.168.72.170'
> > valid 20.3% 17.2% 'xxxx\_prod\_cluster@192.168.72.176'
> > valid 7.0% 16.4% 'xxxx\_prod\_cluster@192.168.72.19'
> > valid 17.2% 16.4% 'xxxx\_prod\_cluster@192.168.72.7'
> > valid 17.2% 16.4% 'xxxx\_prod\_cluster@192.168.72.74'
> >
> >
> > [root@192.168.72.19 /data/lib/riak] # riak-admin status
> > 1-minute stats for 'xxxx\_prod\_cluster@192.168.72.19'
> > -------------------------------------------
> > riak\_kv\_stat\_ts : 1410194287
> > vnode\_gets : 1607
> > vnode\_gets\_total : 563683
> > vnode\_puts : 39
> > vnode\_puts\_total : 5459724
> > vnode\_index\_refreshes : 0
> > vnode\_index\_refreshes\_total : 0
> > vnode\_index\_reads : 0
> > vnode\_index\_reads\_total : 0
> > vnode\_index\_writes : 39
> > vnode\_index\_writes\_total : 5459724
> > vnode\_index\_writes\_postings : 0
> > vnode\_index\_writes\_postings\_total : 5227558
> > vnode\_index\_deletes : 0
> > vnode\_index\_deletes\_total : 0
> > vnode\_index\_deletes\_postings : 39
> > vnode\_index\_deletes\_postings\_total : 30613
> > node\_gets : 3602
> > node\_gets\_total : 2463956
> > node\_get\_fsm\_siblings\_mean : 1
> > node\_get\_fsm\_siblings\_median : 1
> > node\_get\_fsm\_siblings\_95 : 2
> > node\_get\_fsm\_siblings\_99 : 3
> > node\_get\_fsm\_siblings\_100 : 12
> > node\_get\_fsm\_objsize\_mean : 52047
> > node\_get\_fsm\_objsize\_median : 26936
> > node\_get\_fsm\_objsize\_95 : 167435
> > node\_get\_fsm\_objsize\_99 : 267979
> > node\_get\_fsm\_objsize\_100 : 1313716
> > node\_get\_fsm\_time\_mean : 12223
> > node\_get\_fsm\_time\_median : 6675
> > node\_get\_fsm\_time\_95 : 37390
> > node\_get\_fsm\_time\_99 : 87046
> > node\_get\_fsm\_time\_100 : 345380
> > node\_puts : 39
> > node\_puts\_total : 24915
> > node\_put\_fsm\_time\_mean : 4419
> > node\_put\_fsm\_time\_median : 2444
> > node\_put\_fsm\_time\_95 : 12890
> > node\_put\_fsm\_time\_99 : 18775
> > node\_put\_fsm\_time\_100 : 18775
> > read\_repairs : 0
> > read\_repairs\_total : 0
> > coord\_redirs\_total : 17022
> > executing\_mappers : 0
> > precommit\_fail : 0
> > postcommit\_fail : 0
> > index\_fsm\_create : 0
> > index\_fsm\_create\_error : 0
> > index\_fsm\_active : 0
> > list\_fsm\_create : 0
> > list\_fsm\_create\_error : 0
> > list\_fsm\_active : 0
> > pbc\_active : 0
> > pbc\_connects : 1
> > pbc\_connects\_total : 508
> > node\_get\_fsm\_active : 1
> > node\_get\_fsm\_active\_60s : 3530
> > node\_get\_fsm\_in\_rate : 55
> > node\_get\_fsm\_out\_rate : 56
> > node\_get\_fsm\_rejected : 0
> > node\_get\_fsm\_rejected\_60s : 0
> > node\_get\_fsm\_rejected\_total : 0
> > node\_put\_fsm\_active : 0
> > node\_put\_fsm\_active\_60s : 67
> > node\_put\_fsm\_in\_rate : 1
> > node\_put\_fsm\_out\_rate : 1
> > node\_put\_fsm\_rejected : 0
> > node\_put\_fsm\_rejected\_60s : 0
> > node\_put\_fsm\_rejected\_total : 0
> > leveldb\_read\_block\_error : 0
> > riak\_pipe\_stat\_ts : 1410194286
> > pipeline\_active : 0
> > pipeline\_create\_count : 0
> > pipeline\_create\_one : 0
> > pipeline\_create\_error\_count : 0
> > pipeline\_create\_error\_one : 0
> > cpu\_nprocs : 426
> > cpu\_avg1 : 1352
> > cpu\_avg5 : 1260
> > cpu\_avg15 : 1137
> > mem\_total : 15666507776
> > mem\_allocated : 15479640064
> > disk : [{"/",8256952,60},
> > {"/dev/shm",7649660,0},
> > {"/tmpfs",1048576,14},
> > {"/tmpfs\_mp3",1048576,0},
> > {"/data",1514123712,81}]
> > nodename : 'xxxx\_prod\_cluster@192.168.72.19'
> > connected\_nodes : ['xxxx\_prod\_cluster@192.168.72.170',
> > 'xxxx\_prod\_cluster@192.168.72.176',
> > 'xxxx\_prod\_cluster@192.168.72.74',
> > 'xxxx\_prod\_cluster@192.168.72.135',
> > 'xxxx\_prod\_cluster@192.168.72.7']
> > sys\_driver\_version : <<"2.0">>
> > sys\_global\_heaps\_size : 0
> > sys\_heap\_type : private
> > sys\_logical\_processors : 4
> > sys\_otp\_release : <<"R15B01">>
> > sys\_process\_count : 2469
> > sys\_smp\_support : true
> > sys\_system\_version : <<"Erlang R15B01 (erts-5.9.1) [source] [64-bit]
> > [smp:4:4] [async-threads:64] [kernel-poll:true]">>
> > sys\_system\_architecture : <<"x86\_64-unknown-linux-gnu">>
> > sys\_threads\_enabled : true
> > sys\_thread\_pool\_size : 64
> > sys\_wordsize : 8
> > ring\_members : ['xxxx\_prod\_cluster@192.168.72.135',
> > 'xxxx\_prod\_cluster@192.168.72.170',
> > 'xxxx\_prod\_cluster@192.168.72.176',
> > 'xxxx\_prod\_cluster@192.168.72.19',
> > 'xxxx\_prod\_cluster@192.168.72.7',
> > 'xxxx\_prod\_cluster@192.168.72.74']
> > ring\_num\_partitions : 128
> > ring\_ownership : <<"[{'xxxx\_prod\_cluster@192.168.72.170',23},\n
> > {'xxxx\_prod\_cluster@192.168.72.74',22},\n
> > {'xxxx\_prod\_cluster@192.168.72.135',26},\n
> > {'xxxx\_prod\_cluster@192.168.72.176',26},\n
> > {'xxxx\_prod\_cluster@192.168.72.7',22},\n
> > {'xxxx\_prod\_cluster@192.168.72.19',9}]">>
> > ring\_creation\_size : 128
> > storage\_backend : riak\_kv\_eleveldb\_backend
> > erlydtl\_version : <<"0.7.0">>
> > riak\_control\_version : <<"1.4.10-0-g73c43c3">>
> > cluster\_info\_version : <<"1.2.4">>
> > riak\_search\_version : <<"1.4.10-0-g6e548e7">>
> > merge\_index\_version : <<"1.3.2-0-gcb38ee7">>
> > riak\_kv\_version : <<"1.4.10-0-g64b6ad8">>
> > sidejob\_version : <<"0.2.0">>
> > riak\_api\_version : <<"1.4.10-0-gc407ac0">>
> > riak\_pipe\_version : <<"1.4.10-0-g9353526">>
> > riak\_core\_version : <<"1.4.10">>
> > bitcask\_version : <<"1.6.6-0-g230b6d6">>
> > basho\_stats\_version : <<"1.0.3">>
> > webmachine\_version : <<"1.10.4-0-gfcff795">>
> > mochiweb\_version : <<"1.5.1p6">>
> > inets\_version : <<"5.9">>
> > erlang\_js\_version : <<"1.2.2">>
> > runtime\_tools\_version : <<"1.8.8">>
> > os\_mon\_version : <<"2.2.9">>
> > riak\_sysmon\_version : <<"1.1.3">>
> > ssl\_version : <<"5.0.1">>
> > public\_key\_version : <<"0.15">>
> > crypto\_version : <<"2.1">>
> > sasl\_version : <<"2.2.1">>
> > lager\_version : <<"2.0.1">>
> > goldrush\_version : <<"0.1.5">>
> > compiler\_version : <<"4.8.1">>
> > syntax\_tools\_version : <<"1.6.8">>
> > stdlib\_version : <<"1.18.1">>
> > kernel\_version : <<"2.15.1">>
> > memory\_total : 130705264
> > memory\_processes : 55557705
> > memory\_processes\_used : 55341757
> > memory\_system : 75147559
> > memory\_atom : 545377
> > memory\_atom\_used : 527226
> > memory\_binary : 12172712
> > memory\_code : 11674242
> > memory\_ets : 11913912
> >
> >
> >
> > \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> > riak-users mailing list
> > riak-users@lists.basho.com
> > http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
> >
>
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

