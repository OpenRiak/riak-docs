---
title: "Re: Riak Enterprise: can it be used to migrate to a new configuration?"
description: ""
project: community
lastmod: 2012-10-19T04:54:03-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08976"
mailinglist_parent_id: "msg08975"
author_name: "Rune Skou Larsen"
project_section: "mailinglistitem"
sent_date: 2012-10-19T04:54:03-07:00
---


Yes, we have done excatly that. When we migrated from 256 to 128 
partitions in a live dual-cluster system, we took one cluster down. 
Wiped the data, changed number of partitions, brought it back up and 
synced all data back with a full sync. Then we did the same with the 
other cluster.


However, I must disagree with the recomendation of 512 partitions for 5 
nodes. You should go for 128 or 256 unless you plan on scaling out to 
10+ nodes pr. cluster.


There are downsides to having many partitions. The price of the higher 
granularity is that the more storage backend processes use more 
resources for housekeeping. If you do multibackend, the ressources used 
are multiplied yet again with the number of backends because each vnode 
will have a number of running backend processes.


Say you go with the 512 partitions and have a multibackend config with 4 
backends, because you need to backup 4 different types of data 
independently. That gives you 2k running backends on each node of which 
412 will be actively in use in normal running scenario and more when 
you're doing handoff. Thats a lot of ressources just to run these, that 
you might otherwise have used for doing business.


When you increase the number of partitions you should consider:
- Number of open files. Especially when using eleveldb.
- Late triggering of bitcask compaction. The default is no compaction of 
any file before it hits 2GB. That means up to 2G of dead space per 
vnode. This can however be configured down to a smaller number than the 
2 gigs, which is crazy high in almost any use case involving delete, 
expiry or update of data.
- Leveldb cache is pr. vnode, so you need to lower the number, in order 
to not use all memory, which will lead to death by swapping.
- With a high number of vnodes pr. node, each vnode's leveldb cache will 
be comparatively small leading to (slighty) less effecient cache usage.


Please be in touch if you need onsite or offsite professional assistance 
configuring, testing or running your Riak clusters.


BR Rune Skou Larsen

Trifork
- We do Riak PS.

--

Best regards / Venlig hilsen

\*Rune Skou Larsen\*
Trifork Public A/S / Team Riak
Margrethepladsen 4, 8000 Ã…rhus C, Denmark
Phone: +45 3160 2497 Skype: runeskoularsen twitter: @RuneSkouLarsen



Den 19-10-2012 12:38, Dave Brady skrev:
Can Riak Enterprise replicate between rings where each ring has a 
different number of partitions?


Our five-node ring was originally configured with 64 partitions, and I 
saw that Basho is recommending 512 for that number of machines.


Any ideas on how to make as-painless-a-migration-as-possible are 
welcome, of course!


--
Dave Brady



\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

