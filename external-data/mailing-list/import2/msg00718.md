---
title: "Hitting per-node limitations"
description: ""
project: community
lastmod: 2010-07-12T14:59:21-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg00718"
author_name: "Michael Russo"
project_section: "mailinglistitem"
sent_date: 2010-07-12T14:59:21-07:00
---


Hi all,

I'm currently evaluating Riak and am looking to understand the system in
more depth. One of the best ways I know of doing this is to examine the
edge cases. So, without further ado:

There are several per-node limitations that, if hit, could cause a Riak node
to stop functioning properly. For example,

- disk: each node has a file system of finite size and cannot indefinitely
accept writes
- memory: the Bitcask keydir structure must fit entirely in memory and thus
cannot indefinitely accept writes

>From a management perspective, is the onus on the sysadmin to monitor disk
and memory usage and to increase the number of nodes in the cluster as
appropriate, or are there any built-in mechanisms to automatically
re-balance data across the cluster?

Furthermore, if a limit is inadvertently hit, is there a re-balancing
mechanism available that can be manually triggered to compensate, or is it a
requirement that every node take an equal share of partitions?

Are there any other related best-practices?

Thanks,
Michael
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

