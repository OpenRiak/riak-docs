---
title: "Re: Recommended way to delete keys"
description: ""
project: community
lastmod: 2015-06-03T07:54:55-0700
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16185"
mailinglist_parent_id: "msg16184"
author_name: "Sargun Dhillon"
project_section: "mailinglistitem"
sent_date: 2015-06-03T07:54:55-0700
---


You could map your keys to a given bucket, and that bucket to a given
backend using multi\_backend. There is some cost to having lots of backends
(memory overhead, FDs, etc...). When you want to do a mass drop, you could
down the node, and delete that given backend, and bring it up. Caveat: AAE,
MDC, nor mutable data play well with this scenario.

On Wed, Jun 3, 2015 at 10:43 AM, Peter Herndon  wrote:

> Hi list,
>
> Weâ€™re looking for the best way to handle large scale expiration of
> no-longer-useful data stored in Riak. We asked a while back, and the
> recommendation was to store the data in time-segmented buckets (bucket per
> day or per month), query on the current buckets, and use the streaming list
> keys API to handle slowly deleting the buckets that have aged out.
>
> Is that still the best approach for doing this kind of task? Or is there a
> better approach?
>
> Thanks!
>
> â€”Peter Herndon
> Sr. Application Engineer
> @Bitly
> \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> riak-users mailing list
> riak-users@lists.basho.com
> http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
>
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

