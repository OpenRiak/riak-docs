---
title: "Re: Is Riak suitable for s small-record write-intensive	billion-records application?"
description: ""
project: community
lastmod: 2012-10-19T08:32:33-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08980"
mailinglist_parent_id: "msg08979"
author_name: "Les Mikesell"
project_section: "mailinglistitem"
sent_date: 2012-10-19T08:32:33-07:00
---


On Fri, Oct 19, 2012 at 8:02 AM, Guido Medina  wrote:
> It depends, if you have siblings enabled at the bucket, then you need to
> resolve the conflicts using the object vclock,

How does that work for simultaneous initial inserts?

> if you are not using
> siblings, last write wins, either way, I haven't got any good results by
> delegating that tasks to Riak, with siblings, eventually I ran Riak out in
> speed of the writes making Riak fail (Due to LevelDB write speed?). And with
> last write wins then I don't think you would want unexpected results, and
> hence my recommendation: We use two things to resolve such issues; in-memory
> cache + locking mechanism.

The problem is where the inserting client should handle new keys and
updates differently, or at least be aware that its insert failed or
will be ignored later.

> For the last quote, the locking mechanism if well designed will always take
> care of that.

If it is easy, why doesn't riak handle it?

-- 
 Les Mikesell
 lesmikes...@gmail.com

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

