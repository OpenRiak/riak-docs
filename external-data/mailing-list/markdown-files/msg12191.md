---
title: "Download stops at certain megabyte boundary (RiakCS)"
description: ""
project: community
lastmod: 2013-09-04T08:39:34-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12191"
author_name: "Martin Alpers"
project_section: "mailinglistitem"
sent_date: 2013-09-04T08:39:34-07:00

---


Hello everyone on the list,

I run a test cluster for RiakCS, running on three nodes, mostly using defaults.
Mostly meaning that all modifications were necessary to make RiakCS run, but no 
tweaks have taken place yet.

Now after figuring out how to make objects publicly available we tried to 
download it again, but we saw a strange behavior:
\* downloading from the frist node stopped at exactly 3MB, i.e. 3145728 bytes
\* downloading from the second node stopped at exactly 22MB
\* downloading from the third node stopped at exactly 16MB
\* downloading from the first node using s3cmd stopped at exactly 2MB
\* downloading from the first node using wget stopped several times precisely on 
MB boundaries, but continued afterwards until the download was complete
All halts are abrupt, a 2Mb download slows down to 0b in an instant.
The first two cases were exactly the same for a friend of mine, the remaining 
were only tested by myself.

If you want to test that for yourself, the file can be found at 
http://85.10.193.103:6080$x/xyz/spying\_nsa.webm, where $x is the number of the 
node.

When I first uploaded the file, I interupted c3cmd (Crtl-C) because I had 
forgotten to allow it to be read publicly, and then reuploaded it.
However, I uploaded the file again to another bucket, available at at 
.../abc/sn.webm, and it shows the same behavior.
The number might be different, but the third node is unresponsive as well.
Naturally I had checked if the processes are still up, and "riak-admin 
member-status", and did not find any peculiarities.

I read in the docs about the "enable\_multipart" setting in .s3cfg, but mine is 
"False" and uploading a file of 25MB worked nicely.
(See 
http://docs.basho.com/riakcs/latest/cookbooks/configuration/Configuring-an-S3-Client/)
My .s3cfg was generated by s3cmd and the only modified settings are those for 
login and proxy settings.
For reference, the file, redacted only to remove credentials, can be found as 
an attachment to this mail.

Now what could I have done wrong?
I had several configuration errors in the /etc/riak-cs/app.configs of the 
cluster, fixed them, and restarted riak-cs, but the problem persists.
Could it be a setting in .s3cfg?
What about ulimit? It is still defaulting to 1024, but this is a cluster 
storing a mere 500MB or so, and less than 30 files, serving a few objects per 
hour.
I mean, what would that number look like on a production cluster if 1024 is too 
little for such low-profile testing?
For the same reason, I am sure that IO is not the problem - my 2Mb ADSL will be 
the bottleneck, and 50kb upload even more so.

I have another problem that might or might not be related, and is described 
much easier:
s3cmd ls s3://abc
WARNING: Retrying failed request: /?delimiter=/ ('')
WARNING: Waiting 3 sec...
WARNING: Retrying failed request: /?delimiter=/ ('')
WARNING: Waiting 6 sec...
^CSee ya!
Happens when I try to list objects of a non-empty bucket. Any ideas on that one?

One remaining question:
root@riak3:~# riak-admin diag
...
["sh: 1: exec: sysctl: not found"],
...
root@riak3:~#
I know how this message comes about:
sysctl lives under /sbin, which is not in $PATH for any user except root.
Should I care? What is the best way to fix that? I can think of a few.

Platform information:
Three instances of KVM, running Debian 7 (Squeeze), each connected to the KVM 
host using routed TAP devices
Erlang: Version: 1:15.b.1-dfsg-4 (R15B01 is needed to compile Riak, so this 
looks fine for me)
Prebuilt riak and riak-cs packages built for Debian 6 (Squeeze)
To meet dependencies, libssl0.9.8 from Squeeze was installed using dpkg -i
(Wheezy "only" has libssl1.0.0, which does not satisfy said dependency.)

Big thanks to anyone who has a look at my problems.
Any help is highly appreciated and I will gladly provide any information that I 
failed to provide in the first place.
-- 
Greetings, Martin Alpers
--
martin-alp...@web.de
Mobile: 0176/66185173, but I prefer typing to talking (:
Jabber: martin.alp...@jabber.org
My mails are signed using GPG to verify their origin; request my public key 
(10216CFB).
See also: http://apps.opendatacity.de/stasi-vs-nsa/
[default]
bucket\_location = DE
cloudfront\_host = cloudfront.amazonaws.com
default\_mime\_type = binary/octet-stream
delete\_removed = False
dry\_run = False
enable\_multipart = False
encoding = UTF-8
encrypt = False
follow\_symlinks = False
force = False
get\_continue = False
gpg\_command = /usr/bin/gpg
gpg\_decrypt = %(gpg\_command)s -d --verbose --no-use-agent --batch --yes 
--passphrase-fd %(passphrase\_fd)s -o %(output\_file)s %(input\_file)s
gpg\_encrypt = %(gpg\_command)s -c --verbose --no-use-agent --batch --yes 
--passphrase-fd %(passphrase\_fd)s -o %(output\_file)s %(input\_file)s
gpg\_passphrase = 
guess\_mime\_type = True
host\_base = s3.amazonaws.com
host\_bucket = %(bucket)s.s3.amazonaws.com
human\_readable\_sizes = False
invalidate\_on\_cf = False
list\_md5 = False
log\_target\_prefix = 
mime\_type = 
multipart\_chunk\_size\_mb = 15
preserve\_attrs = True
progress\_meter = True
proxy\_host = 85.10.193.103
proxy\_port = 60801
recursive = False
recv\_chunk = 4096
reduced\_redundancy = False
send\_chunk = 4096
simpledb\_host = sdb.amazonaws.com
skip\_existing = False
socket\_timeout = 300
urlencoding\_mode = normal
use\_https = False
verbosity = WARNING
website\_endpoint = http://%(bucket)s.s3-website-%(location)s.amazonaws.com/
website\_error = 
website\_index = index.html


signature.asc
Description: Digital signature
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

