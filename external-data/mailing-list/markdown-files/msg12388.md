---
title: "Re: Riak Java client bug?"
description: ""
project: community
lastmod: 2013-09-25T11:33:46-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12388"
mailinglist_parent_id: "msg12386"
author_name: "Guido Medina"
project_section: "mailinglistitem"
sent_date: 2013-09-25T11:33:46-07:00
---


To ease the situation we have done some redesign to avoid locks 
contention (Internal to our app), cause we were writing too often in 
very short time to the same key (no siblings), so it might be a 
combination of LevelDB+AAE+2i streaming, tomorrow hopefully things are 
back to normal, the crash.log just reports about nodes timed-out and 
their removal, the timing of such situation happening coincidentally 
matches such conditions, we tried playing with the quorum but that 
didn't help so the best we could come up was to have a finer grain set 
of locks.


We will set our cluster copy to use the with request timeout parameter 
to avoid the been stalled.


Regarding to your comment I guess there is a need to improve 2i+LevelDB 
weird situations.


Thanks for the help and let's see how things move in the future for 
LevelDB and Riak.


Guido.

On 25/09/13 19:21, Brian Roach wrote:

That option is for the connection timeout (i.e. when the connection
pool makes a new connection to Riak).

You can set the read timeout on the socket with the aforementioned
withRequestTimeoutMillis()

The default is the Java default, which is to say it'll block on the
socket read until either there's data to read or the remote side
closes the socket. That would at least get the client "unstuck".

This, however, doesn't explain/solve the real issue you're describing
which is that Riak is hanging up and not sending data.

Someone else will need to chime in on that - are you seeing anything
in the Riak logs?

- Roach

On Wed, Sep 25, 2013 at 12:11 PM, Guido Medina  wrote:

Like this: ....withConnectionTimeoutMillis(5000).build();

Guido.


On 25/09/13 18:08, Brian Roach wrote:

Guido -

When you say "the client is configured to time out" do you mean you're
using PB and you set the SO\_TIMEOUT on the socket via the
PBClientConfig's withRequestTimeoutMillis()?

- Roach

On Wed, Sep 25, 2013 at 5:54 AM, Guido Medina 
wrote:

Hi,

Streaming 2i indexes is not timing out, even though the client is
configured
to timeout, this coincidentally is causing the writes to fail (or or the
opposite?), is there anything elemental that could "lock" (I know the
locking concept in Erlang is out of the equation so LevelDB?) something
in
Riak while trying to stream a 2i index?

Basically, our cluster copier which runs every two minutes once it gets
to
this state it never exists (no timeout) and our app just starts slow
writing
(over a minute to write a key)

Not sure what's going on.

Guido.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com



\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com



\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

