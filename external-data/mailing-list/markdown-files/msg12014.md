---
title: "Re: LevelDB performance (block size question)"
description: ""
project: community
lastmod: 2013-08-13T18:26:41-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12014"
mailinglist_parent_id: "msg12011"
author_name: "István"
project_section: "mailinglistitem"
sent_date: 2013-08-13T18:26:41-07:00
---


It seems Riak does not like the leveldb block\_size to be changed to 64k.

App config:

app.config: {sst\_block\_size, 65536},



basho\_bench logs:

18:04:38.010 [info]
Errors:[{{delete,delete},542},{{get,get},15921},{{put,put},1253},{{{delete,delete},disconnected},542},{{{get,get},disconnected},15921},{{{put,put},disconnected}
,1250},{{{put,put},timeout},3}]
18:04:48.003 [info]
Errors:[{{delete,delete},1131},{{get,get},35704},{{put,put},2738},{{{delete,delete},disconnected},1131},{{{get,get},disconnected},35704},{{{put,put},disconnecte
d},2732},{{{put,put},timeout},6}]


node error.log:

dev2/log/error.log.3:2013-08-09 14:50:51.203 [error]
<0.3399.0>@riak\_api\_pb\_server:handle\_info:141 Unrecognized message
{909113,{error,timeout}}
dev2/log/error.log.3:2013-08-09 14:50:51.207 [error]
<0.3446.0>@riak\_api\_pb\_server:handle\_info:141 Unrecognized message
{22197453,{error,timeout}}
dev2/log/error.log.3:2013-08-09 14:53:54.267 [error]
<0.5125.3>@riak\_api\_pb\_server:handle\_info:141 Unrecognized message
{13631220,{error,timeout}}

dev2/log/error.log.3:2013-08-09 15:15:19.979 [error] <0.655.0> gen\_fsm
<0.655.0> in state active terminated with reason: bad argument in call to
ets:lookup(ets\_riak\_core\_ring\_manager, {bucket,<<"test">>}) in
riak\_core\_ring\_manager:get\_bucket\_meta/1 line 179



I have deleted all the data between the tests and some tests are still
running but it seems this configuration is not ideal.

The important part of the basho\_bench configuration:

{mode, max}.
{duration, 10}.
{concurrent, 64}.
{driver, basho\_bench\_driver\_riakc\_pb}.
{key\_generator, {int\_to\_bin, {uniform\_int, 1000000}}}.
{value\_generator, {exponential\_bin, 524288, 2048}}.


I am running additional tests with different cache size, it might have an
impact on how the system behaves.

Regards,
Istvan


On Tue, Aug 13, 2013 at 3:12 PM, István  wrote:

> Hi Matthew,
>
> Thank you for the explanation.
>
> I am experimenting with different block size and making sure I have at
> least 100G data on disk for the tests.
>
> I.
>
>
> On Tue, Aug 13, 2013 at 12:11 PM, Matthew Von-Maszewski <
> matth...@basho.com> wrote:
>
>> Istvan,
>>
>> "block\_size" is not a "size", it is a threshold. Data is never split
>> across blocks. A single block contains one or more key/value pairs.
>> leveldb starts a new block only when the total size of all key/values in
>> the current block exceed the threshold.
>>
>> Your must set block\_size to a multiple of your typical key/value size if
>> you desire multiple per block.
>>
>> Plus side: block\_size is computed before compression. So, you might get
>> nice reduction in total disk size by having multiple, mutually compressible
>> items in a block. leveldb iterators / Riak 2i might give you slightly
>> better performance with bigger blocks because there are fewer reads if the
>> keys needed are in the same block (or fewer blocks).
>>
>> Negative side: the entire block, not single key/value pairs, go into the
>> block cache uncompressed (cache\_size). You can quickly overwhelm the block
>> cache with lots of large blocks. Also random reads / Gets have to read,
>> decompress, and CRC check the entire block. Therefore it costs you more
>> disk transfer and decompression/CRC CPU time to read random values from
>> bigger blocks.
>>
>>
>> I suggest you experiment with your dataset and usage patterns. Be sure
>> to build big sample datasets before starting to measure and/or restart Riak
>> between building and measuring. These are ways to make sure you see the
>> impact of random reads.
>>
>> Matthew
>>
>>
>> On Aug 13, 2013, at 2:51 PM, István  wrote:
>>
>> Hi guys,
>>
>> I am setting up a new Riak cluster and I was wondering if there is any
>> drawback of increasing the LevelDB blocksize from 4K to 64K. The reason is
>> that we have all of the values way bigger than 4K and I guess from the
>> performance point of view it would make sense to increase the block size.
>> The tests are still running to confirm this theory but I wanted to clarify
>> that there is no big red flag of doing that from the Riak side. I found the
>> following discussion about changing block size:
>>
>> https://groups.google.com/forum/#!msg/leveldb/2JJ4smpSC6Q/1Z7aDSeHiRkJ
>>
>> Is that a good idea to experiment with this in Riak to achieve better
>> performance?
>>
>> Thank you in advance,
>> Istvan
>>
>>
>> --
>> the sun shines for all
>>
>>
>> \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>> riak-users mailing list
>> riak-users@lists.basho.com
>> http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
>>
>>
>>
>
>
> --
> the sun shines for all
>
>
>


-- 
the sun shines for all
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

