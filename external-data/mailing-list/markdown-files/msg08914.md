---
title: "Re: Map Reduce and long queries -"
description: ""
project: community
lastmod: 2012-10-15T01:13:53-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08914"
mailinglist_parent_id: "msg08912"
author_name: "Olav Frengstad"
project_section: "mailinglistitem"
sent_date: 2012-10-15T01:13:53-07:00
---


> The word everywhere is to avoid key filters. It effectively does a 
> whole-bucket key-listing, and that starts to get seriously slow out past 100k 
> items. Since you say test queries work I'll presume you've debugged your map 
> and reduce on some queries where you manually add a set of keys. (Right?)

Just as a note, using the Erlang pb client you can use the key filters
for 2i queries if you include the riak\_kv\_mapred\_filters module in
your client code path.

➜ riak-erlang-client git:(master) ✗ erl -pa ebin -pa deps/\*/ebin -pa
~/src/riak/deps/riak\_kv/ebin
Erlang R15B01 (erts-5.9.1) [source] [64-bit] [smp:2:2]
[async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.9.1 (abort with ^G)
1> O1 = riakc\_obj:new(<<"test">>, <<"abc/def/1">>, []),
1> O2 = riakc\_obj:new(<<"test">>, <<"abc/def/2">>, []),
1> O3 = riakc\_obj:new(<<"test">>, <<"hij/klm/1">>, []),
1> {ok, Pid} = riakc\_pb\_socket:start\_link("127.0.0.1", 8087),
1> riakc\_pb\_socket:put(Pid, O1),riakc\_pb\_socket:put(Pid, O2),
riakc\_pb\_socket:put(Pid, O3).
ok
2> Index = {index, <<"test">>, <<"$key">>, <<0>>, <<255>>},
2> {ok, Filter} = riak\_kv\_mapred\_filters:build\_filter([[<<"ends\_with">>,"1"]]),
2> MR = [
2> { reduce
2> , {qfun, fun(X, F) -> lists:filter(fun({A, B}) -> F(B) end, X) end}
2> , riak\_kv\_mapred\_filters:compose(Filter)
2> , true}],
2> riakc\_pb\_socket:mapred(Pid, Index, MR).
{ok,[{0,
 [{<<"test">>,<<"hij/klm/1">>},
 {<<"test">>,<<"abc/def/1">>}]}]}

Olav

2012/10/14, Adam Lindsay :
- Vis sitert tekst -
>> riak-users@lists.basho.com (mailto:riak-users@lists.basho.com)
>> http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
>>
>>
>
>

2012/10/14, Adam Lindsay :
> Hi David,
>
> The word everywhere is to avoid key filters. It effectively does a
> whole-bucket key-listing, and that starts to get seriously slow out past
> 100k items. Since you say test queries work I'll presume you've debugged
> your map and reduce on some queries where you manually add a set of keys.
> (Right?)
>
> Since you're on LevelDB, it means you can use secondary indices ("2i") to
> drive these queries.
>
> I don't have access to your filter\_map, so I don't have access to how you
> construct your keys, but if you have 2i turned on, then you get the first
> key-field "for free" from 2i.
>
> Let's say, hypothetically, that your keys are constructed as:
> keyprefix:::
>
> Well, you can then rewrite the query input as:
>
> def main():
> client = riak.RiakClient(host=riak\_host,
> port=8087,transport\_class=riak.transports.pbc.RiakPbcTransport)
> query = client.index(
> bucket,
> '$key',
> 'keyprefix:201210',
> 'keyprefix:201210~')
> query.map('''function(value, keyData, arg) { ... }''')
> …
>
>
>
> That's fine as far as it goes, but it doesn't solve the problem of querying
> country or campaign id, right?
>
> As a temporary measure, I'd suggest trying your key filters, cranking up the
> timeout to something on the order of hours (I gave 5 minutes conservatively
> and arbitrarily), and going ahead and running it for however long it takes.
>
>
> If those queries do give good results, I'd suggest going ahead and
> re-indexing your existing entries with 'country\_bin' and 'campaign\_bin'.
> It's up to personal style whether you treat dates as int or bin.
>
> There are lots of tricks and further discussion on how best to get at every
> corner of your data, but how does this strike you so far?
> --
> Adam Lindsay
>
>
> On Sunday, 14 October 2012 at 12:57, David Montgomery wrote:
>
>> Hi,
>>
>> Below is my code for running a map reduce in python. I have a six
>> node cluster, 2 cores each with 4 gigs for ram. I am no load and
>> about 3 Mill keys and using leveldb with riak 1.2. Doing the below
>> is taking a terribly long time. Never finished and I dont even know
>> how I can check if it is even running other than the python script has
>> not timed out. I look at the number of executed mappers in stats and
>> it is flat lined when looking at Graphite. On test queries the below
>> works.
>>
>> So..how do I debug what is going on?
>>
>>
>> def main():
>> client =
>> riak.RiakClient(host=riak\_host,port=8087,transport\_class=riak.transports.pbc.RiakPbcTransport)
>> query = client.add(bucket)
>> filters = key\_filter.tokenize(":", filter\_map['date']) +
>> (key\_filter.starts\_with('201210'))
>> #& key\_filter.tokenize(":", filter\_map['country']).eq("US") \
>> #& key\_filter.tokenize(":", filter\_map['campaign\_id']).eq("t1") \
>> query.add\_key\_filters(filters)
>>
>> query.map('''
>> function(value, keyData, arg) {
>> var data = Riak.mapValuesJson(value)[0];
>>
>> if(data['adx']=='gdn'){
>> var alt\_key = data['hw'];
>> var obj = {};
>> obj[alt\_key] = 1;
>> return [ obj ];
>> }else{
>> return [];
>> }
>>
>>
>> }''')
>>
>>
>> query.reduce('''
>> function(values, arg){
>> return [ values.reduce( function(acc, item) {
>> for (var state in item) {
>> if (acc[state])
>> acc[state] += item[state];
>> else
>> acc[state] = item[state];
>> }
>> return acc;
>> })];
>> }
>> ''')
>>
>> for result in query.run(timeout=300000):
>> print result
>>
>> \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>> riak-users mailing list
>> riak-users@lists.basho.com (mailto:riak-users@lists.basho.com)
>> http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com
>>
>>
>
>
>

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\_lists.basho.com

