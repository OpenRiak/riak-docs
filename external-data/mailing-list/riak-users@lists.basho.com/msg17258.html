<!DOCTYPE html>
<html lang="en">
<head>
<title>Unable to use hadoop distcp with Riak</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="contents" href="index.html#17258" id="c">
<link rel="index" href="maillist.html#17258" id="i">
<link rel="prev" href="msg17257.html" id="p">
<link rel="next" href="msg17259.html" id="n">
<link rel="canonical" href="https://www.mail-archive.com/riak-users@lists.basho.com/msg17258.html">
<link rel="stylesheet" href="/normalize.css" media="screen">
<link rel="stylesheet" href="/master.css" media="screen">

<!--[if lt IE 9]>
<link rel="stylesheet" href="/ie.css" media="screen">
<![endif]-->
</head>
<body>
<script language="javascript" type="text/javascript">
document.onkeydown = NavigateThrough;
function NavigateThrough (event)
{
  if (!document.getElementById) return;
  if (window.event) event = window.event;
  if (event.target.tagName == 'INPUT') return;
  if (event.ctrlKey || event.metaKey) return;
  var link = null;
  switch (event.keyCode ? event.keyCode : event.which ? event.which : null) {
    case 74:
    case 80:
      link = document.getElementById ('p');
      break;
    case 75:
    case 78:
      link = document.getElementById ('n');
      break;
    case 69:
      link = document.getElementById ('e');
      break;
    }
  if (link && link.href) document.location = link.href;
}
</script>
<div itemscope itemtype="http://schema.org/Article" class="container">
<div class="skipLink">
<a href="#nav">Skip to site navigation (Press enter)</a>
</div>
<div class="content" role="main">
<div class="msgHead">
<h1>
<span class="subject"><a href="/search?l=riak-users@lists.basho.com&amp;q=subject:%22Unable+to+use+hadoop+distcp+with+Riak%22&amp;o=newest" rel="nofollow"><span itemprop="name">Unable to use hadoop distcp with Riak</span></a></span>
</h1>
<p class="darkgray font13">
<span class="sender pipe"><a href="/search?l=riak-users@lists.basho.com&amp;q=from:%22psterk%22" rel="nofollow"><span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">psterk</span></span></a></span>
<span class="date"><a href="/search?l=riak-users@lists.basho.com&amp;q=date:20160425" rel="nofollow">Mon, 25 Apr 2016 00:51:07 -0700</a></span>
</p>
</div>
<div itemprop="articleBody" class="msgBody">
<!--X-Body-of-Message-->
<pre>Hi all,

I am trying to copy a file out of Riak using the s3 protocol to HDFS.  I
have the following file:</pre><pre>

I created the following file: /etc/hadoop/conf/jets3t.properties

s3service.s3-endpoint=myhost
s3service.s3-endpoint-http-port=8080
s3service.disable-dns-buckets=true
s3service.s3-endpoint-virtual-path=/

s3service.max-thread-count=10
threaded-service.max-thread-count=10
s3service.https-only=false
httpclient.proxy-autodetect=false
httpclient.proxy-host=myhost
httpclient.proxy-port=8080
httpclient.retry-max=11


hadoop distcp  s3://&lt;access key&gt;:&lt;secret key&gt;@test/test
hdfs://localhost/tmp/test

I get this stack trace:

org.apache.hadoop.fs.s3.S3Exception: org.jets3t.service.S3ServiceException:
Request Error. -- ResponseCode: 404, ResponseStatus: Object Not Found
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:175)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.retrieveINode(Jets3tFileSystemStore.java:221)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy25.retrieveINode(Unknown Source)
        at
org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:340)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:252)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1655)
        at
org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)
        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:84)
        at 
org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:382)
        at org.apache.hadoop.tools.DistCp.createAndSubmitJob(DistCp.java:181)
        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:153)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:126)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:430)
Caused by: org.jets3t.service.S3ServiceException: Request Error. --
ResponseCode: 404, ResponseStatus: Object Not Found
        at org.jets3t.service.S3Service.getObject(S3Service.java:1379)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:163)
        ... 20 more
Caused by: org.jets3t.service.impl.rest.HttpException
        at
org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
        at
org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
        at
org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestGet(RestStorageService.java:981)
        at
org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2150)
        at
org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2087)
        at org.jets3t.service.StorageService.getObject(StorageService.java:1140)
        at org.jets3t.service.S3Service.getObject(S3Service.java:2583)
        at org.jets3t.service.S3Service.getObject(S3Service.java:84)
        at org.jets3t.service.StorageService.getObject(StorageService.java:525)
        at org.jets3t.service.S3Service.getObject(S3Service.java:1377)

However, with a local .s3cfg file that points to a Riak cluster, I can do
this:

[hdfs@dsg01 ~]$ s3cmd ls s3://test
                       DIR   s3://test/home/
                       DIR   s3://test/setup/
                       DIR   s3://test/test/
                       DIR   s3://test/tmp/

So, s3://test/test does exist and is in Riak, not AWS.


Now, if I comment out s3service.s3-endpoint-virtual-path and run:

hadoop distcp  s3://&lt;access key&gt;:&lt;secret key&gt;@test/test
hdfs://localhost/tmp/test

I see:

java.io.IOException: /test doesn't exist
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:170)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.retrieveINode(Jets3tFileSystemStore.java:221)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy25.retrieveINode(Unknown Source)
        at
org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:340)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:252)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1655)
        at
org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)
        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:84)
        at 
org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:382)
        at org.apache.hadoop.tools.DistCp.createAndSubmitJob(DistCp.java:181)
        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:153)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:126)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:430)

Using @test/test/ produces the same exception as above.

Using: hadoop distcp  s3://&lt;access key&gt;:&lt;secret key&gt;@test
hdfs://localhost/tmp/test

java.io.IOException: /user/hdfs doesn't exist
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:170)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.retrieveINode(Jets3tFileSystemStore.java:221)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy25.retrieveINode(Unknown Source)
        at
org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:340)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:252)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1655)
        at
org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)
        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:84)
        at 
org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:382)
        at org.apache.hadoop.tools.DistCp.createAndSubmitJob(DistCp.java:181)
        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:153)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:126)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:430)

I am the user 'hdfs'.

If I comment out these properties

#s3service.s3-endpoint=myhost
#s3service.s3-endpoint-http-port=8080
#s3service.disable-dns-buckets=true
#s3service.s3-endpoint-virtual-path=/

and run: hadoop distcp  s3://&lt;access key&gt;:&lt;secret key&gt;@test/test
hdfs://localhost/tmp/test

I get fresh, new exception:

16/04/22 21:53:34 ERROR tools.DistCp: Exception encountered
org.apache.hadoop.fs.s3.S3Exception: org.jets3t.service.S3ServiceException:
S3 Error Message. -- ResponseCode: 403, ResponseStatus: Forbidden, XML Error
Message: &lt;?xml version=&quot;1.0&quot;
encoding=&quot;UTF-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AccessDenied&lt;/Code&gt;&lt;Message&gt;Access
Denied&lt;/Message&gt;&lt;Resource&gt;/%2Ftest&lt;/Resource&gt;&lt;RequestId&gt;&lt;/RequestId&gt;&lt;/Error&gt;
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:175)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.retrieveINode(Jets3tFileSystemStore.java:221)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy25.retrieveINode(Unknown Source)
        at
org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:340)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:57)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:252)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1655)
        at
org.apache.hadoop.tools.GlobbedCopyListing.doBuildListing(GlobbedCopyListing.java:77)
        at org.apache.hadoop.tools.CopyListing.buildListing(CopyListing.java:84)
        at 
org.apache.hadoop.tools.DistCp.createInputFileListing(DistCp.java:382)
        at org.apache.hadoop.tools.DistCp.createAndSubmitJob(DistCp.java:181)
        at org.apache.hadoop.tools.DistCp.execute(DistCp.java:153)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:126)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:430)
Caused by: org.jets3t.service.S3ServiceException: S3 Error Message. --
ResponseCode: 403, ResponseStatus: Forbidden, XML Error Message: &lt;?xml
version=&quot;1.0&quot;
encoding=&quot;UTF-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AccessDenied&lt;/Code&gt;&lt;Message&gt;Access
Denied&lt;/Message&gt;&lt;Resource&gt;/%2Ftest&lt;/Resource&gt;&lt;RequestId&gt;&lt;/RequestId&gt;&lt;/Error&gt;
        at org.jets3t.service.S3Service.getObject(S3Service.java:1379)
        at
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.get(Jets3tFileSystemStore.java:163)
        ... 20 more

It's odd to see &quot;/%2Ftest&quot;  which is a URL encoding for '/'.  Why is that
there?

Note: 'myhost' is just a placeholder for the actual hostname which does
resolve.

What am I missing?  



--
View this message in context: 
<a  rel="nofollow" href="http://riak-users.197444.n3.nabble.com/Unable-to-use-hadoop-distcp-with-Riak-tp4034185.html">http://riak-users.197444.n3.nabble.com/Unable-to-use-hadoop-distcp-with-Riak-tp4034185.html</a>
Sent from the Riak Users mailing list archive at Nabble.com.

_______________________________________________
riak-users mailing list
riak-users@lists.basho.com
<a  rel="nofollow" href="http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com">http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com</a>
</pre>

</div>
<div class="msgButtons margintopdouble">
<ul class="overflow">
<li class="msgButtonItems"><a class="button buttonleft " accesskey="p" href="msg17257.html">Previous message</a></li>
<li class="msgButtonItems textaligncenter"><a class="button" accesskey="c" href="index.html#17258">View by thread</a></li>
<li class="msgButtonItems textaligncenter"><a class="button" accesskey="i" href="maillist.html#17258">View by date</a></li>
<li class="msgButtonItems textalignright"><a class="button buttonright " accesskey="n" href="msg17259.html">Next message</a></li>
</ul>
</div>
<a name="tslice"></a>
<div class="tSliceList margintopdouble">
<ul class="icons monospace">

</ul>
</div>
<div class="overflow msgActions margintopdouble">
<div class="msgReply" >
<h2>
					Reply via email to
</h2>
<form method="POST" action="/mailto.php">
<input type="hidden" name="subject" value="Unable to use hadoop distcp with Riak">
<input type="hidden" name="msgid" value="1461363232541-4034185.post@n3.nabble.com">
<input type="hidden" name="relpath" value="riak-users@lists.basho.com/msg17258.html">
<input type="submit" value=" psterk ">
</form>
</div>
</div>
</div>
<div class="aside" role="complementary">
<div class="logo">
<a href="/"><img src="/logo.png" width=247 height=88 alt="The Mail Archive"></a>
</div>
<form class="overflow" action="/search" method="get">
<input type="hidden" name="l" value="riak-users@lists.basho.com">
<label class="hidden" for="q">Search the site</label>
<input class="submittext" type="text" id="q" name="q" placeholder="Search riak-users">
<input class="submitbutton" name="submit" type="image" src="/submit.png" alt="Submit">
</form>
<div class="nav margintop" id="nav" role="navigation">
<ul class="icons font16">
<li class="icons-home"><a href="/">The Mail Archive home</a></li>
<li class="icons-list"><a href="/riak-users@lists.basho.com/">riak-users - all messages</a></li>
<li class="icons-about"><a href="/riak-users@lists.basho.com/info.html">riak-users - about the list</a></li>
<li class="icons-expand"><a href="/search?l=riak-users@lists.basho.com&amp;q=subject:%22Unable+to+use+hadoop+distcp+with+Riak%22&amp;o=newest&amp;f=1" title="e" id="e">Expand</a></li>
<li class="icons-prev"><a href="msg17257.html" title="p">Previous message</a></li>
<li class="icons-next"><a href="msg17259.html" title="n">Next message</a></li>
</ul>
</div>
<div class="listlogo margintopdouble">

</div>
<div class="margintopdouble">

</div>
</div>
</div>
<div class="footer" role="contentinfo">
<ul>
<li><a href="/">The Mail Archive home</a></li>
<li><a href="/faq.html#newlist">Add your mailing list</a></li>
<li><a href="/faq.html">FAQ</a></li>
<li><a href="/faq.html#support">Support</a></li>
<li><a href="/faq.html#privacy">Privacy</a></li>
<li class="darkgray">1461363232541-4034185.post@n3.nabble.com</li>
</ul>
</div>
</body>
</html>
