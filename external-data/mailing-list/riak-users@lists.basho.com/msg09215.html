<!DOCTYPE html>
<html lang="en">
<head>
<title>Re: avg write io wait time regression in 1.2.1</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="contents" href="index.html#09215" id="c">
<link rel="index" href="maillist.html#09215" id="i">
<link rel="prev" href="msg09212.html" id="p">
<link rel="next" href="msg09213.html" id="n">
<link rel="canonical" href="https://www.mail-archive.com/riak-users@lists.basho.com/msg09215.html">
<link rel="stylesheet" href="/normalize.css" media="screen">
<link rel="stylesheet" href="/master.css" media="screen">

<!--[if lt IE 9]>
<link rel="stylesheet" href="/ie.css" media="screen">
<![endif]-->
</head>
<body>
<script language="javascript" type="text/javascript">
document.onkeydown = NavigateThrough;
function NavigateThrough (event)
{
  if (!document.getElementById) return;
  if (window.event) event = window.event;
  if (event.target.tagName == 'INPUT') return;
  if (event.ctrlKey || event.metaKey) return;
  var link = null;
  switch (event.keyCode ? event.keyCode : event.which ? event.which : null) {
    case 74:
    case 80:
      link = document.getElementById ('p');
      break;
    case 75:
    case 78:
      link = document.getElementById ('n');
      break;
    case 69:
      link = document.getElementById ('e');
      break;
    }
  if (link && link.href) document.location = link.href;
}
</script>
<div itemscope itemtype="http://schema.org/Article" class="container">
<div class="skipLink">
<a href="#nav">Skip to site navigation (Press enter)</a>
</div>
<div class="content" role="main">
<div class="msgHead">
<h1>
<span class="subject"><a href="/search?l=riak-users@lists.basho.com&amp;q=subject:%22Re%5C%3A+avg+write+io+wait+time+regression+in+1.2.1%22&amp;o=newest" rel="nofollow"><span itemprop="name">Re: avg write io wait time regression in 1.2.1</span></a></span>
</h1>
<p class="darkgray font13">
<span class="sender pipe"><a href="/search?l=riak-users@lists.basho.com&amp;q=from:%22Dietrich+Featherston%22" rel="nofollow"><span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Dietrich Featherston</span></span></a></span>
<span class="date"><a href="/search?l=riak-users@lists.basho.com&amp;q=date:20121106" rel="nofollow">Tue, 06 Nov 2012 17:57:21 -0800</a></span>
</p>
</div>
<div itemprop="articleBody" class="msgBody">
<!--X-Body-of-Message-->
<pre>Our raid controller is --&gt; 03:00.0 RAID bus controller: LSI Logic / Symbios
Logic LSI MegaSAS 9260 (rev 05)</pre><pre>

Here's one processor from /proc/cpuinfo

processor : 0
&gt; vendor_id : GenuineIntel
&gt; cpu family : 6
&gt; model : 44
&gt; model name : Intel(R) Xeon(R) CPU           X5647  @ 2.93GHz
&gt; stepping : 2
&gt; cpu MHz : 2925.659
&gt; cache size : 12288 KB
&gt; physical id : 1
&gt; siblings : 8
&gt; core id : 0
&gt; cpu cores : 4
&gt; apicid : 32
&gt; initial apicid : 32
&gt; fpu : yes
&gt; fpu_exception : yes
&gt; cpuid level : 11
&gt; wp : yes
&gt; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat
&gt; pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb
&gt; rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc
&gt; aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16
&gt; xtpr pdcm dca sse4_1 sse4_2 popcnt aes lahf_lm ida arat tpr_shadow vnmi
&gt; flexpriority ept vpid
&gt; bogomips : 5851.31
&gt; clflush size : 64
&gt; cache_alignment : 64
&gt; address sizes : 40 bits physical, 48 bits virtual
&gt; power management:



On Tue, Nov 6, 2012 at 5:17 PM, Matthew Von-Maszewski &lt;matth...@basho.com&gt;wrote:

&gt; Would you paste the data for one core from /proc/cpuinfo?  And do you know
&gt; the brand of controller running the SSD drives?
&gt;
&gt; Thank you,
&gt; Matthew
&gt;
&gt;
&gt; On Nov 6, 2012, at 7:04 PM, Dietrich Featherston wrote:
&gt;
&gt; Thanks for the feedback. We haven't noticed any drop in riak
&gt; responsiveness--quite the opposite. We were just alarmed at some of the
&gt; iostat information we were seeing which may very well result from, as you
&gt; pointed out, greater concurrency in layers above the disk subsystem. It's
&gt; not of concern at the moment.
&gt;
&gt; As for the cluster itself--we are running 9 physical notes with a ring
&gt; size of 64. Each with a 2.93Ghz 8-core Xeon and ~2 TB of RAID0 SSD storage
&gt; across 6 physical drives.
&gt;
&gt; Thanks again for looking into this.
&gt;
&gt; D
&gt;
&gt;
&gt; On Tue, Nov 6, 2012 at 3:19 PM, Matthew Von-Maszewski 
&gt; &lt;matth...@basho.com&gt;wrote:
&gt;
&gt;&gt; Dietrich,
&gt;&gt;
&gt;&gt; I finally reviewed your LOG.all today.  The basic analysis is:
&gt;&gt;
&gt;&gt; - you have a really fast disk subsystem, and
&gt;&gt; - your machine is bored.
&gt;&gt;
&gt;&gt; I make the first comment based upon the fact that your Level-0 file
&gt;&gt; creations take less than 200 ms on files of 40Mbyte with 10,000 keys (or
&gt;&gt; more).  I would like to know more specifics about your hardware and
&gt;&gt; operating system (and disk parameters).  That information is likely worthy
&gt;&gt; of sharing with all.
&gt;&gt;
&gt;&gt; I make the second comment after running a shallow analysis of all
&gt;&gt; compaction activity per minute in LOG.all.  Your current ingest rate (rate
&gt;&gt; of adding data to leveldb) is not very high compared to other sites I have
&gt;&gt; seen.  So we should continue this discussion if you still believe there is
&gt;&gt; an overall slow down.
&gt;&gt;
&gt;&gt; I will note that the authors of Erlang have given us some suggested
&gt;&gt; changes in our Erlang to leveldb interface this past weekend.  That
&gt;&gt; information could also give leveldb a throughput boost if proven valid.
&gt;&gt;  Keep you posted.
&gt;&gt;
&gt;&gt; But at this time I see nothing that yells &quot;massive slow down&quot;.  I am of
&gt;&gt; course open to being wrong.
&gt;&gt;
&gt;&gt; Matthew
&gt;&gt;
&gt;&gt;
&gt;&gt; On Nov 2, 2012, at 10:32 AM, Dietrich Featherston wrote:
&gt;&gt;
&gt;&gt; Here's the level output from one of our upgraded nodes. Included our
&gt;&gt; app.config as well. Will continue looking for clues. I can put together
&gt;&gt; some snapshots of our sst file sizes across the cluster if you think that
&gt;&gt; would help as well.
&gt;&gt;
&gt;&gt; On Fri, Nov 2, 2012 at 6:19 AM, Matthew Von-Maszewski &lt;matth...@basho.com
&gt;&gt; &gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Dietrich,
&gt;&gt;&gt;
&gt;&gt;&gt; I can make two guesses into the increased disk writes.  But I am also
&gt;&gt;&gt; willing to review your actual LOG files to isolate root cause.  If you
&gt;&gt;&gt; could run the following and post the resulting file from one server, I will
&gt;&gt;&gt; review it over the weekend or early next week:
&gt;&gt;&gt;
&gt;&gt;&gt; sort /var/lib/riak/leveldb/*/LOG &gt;LOG.all
&gt;&gt;&gt;
&gt;&gt;&gt; The file will compress well.  And no need to stop the server, just
&gt;&gt;&gt; gather the LOG data live.
&gt;&gt;&gt;
&gt;&gt;&gt; Guess 1:  your data is in a transition phase.  1.1 used 2 Megabyte files
&gt;&gt;&gt; exclusively.  1.2 is resizing the files to much larger sizes during a
&gt;&gt;&gt; compaction.  You could be seeing a larger number of files than usual
&gt;&gt;&gt; participating in each compaction as the file sizes change.  While this is
&gt;&gt;&gt; possible, I have doubts … hence this is a guess.
&gt;&gt;&gt;
&gt;&gt;&gt; Guess 2:  I increased the various leveldb file sizes to reduce the
&gt;&gt;&gt; number of open and closes, both for writes and random reads.  This helped
&gt;&gt;&gt; latencies in both the compactions and random reads.  Any compaction in 1.2
&gt;&gt;&gt; is likely to reread and write larger total number of bytes.  While this is
&gt;&gt;&gt; possible, I again have doubts … the number of read operations should also
&gt;&gt;&gt; go up if this guess is correct.  Your read operations have not increased.
&gt;&gt;&gt;  This guess might still be valid if the read operations were satisfied by
&gt;&gt;&gt; the Linux memory data cache.  I do not how those would be counted or not
&gt;&gt;&gt; counted.
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Matthew
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Nov 1, 2012, at 10:01 PM, Dietrich Featherston wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Will check on that.
&gt;&gt;&gt;
&gt;&gt;&gt; Can you think of anything that would explain the 5x increase in disk
&gt;&gt;&gt; writes we are seeing with the same workload?
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Thu, Nov 1, 2012 at 6:03 PM, Matthew Von-Maszewski &lt;
&gt;&gt;&gt; matth...@basho.com&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Look for any activity in the LOG.  Level-0 &quot;creations&quot; are fast and not
&gt;&gt;&gt;&gt; typically relevant.  You would be most interested in LOG lines containing
&gt;&gt;&gt;&gt; &quot;Compacting&quot; (start) and &quot;Compacted&quot; (end).  The time in between will
&gt;&gt;&gt;&gt; throttle.  The idea is that these compaction events can pile up, one after
&gt;&gt;&gt;&gt; another and multiple overlapping.  It is these heavy times where the
&gt;&gt;&gt;&gt; throttle saves the user experience.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; On Nov 1, 2012, at 8:54 PM, Dietrich Featherston wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks. The amortized stalls may very well describe what we are seeing.
&gt;&gt;&gt;&gt; If I combine leveldb logs from all partitions on one of the upgraded nodes
&gt;&gt;&gt;&gt; what should I look for in terms of compaction activity to verify this?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; On Thu, Nov 1, 2012 at 5:48 PM, Matthew Von-Maszewski &lt;
&gt;&gt;&gt;&gt; matth...@basho.com&gt; wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Dietrich,
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; I can see your concern with the write IOS statistic.  Let me comment
&gt;&gt;&gt;&gt;&gt; on the easy question first:  block_size.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; The block_size parameter in 1.1 was not getting passed to leveldb from
&gt;&gt;&gt;&gt;&gt; the erlang layer.  You were using a 4096 byte block parameter no matter
&gt;&gt;&gt;&gt;&gt; what you typed in the app.config.  The block_size is used by leveldb as a
&gt;&gt;&gt;&gt;&gt; threshold.  Once you accumulate enough data above that threshold, the
&gt;&gt;&gt;&gt;&gt; current block is written to disk and a new one started.  If you have 10k
&gt;&gt;&gt;&gt;&gt; data values, your get one data item per block and its size is ~10k.  If 
&gt;&gt;&gt;&gt;&gt; you
&gt;&gt;&gt;&gt;&gt; have 1k data values, you get about four per block and the block is about 
&gt;&gt;&gt;&gt;&gt; 4k.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; We recommend 4k blocks to help read performance.  The entire block has
&gt;&gt;&gt;&gt;&gt; to run through decompression and potentially CRC calculation when it comes
&gt;&gt;&gt;&gt;&gt; off the disk.  That CPU time really kills any disk performance gains by
&gt;&gt;&gt;&gt;&gt; having larger blocks.  Ok, that might change in 1.3 as we enable hardware
&gt;&gt;&gt;&gt;&gt; CRC … but only if you have &quot;verify_checksums, true&quot; in app.config.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Back to performance:  I have not seen the change your graph details
&gt;&gt;&gt;&gt;&gt; when testing with SAS drives under moderate load.  I am only today 
&gt;&gt;&gt;&gt;&gt; starting
&gt;&gt;&gt;&gt;&gt; qualification tests with SSD drives.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; But my 1.2 and 1.3 tests focus on drive / Riak saturation.  1.1 has
&gt;&gt;&gt;&gt;&gt; the nasty tendency to stall (intentionally) when we saturate the write 
&gt;&gt;&gt;&gt;&gt; side
&gt;&gt;&gt;&gt;&gt; of leveldb, .  The stall was measured in seconds or even minutes in 1.1.
&gt;&gt;&gt;&gt;&gt;  1.2.1 has a write throttle that forecasts leveldb's stall state and
&gt;&gt;&gt;&gt;&gt; incrementally slows the individual writes to prevent the stalls.  Maybe
&gt;&gt;&gt;&gt;&gt; that is what is being seen in the graph.  The only way to know for sure is
&gt;&gt;&gt;&gt;&gt; to get an dump of your leveldb LOG files, combined them, then compare
&gt;&gt;&gt;&gt;&gt; compaction activity to your graph.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Write stalls are detailed here:
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="http://basho.com/blog/technical/2012/10/30/leveldb-in-riak-1p2/">http://basho.com/blog/technical/2012/10/30/leveldb-in-riak-1p2/</a>
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; How can I better assist you at this point?
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; On Nov 1, 2012, at 8:13 PM, Dietrich Featherston wrote:
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; We've just gone through the process of upgrading two riak clusters
&gt;&gt;&gt;&gt;&gt; from 1.1  to 1.2.1. Both are on the leveldb backend backed by RAID0'd 
&gt;&gt;&gt;&gt;&gt; SSDs.
&gt;&gt;&gt;&gt;&gt; The process has gone smoothly and we see that latencies as measured at the
&gt;&gt;&gt;&gt;&gt; gen_fsm level are largely unaffected.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; However, we are seeing some troubling disk statistics and I'm looking
&gt;&gt;&gt;&gt;&gt; for an explanation before we upgrade the remainder of our nodes. The 
&gt;&gt;&gt;&gt;&gt; source
&gt;&gt;&gt;&gt;&gt; of the worry seems to be a huge amplification in the number of writes
&gt;&gt;&gt;&gt;&gt; serviced by the disk which may be the cause of rising io wait times.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; My first thought was that this could be due to some leveldb tuning in
&gt;&gt;&gt;&gt;&gt; 1.2.1 which increases file sizes per the release notes (
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="https://github.com/basho/riak/blob/master/RELEASE-NOTES.md">https://github.com/basho/riak/blob/master/RELEASE-NOTES.md</a>). But
&gt;&gt;&gt;&gt;&gt; nodes that were upgraded yesterday are still showing this symptom. I would
&gt;&gt;&gt;&gt;&gt; have expected any block re-writing to have subsided by now.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Next hypothesis has to do with block size overriding in app.config. In
&gt;&gt;&gt;&gt;&gt; 1.1, we had specified custom block sizes of 256k. We removed this prior to
&gt;&gt;&gt;&gt;&gt; upgrading to 1.2.1 at the advice of #riak since block size configuration
&gt;&gt;&gt;&gt;&gt; was ignored prior to 1.2 ('&quot;block_size&quot; parameter within app.config for
&gt;&gt;&gt;&gt;&gt; leveldb was ignored.  This parameter is now properly passed to leveldb.'
&gt;&gt;&gt;&gt;&gt; --&gt;
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="https://github.com/basho/riak/commit/f12596c221a9d942cc23d8e4fd83c9ca46e02105">https://github.com/basho/riak/commit/f12596c221a9d942cc23d8e4fd83c9ca46e02105</a>).
&gt;&gt;&gt;&gt;&gt; I'm wondering if the block size parameter really was being passed to
&gt;&gt;&gt;&gt;&gt; leveldb, and having removed it, blocks are now being rewritten to a new
&gt;&gt;&gt;&gt;&gt; size, perhaps different from what they were being written as before (
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="https://github.com/basho/riak_kv/commit/ad192ee775b2f5a68430d230c0999a2caabd1155">https://github.com/basho/riak_kv/commit/ad192ee775b2f5a68430d230c0999a2caabd1155</a>
&gt;&gt;&gt;&gt;&gt; )
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Here is the output of the following script showing the increased
&gt;&gt;&gt;&gt;&gt; writes to disk (<a  rel="nofollow" href="https://gist.github.com/37319a8ed2679bb8b21d">https://gist.github.com/37319a8ed2679bb8b21d</a>)
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;  --an upgraded 1.2.1 node--
&gt;&gt;&gt;&gt;&gt; read ios: 238406742
&gt;&gt;&gt;&gt;&gt; write ios: 4814320281
&gt;&gt;&gt;&gt;&gt; read/write ratio: .04952033
&gt;&gt;&gt;&gt;&gt; avg wait: .10712340
&gt;&gt;&gt;&gt;&gt; read wait: .49174364
&gt;&gt;&gt;&gt;&gt; write wait: .42695475
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; --a node still running 1.1--
&gt;&gt;&gt;&gt;&gt; read ios: 267770032
&gt;&gt;&gt;&gt;&gt; write ios: 944170656
&gt;&gt;&gt;&gt;&gt; read/write ratio: .28360342
&gt;&gt;&gt;&gt;&gt; avg wait: .34237204
&gt;&gt;&gt;&gt;&gt; read wait: .47222371
&gt;&gt;&gt;&gt;&gt; write wait: 1.83283749
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; And here's what munin is showing us in terms of avg io wait times.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; &lt;image.png&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Any thoughts on what might explain this?
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Thanks,
&gt;&gt;&gt;&gt;&gt; D
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; _______________________________________________
&gt;&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com">http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com</a>
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; _______________________________________________
&gt;&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt;&gt; <a  rel="nofollow" href="http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com">http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com</a>
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt; &lt;disk-latency-riak-1.2.1.tar.gz&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;
&gt;
</pre><pre>_______________________________________________
riak-users mailing list
riak-users@lists.basho.com
<a  rel="nofollow" href="http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com">http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com</a>
</pre>

</div>
<div class="msgButtons margintopdouble">
<ul class="overflow">
<li class="msgButtonItems"><a class="button buttonleft " accesskey="p" href="msg09212.html">Previous message</a></li>
<li class="msgButtonItems textaligncenter"><a class="button" accesskey="c" href="index.html#09215">View by thread</a></li>
<li class="msgButtonItems textaligncenter"><a class="button" accesskey="i" href="maillist.html#09215">View by date</a></li>
<li class="msgButtonItems textalignright"><a class="button buttonright " accesskey="n" href="msg09213.html">Next message</a></li>
</ul>
</div>
<a name="tslice"></a>
<div class="tSliceList margintopdouble">
<ul class="icons monospace">
<li class="icons-email"><span class="subject"><a href="msg09149.html">Re: avg write io wait time regression in 1.2.1</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li><ul>
<li class="icons-email"><span class="subject"><a href="msg09150.html">Re: avg write io wait time regression in 1.2.1</a></span> <span class="sender italic">Dietrich Featherston</span></li>
<li><ul>
<li class="icons-email"><span class="subject"><a href="msg09156.html">Re: avg write io wait time regression in 1....</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li><ul>
<li class="icons-email"><span class="subject"><a href="msg09161.html">Re: avg write io wait time regression i...</a></span> <span class="sender italic">Dave Brady</span></li>
<li><ul>
<li class="icons-email"><span class="subject"><a href="msg09172.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li class="icons-email"><span class="subject"><a href="msg09191.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Dave Brady</span></li>
</ul></li>
<li class="icons-email"><span class="subject"><a href="msg09173.html">Re: avg write io wait time regression i...</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li class="icons-email"><span class="subject"><a href="msg09210.html">Re: avg write io wait time regression i...</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li><ul>
<li class="icons-email"><span class="subject"><a href="msg09211.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Dietrich Featherston</span></li>
<li class="icons-email"><span class="subject"><a href="msg09212.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li class="icons-email tSliceCur"><span class="subject">Re: avg write io wait time regressi...</span> <span class="sender italic">Dietrich Featherston</span></li>
<li class="icons-email"><span class="subject"><a href="msg09213.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Matthew Von-Maszewski</span></li>
<li class="icons-email"><span class="subject"><a href="msg09214.html">Re: avg write io wait time regressi...</a></span> <span class="sender italic">Dietrich Featherston</span></li>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</ul>
</div>
<div class="overflow msgActions margintopdouble">
<div class="msgReply" >
<h2>
					Reply via email to
</h2>
<form method="POST" action="/mailto.php">
<input type="hidden" name="subject" value="Re: avg write io wait time regression in 1.2.1">
<input type="hidden" name="msgid" value="CAHQXTbHbDY+7WXdUB+8LZYYN37zTHifsLpUXfZoDQ0JDP9Dbhg@mail.gmail.com">
<input type="hidden" name="relpath" value="riak-users@lists.basho.com/msg09215.html">
<input type="submit" value=" Dietrich Featherston ">
</form>
</div>
</div>
</div>
<div class="aside" role="complementary">
<div class="logo">
<a href="/"><img src="/logo.png" width=247 height=88 alt="The Mail Archive"></a>
</div>
<form class="overflow" action="/search" method="get">
<input type="hidden" name="l" value="riak-users@lists.basho.com">
<label class="hidden" for="q">Search the site</label>
<input class="submittext" type="text" id="q" name="q" placeholder="Search riak-users">
<input class="submitbutton" name="submit" type="image" src="/submit.png" alt="Submit">
</form>
<div class="nav margintop" id="nav" role="navigation">
<ul class="icons font16">
<li class="icons-home"><a href="/">The Mail Archive home</a></li>
<li class="icons-list"><a href="/riak-users@lists.basho.com/">riak-users - all messages</a></li>
<li class="icons-about"><a href="/riak-users@lists.basho.com/info.html">riak-users - about the list</a></li>
<li class="icons-expand"><a href="/search?l=riak-users@lists.basho.com&amp;q=subject:%22Re%5C%3A+avg+write+io+wait+time+regression+in+1.2.1%22&amp;o=newest&amp;f=1" title="e" id="e">Expand</a></li>
<li class="icons-prev"><a href="msg09212.html" title="p">Previous message</a></li>
<li class="icons-next"><a href="msg09213.html" title="n">Next message</a></li>
</ul>
</div>
<div class="listlogo margintopdouble">

</div>
<div class="margintopdouble">

</div>
</div>
</div>
<div class="footer" role="contentinfo">
<ul>
<li><a href="/">The Mail Archive home</a></li>
<li><a href="/faq.html#newlist">Add your mailing list</a></li>
<li><a href="/faq.html">FAQ</a></li>
<li><a href="/faq.html#support">Support</a></li>
<li><a href="/faq.html#privacy">Privacy</a></li>
<li class="darkgray">CAHQXTbHbDY+7WXdUB+8LZYYN37zTHifsLpUXfZoDQ0JDP9Dbhg@mail.gmail.com</li>
</ul>
</div>
</body>
</html>
