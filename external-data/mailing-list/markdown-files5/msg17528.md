---
title: "Re: Recovering Riak data if it can no longer load in memory"
description: ""
project: community
lastmod: 2016-07-12T13:21:33-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg17528"
mailinglist_parent_id: "msg17527"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2016-07-12T13:21:33-07:00
---


You can further reduce memory used by leveldb with the following setting in 
riak.conf:

 leveldb.threads = 5

The value "5" needs to be a prime number. The system defaults to 71. Many 
Linux implementations will allocate 8Mbytes per thread for stack. So bunches 
of threads lead to bunches of memory reserved for stack. That is fine on 
servers with higher memory. But probably part of your problem on a small 
memory machine.

The thread count is high to promote parallelism across vnodes on the same 
server, especially with "entropy = active". So again, this setting is 
sacrificing performance to save memory.

Matthew

P.S. You really want 8 CPU cores, 4 as a dirt minimum. And review this for 
more cpu performance info:

 https://github.com/basho/leveldb/wiki/riak-tuning-2



&gt; On Jul 12, 2016, at 4:04 PM, Vikram Lalit  wrote:
&gt; 
&gt; Thanks much Matthew. Yes the server is low-memory given only development 
&gt; right now - I'm using an AWS micro instance, so 1 GB RAM and 1 vCPU.
&gt; 
&gt; Thanks for the tip - let me try move the manifest file to a larger instance 
&gt; and see how that works. More than reducing the memory footprint in dev, my 
&gt; concern was more around reacting to a possible production scenario where the 
&gt; db stops responding due to memory overload. Understood now that moving to a 
&gt; larger instance should be possible. Thanks again.
&gt; 
&gt; On Tue, Jul 12, 2016 at 12:26 PM, Matthew Von-Maszewski  &gt; wrote:
&gt; It would be helpful if you described the physical characteristics of the 
&gt; servers: memory size, logical cpu count, etc.
&gt; 
&gt; Google created leveldb to be highly reliable in the face of crashes. If it 
&gt; is not restarting, that suggests to me that you have a low memory condition 
&gt; that is not able to load leveldb's MANIFEST file. That is easily fixed by 
&gt; moving the dataset to a machine with larger memory.
&gt; 
&gt; There is also a special flag to reduce Riak's leveldb memory foot print 
&gt; during development work. The setting reduces the leveldb performance, but 
&gt; lets you run with less memory.
&gt; 
&gt; In riak.conf, set:
&gt; 
&gt; leveldb.limited\\_developer\\_mem = true
&gt; 
&gt; Matthew
&gt; 
&gt; 
&gt; &gt; On Jul 12, 2016, at 11:56 AM, Vikram Lalit  &gt; &gt; wrote:
&gt; &gt;
&gt; &gt; Hi - I've been testing a Riak cluster (of 3 nodes) with an ejabberd 
&gt; &gt; messaging cluster in front of it that writes data to the Riak nodes. Whilst 
&gt; &gt; load testing the platform (by creating 0.5 million ejabberd users via 
&gt; &gt; Tsung), I found that the Riak nodes suddenly crashed. My question is how do 
&gt; &gt; we recover from such a situation if it were to occur in production?
&gt; &gt;
&gt; &gt; To provide further context / details, the leveldb log files storing the 
&gt; &gt; data suddenly became too huge, thus making the AWS Riak instances not able 
&gt; &gt; to load them in memory anymore. So we get a core dump if 'riak start' is 
&gt; &gt; fired on those instances. I had an n\\_val = 2, and all 3 nodes went down 
&gt; &gt; almost simultaneously, so in such a scenario, we cannot even rely on a 2nd 
&gt; &gt; copy of the data. One way to of course prevent it in the first place would 
&gt; &gt; be to use auto-scaling, but I'm wondering is there a ex post facto / post 
&gt; &gt; the event recovery that can be performed in such a scenario? Is it possible 
&gt; &gt; to simply copy the leveldb data to a larger memory instance, or to curtail 
&gt; &gt; the data further to allow loading in the same instance?
&gt; &gt;
&gt; &gt; Appreciate if you can provide inputs - a tad concerned as to how we could 
&gt; &gt; recover from such a situation if it were to happen in production (apart 
&gt; &gt; from leveraging auto-scaling as a preventive measure).
&gt; &gt;
&gt; &gt; Thanks!
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com 
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com 
&gt; &gt; 
&gt; 
&gt; 

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

