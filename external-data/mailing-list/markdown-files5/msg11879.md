---
title: "Re: memory consumption"
description: ""
project: community
lastmod: 2013-08-03T17:41:27-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11879"
mailinglist_parent_id: "msg11867"
author_name: "Evan Vigil-McClanahan"
project_section: "mailinglistitem"
sent_date: 2013-08-03T17:41:27-07:00
---


Some responses inline.

On Fri, Aug 2, 2013 at 3:11 AM, Alexander Ilyin  wrote:
&gt; Hi,
&gt;
&gt; I have a few questions about Riak memory usage.
&gt; We're using Riak 1.3.1 on a 3 node cluster. According to bitcask capacity
&gt; calculator
&gt; (http://docs.basho.com/riak/1.3.1/references/appendices/Bitcask-Capacity-Planning/)
&gt; Riak should use about 30Gb of RAM for out data. Actually, it uses about 45Gb
&gt; and I can't figure out why. I'm looking at %MEM column in top on each node
&gt; for a beam.smp process.

I've recently done some research on this and have filed bugs against
the calculator, it's a bit wrong and has been that way for a while:

https://github.com/basho/basho\\_docs/issues/467

The numbers there look a bit closer to what you're seeing.

The good news is that I am looking into reducing memory consumption
this development cycle and our next release should see some
improvements on that front. The bad news is that it may be a while.
If you want to watch the bitcask repo on github to see when these
changes go in, it's usually pretty easy to build a new bitcask and
replace the one that you're running.

&gt; Disk usage is also about 1,5 times more than I have expected (270Gb instead
&gt; of 180Gb). I rechecked that I have n\\_val=2 (not 3), it seems alright. Why
&gt; this could happen?

There is definitely some overhead on the stored values, especially
when you're using bitcask. How big are your values? Overheads, if I
recall correctly, run to a few hundred bytes, but I'll have to ask
some people to refresh my memory.

&gt; Second question is about performance degradation when Riak uses almost all
&gt; available memory on the node. We see that 95/99 put percentiles twice as
&gt; large for nodes which don't have much free RAM. How much free memory I
&gt; should have to keep performance high?

I don't have a good answer for this; when I was working as a CSE we
generally urged people to start adding nodes when their most limited
resource (memory, disk, cpu, etc) was 70-80% utilized (as a grossly
oversimplified rule of thumb).

&gt; And the last question about memory\\_total metric. riak-admin status returns
&gt; value which is less than actual memory consumption as seen in the top.
&gt; According to memory\\_total description
&gt; (http://docs.basho.com/riak/1.3.1/references/appendices/Inspecting-a-Node/)
&gt; they should be equal. Why they are not?

Top factors in OS/libc overheads that memory\\_total cannot see. I'll
check out the docs and get them amended if they're wrong.

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

