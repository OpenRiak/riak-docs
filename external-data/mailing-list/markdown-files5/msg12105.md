---
title: "Re: Riak Memory Bloat issues with RiakCS/BitCask"
description: ""
project: community
lastmod: 2013-08-20T17:42:40-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12105"
mailinglist_parent_id: "msg12100"
author_name: "Evan Vigil-McClanahan"
project_section: "mailinglistitem"
sent_date: 2013-08-20T17:42:40-07:00
---


IIRC cs stores ~3x1mb entries for each 1mb of object that you store at
default n\\_val. so, 300k \\* 3 \\* 9 = 810k, \\* 150b (to be conservative) = 1.1
GB. There will be some other static and per-entry overheads, but you
should be able to do better than that before you OOM, even on a 1 node
system.

Might be best to start again with all of the default files before you
started tuning and retry, there may be a subtle error in your configs
that's causing an issue.


On Tue, Aug 20, 2013 at 4:31 PM, Idan Shinberg wrote:

&gt; Thank you all for you kind and quick answers
&gt;
&gt; However , even on a 3 node or 5 node cluster
&gt; We're still seeing memory bloat ( only much notably slower , as load is
&gt; distributed between more machines )
&gt;
&gt; it's important to stress , this is an "read-append" only cluster - This
&gt; means the data never expires , and from the moment the cluster is
&gt; up , we keep adding data in the form of S3 puts ( of around 9MB objects )
&gt; , until we reach around 300K PUTS
&gt;
&gt; This is also why merges don't happen ( no stale data )
&gt;
&gt; Has anyone come across this situation in the past ?
&gt; does Riak even fit for something like this ?
&gt;
&gt;
&gt; Regards,
&gt;
&gt; Idan Shinberg
&gt;
&gt;
&gt; System Architect
&gt;
&gt; Idomoo Ltd.
&gt;
&gt;
&gt;
&gt; Mob +972.54.562.2072
&gt;
&gt; email idan.shinb...@idomoo.com
&gt;
&gt; web www.idomoo.com
&gt;
&gt; [image: Description: cid:FC66336E-E750-4C2D-B6E3-985D5A06B5BE@idomoo.co.il]
&gt;
&gt;
&gt; On Tue, Aug 20, 2013 at 11:32 AM, Erik Søe Sørensen wrote:
&gt;
&gt;&gt; Your max file size is (far!) less than your small file size threshold -
&gt;&gt; which means that at each merge, \\*all\\* of the files will participate in the
&gt;&gt; merge. No wonder you need a lot of simultaneously open files... and long
&gt;&gt; merge times too, of course.
&gt;&gt; Try changing these parameters.
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; -------- Oprindelig meddelelse --------
&gt;&gt; Fra: Idan Shinberg 
&gt;&gt; Dato:
&gt;&gt; Til: riak-users 
&gt;&gt; Cc: Arik Katsav ,Assaf Fogel 
&gt;&gt; Emne: Riak Memory Bloat issues with RiakCS/BitCask
&gt;&gt;
&gt;&gt;
&gt;&gt; Hi all
&gt;&gt;
&gt;&gt; We have a ~300GB Riak Single Node Cluster
&gt;&gt; This seems to have worked fine ( merging worked good ) until an
&gt;&gt; OpenFile/OpenPorts limit was reached ( since then , we've tweaked both to
&gt;&gt; 64K )
&gt;&gt; The above error caused a crash that left corrupted hint files .We've
&gt;&gt; deleted the hint ( and their corrosponding the data files ) to allow a
&gt;&gt; clean start to riak ( no errors upon start) .
&gt;&gt;
&gt;&gt; However , merges have not been really working ( taking forever to
&gt;&gt; complete ) since then , therefor causing :
&gt;&gt;
&gt;&gt; \\* Huge Bloat on disk ( Data is around 150K objects of roughly 8MB each
&gt;&gt; , but has already more then quadrupled in size the riak storage used (
&gt;&gt; around 1.2 TB )
&gt;&gt; \\* Huge Bloat in memory , which eventually kills riak itself ( OOM
&gt;&gt; killer )
&gt;&gt;
&gt;&gt; We're not doing anything complex , just using riak and riak-cs to emulate
&gt;&gt; S3 access ( and only it ) for roughly 15 client writes per minute.
&gt;&gt;
&gt;&gt; Our merge settings ( uber-low , but have worked correctly in the up till
&gt;&gt; a few days ago ) :
&gt;&gt;
&gt;&gt; {riak\\_kv, [
&gt;&gt; %% Storage\\_backend specifies the Erlang module defining the
&gt;&gt; storage
&gt;&gt; %% mechanism that will be used on this node.
&gt;&gt; {add\\_paths,
&gt;&gt; ["/usr/lib64/riak-cs/lib/riak\\_cs-1.3.1/ebin"]},
&gt;&gt; {storage\\_backend, riak\\_cs\\_kv\\_multi\\_backend},
&gt;&gt; {multi\\_backend\\_prefix\\_list, [{&lt;&lt;"0b:"&gt;&gt;, be\\_blocks}]},
&gt;&gt; {multi\\_backend\\_default, be\\_default},
&gt;&gt; {multi\\_backend, [
&gt;&gt; {be\\_default, riak\\_kv\\_eleveldb\\_backend, [
&gt;&gt; {max\\_open\\_files, 50},
&gt;&gt; {data\\_root, "/var/lib/riak/leveldb"}
&gt;&gt; ]},
&gt;&gt; {be\\_blocks, riak\\_kv\\_bitcask\\_backend, [
&gt;&gt;
&gt;&gt; {max\\_file\\_size, 16#2000000}, %% 32MB
&gt;&gt;
&gt;&gt; %% Trigger a merge if any of the following are
&gt;&gt; true:
&gt;&gt; {frag\\_merge\\_trigger, 10}, %% fragmentation &gt;= 10%
&gt;&gt; {dead\\_bytes\\_merge\\_trigger, 8388608}, %% dead
&gt;&gt; bytes &gt; 8 MB
&gt;&gt;
&gt;&gt; %% Conditions that determine if a file will be
&gt;&gt; examined during a merge:
&gt;&gt; {frag\\_threshold, 5}, %% fragmentation &gt;= 5%
&gt;&gt; {dead\\_bytes\\_threshold, 2097152}, %% dead bytes &gt;
&gt;&gt; 2 MB
&gt;&gt; {small\\_file\\_threshold, 16#80000000}, %% file is &lt;
&gt;&gt; 2GB
&gt;&gt;
&gt;&gt; {data\\_root, "/var/lib/riak/bitcask"},
&gt;&gt; {log\\_needs\\_merge, true}
&gt;&gt;
&gt;&gt;
&gt;&gt; ]}
&gt;&gt; ]},
&gt;&gt;
&gt;&gt; As you've noticed , log\\_needs\\_merge is set to true and we do get our logs
&gt;&gt; filled with needs\\_merge messages such as this one :
&gt;&gt;
&gt;&gt; ,{"/var/l...",...},...]
&gt;&gt; 2013-08-19 00:09:49.043 [info] &lt;0.17972.0&gt;
&gt;&gt; "/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728"
&gt;&gt; needs\\_merge:
&gt;&gt; [{"/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/1153.bitcask.data",[{small\\_file,20506434}]},{"/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/1152.bitcask.data",[{small\\_file,33393237}]},{"/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/1151.bitcask.data",[{small\\_file,33123254}]},{"/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/1150.bitcask.data",[{small\\_file,32505520}]},{"/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/1149.
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt;
&gt;&gt; Yet a merge Only a single merge happened ( and only after around 20
&gt;&gt; minutes since we started putting pressure on the riak) :
&gt;&gt;
&gt;&gt; 2013-08-19 00:17:29.456 [info] &lt;0.18964.14&gt; Merged
&gt;&gt; {["/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/712.bitcask.data","/var/lib/riak/
&gt;&gt;
&gt;&gt; bitcask/388211372416021087647853783690262677096107081728/711.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/710.bitcask
&gt;&gt;
&gt;&gt; .data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/709.bitcask.data","/var/lib/riak/bitcask/38821137241602108764785378369026267709
&gt;&gt;
&gt;&gt; 6107081728/708.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/707.bitcask.data","/var/lib/riak/bitcask/388211
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt; var/lib/riak/bitc
&gt;&gt;
&gt;&gt; ask/388211372416021087647853783690262677096107081728/697.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/696.bitcask.dat
&gt;&gt;
&gt;&gt; a","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/695.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107
&gt;&gt;
&gt;&gt; 081728/694.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/693.bitcask.data","/var/lib/riak/bitcask/38821137241602108764
&gt;&gt;
&gt;&gt; 7853783690262677096107081728/692.bitcask.data","/var/lib/riak/bitcask/388211372416021087647853783690262677096107081728/691.bitcask.data","/var/lib/riak/bitcas
&gt;&gt; k/38821137241602108...",...],...} in 1325.611982 seconds.
&gt;&gt;
&gt;&gt; Is it reasonable for a merge to take more then 20 minutes ?
&gt;&gt; Especially assuming riak's memory usage is bloating much faster ?
&gt;&gt; Will Scaling the cluster from a single node to a 3-node cluster ease the
&gt;&gt; problem ?
&gt;&gt;
&gt;&gt; As for the server and usage specs
&gt;&gt;
&gt;&gt; - Virtual machine having around 8 virtual cores
&gt;&gt; - 12 GB of RAM
&gt;&gt; - 8 TB of Storage composed of 4 x 2TB disks in Raid 10 ( 4TB available
&gt;&gt; storage )
&gt;&gt; - ~150 keys several 10s of bytes long ( using Riak-CS for s3 storage ) .
&gt;&gt; - ~8MB value size for each key ( raw file )
&gt;&gt; - ~22000 Open files ( mostly hint files ) by riak
&gt;&gt; - Replication factor of 1
&gt;&gt; - Ring size is 64
&gt;&gt;
&gt;&gt; I'll provide the logs if needed , yet I doubt they'll prove useful .
&gt;&gt;
&gt;&gt; Any ideas/advice will be appreciated
&gt;&gt;
&gt;&gt;
&gt;&gt; Regards,
&gt;&gt;
&gt;&gt; Idan Shinberg
&gt;&gt;
&gt;&gt;
&gt;&gt; System Architect
&gt;&gt;
&gt;&gt; Idomoo Ltd.
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; Mob +972.54.562.2072
&gt;&gt;
&gt;&gt; email idan.shinb...@idomoo.com
&gt;&gt;
&gt;&gt; web www.idomoo.com
&gt;&gt;
&gt;&gt; [cid:image001.jpg@01CE98F3.21F78EB0]
&gt;&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&lt;&gt;\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

