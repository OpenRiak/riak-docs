---
title: "Re: Comparing Riak MapReduce and Hadoop MapReduce"
description: ""
project: community
lastmod: 2013-07-21T22:33:06-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11674"
mailinglist_parent_id: "msg11673"
author_name: "Jeremiah Peschka"
project_section: "mailinglistitem"
sent_date: 2013-07-21T22:33:06-07:00
---


Ah, yeah, I'm mistaken about search partitioning. The docs are correct.

I have no idea how the scheduling works.

If I had to guess, I would guess that it is a streaming operation.

--
Jeremiah Peschka - Founder, Brent Ozar Unlimited
MCITP: SQL Server 2008, MVP
Cloudera Certified Developer for Apache Hadoop

On Jul 21, 2013, at 10:08 PM, Xiaoming Gao  wrote:

&gt; Thanks a lot, Jeremiah! Your answers really help clarify the issues. 
&gt; 
&gt; Just one more question, by "document-based indices", do you mean 
&gt; document-based partitioning for the indices? Because what I found in the 
&gt; online document 
&gt; http://docs.basho.com/riak/latest/dev/advanced/search/#Search-KV-and-MapReduce
&gt; is "Search uses term-based partitioning â€“ also known as a global index." I 
&gt; am not sure if the implementation has changed for the latest version of Riak, 
&gt; but if term-based partitioning is used, does that mean Riak will only 
&gt; schedule the mappers after the whole list of  pair is returned 
&gt; from the index?
&gt; 
&gt; Thanks,
&gt; Xiaoming
&gt; 
&gt; 
&gt; On Sun, Jul 21, 2013 at 11:20 PM, Jeremiah Peschka [via Riak Users] &lt;[hidden 
&gt; email]&gt; wrote:
&gt;&gt; Responses inline. Hopefully they shed some light on the subject.
&gt;&gt; 
&gt;&gt; ---
&gt;&gt; Jeremiah Peschka - Founder, Brent Ozar Unlimited
&gt;&gt; MCITP: SQL Server 2008, MVP
&gt;&gt; Cloudera Certified Developer for Apache Hadoop
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Fri, Jul 19, 2013 at 5:07 PM, Xiaoming Gao &lt;[hidden email]&gt; wrote:
&gt;&gt;&gt; Hi everyone,
&gt;&gt;&gt; 
&gt;&gt;&gt; I am trying to learn about Riak MapReduce and comparing it with Hadoop
&gt;&gt;&gt; MapReduce, and there are some details that I am interested in but not
&gt;&gt;&gt; covered in the online documents. So hopefully we can get some help here
&gt;&gt;&gt; about the following questions? Thanks in advance!
&gt;&gt; 
&gt;&gt; They're not at all similar. Hadoop MR is optimized for sequential data 
&gt;&gt; processing in large batches. Riak MR works better when you think of it like 
&gt;&gt; a multi-processing engine - you can perform work across a matching set of 
&gt;&gt; items and that work will be distributed across the cluster during map 
&gt;&gt; phases. 
&gt;&gt; 
&gt;&gt; Take a look at this thread for a bit of discussion about when you should use 
&gt;&gt; Riak MapReduce: http://markmail.org/message/qpoilvmm635inb5v
&gt;&gt; 
&gt;&gt; Or, if you want to, you can run a Riak MR job across an entire bucket, which 
&gt;&gt; really is like scanning every table in an RDBMS while looking for rows from 
&gt;&gt; a single table. MR jobs run with an R of 1. So, at least there's that.
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 1. For a given MapReduce request (or to say, job), how does Riak decide how
&gt;&gt;&gt; many mappers to use for the job? For example, if I have 8 nodes and my data
&gt;&gt;&gt; are distributed across all nodes with an "N" value of 2, will I have 4
&gt;&gt;&gt; mappers running on 4 nodes concurrently? Is it possible to have multiple
&gt;&gt;&gt; mappers (e.g., 4 or even 6) for the same MR job running on each node (for
&gt;&gt;&gt; better processing speed)?
&gt;&gt; 
&gt;&gt; To the best of my recollection, this will be based on either:
&gt;&gt; 
&gt;&gt; 1) If you're using JavaScript MR jobs, the number of mappers and reducers is 
&gt;&gt; controlled by the the map\\_js\\_vm\\_count and reduce\\_js\\_vm\\_count settings from 
&gt;&gt; each node's app.config file.
&gt;&gt; 2) If you're using Erlang: magic. This will be handled by the Erlang VM and 
&gt;&gt; is based on number of processors and your overall Erlang VM configuration.
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 2. If I run a MapReduce job over the results of a Riak Search query, how
&gt;&gt;&gt; does Riak schedule the mappers based on the search results?
&gt;&gt; 
&gt;&gt; Riak Search uses document-based indices - search will query every node in 
&gt;&gt; the cluster. Map phases happen and then results are then streamed to the 
&gt;&gt; reducer.
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 3. How does Riak handle intermediate data generated by mappers?
&gt;&gt;&gt; Specifically:
&gt;&gt;&gt; (1) In Hadoop MapReduce, the output of mappers are  pairs, and
&gt;&gt;&gt; the output from all mappers are first grouped based on keys, and then handed
&gt;&gt;&gt; over to the reducer. Does Riak do similar grouping of intermediate data?
&gt;&gt; 
&gt;&gt; The only reason for the intermediate grouping/scratch work in Hadoop MR jobs 
&gt;&gt; is to deal with multiple reducers. Although, I'm not entirely sure how this 
&gt;&gt; works in Riak, my suspicion is that data is streamed across the wire after 
&gt;&gt; the data is read from disk. 
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; (2) How are mapper outputs transmitted to the reducer? Does Riak use local
&gt;&gt;&gt; disks on the mapper nodes or reducer nodes to store the intermediate data
&gt;&gt;&gt; temporarily?
&gt;&gt; 
&gt;&gt; Since large MR jobs can cause out of memory errors, you can bet good money 
&gt;&gt; that the answer is "no".
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 4. According to the document
&gt;&gt;&gt; http://docs.basho.com/riak/latest/dev/advanced/mapreduce/#How-Phases-Work ,
&gt;&gt;&gt; each MR job only schedules one reducer, which runs on the coordinate node.
&gt;&gt;&gt; Is there any way to configure a MR job to use multiple reducers?
&gt;&gt; 
&gt;&gt; Using Riak MR, there's no way to create a job that runs reducers on multiple 
&gt;&gt; nodes. You can have multiple reducer processes on a single node, but not 
&gt;&gt; reducers on multiple nodes.
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; Best regards,
&gt;&gt;&gt; Xiaoming
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; --
&gt;&gt;&gt; View this message in context: 
&gt;&gt;&gt; http://riak-users.197444.n3.nabble.com/Comparing-Riak-MapReduce-and-Hadoop-MapReduce-tp4028454.html
&gt;&gt;&gt; Sent from the Riak Users mailing list archive at Nabble.com.
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; [hidden email]
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; 
&gt;&gt; 
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ 
&gt;&gt; riak-users mailing list 
&gt;&gt; [hidden email] 
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; 
&gt;&gt; 
&gt;&gt; If you reply to this email, your message will be added to the discussion 
&gt;&gt; below:
&gt;&gt; http://riak-users.197444.n3.nabble.com/Comparing-Riak-MapReduce-and-Hadoop-MapReduce-tp4028454p4028474.html
&gt;&gt; To unsubscribe from Comparing Riak MapReduce and Hadoop MapReduce, click 
&gt;&gt; here.
&gt;&gt; NAML
&gt; 
&gt; 
&gt; View this message in context: Re: Comparing Riak MapReduce and Hadoop 
&gt; MapReduce
&gt; Sent from the Riak Users mailing list archive at Nabble.com.
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

