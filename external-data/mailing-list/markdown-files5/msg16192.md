---
title: "Re: Recommended way to delete keys"
description: ""
project: community
lastmod: 2015-06-03T12:55:01-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16192"
mailinglist_parent_id: "msg16188"
author_name: "Peter Herndon"
project_section: "mailinglistitem"
sent_date: 2015-06-03T12:55:01-07:00
---


Interesting thought. It might work for us, it might not, I’ll have to check 
with our CTO to see whether the expense makes sense under our circumstances.

Thanks!

—Peter
&gt; On Jun 3, 2015, at 2:21 PM, Drew Kerrigan  wrote:
&gt; 
&gt; Another idea for a large-scale one-time removal of data, as well as an 
&gt; opportunity for a fresh start, would be to:
&gt; 
&gt; 1. set up multi-data center replication between 2 clusters
&gt; 2. implement a recv/2 hook on the sink which refuses data from the buckets / 
&gt; keys you would like to ignore / delete
&gt; 3. trigger a full sync replication
&gt; 4. start using the sync as your new source of data sans the ignored data
&gt; 
&gt; Obviously this is costly, but it should have a fairly minimal impact to 
&gt; existing production users other than the moment that you switch traffic from 
&gt; the old cluster to the new one.
&gt; 
&gt; Caveats: Not all Riak features are supported with MDC (search indexes and 
&gt; strong consistency in particular).
&gt; 
&gt; On Wed, Jun 3, 2015 at 2:11 PM Peter Herndon  wrote:
&gt; Sadly, this is a production cluster already using leveldb as the backend. 
&gt; With that constraint in mind, and rebuilding the cluster not really being an 
&gt; option to enable multi-backends or bitcask, what would our best approach be?
&gt; 
&gt; Thanks!
&gt; 
&gt; —Peter
&gt; 
&gt; &gt; On Jun 3, 2015, at 12:09 PM, Alexander Sicular  wrote:
&gt; &gt;
&gt; &gt; We are actively investigating better options for deletion of large amounts 
&gt; &gt; of keys. As Sargun mentioned, deleting the data dir for an entire backend 
&gt; &gt; via an operationalized rolling restart is probably the best approach right 
&gt; &gt; now for killing large amounts of keys.
&gt; &gt;
&gt; &gt; But if your key space can fit in memory the best way to kill keys is to use 
&gt; &gt; bitcask ttl if that's an option. 1. If you can even use bitcask in your 
&gt; &gt; environment due to the memory overhead and 2. If your use case allows for 
&gt; &gt; ttls which it may considering you may already be using time bound 
&gt; &gt; buckets....
&gt; &gt;
&gt; &gt; -Alexander
&gt; &gt;
&gt; &gt; @siculars
&gt; &gt; http://siculars.posthaven.com
&gt; &gt;
&gt; &gt; Sent from my iRotaryPhone
&gt; &gt;
&gt; &gt; On Jun 3, 2015, at 09:54, Sargun Dhillon  wrote:
&gt; &gt;
&gt; &gt;&gt; You could map your keys to a given bucket, and that bucket to a given 
&gt; &gt;&gt; backend using multi\\_backend. There is some cost to having lots of backends 
&gt; &gt;&gt; (memory overhead, FDs, etc...). When you want to do a mass drop, you could 
&gt; &gt;&gt; down the node, and delete that given backend, and bring it up. Caveat: 
&gt; &gt;&gt; AAE, MDC, nor mutable data play well with this scenario.
&gt; &gt;&gt;
&gt; &gt;&gt; On Wed, Jun 3, 2015 at 10:43 AM, Peter Herndon  wrote:
&gt; &gt;&gt; Hi list,
&gt; &gt;&gt;
&gt; &gt;&gt; We’re looking for the best way to handle large scale expiration of 
&gt; &gt;&gt; no-longer-useful data stored in Riak. We asked a while back, and the 
&gt; &gt;&gt; recommendation was to store the data in time-segmented buckets (bucket per 
&gt; &gt;&gt; day or per month), query on the current buckets, and use the streaming 
&gt; &gt;&gt; list keys API to handle slowly deleting the buckets that have aged out.
&gt; &gt;&gt;
&gt; &gt;&gt; Is that still the best approach for doing this kind of task? Or is there a 
&gt; &gt;&gt; better approach?
&gt; &gt;&gt;
&gt; &gt;&gt; Thanks!
&gt; &gt;&gt;
&gt; &gt;&gt; —Peter Herndon
&gt; &gt;&gt; Sr. Application Engineer
&gt; &gt;&gt; @Bitly
&gt; &gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt;&gt; riak-users mailing list
&gt; &gt;&gt; riak-users@lists.basho.com
&gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; &gt;&gt;
&gt; &gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt;&gt; riak-users mailing list
&gt; &gt;&gt; riak-users@lists.basho.com
&gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
&gt; 
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

