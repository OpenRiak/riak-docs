---
title: "Re: vm.args change for 15% to 80% improvement in leveldb"
description: ""
project: community
lastmod: 2013-08-14T06:56:58-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12022"
mailinglist_parent_id: "msg12021"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-08-14T06:56:58-07:00
---


We are not yet tuning specifically for NUMA. This recent testing had both NUMA 
and nonNUMA. 

I count 64 logical cores in your example, so +S 32:32. 



On Aug 14, 2013, at 9:31 AM, Jeremiah Peschka  
wrote:

&gt; Final question - does NUMA matter?
&gt; 
&gt; e.g. quad socket system with 8 cores per socket + HT 
&gt; 
&gt; should it be +S 8:8 or +S 32:32 ?
&gt; 
&gt; ---
&gt; Jeremiah Peschka - Founder, Brent Ozar Unlimited
&gt; MCITP: SQL Server 2008, MVP
&gt; Cloudera Certified Developer for Apache Hadoop
&gt; 
&gt; 
&gt; On Wed, Aug 14, 2013 at 4:14 AM, Matthew Von-Maszewski  
&gt; wrote:
&gt;&gt; Yes, use logical CPU count.
&gt;&gt; 
&gt;&gt; Matthew
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Aug 13, 2013, at 23:17, Jeremiah Peschka  
&gt;&gt; wrote:
&gt;&gt; 
&gt;&gt;&gt; When you say "CPU" does that mean "logical CPU core"? Or is this actually 
&gt;&gt;&gt; referring to physical CPU cores?
&gt;&gt;&gt; 
&gt;&gt;&gt; E.g. On my laptop with 4 physical cores + HyperThreading, should I set +S 
&gt;&gt;&gt; to +S 4:4
&gt;&gt;&gt; 
&gt;&gt;&gt; You hint that it doesn't matter, but I just wanted to trick you into 
&gt;&gt;&gt; explicitly saying something.
&gt;&gt;&gt; 
&gt;&gt;&gt; ---
&gt;&gt;&gt; Jeremiah Peschka - Founder, Brent Ozar Unlimited
&gt;&gt;&gt; MCITP: SQL Server 2008, MVP
&gt;&gt;&gt; Cloudera Certified Developer for Apache Hadoop
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On Tue, Aug 13, 2013 at 5:38 PM, Matthew Von-Maszewski  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;&gt; \\*\\* The following is copied from Basho's leveldb wiki page:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; https://github.com/basho/leveldb/wiki/Riak-tuning-1
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Summary:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; leveldb has a higher read and write throughput in Riak if the Erlang 
&gt;&gt;&gt;&gt; scheduler count is limited to half the number of CPU cores. Tests have 
&gt;&gt;&gt;&gt; demonstrated improvements of 15% to 80% greater throughput.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The scheduler limit is set in the vm.args file:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; +S x:x
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; where "x" is the number of schedulers Erlang may use. Erlang's default 
&gt;&gt;&gt;&gt; value of "x" is the total number of CPUs in the system. For Riak 
&gt;&gt;&gt;&gt; installations using leveldb, the recommendation is to set "x" to half the 
&gt;&gt;&gt;&gt; number of CPUs. Virtual environments are not yet tested.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Example: for 24 CPU system
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; +S 12:12
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Discussion:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; We have tested a limited number of CPU configurations and customer loads. 
&gt;&gt;&gt;&gt; In all cases, there is a performance increase when the +S option is added 
&gt;&gt;&gt;&gt; to the vm.args file to reduce the number of Erlang schedulers. The working 
&gt;&gt;&gt;&gt; hypothesis is that the Erlang schedulers perform enough "busy wait" work 
&gt;&gt;&gt;&gt; that they always create context switch away from leveldb when leveldb is 
&gt;&gt;&gt;&gt; actually the only system task with real work.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The tests included 8 CPU (no hyper threading, physical cores only) and 24 
&gt;&gt;&gt;&gt; CPU (12 physical cores with hyper threading) systems. All were 64bit Intel 
&gt;&gt;&gt;&gt; platforms. Generalized findings:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; • servers running higher number of vnodes (64) had larger 
&gt;&gt;&gt;&gt; performance gains than those with fewer (8)
&gt;&gt;&gt;&gt; • servers running SSD arrays had larger performance gains than 
&gt;&gt;&gt;&gt; those running SATA arrays
&gt;&gt;&gt;&gt; • Get and Write operations showed performance gains, 2i query 
&gt;&gt;&gt;&gt; operations (leveldb iterators) were unchanged
&gt;&gt;&gt;&gt; • Not recommended for servers with less than 8 CPUs (go no lower 
&gt;&gt;&gt;&gt; than +S 4:4)
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Performance improvements were as high as 80% over extended, heavily loaded 
&gt;&gt;&gt;&gt; intervals on servers with SSD arrays and 64 vnodes. No test resulted in 
&gt;&gt;&gt;&gt; worse performance due to the addition of +S x:x.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The +S x:x configuration change does not have to be implemented 
&gt;&gt;&gt;&gt; simultaneously to an entire Riak cluster. The change may be applied to a 
&gt;&gt;&gt;&gt; single server for verification. Steps: update the vm.args file, then 
&gt;&gt;&gt;&gt; restart the Riak node. Erlang command line changes to schedules were 
&gt;&gt;&gt;&gt; ineffective.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; This configuration change has been running in at least one large, 
&gt;&gt;&gt;&gt; multi-datacenter production environment for several months.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt; 
&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

