---
title: "Re: Riak cluster-f#$%"
description: ""
project: community
lastmod: 2012-10-01T13:30:12-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08771"
mailinglist_parent_id: "msg08770"
author_name: "Callixte Cauchois"
project_section: "mailinglistitem"
sent_date: 2012-10-01T13:30:12-07:00
---


Thank you, but can you explain a bit more?
I mean I understand why it is a bad thing with regards to reliability and
in case of hardware issues. But does it have also an impact on the
behaviour when the hardware is performing correctly and the load on the
machines are the same?

On Mon, Oct 1, 2012 at 1:25 PM, Alexander Sicular wrote:

&gt; Inline.
&gt;
&gt; -Alexander Sicular
&gt;
&gt; @siculars
&gt;
&gt; On Oct 1, 2012, at 3:23 PM, Callixte Cauchois wrote:
&gt;
&gt; &gt; Hi there,
&gt; &gt;
&gt; &gt; so, I am currently evaluating Riak to see how it can fit in our
&gt; platform. To do so I have set up a cluster of 4 nodes on SmartOS, all of
&gt; them on the same physical box.
&gt;
&gt; Mistake. Just stop here. Everything else doesn't matter. Do not put all
&gt; your virtual machines (riak nodes) on one physical machine. Put em on
&gt; different physical machines. Fix the config files and try again.
&gt;
&gt; &gt; I then built a simple application in node.js that get log events from
&gt; our production system through a RabbitMQ queue and store them in my
&gt; cluster. I let Riak generate the ids, but I have added two secondary
&gt; indices to be able to retrieve more easily all the log events that belong
&gt; to a single session.
&gt; &gt; Everything was going fine, events come around 130 messages per second
&gt; are easily ingested by Riak. When stop it and then restart it, there is a
&gt; bit of an issue as the events are read from the queue at 1500 messages per
&gt; second and the insertion times go up, so I need some retries to actually
&gt; store everything.
&gt; &gt; I wanted to tweak the LevelDB params to increase the throughput. To do
&gt; so, I first upgraded from 1.1.6 to 1.2.0. I chose what I thought was the
&gt; safest way: node by node, I have them leave the cluster, then I upgrade,
&gt; then join again. During the whole process I kept inserting.
&gt; &gt; It went quite well. But, when I ran some queries using 2i, it gave me
&gt; errors and I realized that for two of my four nodes, I forgot to put back
&gt; eLevelDB as the default engine. As soon as I ran this query, everything
&gt; went havoc, a lot of inserts failed, some nodes where not reachable using
&gt; the ping url.
&gt; &gt; I changed the default engine and restarted those nodes, nothing changed.
&gt; I tried to make them leave the cluster, after two days, they are still
&gt; leaving. Riak-admin transfers tells that a lot of transfers need to occur,
&gt; but the system is stuck: the numbers there do not change.
&gt; &gt;
&gt; &gt; I guess I have done several things wrong. It is test data, so it doesn't
&gt; really matter if I loose data or if I have to re-start from scratch, but I
&gt; want to understand what have gone wrong how I could have fixed it. Or if I
&gt; even can recover from there now.
&gt; &gt;
&gt; &gt; Thank you.
&gt; &gt; C.
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

