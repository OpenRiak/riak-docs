---
title: "Re: The power of the siblings...."
description: ""
project: community
lastmod: 2011-10-03T09:45:35-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04994"
mailinglist_parent_id: "msg04993"
author_name: "Jeremiah Peschka"
project_section: "mailinglistitem"
sent_date: 2011-10-03T09:45:35-07:00
---


Going along with the flushing option, would it be possible for you to write to 
an in memory bucket in Riak and then periodically flush to disk? RAM is going 
to be faster than an SSD ;) 
---
Jeremiah Peschka - Founder, Brent Ozar PLF, LLC
Microsoft SQL Server MVP

On Oct 3, 2011, at 9:11 AM, Ryan Zezeski wrote:

&gt; Mike,
&gt; 
&gt; I'd say you're going to be pushing the limits of Riak pretty hard given that 
&gt; fact that you're talking about 5k writes-pre-second on a \\_single\\_ key. I 
&gt; hope you listen to Artur Bergman and run SSDs in your data center, heh [1]. 
&gt; My first thought would be to batch those writes locally for a given period of 
&gt; time and then flush to Riak.
&gt; 
&gt; To your question, if you really have 5k/s then that's 300k siblings for one 
&gt; minute. Given that Riak uses lists for siblings underneath I highly doubt 
&gt; this will be feasible. Also, will there be many concurrent writers like 
&gt; this? I.e. many keys being rapidly updated?
&gt; 
&gt; -Ryan
&gt; 
&gt; [1]: http://www.youtube.com/watch?v=H7PJ1oeEyGg
&gt; 
&gt; On Mon, Sep 19, 2011 at 10:44 PM, Mike Oxford  wrote:
&gt; High performance updates to a single bucket/key space where ordering
&gt; isn't critical. Say, 5k TPS into a single bucket/key. Data is
&gt; written out such that it can be ordered later.
&gt; 
&gt; I'm aware of sharding/fragmenting/splitting and what not ... I'm
&gt; looking purely at intra-bucket performance. Yes, 5k is going to run
&gt; into a lot of contention; that's the point.
&gt; 
&gt; Options:
&gt; 1) Read old data, [NewData|Olddata] and write it back out, dealing
&gt; with siblings as they arise, -or-
&gt; 2) Go full sibling explosion (read: force it) and resolve the whole
&gt; thing at intervals, say, once per day, offline or on another system.
&gt; The logistics of this are doable in my case, so let's not worry about
&gt; them and just focus on raw TPS.
&gt; 
&gt; #1 has more round trips and still has siblings to deal with.
&gt; #2 takes up more space but you skip the pull/update/push in lieu of
&gt; "just push it, we'll deal with it later."
&gt; 
&gt; Thoughts from those in the know? How expensive, really, is forcing
&gt; the explosion? Has anyone done this (intentionally or not) and can
&gt; share what they ran into with real data sets?
&gt; 
&gt; Thanks!
&gt; 
&gt; -mox
&gt; 
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

