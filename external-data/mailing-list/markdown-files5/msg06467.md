---
title: "Re: Very (very) slow handoff, how to investigate?"
description: ""
project: community
lastmod: 2012-01-31T02:32:25-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06467"
mailinglist_parent_id: "msg06445"
author_name: "Gal Barnea"
project_section: "mailinglistitem"
sent_date: 2012-01-31T02:32:25-08:00
---


Guys
Thanks a lot for the helpful pointers

I decided to focus more on speeding the process of joining servers to the
cluster, where it is easier to monitor disk space during the handoff
("&gt;watch df -B M" and "dstat -dn -D") and deduct the actual handoff
progress (When partitions are big enough, there is very little indication
of their handoff progress in riak's logs)

Increasing the handoff\\_cuncurrency did indeed help push the handoff rate
much higher
Also, running on EC2 I was able to setup RAID0 on multiple ephemeral drives
which helped me reach rates of around 35-40 MB/s - practically the IO limit
set by amazon

Thanks guys!


On Fri, Jan 27, 2012 at 9:26 PM, Joseph Blomstedt  wrote:

&gt; Gal,
&gt;
&gt; 0.5 to 1 MB/s is indeed painfully slow.
&gt;
&gt; A few questions:
&gt; What backend are you running: bitcask,leveldb, etc?
&gt; Are you using the local ephemeral storage, or running off EBS?
&gt; Are you running any software RAID?
&gt; What filesystem are you running?
&gt; Which OS are you using?
&gt; Have you changed any of Riak's default settings?
&gt;
&gt; Also, any chance you could provide the output of "iostat -x" during
&gt; one of these long handoff sessions? Preferably on both the sending and
&gt; receiving nodes.
&gt;
&gt; The more information we have, the better we can try to help out here.
&gt;
&gt; Regards,
&gt; Joe
&gt;
&gt; On Fri, Jan 27, 2012 at 7:44 AM, Ian Plosker  wrote:
&gt; &gt; Gal,
&gt; &gt;
&gt; &gt; You could try using `riak attach` and running the following to increase
&gt; the
&gt; &gt; handoff\\_concurrency from 1 to 4:
&gt; &gt;
&gt; &gt; application:set\\_env(riak\\_core, handoff\\_concurrency, 4).
&gt; &gt;
&gt; &gt; You will need to do this on all nodes. This will only remain in effect as
&gt; &gt; long as the nodes remain running. If you wish to permanently increase the
&gt; &gt; handoff concurrency you will have to do so in the app.config.
&gt; &gt;
&gt; &gt; --
&gt; &gt; Ian Plosker 
&gt; &gt; Developer Advocate
&gt; &gt; Basho Technologies
&gt; &gt;
&gt; &gt; On Friday, January 27, 2012 at 7:45 AM, Gal Barnea wrote:
&gt; &gt;
&gt; &gt; Hi Ian
&gt; &gt;
&gt; &gt; Thanks for the informative answer, I am using 1.0.3 indeed.
&gt; &gt;
&gt; &gt; A day later, the cluster is making progress, but than I saw this in the
&gt; &gt; console.log:
&gt; &gt; 2012-01-27 08:51:32.643 [info]
&gt; &gt; &lt;0.30733.2881&gt;@riak\\_core\\_handoff\\_sender:start\\_fold:87 Handoff of
&gt; partition
&gt; &gt; riak\\_kv\\_vnode 50239118783249787813
&gt; &gt; 2516661246222288006726811648 from
&gt; &gt; 'r...@ec2-107-21-156-59.compute-1.amazonaws.com' to
&gt; &gt; 'r...@ec2-leaving.compute-1.amazonaws.com' completed: sent 5100479
&gt; objects
&gt; &gt; in 10596.49 seconds
&gt; &gt;
&gt; &gt; so we've dropped 50% in rate and are now less than 500 records/second !
&gt; &gt;
&gt; &gt; Frankly, I think this is problematic any way you look at it...If I need
&gt; to
&gt; &gt; wait days every time I manually remove a server from the cluster, it
&gt; isn't
&gt; &gt; really a valid solution from my perspective.
&gt; &gt;
&gt; &gt; Any thoughts?
&gt; &gt;
&gt; &gt; Regards
&gt; &gt; Gal
&gt; &gt;
&gt; &gt;
&gt; &gt; On Thu, Jan 26, 2012 at 11:35 PM, Ian Plosker  wrote:
&gt; &gt;
&gt; &gt; Gal,
&gt; &gt;
&gt; &gt; The limiting factor on EC2 will likely be IOPs (i.e. Disk throughput).
&gt; EC2
&gt; &gt; is a IOPs constrained environment, especially if you're using EBS.
&gt; Further,
&gt; &gt; doing a leave can induce a large number of ownership changes to ensure
&gt; that
&gt; &gt; preflists maintain the appropriate n\\_vals. The number of partitions that
&gt; &gt; need to be shuffled can exceed 80% of all partitions. In short, it can
&gt; take
&gt; &gt; a while for the rebalance to complete. Assuming you're using a &gt;=1.0
&gt; &gt; release, you're cluster should still correctly respond to all incoming
&gt; &gt; requests.
&gt; &gt;
&gt; &gt; Which version of Riak are you using? As of Riak 1.0.3,
&gt; &gt; `handoff\\_concurrency`, the number of outgoing handoffs per node, is set
&gt; to
&gt; &gt; 1. This will reduce the rate at which the rebalance occurs, but it
&gt; reduces
&gt; &gt; the impact of the rebalance on your cluster.
&gt; &gt;
&gt; &gt; --
&gt; &gt; Ian Plosker 
&gt; &gt; Developer Advocate
&gt; &gt; Basho Technologies, Inc.
&gt; &gt;
&gt; &gt; On Thursday, January 26, 2012 at 3:43 PM, Gal Barnea wrote:
&gt; &gt;
&gt; &gt; Ok, so now I can see in the "leaving" node logs:
&gt; &gt; 2012-01-26 19:18:23.015 [info]
&gt; &gt; &lt;0.32148.2873&gt;@riak\\_core\\_handoff\\_sender:start\\_fold:39 Starting handoff of
&gt; &gt; partition riak\\_kv\\_vnode 685078892498860742907977265335757665463718379520
&gt; &gt; from 'r...@ec2-leaving.compute-1.amazonaws.com' to
&gt; &gt; 'r...@ec2-othernode.compute-1.amazonaws.com'
&gt; &gt; 2012-01-26 19:24:17.798 [info] &lt;0.31620.2873&gt; alarm\\_handler:
&gt; &gt; {set,{system\\_memory\\_high\\_watermark,[]}}
&gt; &gt; 2012-01-26 20:23:28.991 [info]
&gt; &gt; &lt;0.32148.2873&gt;@riak\\_core\\_handoff\\_sender:start\\_fold:87 Handoff of
&gt; partition
&gt; &gt; riak\\_kv\\_vnode 685078892498860742907977265335757665463718379520 from
&gt; &gt; 'r...@leaving.compute-1.amazonaws.com' to
&gt; &gt; 'r...@ec2-othernode.compute-1.amazonaws.com' completed: sent 5110665
&gt; objects
&gt; &gt; in 3905.97 seconds
&gt; &gt;
&gt; &gt; so things \\*are\\* moving but at a rate of 1308 records per second.
&gt; &gt; This sounds very slow to me, accounting for the small record size, the
&gt; high
&gt; &gt; bw rate inside ec2 and practically 0% load on the servers
&gt; &gt;
&gt; &gt; any thoughts?
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; On Thu, Jan 26, 2012 at 10:12 PM, Gal Barnea 
&gt; wrote:
&gt; &gt;
&gt; &gt; Hi all
&gt; &gt;
&gt; &gt; I have a 6 server cluster running on ec2 (m1.large) - this is an
&gt; evaluation
&gt; &gt; environment, so practically no load besides the existing data
&gt; &gt; (~200 million records, ~1k each)
&gt; &gt;
&gt; &gt; after running "riak-admin leave" on one of the node, I noticed that for
&gt; more
&gt; &gt; than 3 hours
&gt; &gt; 1 - member\\_status showed that there is one "leaving" node and pending
&gt; data
&gt; &gt; to handoff on the rest but the numbers never changed
&gt; &gt; 2 - riak-admin transfers - showed handoffs waiting, but nothing changed
&gt; &gt;
&gt; &gt; at this point, I restarted the "leaving" node, so now the status is
&gt; &gt; 1 - member\\_status - still stuck with the same numbers
&gt; &gt; 2 - transfers - are slowly changing
&gt; &gt;
&gt; &gt; The leaving server's logs are showing that a single handoff started after
&gt; &gt; the restart,but nothing since (roughly an hour ago)
&gt; &gt;
&gt; &gt; Interestingly, the leaving server is pretty idle while the remaining
&gt; servers
&gt; &gt; are working hard at 50%-60% cpu
&gt; &gt;
&gt; &gt; so, the question now is where should I dig around to try and understand
&gt; &gt; what's going on. Any thoughts?
&gt; &gt;
&gt; &gt; Thanks
&gt; &gt; Gal
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; &gt;
&gt;
&gt;
&gt;
&gt; --
&gt; Joseph Blomstedt 
&gt; Software Engineer
&gt; Basho Technologies, Inc.
&gt; http://www.basho.com/
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

