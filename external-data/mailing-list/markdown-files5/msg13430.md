---
title: "Re: Performance Tuning in OmniOS"
description: ""
project: community
lastmod: 2014-01-21T10:03:11-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13430"
mailinglist_parent_id: "msg13427"
author_name: "Jared Morrow"
project_section: "mailinglistitem"
sent_date: 2014-01-21T10:03:11-08:00
---


What type of RAID did you chose for your spool of 5 volumes? If you chose
the default of raidz, you will not be getting much of a performance boost
over vanilla EBS, just a big integrity boost. Also, unless you are using
provisioned IOPS for EBS, you are starting from an extremely slow
base-case, so adding ZFS on top might not help matters much.

If speed is the concern, as a test I'm willing to bet if you do another
test run against the two instance storage disks on that m1.large, you will
probably beat those 5 EBS volumes pretty easily.

-Jared


On Tue, Jan 21, 2014 at 9:22 AM, Hari John Kuriakose wrote:

&gt; Hello,
&gt;
&gt; I am using standard EBS devices, with a zpool in an instance comprising of
&gt; five 40GB volumes.
&gt; Each of the Riak instance is of m1.large type.
&gt;
&gt; I have made the following changes in zfs properties:
&gt;
&gt; # My reason: the default sst block size for leveldb is 4k.
&gt; zfs set recordsize=4k tank/riak
&gt; # My reason: by default, leveldb verifies checksums automatically.
&gt; zfs set checksum=off tank/riak
&gt; zfs set atime=off tank/riak
&gt; zfs set snapdir=visible tank/riak
&gt;
&gt; And I did the following with help from Basho AWS tuning docs:
&gt;
&gt; projadd -c "riak" -K "process.max-file-descriptor=(basic,65536,deny)"
&gt; user.riak
&gt; bash -c "echo 'set rlim\\_fd\\_max=65536' &gt;&gt; /etc/system"
&gt; bash -c "echo 'set rlim\\_fd\\_cur=65536' &gt;&gt; /etc/system"
&gt; ndd -set /dev/tcp tcp\\_conn\\_req\\_max\\_q0 40000
&gt; ndd -set /dev/tcp tcp\\_conn\\_req\\_max\\_q 4000
&gt; ndd -set /dev/tcp tcp\\_tstamp\\_always 0
&gt; ndd -set /dev/tcp tcp\\_sack\\_permitted 2
&gt; ndd -set /dev/tcp tcp\\_wscale\\_always 1
&gt; ndd -set /dev/tcp tcp\\_time\\_wait\\_interval 60000
&gt; ndd -set /dev/tcp tcp\\_keepalive\\_interval 120000
&gt; ndd -set /dev/tcp tcp\\_xmit\\_hiwat 2097152
&gt; ndd -set /dev/tcp tcp\\_recv\\_hiwat 2097152
&gt; ndd -set /dev/tcp tcp\\_max\\_buf 8388608
&gt;
&gt; Thanks again.
&gt;
&gt;
&gt; On Tue, Jan 21, 2014 at 9:12 PM, Hector Castro  wrote:
&gt;
&gt;&gt; Hello,
&gt;&gt;
&gt;&gt; Can you please clarify what type of disk you are using within AWS?
&gt;&gt; EBS, EBS with PIOPS, instance storage? In addition, maybe some details
&gt;&gt; on volume sizes and instance types.
&gt;&gt;
&gt;&gt; These details may help someone attempting to answer your question.
&gt;&gt;
&gt;&gt; --
&gt;&gt; Hector
&gt;&gt;
&gt;&gt;
&gt;&gt; On Tue, Jan 21, 2014 at 8:11 AM, Hari John Kuriakose 
&gt;&gt; wrote:
&gt;&gt; &gt;
&gt;&gt; &gt; I am running LevelDB on ZFS in Solaris (OmniOS specifically) in Amazon
&gt;&gt; AWS.
&gt;&gt; &gt; The iops is very very low. There is no significant progress with tuning
&gt;&gt; too.
&gt;&gt; &gt;
&gt;&gt; &gt; Why I chose ZFS is that since LevelDB requires the node to be stopped
&gt;&gt; before
&gt;&gt; &gt; taking a backup, I needed a filesystem with snapshot ability. And the
&gt;&gt; most
&gt;&gt; &gt; favourable Amazon community AMI seemed to be using OmniOS (fork of
&gt;&gt; Solaris).
&gt;&gt; &gt; Everything is fine, except the performance.
&gt;&gt; &gt;
&gt;&gt; &gt; I did all the AWS tuning proposed by Basho but still Basho Bench gave
&gt;&gt; twice
&gt;&gt; &gt; iops on Ubuntu as compared to OmniOS, under same conditions. Also, I am
&gt;&gt; &gt; using riak-js client library, and its a 5 node Riak cluster with 8GB ram
&gt;&gt; &gt; each.
&gt;&gt; &gt;
&gt;&gt; &gt; Could not yet figure out what is really causing the congestion in
&gt;&gt; OmniOS.
&gt;&gt; &gt; Any pointers will be really helpful.
&gt;&gt; &gt;
&gt;&gt; &gt; Thanks and regards,
&gt;&gt; &gt; Hari John Kuriakose.
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

