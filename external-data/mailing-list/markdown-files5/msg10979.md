---
title: "Re: the optimal value of the ring_creation_size"
description: ""
project: community
lastmod: 2013-04-25T15:38:30-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10979"
mailinglist_parent_id: "msg10978"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2013-04-25T15:38:30-07:00
---


Minor correction to Dmitri's calcuation: the size of the covering set of
vnodes is RingSize / NVal, or 64 / 3 ~= 22 for the default configuration.
 That said, it is still what one would consider "spammy" and should be done
with caution.


On Thu, Apr 25, 2013 at 11:10 PM, Dev Vasantharajan wrote:

&gt; Speaking of ring resizing, this SO answer from Dmitri could also be good
&gt; reference (if you ever wanna go there).
&gt;
&gt;
&gt; http://stackoverflow.com/questions/14685236/migrating-riak-data-when-ring-size-changes
&gt;
&gt;
&gt; On Fri, Apr 26, 2013 at 12:04 AM, Dmitri Zagidulin 
&gt; wrote:
&gt;
&gt;&gt; Tom,
&gt;&gt;
&gt;&gt; Just to emphasize Joe's comment -- 512 should be the \\_maximum\\_ you want
&gt;&gt; to use as your ring size with leveldb/multi backend. But you should
&gt;&gt; probably use a smaller size, unless your cluster is going to have several
&gt;&gt; dozen nodes.
&gt;&gt;
&gt;&gt; The recommended rule of thumb with ring size is "~10 vnodes to a physical
&gt;&gt; machine". Meaning, if you have a 5 node cluster (and it's going to stay at
&gt;&gt; 5 nodes and not scale that much), using a ring size of 64 is perfectly fine
&gt;&gt; (since each node is going to have 12 to 13 vnodes on it ( 64 / 5) ).
&gt;&gt;
&gt;&gt; Say you scale that cluster to 10 nodes, and keep the 64 ring size. Here,
&gt;&gt; each machine is going to be running 6 to 7 virtual nodes on it (64/10), and
&gt;&gt; will probably be under-utilized, in terms of hardware resources.
&gt;&gt; Whereas if you select a ring size of 128 for that 10 node cluster, you're
&gt;&gt; back to the 12-13 vnodes per machine range.
&gt;&gt;
&gt;&gt; On the other hand, if you have a 5 node cluster with a ring size of 512,
&gt;&gt; each machine will be responsible for around 100 vnodes, so unless your
&gt;&gt; servers are very powerful, they're going to compete with each other for
&gt;&gt; resources (ram, cpu, etc) and be overwhelmed. Also, keep in mind, that
&gt;&gt; Secondary Index (2i) queries get slower the bigger your ring size is (since
&gt;&gt; 2i uses "covering" queries -- each request has to contact half of all the
&gt;&gt; vnodes, so it matters whether it has to contact around 32 vnodes (for ring
&gt;&gt; size 64) or 256 (for 512)).
&gt;&gt;
&gt;&gt; So in short, most small to medium sized clusters out there use 128 or 256
&gt;&gt; ring sizes. If you \\_know\\_ you're not going to scale past 7-9 nodes, it's
&gt;&gt; safe to go with 64. If you know you're going to scale to a giant cluster of
&gt;&gt; 50 nodes or some such, use 512 (though at that point, you should
&gt;&gt; re-evaluate your use of Secondary Indexes).
&gt;&gt;
&gt;&gt; Last thought - migrating to a different ring size is a big pain, although
&gt;&gt; it's doable. (You basically have to resort to logical backup tools --
&gt;&gt; export all your data from the old cluster to disk, and then import it all
&gt;&gt; to the new cluster).
&gt;&gt;
&gt;&gt; Dmitri
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On Mon, Apr 22, 2013 at 5:30 PM, Tom Zeng  wrote:
&gt;&gt;
&gt;&gt;&gt; Ok thanks Joe. We plan to switch to the Multi backend, so will use 512.
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Mon, Apr 22, 2013 at 5:17 PM, Joe Caswell  wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Tom,
&gt;&gt;&gt;&gt; There is no hard and fast rule for the "best value." The optimal
&gt;&gt;&gt;&gt; value for your situation will need to take into account the physical
&gt;&gt;&gt;&gt; resources available both in your starting cluster as well as your planned
&gt;&gt;&gt;&gt; end-state cluster. If you plan to use secondary indexing, the maximum
&gt;&gt;&gt;&gt; ring\\_creation\\_size you should consider is 512.
&gt;&gt;&gt;&gt; There will be a separate concurrent vnode\\_proxy process for each
&gt;&gt;&gt;&gt; vnode, and a process for each backend for each vnode. Each backend will
&gt;&gt;&gt;&gt; need open file handles and RAM for caching objects. The backend
&gt;&gt;&gt;&gt; configuration section of the docs should help plan your backed settings
&gt;&gt;&gt;&gt; http://docs.basho.com/riak/1.3.1/tutorials/choosing-a-backend/
&gt;&gt;&gt;&gt; Your planning must also include failure scenarios. If any of your
&gt;&gt;&gt;&gt; nodes crash, the surviving nodes will each start more vnodes to cover the
&gt;&gt;&gt;&gt; missing node(s). The 10 vnodes per node recommendation is to ensure that
&gt;&gt;&gt;&gt; the vnodes from any single failed node can be divided among enough
&gt;&gt;&gt;&gt; surviving nodes to not leave one node handling significantly more load than
&gt;&gt;&gt;&gt; the other, but this also is not a hard and fast rule.
&gt;&gt;&gt;&gt; At this time changing number of partitions in the ring does require a
&gt;&gt;&gt;&gt; complete rebuild of the cluster, we do have dynamic ring sizing on the
&gt;&gt;&gt;&gt; product roadmap, but there is no release date set for that feature.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Joe Caswell
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; From: Tom Zeng 
&gt;&gt;&gt;&gt; Date: Sunday, April 21, 2013 9:38 PM
&gt;&gt;&gt;&gt; To: 
&gt;&gt;&gt;&gt; Subject: the optimal value of the ring\\_creation\\_size
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Hi,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I am wondering what's the best value for ring\\_creation\\_size, the
&gt;&gt;&gt;&gt; default is 64. According to the docs 64 will work for a cluster of no more
&gt;&gt;&gt;&gt; than 6 nodes (64 /10), and ring\\_creation\\_size of 128 will allow cluster of
&gt;&gt;&gt;&gt; up to 12 mode. I am wondering what kind of overhead of is associated with
&gt;&gt;&gt;&gt; a large ring\\_creation\\_size. Since changing the ring\\_creation\\_size will
&gt;&gt;&gt;&gt; result in rebuilding the cluster(destuctive), would a larger value make
&gt;&gt;&gt;&gt; more sense and allow scaling by adding more nodes?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks,
&gt;&gt;&gt;&gt; Tom
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; --
&gt;&gt;&gt;&gt; Tom Zeng
&gt;&gt;&gt;&gt; Director of Engineering
&gt;&gt;&gt;&gt; Intridea, Inc. | www.intridea.com
&gt;&gt;&gt;&gt; t...@intridea.com
&gt;&gt;&gt;&gt; (o) 888.968.4332 x519
&gt;&gt;&gt;&gt; (c) 240-643-8728
&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ riak-users mailing
&gt;&gt;&gt;&gt; list riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; --
&gt; \\*Dev Kanchen \\*|\\* \\*Solution Architect
&gt; \\*Sourcebits\\*
&gt;
&gt; \\*Bangalore\\* | San Francisco | Wroclaw | Connecticut | Atlanta
&gt; M: +91 96111 07106
&gt; GTalk ID: d...@sourcebits.com | Skype ID: dev.kanchen
&gt;
&gt; Disclaimer:This email and any attachments are sent in strictest confidence
&gt; for the sole use of the addressee and may contain legally privileged,
&gt; confidential, and proprietary data. If you are not the intended recipient,
&gt; please advise the sender by replying promptly to this email and then delete
&gt; and destroy this email and any attachments without any further use, copying
&gt; or forwarding.
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;


-- 
Sean Cribbs 
Software Engineer
Basho Technologies, Inc.
http://basho.com/
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

