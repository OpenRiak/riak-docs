---
title: "Re: Cluster rebalancing"
description: ""
project: community
lastmod: 2014-07-06T06:11:24-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14462"
mailinglist_parent_id: "msg14461"
author_name: "Thomas Santero"
project_section: "mailinglistitem"
sent_date: 2014-07-06T06:11:24-07:00
---


Hi Chaim,

Inline

&gt; On Jul 6, 2014, at 1:13 AM, Chaim Solomon  wrote:
&gt; 
&gt; I don't think I was quite clear in what I asked for.

My apologies for misunderstanding your previous query.

&gt; 
&gt; I am not asking for the ability to influence the hashing algorithm. That 
&gt; would be a mess.
&gt; But I would like to be able to have more influence on the distribution of 
&gt; vnodes on the nodes - and that is something that RIAK already does.
&gt; 
&gt; So a command to bump a vnode off a particular node or reduce the number of 
&gt; vnodes on a node or set the target percentage on a node would be nice. It 
&gt; seems like the current algorithm already does something similar - but I 
&gt; didn't see how one can influence that.
&gt; 
&gt; The other issue was that I would suggest taking the disk space into 
&gt; consideration.
&gt; If you have nodes that have different storage then balancing the data equally 
&gt; between nodes may not be the best option. 
&gt; It may be better to take the available disk space into consideration and move 
&gt; vnodes to nodes that have free space if a node runs low on space.

What you refer to here would be nice, and is something referred to as "weighted 
claim." I know it's been discussed a bit in the past. Perhaps someone from 
Basho can chime in and let us know if it's on the roadmap for a future release?

&gt; 
&gt; One simple use case would be expanding a cluster with newer nodes (that have 
&gt; more storage) and being able to utilise that storage. 
&gt; 
&gt; Another would be to be able to distribute larger partitions more evenly - in 
&gt; particular if the size per partition is not evenly distributed.
&gt; 
&gt; Chaim Solomon
&gt; 
&gt; 
&gt; 
&gt;&gt; On Thu, Jul 3, 2014 at 8:51 PM, Tom Santero  wrote:
&gt;&gt; responses inline
&gt;&gt; 
&gt;&gt; 
&gt;&gt;&gt; On Thu, Jul 3, 2014 at 2:45 AM, Chaim Solomon  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; Hi,
&gt;&gt;&gt; 
&gt;&gt;&gt; I'm running a 2.0.0b cluster (small) and have been running out of space on 
&gt;&gt;&gt; one node. 
&gt;&gt;&gt; I had expected that adding a node would lead to freeing up of space on 
&gt;&gt;&gt; other nodes - but it's not working too fast.
&gt;&gt; 
&gt;&gt; Keep in mind that the speed of transfers is bound by the bandwidth available 
&gt;&gt; on the network as well as the speed at which you can actually read the data 
&gt;&gt; off disk. Once the transfers complete you should see the disk freed. 
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; I would suggest to add to RIAK a way to have the distribution algorithm 
&gt;&gt;&gt; take free space into consideration and to move data to empty nodes fast. 
&gt;&gt;&gt; Another issue is that adding the node moved most nodes from 25% to 18.8% - 
&gt;&gt;&gt; but one stayed on 25% in the planner.
&gt;&gt; 
&gt;&gt; The algorithm Riak uses to determine vnode placement is non-deterministic; 
&gt;&gt; if you don't like any given staged vnode distribution I might suggest you 
&gt;&gt; run riak-admin cluster clear to undo any staged changed and attempt to add 
&gt;&gt; the node again, until you're content with the new plan. 
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; And I would also suggest adding some way to force a rebalancing of the 
&gt;&gt;&gt; cluster to force nodes to take up more load if they don't have enough or 
&gt;&gt;&gt; hand off load to others.
&gt;&gt; 
&gt;&gt; The hashing algorithm used by Riak to determine object placement in the ring 
&gt;&gt; is uniform--over time and with a greater number of total keys you'll start 
&gt;&gt; to see a smoother distribution across all partitions. 
&gt;&gt; 
&gt;&gt; On the fly rebalancing would be incredibly expensive, especially for users 
&gt;&gt; who have lots of nodes and petabytes of data stored in Riak. Ad-hoc 
&gt;&gt; partition handoff would most likely be brittle and error-prone, given the 
&gt;&gt; unreliability of the network.
&gt;&gt; 
&gt;&gt; In my humble opinion the engineers at Basho work harder than most other 
&gt;&gt; distributed systems developers, considering all the edge cases where systems 
&gt;&gt; can fail unexpectedly; I say this not to boost their egos, but rather to 
&gt;&gt; point out that their approach has the effect of making Riak more robust and 
&gt;&gt; resilient than most other distributed datastores. But such resiliency isn't 
&gt;&gt; free, and for these guarantees every user must pay the price. Riak might not 
&gt;&gt; be the fastest database, and it may even underutilize that really expensive 
&gt;&gt; hardware you might throw at it...but i'll be damned if it doesn't lie to me, 
&gt;&gt; lose my data or pretend that failures like network partitions don't happen. 
&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; Chaim Solomon
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

