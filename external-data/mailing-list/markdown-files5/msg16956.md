---
title: "Re: Riak-S2 javascript aws-sdk failing on multi-part uploads"
description: ""
project: community
lastmod: 2016-01-13T15:53:50-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16956"
mailinglist_parent_id: "msg16955"
author_name: "Luke Bakken"
project_section: "mailinglistitem"
sent_date: 2016-01-13T15:53:50-08:00
---


Hi John,

Thanks for the info. I'm very curious to see what's in the haproxy
logs with regard to TCP.
--
Luke Bakken
Engineer
lbak...@basho.com


On Wed, Jan 13, 2016 at 3:50 PM, John Fanjoy  wrote:
&gt; Luke,
&gt;
&gt; As a test I’ve already increased all timeouts to 5 minutes but the failure 
&gt; occurs within under 1 minute so it doesn’t appear to be timeout related. I 
&gt; change the logs to tcplog tomorrow and let you know if I find anything.
&gt;
&gt; Thanks
&gt;
&gt; John Fanjoy
&gt; Systems Engineer
&gt; jfan...@inetu.net
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; On 1/13/16, 6:05 PM, "Luke Bakken"  wrote:
&gt;
&gt;&gt;haproxy ships with some "short" default timeouts. If CyberDuck is able
&gt;&gt;to upload these files faster than aws-sdk, it may be doing so within
&gt;&gt;the default haproxy timeouts.
&gt;&gt;
&gt;&gt;You can also look at haproxy's log to see if you find any TCP
&gt;&gt;connections that it has closed.
&gt;&gt;--
&gt;&gt;Luke Bakken
&gt;&gt;Engineer
&gt;&gt;lbak...@basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt;On Wed, Jan 13, 2016 at 3:02 PM, John Fanjoy  wrote:
&gt;&gt;&gt; Luke,
&gt;&gt;&gt;
&gt;&gt;&gt; I may be able to do that. The only problem is without haproxy I have no way 
&gt;&gt;&gt; to inject CORS headers which the browser requires, but I may be able to 
&gt;&gt;&gt; write up small nodejs app to get past that and see if it is somehow related 
&gt;&gt;&gt; to haproxy. The fact that these errors are not present when using Cyberduck 
&gt;&gt;&gt; which is also talking to haproxy leads me to believe that’s not the cause, 
&gt;&gt;&gt; but it’s definitely worth testing.
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; John Fanjoy
&gt;&gt;&gt; Systems Engineer
&gt;&gt;&gt; jfan...@inetu.net
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On 1/13/16, 5:55 PM, "Luke Bakken"  wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt;John -
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;The following error indicates that the connection was unexpectedly
&gt;&gt;&gt;&gt;closed by something outside of Riak while the chunk is uploading:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;{badmatch,{error,closed}}
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;Is it possible to remove haproxy to test using the the aws-sdk?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;That is my first thought as to the cause of this issue, especially
&gt;&gt;&gt;&gt;since writing to S3 works with the same code.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;--
&gt;&gt;&gt;&gt;Luke Bakken
&gt;&gt;&gt;&gt;Engineer
&gt;&gt;&gt;&gt;lbak...@basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;On Wed, Jan 13, 2016 at 2:46 PM, John Fanjoy  wrote:
&gt;&gt;&gt;&gt;&gt; Luke,
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Yes on both parts. To confirm cyberduck was using multi-part I actually 
&gt;&gt;&gt;&gt;&gt; tailed the console.log while it was uploading the file, and it uploaded 
&gt;&gt;&gt;&gt;&gt; the file in approx. 40 parts. Afterwards the parts were reassembled as 
&gt;&gt;&gt;&gt;&gt; you would expect. The AWS-SDK for javascript has an object called 
&gt;&gt;&gt;&gt;&gt; ManagedUpload which automatically switches to multi-part when the input 
&gt;&gt;&gt;&gt;&gt; is larger than the maxpartsize (default 5mb). I have confirmed that it is 
&gt;&gt;&gt;&gt;&gt; splitting the files up, but so far I’ve only ever seen one part get 
&gt;&gt;&gt;&gt;&gt; successfully uploaded before the others failed at which point it removes 
&gt;&gt;&gt;&gt;&gt; the upload (DELETE call) automatically. I also verified that the 
&gt;&gt;&gt;&gt;&gt; javascript I have in place does work with an actual AWS S3 bucket to rule 
&gt;&gt;&gt;&gt;&gt; out coding issues on my end and the same &gt;400mb file was successfully 
&gt;&gt;&gt;&gt;&gt; uploaded to the bucket I created there without issue.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; A few things worth mentioning that I missed before. I am running riak-s2 
&gt;&gt;&gt;&gt;&gt; behind haproxy. Haproxy is handling ssl and enabling CORS for browser 
&gt;&gt;&gt;&gt;&gt; based requests. I have tested smaller files (~4-5mb) and GET requests 
&gt;&gt;&gt;&gt;&gt; using the browser client and everything works with my current haproxy 
&gt;&gt;&gt;&gt;&gt; configuration, but the larger files are failing, usually after 1 part is 
&gt;&gt;&gt;&gt;&gt; successfully uploaded. I can also list bucket contents and delete 
&gt;&gt;&gt;&gt;&gt; existing contents. The only feature that is not working appears to be the 
&gt;&gt;&gt;&gt;&gt; multi-part uploads. We are running centOS 7 (kernel version 
&gt;&gt;&gt;&gt;&gt; 3.10.0-327.4.4.el7.x86\\_64). Please let me know if you have any further 
&gt;&gt;&gt;&gt;&gt; questions.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; --
&gt;&gt;&gt;&gt;&gt; John Fanjoy
&gt;&gt;&gt;&gt;&gt; Systems Engineer
&gt;&gt;&gt;&gt;&gt; jfan...@inetu.net

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

