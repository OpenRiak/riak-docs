---
title: "Re: Measuring Riak disk usage"
description: ""
project: community
lastmod: 2013-04-10T10:15:13-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10824"
mailinglist_parent_id: "msg10821"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-04-10T10:15:13-07:00
---


Ben,

The runtime recovery log ends in "XXXXXX.log" where XXXXXX is a six digit 
numeric. Its size will vary between 30Mbytes and 60Mbytes per vnode 
directory.no

My recommendation is that you change the app.config file's default\\_bucket\\_props 
detailed below. Completely erase the data storage area. Then run again. 
Should make a big total size difference.

See if this results in more reasonable / comparable sizes. This will give you 
a default compression comparison. There is also a way to tune the database 
such that it would compress even more, but at the cost of random read 
performance. We can try that next.

Matthew




On Apr 10, 2013, at 12:31 PM, Ben McCann  wrote:

&gt; Thanks for the help. If I were saving three copies of the data in Riak that 
&gt; would certainly explain it! I installed Riak via the apt repository 
&gt; instructions. Not sure what that does by default. If it's saving three copies 
&gt; of the data then I assume it would also be running three server nodes or does 
&gt; it run only a single Riak node and store three copies of the data? I'm 
&gt; accessing Riak on port 8098, which seems to be the default if only one node 
&gt; is running.
&gt; 
&gt; The first level of leveldb storage looks to be quite small to me. Is the 
&gt; runtime data recovery log likely to be very large? Can you tell me where that 
&gt; would be located or point me to some docs on it?
&gt; 
&gt; I'm not super interested in squeezing out an extra percent or two of storage 
&gt; here or there, but just want to roughly have some idea if storing my data 
&gt; with snappy compression will yield me a 30% savings or 50% savings or 80% 
&gt; savings, etc. So any really big things like perhaps storing three copies of 
&gt; the data are interesting =) In production, my average document size is 
&gt; probably about 2k and I have tens of millions and soon to be hundreds of 
&gt; millions of them.
&gt; 
&gt; Thanks!
&gt; -Ben
&gt; 
&gt; 
&gt; On Wed, Apr 10, 2013 at 6:22 AM, Matthew Von-Maszewski  
&gt; wrote:
&gt; Greetings Ben,
&gt; 
&gt; Also, leveldb stores data in "levels". The very first storage level and the 
&gt; runtime data recovery log are not compressed.
&gt; 
&gt; That said, I agree with Tom that you are most likely seeing Riak store 3 
&gt; copies of your data versus only one for mongodb. It is possible to dumb down 
&gt; Riak so that it is closer to mongodb:
&gt; 
&gt; 1. in app.config, look for the riak\\_core options, add the following line:
&gt; 
&gt; {default\\_bucket\\_props, [{n\\_val,1}]},
&gt; 
&gt; This will default the system to only storing one copy of your data.
&gt; 
&gt; 
&gt; 2. if you are using Riak 1.3, again in app.config, look for the riak\\_kv 
&gt; options:
&gt; 
&gt; change this
&gt; 
&gt; {anti\\_entropy, {on, []}},
&gt; 
&gt; to
&gt; 
&gt; {anti\\_entropy, {off, []}},
&gt; 
&gt; This will disable Riak's automatic detection and correction of data loss / 
&gt; corruption. The feature requires an added 1 to 2% data on disk.
&gt; 
&gt; 
&gt; Matthew
&gt; 
&gt; 
&gt; 
&gt; On Apr 10, 2013, at 9:01 AM, Tom Santero  wrote:
&gt; 
&gt;&gt; Hi Ben,
&gt;&gt; 
&gt;&gt; First, allow me to welcome to the list! Stick around, I think you'll like it 
&gt;&gt; here. :)
&gt;&gt; 
&gt;&gt; How many nodes of Riak are you running vs how many nodes of Mongo?
&gt;&gt; 
&gt;&gt; How much more disk space did Riak take?
&gt;&gt; 
&gt;&gt; Riak is designed to run as a cluster of several nodes, utilizing replication 
&gt;&gt; to provide resiliency and high-availability during partial failure. By 
&gt;&gt; default Riak stores three replicas of every object you persist. If you are 
&gt;&gt; only running a single node of Riak for your testing purposes, I suspect this 
&gt;&gt; may explain the significant divergence you're seeing when compared to the 
&gt;&gt; disk space used vs a single mongo, as each replica in Riak is being stored 
&gt;&gt; to the same disk.
&gt;&gt; 
&gt;&gt; Also, Snappy is optimizes for speed over disk utility, which will have a 
&gt;&gt; negligible impact on total disk usage when compared to other compression 
&gt;&gt; libraries such as zlib, etc. That said, for sufficiently large JSON files I 
&gt;&gt; know that BSON's prefixes can add significant overhead to object sizes such 
&gt;&gt; that BSON is actually heavier than the JSON it represents. What is the 
&gt;&gt; average size of the documents you're seeking to store?
&gt;&gt; 
&gt;&gt; Could you tell us a bit more about what you're trying to achieve with both 
&gt;&gt; Riak and Mongo, respectfully?
&gt;&gt; 
&gt;&gt; Tom
&gt;&gt; 
&gt;&gt; On Wed, Apr 10, 2013 at 12:39 AM, Ben McCann  wrote:
&gt;&gt; Hi, 
&gt;&gt; 
&gt;&gt; I'm currently storing data in MongoDB and would like to evaluate Riak as an 
&gt;&gt; alternative. Riak is appealing to me because LevelDB uses Snappy, so I would 
&gt;&gt; expect it to take less disk space to store my data set than MongoDB which 
&gt;&gt; does not use compression. However, when I benchmarked it by inserting a few 
&gt;&gt; hundred thousand JSON records into each datastore, Riak in fact took far 
&gt;&gt; more disk space. I'm wondering if there's something I might be missing here 
&gt;&gt; as a newcomer to Riak. E.g. I checked the disk space used by running "du -ch 
&gt;&gt; /var/lib/riak/leveldb". Is this perhaps not a good way to check disk space 
&gt;&gt; usage because perhaps Riak/LevelDB preallocates files? (I know MongoDB does 
&gt;&gt; this and has a built-in db.collection.stats command to provide true disk 
&gt;&gt; usage information). Are there any other reasons why Riak might be taking 
&gt;&gt; more space or anything I could have screwed up? 
&gt;&gt; 
&gt;&gt; Thanks, 
&gt;&gt; Ben 
&gt;&gt; 
&gt;&gt; -- 
&gt;&gt; about.me/benmccann 
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; 
&gt;&gt; 
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
&gt; 
&gt; 
&gt; 
&gt; -- 
&gt; about.me/benmccann

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

