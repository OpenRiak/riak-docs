---
title: "Re: vm.args change for 15% to 80% improvement in leveldb"
description: ""
project: community
lastmod: 2013-08-15T14:33:54-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12053"
author_name: "István"
project_section: "mailinglistitem"
sent_date: 2013-08-15T14:33:54-07:00
---


Awesome work! Just on time for out performance testing... :)


On Tue, Aug 13, 2013 at 5:38 PM, Matthew Von-Maszewski
wrote:

&gt; \\*\\* The following is copied from Basho's leveldb wiki page:
&gt;
&gt; https://github.com/basho/leveldb/wiki/Riak-tuning-1
&gt;
&gt;
&gt;
&gt; Summary:
&gt;
&gt; leveldb has a higher read and write throughput in Riak if the Erlang
&gt; scheduler count is limited to half the number of CPU cores. Tests have
&gt; demonstrated improvements of 15% to 80% greater throughput.
&gt;
&gt; The scheduler limit is set in the vm.args file:
&gt;
&gt; +S x:x
&gt;
&gt; where "x" is the number of schedulers Erlang may use. Erlang's default
&gt; value of "x" is the total number of CPUs in the system. For Riak
&gt; installations using leveldb, the recommendation is to set "x" to half the
&gt; number of CPUs. Virtual environments are not yet tested.
&gt;
&gt; Example: for 24 CPU system
&gt;
&gt; +S 12:12
&gt;
&gt; Discussion:
&gt;
&gt; We have tested a limited number of CPU configurations and customer loads.
&gt; In all cases, there is a performance increase when the +S option is added
&gt; to the vm.args file to reduce the number of Erlang schedulers. The working
&gt; hypothesis is that the Erlang schedulers perform enough "busy wait" work
&gt; that they always create context switch away from leveldb when leveldb is
&gt; actually the only system task with real work.
&gt;
&gt; The tests included 8 CPU (no hyper threading, physical cores only) and 24
&gt; CPU (12 physical cores with hyper threading) systems. All were 64bit Intel
&gt; platforms. Generalized findings:
&gt;
&gt; • servers running higher number of vnodes (64) had larger
&gt; performance gains than those with fewer (8)
&gt; • servers running SSD arrays had larger performance gains than
&gt; those running SATA arrays
&gt; • Get and Write operations showed performance gains, 2i query
&gt; operations (leveldb iterators) were unchanged
&gt; • Not recommended for servers with less than 8 CPUs (go no lower
&gt; than +S 4:4)
&gt;
&gt; Performance improvements were as high as 80% over extended, heavily loaded
&gt; intervals on servers with SSD arrays and 64 vnodes. No test resulted in
&gt; worse performance due to the addition of +S x:x.
&gt;
&gt; The +S x:x configuration change does not have to be implemented
&gt; simultaneously to an entire Riak cluster. The change may be applied to a
&gt; single server for verification. Steps: update the vm.args file, then
&gt; restart the Riak node. Erlang command line changes to schedules were
&gt; ineffective.
&gt;
&gt; This configuration change has been running in at least one large,
&gt; multi-datacenter production environment for several months.
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;



-- 
the sun shines for all
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

