---
title: "Re: write value reality check"
description: ""
project: community
lastmod: 2013-06-28T08:16:47-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11351"
mailinglist_parent_id: "msg11350"
author_name: "Justin Sheehy"
project_section: "mailinglistitem"
sent_date: 2013-06-28T08:16:47-07:00
---


Hi, Louis-Philippe.

With a 2-node cluster and N=3, each value will be written to disk a total of 
three times: twice on one node, once on the other. (The W setting has no effect 
on the number of copies made or hosts used.) That behavior might seem a bit 
strange, but it's a strange configuration to run Riak on only two machines 
while asking it to store data on three of them.

The standard settings and behavior of Riak are generally optimized for non-tiny 
clusters, and make much more sense when there are at least five machines.

I hope this helps with your understanding.

-Justin



On Jun 28, 2013, at 10:54 AM, Louis-Philippe Perron wrote:

&gt; So if I get you right and extrapolate with the replication documentation 
&gt; page, can I say that on a 2 nodes cluster, with a bucket set to N=3 and 
&gt; W=ALL, my writes would be written 3 times to disk? (and with no guarantee to 
&gt; be on different nodes)?
&gt; 
&gt; thanks! 
&gt; 
&gt; On Wed, Jun 26, 2013 at 8:17 PM, Mark Phillips  wrote:
&gt; Hi Louis-Philippe 
&gt; 
&gt; There are no dumb questions. :)
&gt; 
&gt; On Wednesday, June 26, 2013, Louis-Philippe Perron wrote:
&gt; Hi Riak people!
&gt; Here is a dumb question, but anyway I want to clear this doubt out:
&gt; 
&gt; What happens when a bucket has a W quorum value higher than the N number of 
&gt; nodes?
&gt; are writes to disk multiplied?
&gt; 
&gt; 
&gt; Precisely. For example, if you run a one node Riak cluster on your dev 
&gt; machine you'll be writing with a N val of 3 and W of 2 by default. In other 
&gt; words, Riak will always attempt to satisfy the W value regardless of physical 
&gt; node count. 
&gt; 
&gt; Hope that helps. 
&gt; 
&gt; Mark 
&gt; twitter.com/pharkmillups 
&gt; 
&gt; thanks!
&gt; 
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

