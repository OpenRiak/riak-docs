---
title: "Re: nodes with 100% HD usage"
description: ""
project: community
lastmod: 2015-04-13T04:28:31-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16004"
mailinglist_parent_id: "msg16002"
author_name: "Alex De la rosa"
project_section: "mailinglistitem"
sent_date: 2015-04-13T04:28:31-07:00
---


Awesome! thanks Bryan, that's exactly what I wanted to know.

Monitoring that all nodes are below 80% of capacity and add nodes when
reaching those limits to rebalance data and free space on this nodes seems
the right way to go then : )

Thanks,
Alex

On Mon, Apr 13, 2015 at 1:16 PM, bryan hunt  wrote:

&gt; Result - Failed writes, reduced AAE availability, system errors, probably
&gt; other (OS level) processes terminating.
&gt;
&gt; 100% disk usage is never good. However, our storage systems are
&gt; write-append, which will mitigate against data corruption.
&gt;
&gt; If the node becomes completely unavailable, the other nodes will also
&gt; attempt to rebalance the data, with less nodes this means each node will be
&gt; responsible for more storage, which could potentially cause a cascading
&gt; failure.
&gt;
&gt; Moral of the story - monitor, and start sending SMS messages when disk use
&gt; goes above 80%, a standard devops chore, and applicable to any business
&gt; critical computer system.
&gt;
&gt; Bryan
&gt;
&gt; &gt; On 9 Apr 2015, at 14:10, Alex De la rosa 
&gt; wrote:
&gt; &gt;
&gt; &gt; Hi there,
&gt; &gt;
&gt; &gt; One theoretical question; what happens when a node (or more) hits a 100%
&gt; HD usage?
&gt; &gt;
&gt; &gt; Riak can easily scale horizontally adding new nodes to the cluster, but
&gt; what if one of them is full? will the system have troubles? will this node
&gt; only be used only for reading and new items get saved in the other nodes?
&gt; will the data rebalance in newly added servers freeing some space in the
&gt; fully used node?
&gt; &gt;
&gt; &gt; Thanks!
&gt; &gt; Alex
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

