---
title: "Re: Riak 1.0 pre2 legacy_keylisting crash"
description: ""
project: community
lastmod: 2011-10-12T20:20:01-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05146"
mailinglist_parent_id: "msg05109"
author_name: "Fyodor Yarochkin"
project_section: "mailinglistitem"
sent_date: 2011-10-12T20:20:01-07:00
---


I am still experimenting with this issue (and I'll write more detailed
report on that) but here is my findings so far:

1. This behavior appears only when large number of keys is returned by
secondary index filter. I am able to successefully execute the same
map-reduce set on functions if I ajust secondary index filter to
return a smaller subset.

2. When i switched to erlang map function, and kept original
javascript-written reduce function, I was still getting the same
behavior, switching to very simple erlang-based map-reduce set of
functions works and I am able to complete the query under 9 seconds.

Here's the set of functions I used in my testing:

 {"map": 
{"language":"erlang","module":"riak\\_kv\\_mapreduce","function":"map\\_object\\_value","arg":"filter\\_notfound"}
 },
 {"reduce": {"language":"erlang",
"module":"riak\\_kv\\_mapreduce","function":"reduce\\_sort","arg":"filter\\_notfound"}}


so I believe the bottleneck that kills queries is Javascript VM overhead.

On Mon, Oct 10, 2011 at 6:57 AM, Jim Adler  wrote:
&gt; I'm seeing the same behavior and logs on a bucket with about 8M keys.
&gt; Fyodor, any luck with any of Bryan's suggestions?
&gt; Jim
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; From: "Bryan Fink" 
&gt; To: "Fyodor Yarochkin" 
&gt; Cc: riak-users@lists.basho.com
&gt; Sent: Friday, October 7, 2011 6:06:15 AM
&gt; Subject: Re: Riak 1.0 pre2 legacy\\_keylisting crash
&gt;
&gt; On Fri, Oct 7, 2011 at 1:50 AM, Fyodor Yarochkin 
&gt; wrote:
&gt;&gt; Here's one of the queries that consistently generates series of
&gt;&gt; 'fitting\\_died' log messages:
&gt;&gt;
&gt;&gt; {
&gt;&gt;   "inputs":{
&gt;&gt;       "bucket":"test",
&gt;&gt;       "index":"integer\\_int",
&gt; …
&gt;&gt;   },
&gt;&gt;   "query":[
&gt;&gt;    {"map":{"language":"javascript",
&gt; …
&gt;&gt;    },
&gt;&gt;    {"reduce":{"language":"javascript",
&gt; …
&gt;&gt;  {"reduce":{"language":"javascript",
&gt; …
&gt;&gt;    ],"timeout": 9000
&gt;&gt; }
&gt;&gt;
&gt;&gt; produces over hundred of " "Supervisor riak\\_pipe\\_vnode\\_worker\\_sup had
&gt;&gt; child at module undefined at &lt;0.28835.0&gt; exit with reason fitting\\_died
&gt;&gt; in context child\\_terminated" entries in log file and returns 'timeout'
&gt;
&gt; My interpretation of your report is that 9 seconds is not long enough
&gt; to finish your MapReduce query.  I'll explain how I arrived at this
&gt; interpretation:
&gt;
&gt; The log message you're seeing says that many processes that
&gt; riak\\_pipe\\_vnode\\_worker\\_sup was monitor exited abnormally.  That
&gt; supervisor only monitors Riak Pipe worker processes, the processes
&gt; that do the work for Riak 1.0's MapReduce phases.
&gt;
&gt; The reason those workers gave for exiting abnormally was
&gt; 'fitting\\_died'.  This means that the pipeline they were working for
&gt; closed before they were finished with their work.
&gt;
&gt; The result your received was 'timeout'.  The way timeouts work in
&gt; Riak-Pipe-based MapReduce is that a timer triggers a message at the
&gt; given time, causing a monitoring process to cease waiting for results,
&gt; tear down the pipe, and return a timeout message to your client.
&gt;
&gt; The "tear down the pipe" step in the timeout process is what causes
&gt; all of those 'fitting\\_died' message you see.  They're normal, and are
&gt; intended to aid in analysis like the above.
&gt;
&gt; With that behind us, though, the question remains: why isn't 9 seconds
&gt; long enough to finish this query?  To figure that out, I'd start from
&gt; the beginning:
&gt;
&gt; 1. Is 9 seconds long enough to just finish the index query (using the
&gt; index API outside of MapReduce)?  If not, then the next people to jump
&gt; in with help here will want to know more about the types, sizes, and
&gt; counts of data you have indexed.
&gt;
&gt; 2. Assuming the bare index query finishes fast enough, is 9 seconds
&gt; long enough to get through just the index and map phase (no reduce
&gt; phases)?  If not, it's likely that either it takes longer than 9
&gt; seconds to pull every object matching your index query out of KV, or
&gt; that contention for Javascript VMs prohibits the throughput needed.
&gt;
&gt; 2a. Try switching to an Erlang map phase.
&gt; {"language":"erlang","module":"riak\\_kv\\_mapreduce","function":"map\\_object\\_value","arg":"filter\\_notfound"}
&gt; should do exactly what your Javascript function does, without
&gt; contending for a JS VM.
&gt;
&gt; 2b. Try increasing the number of JS VMs available for map phases.  In
&gt; your app.config, find the 'map\\_js\\_vm\\_count' setting, and increase it.
&gt;
&gt; 3. Assuming just the map phase also makes it through, is 9 seconds
&gt; long enough to get through just the index, map, and first reduce phase
&gt; (leave off the second)?  Your first reduce phase looks like it doesn't
&gt; do anything … is it needed?  Try removing it.
&gt;
&gt; 4. If you get all the way to the final phase before hitting the 9
&gt; second timeout, then it's may be that the re-reduce behavior of Riak
&gt; KV's MapReduce causes your function to be too expensive.  This will be
&gt; especially true if you expect that phase to receive thousands of
&gt; inputs.  A sort function such as yours probably doesn't benefit from
&gt; re-reduce, so I would recommend disabling it by adding
&gt; "arg":{"reduce\\_phase\\_only\\_1":true} to that reduce phase's
&gt; specification.  With that in place, your function should be evaluated
&gt; only once, with all the inputs it will receive.  This may still fail
&gt; because of the time it can take to encode/decode a large set of
&gt; inputs/outputs to/from JSON, but doing it only once may be enough to
&gt; get you finished.
&gt;
&gt; Hope that helps,
&gt; Bryan
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

