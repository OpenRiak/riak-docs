---
title: "Re: Riak 1.4 - fastest way to count all records in bucket (100+	millions)"
description: ""
project: community
lastmod: 2013-08-01T14:10:20-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11854"
mailinglist_parent_id: "msg11853"
author_name: "Christian Rosnes"
project_section: "mailinglistitem"
sent_date: 2013-08-01T14:10:20-07:00
---


On Thu, Aug 1, 2013 at 10:46 PM, Jeremiah Peschka &lt;
jeremiah.pesc...@gmail.com&gt; wrote:

&gt; What's the underlying goal of getting this count of records in a bucket?
&gt; Do you want to just have a live count or will you be eventually performing
&gt; additional filters on the count?
&gt;

The main goal was to find out how many records the bucket contained, and
get a feel for how long such a job would take when the number of records
exceed 100+ million.
But I'm also interested in taking this further and use is as a basis to
create some "group by" map-reduce jobs to be able to find out how many
entries there are in certain "categories", e.g a "group by" criteria on a
'city' field and number of entries for that city. And assuming the number
of entries would be in the millions or 10s of millions, and counters are
not in use, and the numbers are not used "live".

I will look into the counters for "live" usage.

Christian
@NorSoulx
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

