---
title: "Re: Is Riak suitable for a short-term scatter/gather sort of data	store?"
description: ""
project: community
lastmod: 2011-11-12T15:43:44-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05567"
mailinglist_parent_id: "msg05566"
author_name: "Keith Irwin"
project_section: "mailinglistitem"
sent_date: 2011-11-12T15:43:44-08:00
---


On Nov 12, 2011, at 2:32 PM, Gordon Tillman wrote:

&gt; Keith I have an idea that might work for you. This is a bit vague but I 
&gt; would be glad to put together a more concrete example if you like.

Okay, thanks! Not sure I understand everything, though.

&gt; Use secondary indexes to tag each entry with the device id.

I get the tagging part, but I'm not sure what the bucket and key being tagged 
would look like. Are you taking a single bucket for all data?

put /buckets/mydata/keys/-
x-riak-index-device\\_bin: FF06541287AB

Something like that?

&gt; You can then find all of the entries for a given device by using the the 
&gt; secondary index to feed into a simple map phase operation that returns only 
&gt; the entries that you want; i.e., those that are in a given time range.

This I don't know how to do based on my reading of the docs. Something like:

 get /buckets/mydata/index/device\\_bin/FF345678912

which would return a list of .... what, device-timestamp compound keys? And 
then would I feed a potentially huge list of "bucket/key" pairs into a gigantic 
javascript query for the map-reduce phase?

&gt; In addition, to easily find all of the registered device ids easily you can 
&gt; create one entry for each device. The key can be most anything (even the 
&gt; device id if you encode it properly -- hash it), and you could tag each of 
&gt; those entries with a secondary index whose field is something like "type" or 
&gt; whatever and whose value is "deviceid". The value for each entry could be 
&gt; just a simple text/plain value whose contents is just the device id of the 
&gt; registered device.

Okay, I think I get this:

When a device comes in, just do something like:

put /buckets/devices/
x-riak-index-type\\_bin: "device"

When I want a list of device IDs, I can:

get /buckets/devices/index/type\\_bin/device

and get them all, right? This is more efficient than the various list 
functions? That makes sense to me.

I guess I'll have to try a few examples and see what happens. What you're 
telling me is that what I want to do is possible, or is at least not pressing 
against Riak's particular trade-offs too much. Or at least I hope that's what 
you're telling me. ;)

Keith


&gt; 
&gt; --gordon
&gt; 
&gt; On Nov 12, 2011, at 16:19 , Keith Irwin wrote:
&gt; 
&gt;&gt; Folks--
&gt;&gt; 
&gt;&gt; (Apologies up front for the length of this.)
&gt;&gt; 
&gt;&gt; I'm wondering if you can let me know if Riak is a good fit for a simple 
&gt;&gt; not-quite-key-value scenario described below. MongoDB or (say) Postgresql 
&gt;&gt; seem a more natural fit conceptually, but I really, really like Riak's 
&gt;&gt; distribution strategy.
&gt;&gt; 
&gt;&gt; ## context
&gt;&gt; 
&gt;&gt; The basic overview is this: 
&gt;&gt; 
&gt;&gt; 50K devices push data once a second to web services which need to store that 
&gt;&gt; data in short-term storage (Riak). Once an hour, a sweeper needs to take an 
&gt;&gt; hour's worth of data per device (if there is any) and ship it off to long 
&gt;&gt; term storage, then delete it from short-term storage. Ideally, there'd only 
&gt;&gt; ever be slightly more than 1 hour's worth of data still in short-term 
&gt;&gt; storage for any given device. The goal is to write down the data as simply 
&gt;&gt; and safely as possible, with little or no processing on that data.
&gt;&gt; 
&gt;&gt; Each second's worth of data is:
&gt;&gt; 
&gt;&gt; \\* A device identifier
&gt;&gt; \\* A timestamp (epoch seconds, integer) for the slice of time the data 
&gt;&gt; represents
&gt;&gt; \\* An opaque blob of binary data (2 to 4k)
&gt;&gt; 
&gt;&gt; Once an hour, I'd like to do something like:
&gt;&gt; 
&gt;&gt; \\* For each device:
&gt;&gt; \\* Find (and concat) all the data between time1 and time2 (an hour).
&gt;&gt; \\* Move that data to long-term storage (not Riak) as a single blob.
&gt;&gt; \\* Delete that data from Riak.
&gt;&gt; 
&gt;&gt; For an SQL db, this is a really simple problem, conceptually. You can have a 
&gt;&gt; table with three columns: device-id, timestamp, blob. You can index the 
&gt;&gt; first two columns and roll up the data easily enough and then delete it via 
&gt;&gt; single SQL statements (or buffer as needed). The harder part is 
&gt;&gt; partitioning, replication, etc, etc.
&gt;&gt; 
&gt;&gt; For MongoDB, it's also fairly simple. Just use a document with the same 
&gt;&gt; device-id, timestamp and binary-array data (as JSON), make sure indexes are 
&gt;&gt; declared, and query/delete just as in SQL. MongoDB provides sharding, 
&gt;&gt; replica-sets, recovery, etc. Set up, while less complicated than an RDBMS, 
&gt;&gt; still seems way more complicated than necessary.
&gt;&gt; 
&gt;&gt; These solutions also provide sorting (which, while nice, isn't a requirement 
&gt;&gt; for my case).
&gt;&gt; 
&gt;&gt; ## question
&gt;&gt; 
&gt;&gt; I've been reading the Riak docs, and I'm just not sure if this simple 
&gt;&gt; "queryable" case can really fit all that well. I'm not so concerned about 
&gt;&gt; having to send 50K "deletes" to delete data. I'm more concerned about being 
&gt;&gt; able to find it. Given what I've written above, I may be blocked 
&gt;&gt; conceptually by the above index/query mentality such that I'm just not 
&gt;&gt; seeing the Riak way of doing things.
&gt;&gt; 
&gt;&gt; Anyway, I can "tag" (via the secondary index feature) each blob of data with 
&gt;&gt; the device-id and the timestamp. I could then do a range query similar to:
&gt;&gt; 
&gt;&gt; GET /buckets/devices/index/timestamp/start/end
&gt;&gt; 
&gt;&gt; However, this doesn't allow me to group based on device-id. I could create a 
&gt;&gt; separate bucket for every device, such that I could do:
&gt;&gt; 
&gt;&gt; GET /buckets/device-id/index/timestamp/start/end
&gt;&gt; 
&gt;&gt; but if I do this, how can I get a list of the device-ids I need so that I 
&gt;&gt; can create that specific URL? The docs say listing buckets and keys is 
&gt;&gt; problematic.
&gt;&gt; 
&gt;&gt; Might be that Riak just isn't a good case for this sort of thing, especially 
&gt;&gt; given I want to use it for short-term transient data, and that's fine. But I 
&gt;&gt; wanted to ask you all just to make sure that I'm not missing something 
&gt;&gt; somewhere.
&gt;&gt; 
&gt;&gt; For instance, might link walking help? How about a map/reduce to find a 
&gt;&gt; unique list of device-ids within a given time-horizon, and a streaming map 
&gt;&gt; job to gather the data for export? Does that seem pretty reasonable?
&gt;&gt; 
&gt;&gt; Thanks!
&gt;&gt; 
&gt;&gt; Keith
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

