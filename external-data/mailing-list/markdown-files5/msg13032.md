---
title: "Re: Ownership handoff never completes"
description: ""
project: community
lastmod: 2013-11-20T08:53:17-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13032"
mailinglist_parent_id: "msg13028"
author_name: "Mark Phillips"
project_section: "mailinglistitem"
sent_date: 2013-11-20T08:53:17-08:00
---


Hmm. The fact that you've disabled Search probably changes things but I'm
not entirely sure how.

Ryan et al - any ideas?

Mark

On Wednesday, November 20, 2013, Jeppe Toustrup wrote:

&gt; Hi
&gt;
&gt; Thank you for the guide. I stopped two of the nodes (the source and
&gt; the destination of the partition transfers), renamed the folders
&gt; inside the merge\\_index folder and started them again. The ownership
&gt; handoff does however not seem to be retried.
&gt;
&gt; Looking at the logs it seems like the last attempt was 48 hours ago.
&gt; Is there any logic inside Riak which causes it to give up after a
&gt; certain amount of tries?
&gt; Is there a way I can retrigger the handoffs?
&gt; I have tried to set the transfer-limit on the cluster to 0 and then
&gt; back to 2, but it doesn't seem to do anything.
&gt;
&gt; I wonder if we need the merge\\_index folder at all, as we have disabled
&gt; Riak search since the initial configuration of the cluster. We found a
&gt; better way to query our data so that we don't need Riak search
&gt; anymore. We disabled it by resetting the properties on the buckets
&gt; where search was enabled, and then disabled search in app.config
&gt; followed by a restart of each of the nodes. This was done after the
&gt; ownership handoff issue first occurred.
&gt;
&gt; --
&gt; Jeppe Fihl Toustrup
&gt; Operations Engineer
&gt; Falcon Social
&gt;
&gt;
&gt; On 19 November 2013 23:17, Mark Phillips  wrote:
&gt; &gt; Hi Jeppe,
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; As you suspected, this looks like index corruption in Search that's
&gt; &gt; preventing handoff from finishing. Specifically, you'll need to delete
&gt; the
&gt; &gt;
&gt; &gt; segment files for the two partitions' indexes and rebuild those indexes
&gt; &gt; post-transfer.
&gt; &gt;
&gt; &gt;
&gt; &gt; Here's the full process:
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; - Stop each node that owns the partitions in question.
&gt; &gt; - Delete the data directory for each partition (which contains the
&gt; segment
&gt; &gt; files). It should be something like:
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; "rm -rf /var/lib/riak/merge\\_index/"
&gt; &gt;
&gt; &gt;
&gt; &gt; - Restart each node
&gt; &gt;
&gt; &gt; - Wait for the transfers to complete
&gt; &gt; - Rebuild the indexes in question [1]
&gt; &gt;
&gt; &gt;
&gt; &gt; Let us know if you run into any further issues.
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; Mark
&gt; &gt;
&gt; &gt;
&gt; &gt; [1]
&gt; &gt;
&gt; http://docs.basho.com/riak/latest/ops/running/recovery/repairing-indexes/
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; On Tue, Nov 19, 2013 at 4:26 AM, Jeppe Toustrup 
&gt; &gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Hi
&gt; &gt;&gt;
&gt; &gt;&gt; I have recently added two extra nodes to the now seven node Riak
&gt; &gt;&gt; cluster. The rebalancing following the expansion worked fine, except
&gt; &gt;&gt; for two partitions which seem to not being able to go through. Running
&gt; &gt;&gt; "riak-admin ring-status" shows the following:
&gt; &gt;&gt;
&gt; &gt;&gt; ============================== Ownership Handoff
&gt; &gt;&gt; ==============================
&gt; &gt;&gt; Owner: riak@10.0.0.96
&gt; &gt;&gt; Next Owner: riak@10.0.0.93
&gt; &gt;&gt;
&gt; &gt;&gt; Index: 239777612374601260017792042867515182912301432832
&gt; &gt;&gt; Waiting on: []
&gt; &gt;&gt; Complete: [riak\\_kv\\_vnode,riak\\_pipe\\_vnode]
&gt; &gt;&gt;
&gt; &gt;&gt; Index: 696496874040508421956443553091353626554780352512
&gt; &gt;&gt; Waiting on: []
&gt; &gt;&gt; Complete: [riak\\_kv\\_vnode,riak\\_pipe\\_vnode]
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; -------------------------------------------------------------------------------
&gt; &gt;&gt;
&gt; &gt;&gt; I can see from the log file on the source node (10.0.0.96) that it has
&gt; &gt;&gt; made numerous attempt to transfer the partitions, but it ends up
&gt; &gt;&gt; failing all the time. Here's an except of the log file showing the
&gt; &gt;&gt; lines from when the transfer attempt ends up failing:
&gt; &gt;&gt;
&gt; &gt;&gt; 2013-11-18 12:29:03.694 [error] emulator Error in process &lt;0.5745.8&gt;
&gt; &gt;&gt; on node 'riak@10.0.0.96' with exit value:
&gt; &gt;&gt; {badarg,[{erlang,binary\\_to\\_term,[&lt;&lt;29942
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; bytes&gt;&gt;],[]},{mi\\_segment,iterate\\_all\\_bytes,2,[{file,"src/mi\\_segment.erl"},{line,167}]},{mi\\_server,'-group\\_iterator/2-fun-1-',2,[{file,"src/mi\\_server.erl"},{line,725}]},{mi\\_server,'-group\\_iterator/2-fun-0-'...
&gt; &gt;&gt; 2013-11-18 12:29:03.885 [error] &lt;0.3269.0&gt;@mi\\_server:handle\\_info:524
&gt; &gt;&gt; lookup/range failure:
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; {badarg,[{erlang,binary\\_to\\_term,[&lt;&lt;131,109,0,0,244,240,108,109,102,97,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com



