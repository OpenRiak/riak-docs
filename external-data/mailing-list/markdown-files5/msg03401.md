---
title: "Re: General Memory/Performance Tuning Guidelines"
description: ""
project: community
lastmod: 2011-05-25T05:30:03-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg03401"
mailinglist_parent_id: "msg03397"
author_name: "Gordon Tillman"
project_section: "mailinglistitem"
sent_date: 2011-05-25T05:30:03-07:00
---


Morning Rusty,

Thanks very much for your time and trouble. Great info, very helpful, and very 
timely!

Regards,

--gordon


On May 24, 2011, at 16:32 , Rusty Klophaus wrote:

Hi Gordon,

I have limited knowledge of configuring Innostore but can help answer some of 
your merge\\_index questions.

The most important merge\\_index setting in terms of memory usage is 
'buffer\\_rollover\\_size'. This affects how large the buffer is allowed to grow, 
in bytes, before getting converted to an on-disk segment. Each partition 
maintains a separate buffer, so any increases to this number will be multiplied 
by the number of partitions in your system. The higher this number, the less 
frequently merge\\_index will need to perform compactions.

The second most important settings for memory usage are a combination of 
'segment\\_full\\_read\\_size' and 'max\\_compact\\_segments'. During compaction, the 
system will completely page any segments smaller than the 
'segment\\_full\\_read\\_size' value into memory. This should generally be as large 
or larger than the 'buffer\\_rollover\\_size'. The higher this number, the quicker 
each compaction will be. 'max\\_compact\\_segments' is the maximum number of 
segments to compact at one time. The higher this number, the more segments 
merge\\_index can involve in each compaction. In the worst case, a compaction 
could take ('segment\\_full\\_read\\_size' \\* 'max\\_compact\\_segments') bytes of RAM.

The rest of the settings have a much smaller impact on performance and memory 
usage, and exist mainly for tweaking and special cases.

This is a completely unscientific estimate based on observing other Riak Search 
applications, but I'd set buffer\\_rollover\\_size so that (# Partitions \\* 
buffer\\_rollover\\_size) is about one-half the memory you wish for merge\\_index to 
consume, hopefully somewhere between 1M and 10M. The rest of the memory will be 
used by in-memory offset tables, compaction processes, and during query 
operations.

Hope that helps.

Best,
Rusty


On Mon, May 23, 2011 at 2:05 PM, Gordon Tillman 
&gt; wrote:
Greetings!

We are working with a riaksearch cluster that uses innostore as the primary 
backend in tandem with merge\\_index that is required by search. From reading 
the Basho wiki it looks like the following are the most important factors 
affecting memory and performance:

 • innostore
 • put data\\_home\\_dir and log\\_group\\_home\\_dir on different spindles
 • noatime
 • buffer\\_pool\\_size
 • flush\\_method
 • merge\\_index
 • data\\_root
 • buffer\\_rollover\\_size
 • max\\_compact\\_segments
 • segment\\_file\\_buffer\\_size
 • segment\\_full\\_read\\_size
 • segment\\_block\\_size

Ideally, data\\_home\\_dir, log\\_group\\_home\\_dir, and data\\_root would all be on 
different spindles, but if you had just 2 disks available what would you 
recommend? Would it be best to have data\\_home\\_dir and data\\_root on one and 
then log\\_group\\_home\\_dir on the other?

in calculating the proper setting for buffer\\_pool\\_size you are directed to 
allocate 60-80 percent of available RAM. So lets assume you want to take the 
remaining 20-40% of available RAM and split it up between innostore and 
merge\\_index?

Would it be best to give each of them half of that value?

Determining the approximate memory requirements for merge\\_index isn't (to me) 
real obvious. I looks like the following all have an effect:

 \\* buffer\\_rollover\\_size
 \\* buffer\\_delayed\\_write\\_size
 \\* max\\_compact\\_segments
 \\* segment\\_query\\_read\\_ahead\\_size
 \\* segment\\_compaction\\_read\\_ahead\\_size
 \\* segment\\_full\\_read\\_size
 \\* segment\\_block\\_size
 \\* segment\\_values\\_staging\\_size

Is there a formula for determining the (approximate) proper values to use given 
a certain amount of available RAM?

Thanks in advance for any advice. Sorry for all the questions!

--gordon



\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

