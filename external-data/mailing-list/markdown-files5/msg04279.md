---
title: "Re: High volume data series storage and queries"
description: ""
project: community
lastmod: 2011-08-09T07:25:02-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04279"
mailinglist_parent_id: "msg04268"
author_name: "Jeremiah Peschka"
project_section: "mailinglistitem"
sent_date: 2011-08-09T07:25:02-07:00
---



---
Jeremiah Peschka - Founder, Brent Ozar PLF, LLC
 Microsoft SQL Server MVP

On Aug 8, 2011, at 6:40 PM, Paul O wrote:

&gt; Indeed, storage capacity is also an issue but IOPS would be important, too. I 
&gt; assume that sending batches to Riak (opaque blobs) would help a lot with the 
&gt; quantity of writes, but it's still a very important point.
&gt; 
&gt; You may want to look into ways to force Riak to clean up the bitcask files. I 
&gt; don't entirely remember how it's going to handle cleaning up deleted records, 
&gt; but you might run into some tricky situations where compactions aren't 
&gt; occurring.
&gt; 
&gt; Hm, any references regarding that? It would be a major snag in the whole 
&gt; schema Riak doesn't properly reclaim space for deleted records.

You might have to tweak the merge settings 
(http://wiki.basho.com/Bitcask-Configuration.html#Disk-Usage-and-Merging-Settings)
 depending on how and when data is deleted. You could bypass these 
configuration settings by manually running bitcask:merge.

More info here: 
https://help.basho.com/entries/20141178-why-does-it-seem-that-bitcask-merging-is-only-triggered-when-a-riak-node-is-restarted
and here: 
http://lists.basho.com/pipermail/riak-users\\_lists.basho.com/2011-July/005055.html

&gt; 
&gt; Riak is pretty constant time for Bitcask. The tricky part with the amount of 
&gt; data you're describing is that Bitcask requires (I think) that all keys fit 
&gt; into memory. As your data volume increases, you'll need to do a combination 
&gt; of scaling up and scaling out. Scale up RAM in the nodes and then add 
&gt; additional nodes to handle load. RAM will help with data volume, more nodes 
&gt; will help with write throughput.
&gt; 
&gt; Indeed, for high frequency sources that would create lots of bundles even the 
&gt; MaxN to 1 reduction for key names might still generate loads of keys. Any 
&gt; idea how much RAM Riak requires per record, or a reference that would point 
&gt; me to it?

There's a capacity planning page: 
http://wiki.basho.com/Bitcask-Capacity-Planning.html
And some additional information about RAM and disk requirements here: 
http://wiki.basho.com/Cluster-Capacity-Planning.html

&gt; 
&gt; Since you're searching on time series, mostly, you could build time indexes 
&gt; in your RDBMS. The nice thing is that querying temporal data is well 
&gt; documented in the relational world, especially in the data warehousing world. 
&gt; In your case, I'd create a dates table and have a foreign key relating to my 
&gt; RDBMS index table to make it easy to search for dates. Querying your time 
&gt; table will be fast which reduces the need for scans in your index table.
&gt; 
&gt; EXAMPLE:
&gt; 
&gt; CREATE TABLE timeseries (
&gt; time\\_key INT,
&gt; date TIMESTAMP,
&gt; datestring VARCHAR(30),
&gt; year SMALLINT,
&gt; month TINYINT,
&gt; day TINYINT,
&gt; day\\_of\\_week TINYINT
&gt; -- etc
&gt; );
&gt; 
&gt; CREATE TABLE riak\\_index (
&gt; id INT NOT NULL,
&gt; time\\_key INT NOT NULL REFERENCES timeseries(time\\_key),
&gt; riak\\_key VARCHAR(100) NOT NULL
&gt; );
&gt; 
&gt; 
&gt; SELECT ri.riak\\_key
&gt; FROM timeseries ts
&gt; JOIN riak\\_index ri ON ts.time\\_key = ri.time\\_key
&gt; WHERE ts.date BETWEEN '20090702' AND '20100702';
&gt; 
&gt; My plan was to have the riak\\_index contain something like: (id, start\\_time, 
&gt; end\\_time, source\\_id, record\\_count.)
&gt; 
&gt; Without going too much into RDBMS fun, this pattern can get your RDBMS 
&gt; running pretty quickly and then you can combine that with Riak's performance 
&gt; and have a really good idea of how quick any query will be.
&gt; 
&gt; That's roughly the plan, thanks again for your contributions to the 
&gt; discussion!
&gt; 
&gt; Paul 
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

