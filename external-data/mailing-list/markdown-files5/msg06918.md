---
title: "Re: Problems writing objects to an half full bucket"
description: ""
project: community
lastmod: 2012-03-07T12:32:24-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06918"
mailinglist_parent_id: "msg06899"
author_name: "Marco Monteiro"
project_section: "mailinglistitem"
sent_date: 2012-03-07T12:32:24-08:00
---


Having the keys prefixed with the seconds since epoch solved the problem.

Thanks,
Marco

On 6 March 2012 15:47, Marco Monteiro  wrote:

&gt; It makes sense, David. I'm going to give it a try.
&gt; Hopefully this will make it usable for the next month
&gt; until the issue is addressed.
&gt;
&gt; I'll let you know how it goes.
&gt;
&gt; Thanks,
&gt; Marco
&gt;
&gt;
&gt; On 6 March 2012 15:19, David Smith  wrote:
&gt;
&gt;&gt; On Mon, Mar 5, 2012 at 9:55 PM, Marco Monteiro 
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt; &gt; I'm using riak-js and the error I get is:
&gt;&gt; &gt;
&gt;&gt; &gt; { [Error: socket hang up] code: 'ECONNRESET' }
&gt;&gt;
&gt;&gt; That is a strange error -- are there any corresponding errors in
&gt;&gt; server logs? I would have expected a timeout or some such...
&gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; UUIDs. They are created by Riak. All my queries use 2i. The 2i are
&gt;&gt; integers
&gt;&gt; &gt; (representing seconds) and random strings (length 16) used as
&gt;&gt; identifiers
&gt;&gt; &gt; for user sessions and similar.
&gt;&gt;
&gt;&gt; So, this explains why the problem goes away when you switch to an
&gt;&gt; empty bucket. A bit of background...
&gt;&gt;
&gt;&gt; If you're using the functionality in Riak that automatically generates
&gt;&gt; a UUID on PUT, you're going to get a uniformly distributed 160-bit
&gt;&gt; number (since the implementation SHA-1 hashes the input). This sort of
&gt;&gt; distribution is great for uniqueness, since there is a 1 in 2^160
&gt;&gt; chance (roughly) that you will encounter another similar ID. It can be
&gt;&gt; very bad from a caching perspective, however, if you have a cache that
&gt;&gt; uses pages of information for locality purposes. In a scheme such as
&gt;&gt; this (which is what LevelDB uses), the system will wind up churning
&gt;&gt; the cache constantly since the odds are quite low that the next UUID
&gt;&gt; to be accessed will be already in memory (remember, uniform
&gt;&gt; distribution of keys).
&gt;&gt;
&gt;&gt; LevelDB also makes this pathological case a bit worse by not having
&gt;&gt; bloom filters -- when inserting a new UUID, you will potentially have
&gt;&gt; to do 7 disk seeks just to determine if the UUID is not present. The
&gt;&gt; Google team is working to address this problem, but I'm guessing it'll
&gt;&gt; be a month or so before that's done and then we have to integrate with
&gt;&gt; Riak -- so we can't count on that just yet.
&gt;&gt;
&gt;&gt; Now, all is not lost. :)
&gt;&gt;
&gt;&gt; If you craft your keys so that there is some temporal locality \\_and\\_
&gt;&gt; the access pattern of your keys has some sort of exponential-ish
&gt;&gt; decay, you can still get very good performance out of LevelDB. One
&gt;&gt; simple way to do this is to prefix the current date-time on front of
&gt;&gt; the UUID, like so:
&gt;&gt;
&gt;&gt; 201203060806- (YMDhm-UUID)
&gt;&gt;
&gt;&gt; You could also use seconds since the epoch, etc. This has the effect
&gt;&gt; of keeping recently accessed/hot UUIDs on (close to) the same cache
&gt;&gt; page, and lets you avoid a lot of cache churn and typically
&gt;&gt; dramatically improves LevelDB performance.
&gt;&gt;
&gt;&gt; Does this help/make sense?
&gt;&gt;
&gt;&gt; D.
&gt;&gt; --
&gt;&gt; Dave Smith
&gt;&gt; VP, Engineering
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; diz...@basho.com
&gt;&gt;
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

