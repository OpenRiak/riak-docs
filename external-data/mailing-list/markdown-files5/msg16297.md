---
title: "Re: Riak LevelDB Deletion Problem"
description: ""
project: community
lastmod: 2015-07-15T13:52:40-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16297"
mailinglist_parent_id: "msg16290"
author_name: "Timo Gatsonides"
project_section: "mailinglistitem"
sent_date: 2015-07-15T13:52:40-07:00
---


&gt; From: Antonio Teixeira 
&gt; To: Matthew Von-Maszewski 
&gt; Cc: riak-users 
&gt; Subject: Re: Riak LevelDB Deletion Problem
&gt; Message-ID:
&gt; 
&gt; Content-Type: text/plain; charset="utf-8"
&gt; 
&gt; Hello Matthew,
&gt; 
&gt; Space is reducing slooooowly , now we are faced with another problem :
&gt; Alot of applications store data on this node and we don't have the bucket
&gt; keys (they are uuid4) so :
&gt; 
&gt; We are using listkeys ( I know its bad ) on the erlang client and we also
&gt; tried with curl using both blocking and stream methods.
&gt; And they are all returning {error, timeout}.
&gt; 
&gt; We are 95 % sure that not all data has been migrated so , is there any way
&gt; to get the keys of the bucket, even if we have to shutdown the node (
&gt; Uptime/Availability not important for us ).
&gt; 
&gt; We are currently looking at mapreduce ?!

What are you using to list keys? Are you using secondary indexes? You can get 
all the keys for a bucket using the $bucket index, or do a range scan on $key. 
See http://docs.basho.com/riak/latest/dev/using/2i/ 
 . If your cluster is healthy 
that should return the keys without throwing a timeout error.

Kind regards,
Timo

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

