---
title: "Re: LevelDB performance (block size question)"
description: ""
project: community
lastmod: 2013-08-13T18:26:41-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12014"
mailinglist_parent_id: "msg12011"
author_name: "István"
project_section: "mailinglistitem"
sent_date: 2013-08-13T18:26:41-07:00
---


It seems Riak does not like the leveldb block\\_size to be changed to 64k.

App config:

app.config: {sst\\_block\\_size, 65536},



basho\\_bench logs:

18:04:38.010 [info]
Errors:[{{delete,delete},542},{{get,get},15921},{{put,put},1253},{{{delete,delete},disconnected},542},{{{get,get},disconnected},15921},{{{put,put},disconnected}
,1250},{{{put,put},timeout},3}]
18:04:48.003 [info]
Errors:[{{delete,delete},1131},{{get,get},35704},{{put,put},2738},{{{delete,delete},disconnected},1131},{{{get,get},disconnected},35704},{{{put,put},disconnecte
d},2732},{{{put,put},timeout},6}]


node error.log:

dev2/log/error.log.3:2013-08-09 14:50:51.203 [error]
&lt;0.3399.0&gt;@riak\\_api\\_pb\\_server:handle\\_info:141 Unrecognized message
{909113,{error,timeout}}
dev2/log/error.log.3:2013-08-09 14:50:51.207 [error]
&lt;0.3446.0&gt;@riak\\_api\\_pb\\_server:handle\\_info:141 Unrecognized message
{22197453,{error,timeout}}
dev2/log/error.log.3:2013-08-09 14:53:54.267 [error]
&lt;0.5125.3&gt;@riak\\_api\\_pb\\_server:handle\\_info:141 Unrecognized message
{13631220,{error,timeout}}

dev2/log/error.log.3:2013-08-09 15:15:19.979 [error] &lt;0.655.0&gt; gen\\_fsm
&lt;0.655.0&gt; in state active terminated with reason: bad argument in call to
ets:lookup(ets\\_riak\\_core\\_ring\\_manager, {bucket,&lt;&lt;"test"&gt;&gt;}) in
riak\\_core\\_ring\\_manager:get\\_bucket\\_meta/1 line 179



I have deleted all the data between the tests and some tests are still
running but it seems this configuration is not ideal.

The important part of the basho\\_bench configuration:

{mode, max}.
{duration, 10}.
{concurrent, 64}.
{driver, basho\\_bench\\_driver\\_riakc\\_pb}.
{key\\_generator, {int\\_to\\_bin, {uniform\\_int, 1000000}}}.
{value\\_generator, {exponential\\_bin, 524288, 2048}}.


I am running additional tests with different cache size, it might have an
impact on how the system behaves.

Regards,
Istvan


On Tue, Aug 13, 2013 at 3:12 PM, István  wrote:

&gt; Hi Matthew,
&gt;
&gt; Thank you for the explanation.
&gt;
&gt; I am experimenting with different block size and making sure I have at
&gt; least 100G data on disk for the tests.
&gt;
&gt; I.
&gt;
&gt;
&gt; On Tue, Aug 13, 2013 at 12:11 PM, Matthew Von-Maszewski &lt;
&gt; matth...@basho.com&gt; wrote:
&gt;
&gt;&gt; Istvan,
&gt;&gt;
&gt;&gt; "block\\_size" is not a "size", it is a threshold. Data is never split
&gt;&gt; across blocks. A single block contains one or more key/value pairs.
&gt;&gt; leveldb starts a new block only when the total size of all key/values in
&gt;&gt; the current block exceed the threshold.
&gt;&gt;
&gt;&gt; Your must set block\\_size to a multiple of your typical key/value size if
&gt;&gt; you desire multiple per block.
&gt;&gt;
&gt;&gt; Plus side: block\\_size is computed before compression. So, you might get
&gt;&gt; nice reduction in total disk size by having multiple, mutually compressible
&gt;&gt; items in a block. leveldb iterators / Riak 2i might give you slightly
&gt;&gt; better performance with bigger blocks because there are fewer reads if the
&gt;&gt; keys needed are in the same block (or fewer blocks).
&gt;&gt;
&gt;&gt; Negative side: the entire block, not single key/value pairs, go into the
&gt;&gt; block cache uncompressed (cache\\_size). You can quickly overwhelm the block
&gt;&gt; cache with lots of large blocks. Also random reads / Gets have to read,
&gt;&gt; decompress, and CRC check the entire block. Therefore it costs you more
&gt;&gt; disk transfer and decompression/CRC CPU time to read random values from
&gt;&gt; bigger blocks.
&gt;&gt;
&gt;&gt;
&gt;&gt; I suggest you experiment with your dataset and usage patterns. Be sure
&gt;&gt; to build big sample datasets before starting to measure and/or restart Riak
&gt;&gt; between building and measuring. These are ways to make sure you see the
&gt;&gt; impact of random reads.
&gt;&gt;
&gt;&gt; Matthew
&gt;&gt;
&gt;&gt;
&gt;&gt; On Aug 13, 2013, at 2:51 PM, István  wrote:
&gt;&gt;
&gt;&gt; Hi guys,
&gt;&gt;
&gt;&gt; I am setting up a new Riak cluster and I was wondering if there is any
&gt;&gt; drawback of increasing the LevelDB blocksize from 4K to 64K. The reason is
&gt;&gt; that we have all of the values way bigger than 4K and I guess from the
&gt;&gt; performance point of view it would make sense to increase the block size.
&gt;&gt; The tests are still running to confirm this theory but I wanted to clarify
&gt;&gt; that there is no big red flag of doing that from the Riak side. I found the
&gt;&gt; following discussion about changing block size:
&gt;&gt;
&gt;&gt; https://groups.google.com/forum/#!msg/leveldb/2JJ4smpSC6Q/1Z7aDSeHiRkJ
&gt;&gt;
&gt;&gt; Is that a good idea to experiment with this in Riak to achieve better
&gt;&gt; performance?
&gt;&gt;
&gt;&gt; Thank you in advance,
&gt;&gt; Istvan
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; the sun shines for all
&gt;&gt;
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; --
&gt; the sun shines for all
&gt;
&gt;
&gt;


-- 
the sun shines for all
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

