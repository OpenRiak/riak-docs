---
title: "Re: riak 2.1.1 : Erlang crash dump"
description: ""
project: community
lastmod: 2015-10-04T00:01:29-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16607"
mailinglist_parent_id: "msg16606"
author_name: "Russell Brown"
project_section: "mailinglistitem"
sent_date: 2015-10-04T00:01:29-07:00
---


I doubt it is sibling explosion as 2.1.1 has DVV by default, and the config has 
100 max siblings declared. But it may be, I guess.

Can you send me crash logs, or even the crash dump so I can get a better idea? 
I mean, it surely looks like a memory leak of some kind.

Do you use the “write once” bucket type, or default bucket type? What bucket 
properties on the keys you are writing? Any queries (list\\_keys? 2i?)

Erlang version? Built yourself, or the one shipped with riak? 4 cores but 60gb 
of ram, really, is this because it’s a VM? What does [frame-pointer] mean in 
the header output from erlang there in your first post, I’ve never seen that 
before?

Sorry for all the questions, but at the moment I think more information is the 
way to go. If you want to mail me logs off list, that is fine too.

Cheers

Russell

&gt; On 4 Oct 2015, at 01:43, Matthew Von-Maszewski  wrote:
&gt; 
&gt; Girish,
&gt; 
&gt; This feels like a sibling explosion to me. I cannot help prove or fix it. 
&gt; Writing this paragraph as bait for others to help.
&gt; 
&gt; Matthew
&gt; 
&gt; Sent from my iPad
&gt; 
&gt; On Oct 3, 2015, at 8:34 PM, Girish Shankarraman  
&gt; wrote:
&gt; 
&gt;&gt; Thank you for the response, Jon.
&gt;&gt; 
&gt;&gt; So I changed it to 50% and it crashed again.
&gt;&gt; I have a 5 nodes cluster with 60GB RAM on each node. Ring size is set to 64. 
&gt;&gt; (Attached riak conf if any one has some ideas).
&gt;&gt; 
&gt;&gt; I still see the erlang process consuming the entire capacity of the system 
&gt;&gt; (52 GB).
&gt;&gt; 
&gt;&gt; PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND
&gt;&gt; 24256 riak 20 0 67.134g 0.052t 18740 D 0.0 90.0 2772:44 beam.smp
&gt;&gt; 
&gt;&gt; ---- Cluster Status ----
&gt;&gt; Ring ready: true
&gt;&gt; 
&gt;&gt; +--------------------+------+-------+-----+-------+
&gt;&gt; | node |status| avail |ring |pending|
&gt;&gt; +--------------------+------+-------+-----+-------+
&gt;&gt; | (C) riak@20.0.0.11 |valid | up | 20.3| -- |
&gt;&gt; | riak@20.0.0.12 |valid | up | 20.3| -- |
&gt;&gt; | riak@20.0.0.13 |valid | up | 20.3| -- |
&gt;&gt; | riak@20.0.0.14 |valid | up | 20.3| -- |
&gt;&gt; | riak@20.0.0.15 |valid | up | 18.8| -- |
&gt;&gt; 
&gt;&gt; Thanks,
&gt;&gt; 
&gt;&gt; — Girish Shankarraman
&gt;&gt; 
&gt;&gt; 
&gt;&gt; From: Jon Meredith 
&gt;&gt; Date: Thursday, October 1, 2015 at 2:06 PM
&gt;&gt; To: girish shankarraman , 
&gt;&gt; "riak-users@lists.basho.com" 
&gt;&gt; Subject: Re: riak 2.1.1 : Erlang crash dump
&gt;&gt; 
&gt;&gt; It looks like Riak was unable to allocate 4Gb of memory. You may have to 
&gt;&gt; reduce the amount of memory allocated for leveldb from the default 70%, try 
&gt;&gt; setting this in your /etc/riak/riak.conf file
&gt;&gt; 
&gt;&gt; leveldb.maximum\\_memory.percent = 50
&gt;&gt; 
&gt;&gt; The memory footprint for Riak should stabilize after a few hours and on 
&gt;&gt; servers with smaller amounts of memory, the 30% left over may not be enough.
&gt;&gt; 
&gt;&gt; Please let us know how you get on.
&gt;&gt; 
&gt;&gt; On Wed, Sep 30, 2015 at 5:31 PM Girish Shankarraman 
&gt;&gt;  wrote:
&gt;&gt; I have 7 node cluster for riak with a ring\\_size of 128.
&gt;&gt; 
&gt;&gt; System Details:
&gt;&gt; Each node is a VM with 16GB of memory.
&gt;&gt; The backend is using leveldb.
&gt;&gt; sys\\_system\\_architecture : &lt;&lt;"x86\\_64-unknown-linux-gnu"&gt;&gt;
&gt;&gt; sys\\_system\\_version : &lt;&lt;"Erlang R16B02\\_basho8 (erts-5.10.3) [source] [64-bit] 
&gt;&gt; [smp:4:4] [async-threads:64] [kernel-poll:true] [frame-pointer]"&gt;&gt;
&gt;&gt; riak\\_control\\_version : &lt;&lt;"2.1.1-0-g5898c40"&gt;&gt;
&gt;&gt; cluster\\_info\\_version : &lt;&lt;"2.0.2-0-ge231144"&gt;&gt;
&gt;&gt; yokozuna\\_version : &lt;&lt;"2.1.0-0-gcb41c27”&gt;&gt;
&gt;&gt; 
&gt;&gt; Scenario:
&gt;&gt; We have up to 400-1000 json records being written/sec. Each record might be 
&gt;&gt; a few 100 bytes.
&gt;&gt; I see the following crash message in the erlang logs after a few hours of 
&gt;&gt; processing. Any suggestions on what could be going on here ?
&gt;&gt; 
&gt;&gt; ===== Tue Sep 29 20:20:56 UTC 2015
&gt;&gt; [os\\_mon] memory supervisor port (memsup): Erlang has closed^M
&gt;&gt; [os\\_mon] cpu supervisor port (cpu\\_sup): Erlang has closed^M
&gt;&gt; ^M
&gt;&gt; Crash dump was written to: /var/log/riak/erl\\_crash.dump^M
&gt;&gt; eheap\\_alloc: Cannot allocate 3936326656 bytes of memory (of type "heap").^M
&gt;&gt; 
&gt;&gt; Also tested running this at 50GB per Riak Node(VM) and things work but 
&gt;&gt; memory keeps growing, so throwing hardware at it doesn’t seem very scalable.
&gt;&gt; 
&gt;&gt; Thanks,
&gt;&gt; 
&gt;&gt; — Girish Shankarraman
&gt;&gt; 
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; 
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

