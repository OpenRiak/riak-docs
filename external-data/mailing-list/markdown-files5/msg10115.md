---
title: "Re: Tune Riak for fast inserts - populate DB"
description: ""
project: community
lastmod: 2013-02-13T02:47:59-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg10115"
mailinglist_parent_id: "msg10113"
author_name: "Bogdan Flueras"
project_section: "mailinglistitem"
sent_date: 2013-02-13T02:47:59-08:00
---


Thanks guys :)
I use a ThreadPoolExecutor with 10 threads. I'll try your solutions and
keep you informed

ing. Bogdan Flueras



On Wed, Feb 13, 2013 at 12:40 PM, Guido Medina wrote:

&gt; Also, which I forgot on my reply, make sure your Riak client is connected
&gt; to each node and not only to a single node (cluster config doesn't work
&gt; that well, so try haproxy and make sure you are using protocol buffers)
&gt;
&gt; \\*HA proxy sample config:\\* https://gist.github.com/gburd/1507077
&gt;
&gt; And a single PB config like this one which will connect HA proxy load
&gt; balancer assuming it is running on localhost and it is connected to each
&gt; node:
&gt; \\*
&gt; final PBClientConfig clientConfig=new
&gt; PBClientConfig.Builder().withHost("127.0.0.1").withPort(8087).withPoolSize(N).build();
&gt; \\*
&gt;
&gt; Guido.
&gt;
&gt;
&gt; On 13/02/13 10:29, Guido Medina wrote:
&gt;
&gt; Are you transferring using a single thread? If so, I would recommend you
&gt; to use a ThreaPoolExecutor and schedule each write as you, control the
&gt; failures (if any) using either an AtomicInteger or a
&gt; concurrent/synchronized list where you can track the keys that failed.
&gt;
&gt; No matter how much you do, a single threaded transfer won't help you at
&gt; all. We have done transfers many times and depending on the size of the DB
&gt; table, we use single thread or thread pool service. Try 8 threads and see
&gt; the difference, assuming you have N connections in your Riak client where
&gt; N&gt;max thread pool size.
&gt;
&gt; You might want to remove pw=1 when using multi-threading so Riak doesn't
&gt; fallback behind too much (elevel db catch up? whatever that's called), pw=1
&gt; will add more risk than the benefit you gain.
&gt;
&gt; Hope that helps,
&gt;
&gt; Guido.
&gt;
&gt; On 13/02/13 09:44, Bogdan Flueras wrote:
&gt;
&gt; Ok, so I've done something like this:
&gt; Bucket bucket = client.createBucket("foo"); // lastWriteWins(true)
&gt; doesn't work for Protobuf
&gt;
&gt; when I insert I have:
&gt; bucket.store(someKey, someValue).withoutFetch().pw(1).execute();
&gt;
&gt; It looks like it's 20% faster than before. Is there something I could
&gt; further tweak ?
&gt;
&gt; ing. Bogdan Flueras
&gt;
&gt;
&gt;
&gt; On Wed, Feb 13, 2013 at 10:19 AM, Bogdan Flueras  &gt; wrote:
&gt;
&gt;&gt; Each thread has it's own bucket instance (pointing to the same
&gt;&gt; location) and I don't re-fetch the bucket per insert.
&gt;&gt; Thank you very much!
&gt;&gt;
&gt;&gt; ing. Bogdan Flueras
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; On Wed, Feb 13, 2013 at 10:14 AM, Russell Brown wrote:
&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On 13 Feb 2013, at 08:07, Bogdan Flueras 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; How to set the bucket to last write? Is it in the builder?
&gt;&gt;&gt;
&gt;&gt;&gt; Something like:
&gt;&gt;&gt;
&gt;&gt;&gt; Bucket b = client.createBucket("my\\_bucket").lastWriteWins(true);
&gt;&gt;&gt;
&gt;&gt;&gt; Also, after you've created the bucket, do you use it from all threads?
&gt;&gt;&gt; You don't re-fetch the bucket per-insert operation, do you?
&gt;&gt;&gt;
&gt;&gt;&gt; But the "withoutFecth()" option is probably going to be the biggest
&gt;&gt;&gt; performance increase, and safe if you are only doing inserts.
&gt;&gt;&gt;
&gt;&gt;&gt; Cheers
&gt;&gt;&gt;
&gt;&gt;&gt; Russell
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; I'll have a look..
&gt;&gt;&gt; &gt; Yes, I use more threads and the bucket is configured to spread the
&gt;&gt;&gt; load across all nodes.
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; Thanks, I'll have a deeper look into the API and let you know about my
&gt;&gt;&gt; results.
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; ing. Bogdan Flueras
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; On Wed, Feb 13, 2013 at 10:02 AM, Russell Brown 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; &gt; Hi,
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; On 13 Feb 2013, at 07:37, Bogdan Flueras 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; &gt; Hello all,
&gt;&gt;&gt; &gt; &gt; I've got a 5 node cluster with Riak 1.2.1, all machines are
&gt;&gt;&gt; multicore,
&gt;&gt;&gt; &gt; &gt; with min 4GB RAM.
&gt;&gt;&gt; &gt; &gt;
&gt;&gt;&gt; &gt; &gt; I want to insert something like 50 million records in Riak with the
&gt;&gt;&gt; java client (Protobuf used) with default settings. I've tried also with
&gt;&gt;&gt; HTTP protocol and set w = 1 but got some problems.
&gt;&gt;&gt; &gt; &gt;
&gt;&gt;&gt; &gt; &gt; However the process is very slow: it doesn't write more than 6GB/
&gt;&gt;&gt; hour or aprox. 280 KB/second.
&gt;&gt;&gt; &gt; &gt; To have all my data filled in, it would take aprox 2 days !!
&gt;&gt;&gt; &gt; &gt;
&gt;&gt;&gt; &gt; &gt; What can I do to have the data filled into Riak ASAP?
&gt;&gt;&gt; &gt; &gt; How should I configure the cluster ? (vm.args/ app.config) I don't
&gt;&gt;&gt; care so much about consistency at this point.
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; If you are certain to be only inserting new data setting your
&gt;&gt;&gt; bucket(s) to last write wins will speed things up. Also, are you using
&gt;&gt;&gt; multiple threads for the Java client insert? Spreading the load across all
&gt;&gt;&gt; five nodes? Are you using the "withoutFetch()" option on the java client?
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; Cheers
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; Russell
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt; &gt;
&gt;&gt;&gt; &gt; &gt; Thank you,
&gt;&gt;&gt; &gt; &gt; ing. Bogdan Flueras
&gt;&gt;&gt; &gt; &gt;
&gt;&gt;&gt; &gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; &gt; &gt; riak-users mailing list
&gt;&gt;&gt; &gt; &gt; riak-users@lists.basho.com
&gt;&gt;&gt; &gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt; &gt;
&gt;&gt;&gt; &gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing 
&gt; listriak-users@lists.basho.comhttp://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

