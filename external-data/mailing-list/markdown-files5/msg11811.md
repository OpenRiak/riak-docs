---
title: "Re: Riak 1.4 test on Azure - Webmachine error at path ..."
description: ""
project: community
lastmod: 2013-07-30T05:50:01-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11811"
mailinglist_parent_id: "msg11810"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-07-30T05:50:01-07:00
---


Yes, you can raise max\\_open\\_files as high as you have memory to cover.

The plan for Riak 2.0 is to make these settings automatic and dynamic. Then 
the cache\\_size will automatically decline as max\\_open\\_files increases to cover 
your dataset. Of course, there will be limits to prevent memory going to swap 
or OOM.

Matthew



On Jul 30, 2013, at 4:51 AM, Christian Rosnes  
wrote:

&gt; 
&gt; 
&gt; On Sun, Jul 28, 2013 at 10:08 PM, Matthew Von-Maszewski  
&gt; wrote:
&gt; 
&gt; leveldb has two independent caches: file cache and data block cache. You 
&gt; have raised the data block cache from its default 8M to 256M per your earlier 
&gt; note. I would recommend the follow:
&gt; 
&gt; {max\\_open\\_files, 50}, %% 50 \\* 4Mbytes allocation for file cache
&gt; {cache\\_size, 104857600}, %% 100Mbytes for data block cache
&gt; 
&gt; The max\\_open\\_files default is 20 (which is internally reduced by 10). You 
&gt; are likely thrashing file opens. The file cache is far more important to 
&gt; performance than the data block cache. 
&gt; 
&gt; Find the LOG file within one of your database "vnode" directories. Look for 
&gt; a line like this ' compacted to: files[ 0 9 25 14 2 0 0 ]'. You would like 
&gt; to be covering that total count of files (plus 10) with your max\\_open\\_files 
&gt; setting. Take the cache\\_size down to as low as 8Mbytes to achieve the 
&gt; coverage. Once you are down to 8Mbytes of cache\\_size, you should go no lower 
&gt; and give up on full max\\_open\\_files coverage.
&gt; 
&gt; Summary: total memory per vnode in 1.4 is (max\\_open\\_files - 10) \\* 4Mbytes + 
&gt; cache\\_size;
&gt; 
&gt; 
&gt; Thank you. 
&gt; 
&gt; In app.config I have now set this for the eleveldb section:
&gt; 
&gt; {cache\\_size, 8388608} %% 8MB
&gt; {max\\_open\\_files, 260}
&gt; 
&gt; The 'max\\_open\\_files' was based on the highest sum of the 6 numbers I read
&gt; in the 'compacted to ...' line. Is this the right way to set this parameter,
&gt; or is it too high to have any significant benefit ?
&gt; 
&gt; After the sysctl.conf and app.config changes I've inserted about 
&gt; 50 million json objects via http and not seen any errors. The performance for
&gt; each 1-hour test has ranged from 1700 to 1850 insert req/s. 
&gt; The bucket used during testing now contains over 84 million json objects.
&gt; 
&gt; Btw - when I now check the logs:
&gt; 
&gt; [root@riak01 leveldb]# grep 'compacted' \\*/LOG
&gt; 2013/07/29-19:38:14.650538 7f96a1bdc700 compacted to: files[ 0 1 21 289 0 0 0 
&gt; ]
&gt; 2013/07/29-19:34:58.838520 7f9692138700 compacted to: files[ 2 0 30 288 0 0 0 
&gt; ]
&gt; 2013/07/29-19:38:02.037188 7f96c51b8700 compacted to: files[ 1 0 27 301 0 0 0 
&gt; ]
&gt; 2013/07/29-19:38:12.214409 7f96c51b8700 compacted to: files[ 1 0 26 302 0 0 0 
&gt; ]
&gt; 2013/07/29-19:37:06.503530 7f96a1bdc700 compacted to: files[ 1 1 22 284 0 0 0 
&gt; ]
&gt; 2013/07/29-19:31:41.932370 7f96bffff700 compacted to: files[ 0 1 25 291 0 0 0 
&gt; ]
&gt; 2013/07/29-19:32:18.097417 7f96bffff700 compacted to: files[ 0 1 24 292 0 0 0 
&gt; ]
&gt; 2013/07/29-19:30:20.986832 7f968e538700 compacted to: files[ 2 1 24 278 0 0 0 
&gt; ]
&gt; 2013/07/29-19:37:47.139039 7f96c51b8700 compacted to: files[ 3 0 20 300 0 0 0 
&gt; ]
&gt; 2013/07/29-19:15:10.950633 7f968db37700 compacted to: files[ 0 2 33 263 0 0 0 
&gt; ]
&gt; 2013/07/29-19:33:01.001246 7f968e538700 compacted to: files[ 1 1 30 280 0 0 0 
&gt; ]
&gt; 2013/07/29-19:31:41.494208 7f96bffff700 compacted to: files[ 1 1 25 283 0 0 0 
&gt; ]
&gt; 2013/07/29-19:31:57.008503 7f96bffff700 compacted to: files[ 1 1 24 284 0 0 0 
&gt; ]
&gt; 2013/07/29-19:39:00.008635 7f96a1bdc700 compacted to: files[ 0 1 31 289 0 0 0 
&gt; ]
&gt; 
&gt; Could there be a benefit to increase 'max\\_open\\_files' even further, say to: 
&gt; 340 ? 
&gt; (assuming there is enough memory)
&gt; 
&gt; Christian
&gt; @NorSoulx
&gt; 
&gt; 

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

