---
title: "Re: LevelDB compaction and timeouts"
description: ""
project: community
lastmod: 2013-01-09T08:40:08-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg09768"
mailinglist_parent_id: "msg09760"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2013-01-09T08:40:08-08:00
---


FYI: my theory of the moment (until LOG files arrive) is that maybe a couple 
of the machines are using the operating system swap file during the list\\_keys 
operation. That would explain everything. But maybe you have already ruled 
that out?

Matthew


On Jan 8, 2013, at 2:53 PM, Parnell Springmeyer  wrote:

&gt; Matthew,
&gt; 
&gt; 1. 1.2.1
&gt; 2.
&gt; {eleveldb, [
&gt; {data\\_root, "/var/riak/data/leveldb"}
&gt; ]}
&gt; 3. I'm running 5 physical servers with one Riak node per server.
&gt; 4. Unfortunately all the machines are a hodge podge of parts; we're soon
&gt; going to move to buying our own hardware and coloing it; here's the
&gt; server list (all machines are FreeBSD 9):
&gt; 
&gt; Cores CPU Model CPU Speed RAM HDD Model HDD Size
&gt; 24 Xeon X5650 2.67GHz 48GiB 2X INTEL SSDSA2CW30 on LSI
&gt; MegaRaid SAS 2108 mirrored 280GB
&gt; 4 Xeon E5560 2.13GHz 12GiB Barracuda ST3500418AS 500GB
&gt; 8 Xeon E31230 3.2GHz 8GiB WDC WD1600JS 160GB
&gt; 4 Core2 Q8400 2.66GHz 8GiB Seagate ST500DM002-1BD142 500GB
&gt; 4 Xeon L5320 1.86GHz 12GiB 500GB
&gt; 
&gt; 3. There were no "waiting" entries, but quite a few compaction entries,
&gt; I haven't studied leveldb enough to know if that's "normal" or if it
&gt; indicates heavy compaction.
&gt; 
&gt; The compaction event seemed to be triggered by someone issuing a
&gt; list\\_keys operation; four servers pretty much became unresponsive while
&gt; they were doing compaction. After about an hour only two were dealing
&gt; with compaction but it was still causing the entire cluster to respond
&gt; with timeouts to index().run() queries and M/R jobs.
&gt; 
&gt; I took down those two nodes and marked them as down (riak-admin down)
&gt; and the timeouts disappeared and the cluster operated as it should. So I
&gt; waited till 1AM last night to start the two machines up so they could
&gt; finish compaction. I'm somewhat surprised there isn't a method for
&gt; marking machines as "unavailable" in the event of heavy compaction -
&gt; that way they can finish compacting and the cluster can treat the node
&gt; as unavailable. I don't know how difficult that is though.
&gt;&gt; Parnell,
&gt;&gt; 
&gt;&gt; Would appreciate some configuration info:
&gt;&gt; 
&gt;&gt; - what version of Riak are you running?
&gt;&gt; 
&gt;&gt; - would you copy/paste the eleveldb section of your app.config?
&gt;&gt; 
&gt;&gt; - how many vnodes and physical servers are you running?
&gt;&gt; 
&gt;&gt; - what is hardware? cpu, memory, disk arrays
&gt;&gt; 
&gt;&gt; - are you seeing the work "waiting" in your LOG files?
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Not sure that the above info will lead to a solution. But it is a start.


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

