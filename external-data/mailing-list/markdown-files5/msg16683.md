---
title: "Re: Using Bucket Data Types slowed insert performance"
description: ""
project: community
lastmod: 2015-10-20T20:22:39-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg16683"
mailinglist_parent_id: "msg16680"
author_name: "Alex Moore"
project_section: "mailinglistitem"
sent_date: 2015-10-20T20:22:39-07:00
---


Hi Dennis & Mark,

I noticed some timing code in your snippets:

 long beforeProcessing = DateTime.Now.Ticks;

Do you have any numbers on what an individual operation for KV vs CRDTs
looks like on your system? (Mean, percentiles if possible)
Also, how big are your KV objects?

CRDTs will take extra processing on Riak's side, so I'm wondering if you're
getting limited by a longer RTT + your 20 threads. One easy thing to try
would be to double the thread pool (and connections) and see if that shaves
off any overall time by overlapping the time we're waiting for Riak to
respond.

If it doesn't, then we can look in other directions :)

Thanks,
Alex


On Tue, Oct 20, 2015 at 3:25 PM, Dennis Nicolay 
wrote:

&gt;
&gt;
&gt; ResultObject cdr;
&gt;
&gt; while (queued.TryDequeue(out cdr))
&gt;
&gt; {
&gt;
&gt; long beforeProcessing = DateTime.Now.Ticks;
&gt;
&gt; UpdateMap.Builder builder = BuildMapObject(bucket,
&gt; cdr);
&gt;
&gt; UpdateMap cmd = builder.Build();
&gt;
&gt; RiakResult rslt = client.Execute(cmd);
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; \\*private static UpdateMap.Builder BuildMapObject(string bucketname,
&gt; ResultObject cdr )\\*
&gt;
&gt; \\* {\\*
&gt;
&gt;
&gt;
&gt; \\* var builder = new UpdateMap.Builder()\\*
&gt;
&gt; \\* .WithBucketType("maps")\\*
&gt;
&gt; \\* .WithBucket(bucketname)\\*
&gt;
&gt; \\* .WithKey(cdr.CdrKey); \\*
&gt;
&gt; \\* var mapOperation = new UpdateMap.MapOperation();\\*
&gt;
&gt; \\* mapOperation.SetRegister("FileTimeStamp",
&gt; cdr.CdrValue.FileTimeStamp.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("AuditId",
&gt; cdr.CdrValue.AuditId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CdrId",
&gt; cdr.CdrValue.CdrId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("IsBillable",
&gt; cdr.CdrValue.IsBillable.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SwitchId",
&gt; cdr.CdrValue.SwitchId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SwitchDescription",
&gt; cdr.CdrValue.SwitchDescription.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SequenceNumber",
&gt; cdr.CdrValue.SequenceNumber.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CallDirection",
&gt; cdr.CdrValue.CallDirection.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CallTypeId",
&gt; cdr.CdrValue.CallTypeId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("Partition",
&gt; cdr.CdrValue.Partition.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustomerTrunkId",
&gt; cdr.CdrValue.CustomerTrunkId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OrigIpAddress",
&gt; cdr.CdrValue.OrigIpAddress.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OrigPort",
&gt; cdr.CdrValue.OrigPort.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SupplierTrunkId",
&gt; cdr.CdrValue.SupplierTrunkId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("TermIpAddress",
&gt; cdr.CdrValue.TermIpAddress.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("TermPort",
&gt; cdr.CdrValue.TermPort.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("Ani", cdr.CdrValue.Ani.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OutpulseNumber",
&gt; cdr.CdrValue.OutpulseNumber.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SubscriberNumber",
&gt; cdr.CdrValue.SupplierTrunkId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CallingNoa",
&gt; cdr.CdrValue.CallingNoa.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("DialedNoa",
&gt; cdr.CdrValue.DialedNoa.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OutpulseNoa",
&gt; cdr.CdrValue.OutpulseNumber.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("TreatmentCode",
&gt; cdr.CdrValue.TreatmentCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CompletionCode",
&gt; cdr.CdrValue.CompletionCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustomerName",
&gt; cdr.CdrValue.CustomerName.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustId",
&gt; cdr.CdrValue.CustId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustContractId",
&gt; cdr.CdrValue.CustContractId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustCountryCode",
&gt; cdr.CdrValue.CustCountryCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustDuration",
&gt; cdr.CdrValue.CustDuration.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("Price",
&gt; cdr.CdrValue.Price.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("BasePrice",
&gt; cdr.CdrValue.BasePrice.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("BillingDestinationName",
&gt; cdr.CdrValue.BillingDestinationName.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("BillingGroupId",
&gt; cdr.CdrValue.BillingGroupId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SupplierName",
&gt; cdr.CdrValue.SupplierName.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SuppId",
&gt; cdr.CdrValue.SuppId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SuppContractId",
&gt; cdr.CdrValue.SuppContractId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SuppCountryCode",
&gt; cdr.CdrValue.SuppCountryCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SuppDuration",
&gt; cdr.CdrValue.SuppDuration.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("Cost",
&gt; cdr.CdrValue.Cost.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("BaseCost",
&gt; cdr.CdrValue.BaseCost.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("RoutingDestinationName",
&gt; cdr.CdrValue.RoutingDestinationName.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("RoutingGroupId",
&gt; cdr.CdrValue.RoutingGroupId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("RouteToCountryCode",
&gt; cdr.CdrValue.RouteToCountryCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("Pdd", cdr.CdrValue.Pdd.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("RealDuration",
&gt; cdr.CdrValue.RealDuration.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("StartTime",
&gt; cdr.CdrValue.StartTime.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("EndTime",
&gt; cdr.CdrValue.EndTime.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("NumberCalled",
&gt; cdr.CdrValue.NumberCalled.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CallingLataOcn",
&gt; cdr.CdrValue.CallingLataOcn.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("DialedLataOcn",
&gt; cdr.CdrValue.DialedLataOcn.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("LrnLataOcn",
&gt; cdr.CdrValue.LrnLataOcn.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("CustomerPrefix",
&gt; cdr.CdrValue.CustomerPrefix.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("SupplierPrefix",
&gt; cdr.CdrValue.SupplierPrefix.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OriginationCountryCode",
&gt; cdr.CdrValue.OriginationCountryCode.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("OriginationCost",
&gt; cdr.CdrValue.OriginationCost.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("FixedPricePerCall",
&gt; cdr.CdrValue.FixedPricePerCall.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("FixedCostPerCall",
&gt; cdr.CdrValue.FixedCostPerCall.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("InvoiceId",
&gt; cdr.CdrValue.InvoiceId.ToString());\\*
&gt;
&gt; \\* mapOperation.SetRegister("BusinessId",
&gt; cdr.CdrValue.BusinessId.ToString());\\*
&gt;
&gt;
&gt;
&gt; \\* builder.WithMapOperation(mapOperation);\\*
&gt;
&gt; \\* return builder;\\*
&gt;
&gt; \\* }\\*
&gt;
&gt;
&gt;
&gt;
&gt;
&gt; \\*From:\\* Christopher Mancini [mailto:cmanc...@basho.com]
&gt; \\*Sent:\\* Tuesday, October 20, 2015 11:52 AM
&gt; \\*To:\\* Mark Schmidt; Alexander Sicular; Dennis Nicolay
&gt; \\*Cc:\\* riak-users@lists.basho.com
&gt;
&gt; \\*Subject:\\* Re: Using Bucket Data Types slowed insert performance
&gt;
&gt;
&gt;
&gt; Hi Mark / Dennis,
&gt;
&gt; Can you provide the snippet of the code that puts a 5k record onto Riak as
&gt; a map?
&gt;
&gt; Chris
&gt;
&gt;
&gt;
&gt; On Tue, Oct 20, 2015 at 11:30 AM Mark Schmidt 
&gt; wrote:
&gt;
&gt; Hi folks, sorry for the confusion.
&gt;
&gt;
&gt;
&gt; Our scenario is as follows:
&gt;
&gt;
&gt;
&gt; We have a 6 node development cluster running on its own network segment
&gt; using HAProxy to facilitate load-balancing across the nodes. A single
&gt; Riak-dot-NET client service is performing the insert operations from
&gt; dedicated hardware located within the same network segment. We have basic
&gt; network throughput capabilities of 100 Mbit with an average speed
&gt; achievable of 75 Mbit.
&gt;
&gt;
&gt;
&gt; The data we are attempting to insert is composed of phone call record
&gt; receipts from telephone carriers. These records are batched and written to
&gt; a flat file for incorporation into our reporting engine. 1) Our Riak client
&gt; process takes a flat file (In this case, a 40MB collection of records, each
&gt; record being approximately 5k in size) and parses the entire file so each
&gt; record can be added to a local .NET queue.
&gt;
&gt; 2) Once the entire file has been parsed and each record loaded into the
&gt; local queue, 20 threads are spawned and connections are opened to our Riak
&gt; nodes via the HAProxy.
&gt;
&gt; 3) Each thread will pull a 5k record from the queue on a first come first
&gt; served basis and perform a put to the Riak environment.
&gt;
&gt;
&gt;
&gt; When first testing our client insert process, we were pushing the 5K
&gt; records as whole strings into the Riak environment. Network throughput
&gt; topped out at around 80 Mbits with a total load time of 90 seconds for 149k
&gt; records. When the client process was modified (same queuing and de-queuing
&gt; methods) so that a map datatype bucket would be created and keys stored as
&gt; registers, we saw network throughput drop to around 10 Mbit with total
&gt; upload time increase to around 270 seconds for the 149k records.
&gt;
&gt;
&gt;
&gt; It appears as though we’ve either encountered a potential bottleneck
&gt; unrelated to network throughput, or we’re just seeing an expected
&gt; processing penalty for our use of Riak datatypes. Please note, we’re
&gt; configuring Zabbix so we can monitor disk IO on each node as processor and
&gt; memory resources don’t appear to be the culprit either.
&gt;
&gt;
&gt;
&gt; If the reduction in processing speed is a natural consequence to utilizing
&gt; Riak data types, is the inter-node network the optimum place to increase
&gt; resources? Our eventual datacenter implementation will support speeds of
&gt; over 40 Gbit for inter-node communication. We’re just trying to identify
&gt; which levers from an operational standpoint we can throw to boost
&gt; performance, or if our client implementation is suspect.
&gt;
&gt;
&gt;
&gt; You bring up some excellent points regarding our use of CRDTs. In our
&gt; case, the call data records are mutable as they are subject to changes by
&gt; phone carriers for billing error corrections, incorrect data and a host of
&gt; other reasons. We may be better served by treating the records as immutable
&gt; and performing wide scale record removal and “reprocessing” in the event
&gt; changes to existing records are received/requested.
&gt;
&gt;
&gt;
&gt; Thank you,
&gt;
&gt;
&gt;
&gt; Mark Schmidt
&gt;
&gt;
&gt;
&gt; \\*From:\\* Alexander Sicular [mailto:sicul...@gmail.com]
&gt; \\*Sent:\\* Tuesday, October 20, 2015 10:55 AM
&gt; \\*To:\\* Dennis Nicolay 
&gt; \\*Cc:\\* Christopher Mancini ; riak-users@lists.basho.com;
&gt; Mark Schmidt 
&gt;
&gt;
&gt; \\*Subject:\\* Re: Using Bucket Data Types slowed insert performance
&gt;
&gt;
&gt;
&gt; Let's talk about Riak data types for a moment. Riak data types are
&gt; collectively implementations of what academia refer to as CRDT's
&gt; (convergent or conflict free replicated data types.) The key benefit a CRDT
&gt; offers, over a traditional KV by contrast, is in automatic conflict
&gt; resolution. The various CRDT's provided in Riak have specific conflict
&gt; resolution strategies. This does not come for free. There is a
&gt; computational cost associated with CRDT's. If your use case requires
&gt; automated conflict resolution strategies than CRDT's are a good fit.
&gt; Internally CRDT's rely on vector clocks (see DVV's in the documentation) to
&gt; resolve conflict.
&gt;
&gt;
&gt;
&gt; Considering your ETL use case I'm going to presume that your data is
&gt; immutable (I could very well be wrong here.) If your data is immutable I
&gt; would consider simply using a KV and not paying the CRDT computational
&gt; penalty (and possibly even the write once bucket.) The CRDT penalty you pay
&gt; is obviously subjective to your use case, configuration, hw deployment etc.
&gt;
&gt;
&gt;
&gt; Hope that helps!
&gt; -Alexander
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt; http://siculars.posthaven.com
&gt;
&gt;
&gt;
&gt; Sent from my iRotaryPhone
&gt;
&gt;
&gt; On Oct 20, 2015, at 12:39, Dennis Nicolay  wrote:
&gt;
&gt; Hi Alexander,
&gt;
&gt;
&gt;
&gt; I’m parsing the file and storing each row with own key in a map datatype
&gt; bucket and each column is a register.
&gt;
&gt;
&gt;
&gt; Thanks,
&gt;
&gt; Dennis
&gt;
&gt;
&gt;
&gt; \\*From:\\* Alexander Sicular [mailto:sicul...@gmail.com ]
&gt;
&gt; \\*Sent:\\* Tuesday, October 20, 2015 10:34 AM
&gt; \\*To:\\* Dennis Nicolay
&gt; \\*Cc:\\* Christopher Mancini; riak-users@lists.basho.com
&gt; \\*Subject:\\* Re: Using Bucket Data Types slowed insert performance
&gt;
&gt;
&gt;
&gt; Hi Dennis,
&gt;
&gt;
&gt;
&gt; It's a bit unclear what you are trying to do here. Are you 1. uploading
&gt; the entire file and saving it to one key with the value being the file? Or
&gt; are you 2. parsing the file and storing each row as a register in a map?
&gt;
&gt;
&gt;
&gt; Either of those approaches are not appropriate in Riak KV. For the first
&gt; case I would point you to Riak S2 which is designed to manage large binary
&gt; object storage. You can keep the large file as a single addressable entity
&gt; and access it via Amazon S3 or Swift protocol. For the second case I would
&gt; consider maintaining one key (map) per row in the file and have a register
&gt; per column in the row. Or not use Riak data types (maps, sets, registers,
&gt; flags and counters) and simply keep each row in the file as a KV in Riak
&gt; either as a raw string or as a serialized json string. ETL'ing out of
&gt; relational databases and into Riak is a very common use case and often
&gt; implemented in the fashion I described.
&gt;
&gt;
&gt;
&gt; As Chris mentioned, soft upper bound on value size should be 1MB. I say
&gt; soft because we won't enforce it although there are settings in the config
&gt; that can be changed to enforce it (default 5MB warning, 50MB reject I
&gt; believe.)
&gt;
&gt; Best,
&gt;
&gt; Alexander
&gt;
&gt;
&gt;
&gt; @siculars
&gt;
&gt; http://siculars.posthaven.com
&gt;
&gt;
&gt;
&gt; Sent from my iRotaryPhone
&gt;
&gt;
&gt; On Oct 20, 2015, at 10:22, Christopher Mancini  wrote:
&gt;
&gt; Hi Dennis,
&gt;
&gt; I am not the most experienced, but what I do know is that a file that size
&gt; causes a great deal of network chatter because it has to handoff that data
&gt; to the other nodes in the network and will cause delays in Riak's ability
&gt; to send and confirm consistency across the ring. Typically we recommend
&gt; that you try to structure your objects to around 1mb or less to ensure
&gt; consistent performance. That max object size can vary of course based on
&gt; your network / server specs and configuration.
&gt;
&gt; I hope this helps.
&gt;
&gt; Chris
&gt;
&gt;
&gt;
&gt; On Tue, Oct 20, 2015 at 8:18 AM Dennis Nicolay 
&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt;
&gt;
&gt; I’m using .net RiakClient 2.0 to insert a 44mb delimited file with 139k
&gt; rows of data into riak. I switched to a map bucket data type with
&gt; registers. It is taking about 3 times longer to insert into this bucket
&gt; vs non data typed bucket. Any suggestions?
&gt;
&gt;
&gt;
&gt; Thanks in advance,
&gt;
&gt; Dennis
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

