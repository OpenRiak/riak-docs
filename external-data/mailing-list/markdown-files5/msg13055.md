---
title: "Re: Using Riak to perform aggregate queries"
description: ""
project: community
lastmod: 2013-11-21T15:07:50-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg13055"
author_name: "NC"
project_section: "mailinglistitem"
sent_date: 2013-11-21T15:07:50-08:00
---


Our use-case is very similar to what Chris has described till now. I am new
to the riak store and have a background with RDBMS.

Going over this thread, there was a suggestion to pre-compute things. I am
trying to understand what pre-compute exactly means. Does it mean using pre
or post commit hooks to perform aggregation as different events enter our
system? Or does it mean running map reduce jobs in the background to
precompute the aggregations?

A brief background on our use-case. We have vendors in our system that get
millions of events every week. Every two weeks, we sum the amount on all the
events for the vendor to generate an invoice. Querying millions of events
for the vendor using secondary indices or key filters doesn't seem feasible
in riak. I am wondering if we can use post-commit hooks so that as events
enter our system, we maintain a real-time account for the vendor, adding and
subtracting things on the go. When the time comes to create an invoice, we
just look at the account to find the amount to pay to the vendor.

My questions are: can we even use post-commit hook in that manner where we
insert / update multiple records? Is there a different way to design such a
schema that I am missing?

Thanks.



--
View this message in context: 
http://riak-users.197444.n3.nabble.com/Using-Riak-to-perform-aggregate-queries-tp4027668p4029900.html
Sent from the Riak Users mailing list archive at Nabble.com.

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

