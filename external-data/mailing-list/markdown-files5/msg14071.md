---
title: "Re: oddness when using java client within storm"
description: ""
project: community
lastmod: 2014-04-14T08:56:34-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg14071"
mailinglist_parent_id: "msg14070"
author_name: "Russell Brown"
project_section: "mailinglistitem"
sent_date: 2014-04-14T08:56:34-07:00
---


HTTP or PB? Pretty sure the HTTP client defaults to a pool of 50 connections.

On 14 Apr 2014, at 16:50, Sean Allen  wrote:

&gt; We fire off 100 requests for the items in the batch and wait on the futures 
&gt; to complete.
&gt; 
&gt; 
&gt; On Mon, Apr 14, 2014 at 11:40 AM, Alexander Sicular  
&gt; wrote:
&gt; I'm not sure what "looking up entries... in batches of 100 from Riak" 
&gt; devolves into in the java client but riak doesn't have a native multiget. It 
&gt; either does 100 get ops or a [search&gt;]mapreduce. That might inform some of 
&gt; your performance issues.
&gt; 
&gt; -Alexander
&gt; 
&gt; @siculars
&gt; http://siculars.posthaven.com
&gt; 
&gt; Sent from my iRotaryPhone
&gt; 
&gt; &gt; On Apr 14, 2014, at 8:26, Sean Allen  wrote:
&gt; &gt;
&gt; &gt; I'm seeing something very odd trying to scale out part of code I'm working 
&gt; &gt; on.
&gt; &gt;
&gt; &gt; It runs inside of Storm and lookups up entries from 10 node riak cluster.
&gt; &gt; I've hit a wall that we can't get past. We are looking up entries (json 
&gt; &gt; representation of a job)
&gt; &gt; in batches of 100 from Riak, each batch gets handled by a bolt in Storm, 
&gt; &gt; adding more
&gt; &gt; bolts (an instance of the bolt class with a dedicated thread) results in no 
&gt; &gt; increase
&gt; &gt; in performance. I instrumted the code and saw that waiting for all riak 
&gt; &gt; futures to finish
&gt; &gt; increases as more bolts are added. Thinking that perhaps there was 
&gt; &gt; contention around the
&gt; &gt; RiakCluster object that we were sharing per jvm, I tried giving each bolt 
&gt; &gt; instance its own
&gt; &gt; cluster object and there wasn't any change.
&gt; &gt;
&gt; &gt; Note that changing Thread spool size given to withExecutor not 
&gt; &gt; withExecutionAttempts value
&gt; &gt; has any impact.
&gt; &gt;
&gt; &gt; We're working off of the develop branch for the java client. We've been 
&gt; &gt; using d3cc30d but I also tried with cef7570 and had the same issue.
&gt; &gt;
&gt; &gt; A simplied version of the scala code running this:
&gt; &gt;
&gt; &gt; // called once upon bolt initialization.
&gt; &gt; def prepare(config: JMap[\\_, \\_],
&gt; &gt; context: TopologyContext,
&gt; &gt; collector: OutputCollector): Unit = {
&gt; &gt; ...
&gt; &gt;
&gt; &gt; val nodes = RiakNode.Builder.buildNodes(new RiakNode.Builder, (1 to 
&gt; &gt; 10).map(n =&gt; s"riak-beavis-$n").toList.asJava)
&gt; &gt; riak = new RiakCluster.Builder(nodes)
&gt; &gt; // varying this has made no difference
&gt; &gt; .withExecutionAttempts(1)
&gt; &gt; // nor has varying this
&gt; &gt; .withExecutor(new ScheduledThreadPoolExecutor(200))
&gt; &gt; .build()
&gt; &gt; riak.start
&gt; &gt;
&gt; &gt; ...
&gt; &gt; }
&gt; &gt;
&gt; &gt; private def get(jobLocationId: String): 
&gt; &gt; RiakFuture[FetchOperation.Response] = {
&gt; &gt; val location = new 
&gt; &gt; Location("jobseeker-job-view").setBucketType("no-siblings").setKey(jobLocationId)
&gt; &gt; val fop = new 
&gt; &gt; FetchOperation.Builder(location).withTimeout(75).withR(1).build
&gt; &gt;
&gt; &gt; riak.execute(fop)
&gt; &gt; }
&gt; &gt;
&gt; &gt; def execute(tuple: Tuple): Unit = {
&gt; &gt; val indexType = tuple.getStringByField("index\\_type")
&gt; &gt; val indexName = tuple.getStringByField("index\\_name")
&gt; &gt; val batch = tuple.getValueByField("batch").asInstanceOf[Set[Payload]]
&gt; &gt;
&gt; &gt; var lookups: Set[(Payload, RiakFuture[FetchOperation.Response])] = 
&gt; &gt; Set.empty
&gt; &gt;
&gt; &gt; // this always returns in a standard time based on batch size
&gt; &gt; time("dispatch-calls") {
&gt; &gt; lookups = batch.filter(\\_.key.isDefined).map {
&gt; &gt; payload =&gt; {(payload, get(payload.key.get))}
&gt; &gt; }
&gt; &gt; }
&gt; &gt;
&gt; &gt; val futures = lookups.map(\\_.\\_2)
&gt; &gt;
&gt; &gt; // this is what takes longer and longer when more bolts are added.
&gt; &gt; // it doesnt matter what the sleep time is.
&gt; &gt; time("waiting-on-futures") {
&gt; &gt; while (futures.count(!\\_.isDone) &gt; 0) {
&gt; &gt; Thread.sleep(25L)
&gt; &gt; }
&gt; &gt; }
&gt; &gt;
&gt; &gt;
&gt; &gt; // everything from here to the end returns in a fixed amount of time
&gt; &gt; // and doesn't change with the number of bolts
&gt; &gt; ...
&gt; &gt;
&gt; &gt; }
&gt; &gt;
&gt; &gt;
&gt; &gt; It seems like we are running into contention somewhere in the riak java 
&gt; &gt; client.
&gt; &gt; My first thought was the LinkedBlockingQueue that serves as the retry queue 
&gt; &gt; in RiakCluster
&gt; &gt; but, I've tried running with only a single execution attempt as well as a 
&gt; &gt; custom client
&gt; &gt; version where I removed all retries from the codebase and still experience 
&gt; &gt; the same problem.
&gt; &gt;
&gt; &gt; I'm still digging through the code looking for possible points of 
&gt; &gt; contention.
&gt; &gt;
&gt; &gt; Any thoughts?
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; 
&gt; 
&gt; 
&gt; -- 
&gt; 
&gt; Ce n'est pas une signature
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

