---
title: "Re: Riak Nodes Crashing"
description: ""
project: community
lastmod: 2014-12-08T09:29:47-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg15332"
mailinglist_parent_id: "msg15331"
author_name: "Matthew Von-Maszewski"
project_section: "mailinglistitem"
sent_date: 2014-12-08T09:29:47-08:00
---


Satish,

This is to be expected. You have a ring size of 64 and 5 nodes. 5 does not 
evenly divide into 64. 4 nodes contain 13 vnodes. One node only contains 12 
vnodes:

13 / 64 = 20.3125%
12 / 64 = 18.75 %

All is fine.

Matthew


On Dec 8, 2014, at 12:17 PM, ender  wrote:

&gt; I intend to upgrade to 2.0 at some point but that will be a bigger task. 
&gt; Another question:
&gt; 
&gt; [ec2-user@ip-10-197-93-214 ~]$ sudo riak-admin member\\_status
&gt; ================================= Membership 
&gt; ==================================
&gt; Status Ring Pending Node
&gt; -------------------------------------------------------------------------------
&gt; valid 20.3% -- 'riak@10.196.72.106'
&gt; valid 20.3% -- 'riak@10.196.72.124'
&gt; valid 20.3% -- 'riak@10.196.72.247'
&gt; valid 20.3% -- 'riak@10.197.93.214'
&gt; valid 18.8% -- 'riak@10.197.94.33'
&gt; -------------------------------------------------------------------------------
&gt; Valid:5 / Leaving:0 / Exiting:0 / Joining:0 / Down:0
&gt; 
&gt; When I first created the cluster, all 5 nodes Ring matched to within 0.1% of 
&gt; each other. Now node 5 has consistently been at a lower percentage than the 
&gt; other 4. Is this normal?
&gt; 
&gt; 
&gt; On Mon, Dec 8, 2014 at 9:06 AM, Matthew Von-Maszewski  
&gt; wrote:
&gt; Satish,
&gt; 
&gt; This additional information continues to support my suspicion that the memory 
&gt; management is not fully accounting for your number of open files. A large 
&gt; query can cause many files that were previously unused to open. An open 
&gt; table file in leveldb uses memory heavily (for the file's block index and 
&gt; bloom filter). Also, leveldb will allow the memory limit to be knowingly 
&gt; exceeded in the case of queries that cover large segments of the key space.
&gt; 
&gt; There are fixes for both of those scenarios in Riak 2.0, but not in the 1.x 
&gt; series.
&gt; 
&gt; Matthew 
&gt; 
&gt; 
&gt; On Dec 8, 2014, at 11:22 AM, ender  wrote:
&gt; 
&gt;&gt; Hello Matthew,
&gt;&gt; 
&gt;&gt; I was going through my cluster setup again, checking up on stuff, when I 
&gt;&gt; noticed something. So just for some background, when I originally started 
&gt;&gt; using Riak it was as a replacement for MongoDB. To get things up and 
&gt;&gt; running quickly I "cheated" and just wrote some code that took a MongoDB 
&gt;&gt; query and recast it as a Riak search query. Then I enabled the search hook 
&gt;&gt; on all my buckets, and it just worked! Of course, Riak search wasn't the 
&gt;&gt; fastest thing on 2 legs, so I started to redo my data model to make it more 
&gt;&gt; key-value store friendly. Where I had to, I used secondary indexes. Once 
&gt;&gt; I'd converted the data model for a bucket I would remove the search hook on 
&gt;&gt; that bucket. On Friday evening I discovered that on 2 of my buckets I'd 
&gt;&gt; forgotten to remove the search hook. One of the buckets only has a couple 
&gt;&gt; of thousand records in it, so no big deal. But the other one! - that bucket 
&gt;&gt; has the most reads, the most writes, and has over 200M records stored in it. 
&gt;&gt; I removed the search hook on both of those buckets and the cluster has been 
&gt;&gt; stable over the weekend and is still up as of now. I did not disable active 
&gt;&gt; anti-entropy, since I did not want to change too many variables at the same 
&gt;&gt; time. I will do that today. Question is, was this a coincidence or do you 
&gt;&gt; think it's possible the search indexing was causing the OOM errors?
&gt;&gt; 
&gt;&gt; Satish
&gt;&gt; 
&gt;&gt; On Sat, Dec 6, 2014 at 6:59 AM, Matthew Von-Maszewski  
&gt;&gt; wrote:
&gt;&gt; Satish,
&gt;&gt; 
&gt;&gt; I do NOT recommend adding a sixth node before the other five are stable 
&gt;&gt; again. There was another customer that did that recently and things just 
&gt;&gt; got worse due to the vnode handoff actions to the sixth node.
&gt;&gt; 
&gt;&gt; I do recommend one or both of the following:
&gt;&gt; 
&gt;&gt; - disable active anti-entropy in app.config, {anti\\_entropy, {off, []}}. 
&gt;&gt; Then restart all nodes. We quickly replaced 1.4.7 due to an bug in the 
&gt;&gt; active anti-entropy. I do not know the details of the bug. But no one had 
&gt;&gt; seen a crash from it. However, you may be seeing a long term problem due to 
&gt;&gt; that same bug. The anti-entropy feature in 1.4.7 is not really protecting 
&gt;&gt; your data anyway. It might as well be disabled until you are ready to 
&gt;&gt; upgrade.
&gt;&gt; 
&gt;&gt; - further reduce the max\\_open\\_files parameter simply to get memory stable: 
&gt;&gt; use 75 instead of the recent 150. You must restart all nodes after making 
&gt;&gt; the change in app.config.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; I will need to solicit support from others at Basho if the two workarounds 
&gt;&gt; above do not stabilize the cluster. 
&gt;&gt; 
&gt;&gt; Matthew
&gt;&gt; 
&gt;&gt; On Dec 5, 2014, at 5:54 PM, ender  wrote:
&gt;&gt; 
&gt;&gt;&gt; Would adding a 6th node mean each node would use less memory as a stopgap 
&gt;&gt;&gt; measure?
&gt;&gt;&gt; 
&gt;&gt;&gt; On Fri, Dec 5, 2014 at 2:20 PM, ender  wrote:
&gt;&gt;&gt; Hey Matthew it just crashed again. This time I got the syslog and leveldb 
&gt;&gt;&gt; logs right away.
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On Fri, Dec 5, 2014 at 11:43 AM, Matthew Von-Maszewski  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; Satish,
&gt;&gt;&gt; 
&gt;&gt;&gt; Here is a key line from /var/log/messages:
&gt;&gt;&gt; 
&gt;&gt;&gt; Dec 5 06:52:43 ip-10-196-72-106 kernel: [26881589.804401] beam.smp invoked 
&gt;&gt;&gt; oom-killer: gfp\\_mask=0x201da, order=0, oom\\_adj=0, oom\\_score\\_adj=0
&gt;&gt;&gt; 
&gt;&gt;&gt; The log entry does NOT match the timestamps of the crash.log and error.log 
&gt;&gt;&gt; below. But that is ok. The operating system killed off Riak. There would 
&gt;&gt;&gt; have be no notification in the Riak log's of the operating system's actions.
&gt;&gt;&gt; 
&gt;&gt;&gt; The fact that the out of memory monitor, oom-killer, killed Riak further 
&gt;&gt;&gt; supports the change to max\\_open\\_files. I recommend we now wait to see if 
&gt;&gt;&gt; the problem occurs again.
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; Matthew
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On Dec 5, 2014, at 2:35 PM, ender  wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Hey Matthew,
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The crash occurred around 3:00am:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; -rw-rw-r-- 1 riak riak 920 Dec 5 03:01 crash.log
&gt;&gt;&gt;&gt; -rw-rw-r-- 1 riak riak 617 Dec 5 03:01 error.log
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; I have attached the syslog that covers that time. I also went ahead and 
&gt;&gt;&gt;&gt; changed max\\_open\\_files in app.config to to 150 from 315.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Satish
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On Fri, Dec 5, 2014 at 11:29 AM, Matthew Von-Maszewski 
&gt;&gt;&gt;&gt;  wrote:
&gt;&gt;&gt;&gt; Satish,
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The "key" system log varies by Linux platform. Yes, /var/log/messages may 
&gt;&gt;&gt;&gt; hold some key clues. Again, be sure the file covers the time of a crash.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On Dec 5, 2014, at 1:29 PM, ender  wrote:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Hey Matthew,
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; I see a /var/log/messages file, but no syslog or system.log etc. Is it 
&gt;&gt;&gt;&gt;&gt; the messages file you want?
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Satish
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; On Fri, Dec 5, 2014 at 10:06 AM, Matthew Von-Maszewski 
&gt;&gt;&gt;&gt;&gt;  wrote:
&gt;&gt;&gt;&gt;&gt; Satish,
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; I find nothing compelling in the log or the app.config. Therefore I have 
&gt;&gt;&gt;&gt;&gt; two additional suggestions/requests:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; - lower max\\_open\\_files in app.config to to 150 from 315. There was one 
&gt;&gt;&gt;&gt;&gt; other customer report regarding the limit not properly stopping out of 
&gt;&gt;&gt;&gt;&gt; memory (OOM) conditions.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; - try to locate a /var/log/syslog\\* file from a node that contains the 
&gt;&gt;&gt;&gt;&gt; time of the crash. There may be helpful information there. Please send 
&gt;&gt;&gt;&gt;&gt; that along.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Unrelated to this crash … 1.4.7 has a known bug in its active 
&gt;&gt;&gt;&gt;&gt; anti-entropy (AAE) logic. This bug is NOT known to cause a crash. The 
&gt;&gt;&gt;&gt;&gt; bug does cause AAE to be unreliable for data restoration. The proper 
&gt;&gt;&gt;&gt;&gt; steps for upgrading to the current release (1.4.12) are:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; -- across the entire cluster
&gt;&gt;&gt;&gt;&gt; - disable anti\\_entropy in app.config on all nodes: {anti\\_entropy, {off, 
&gt;&gt;&gt;&gt;&gt; []}}
&gt;&gt;&gt;&gt;&gt; - perform a rolling restart of all nodes … AAE is now disabled in the 
&gt;&gt;&gt;&gt;&gt; cluster 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; -- on each node
&gt;&gt;&gt;&gt;&gt; - stop the node
&gt;&gt;&gt;&gt;&gt; - remove (erase all files and directories) /vol/lib/riak/anti\\_entropy
&gt;&gt;&gt;&gt;&gt; - update Riak to the new software revision
&gt;&gt;&gt;&gt;&gt; - start the node again
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; -- across the entire cluster
&gt;&gt;&gt;&gt;&gt; - enable anti\\_entropy in app.config on all nodes: {anti\\_entropy, {on, []}}
&gt;&gt;&gt;&gt;&gt; - perform a rolling restart of all nodes … AAE is now enabled in the 
&gt;&gt;&gt;&gt;&gt; cluster 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; The nodes will start rebuilding the AAE hash data. Suggest you perform 
&gt;&gt;&gt;&gt;&gt; the last rolling restart during a low utilization time of your cluster.
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; On Dec 5, 2014, at 11:02 AM, ender  wrote:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Hi Matthew,
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Riak version: 1.4.7
&gt;&gt;&gt;&gt;&gt;&gt; 5 Nodes in cluster
&gt;&gt;&gt;&gt;&gt;&gt; RAM: 30GB
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; The leveldb logs are attached.
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; On Thu, Dec 4, 2014 at 1:34 PM, Matthew Von-Maszewski 
&gt;&gt;&gt;&gt;&gt;&gt;  wrote:
&gt;&gt;&gt;&gt;&gt;&gt; Satish,
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Some questions:
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; - what version of Riak are you running? logs suggest 1.4.7
&gt;&gt;&gt;&gt;&gt;&gt; - how many nodes in your cluster?
&gt;&gt;&gt;&gt;&gt;&gt; - what is the physical memory (RAM size) of each node?
&gt;&gt;&gt;&gt;&gt;&gt; - would you send the leveldb LOG files from one of the crashed servers:
&gt;&gt;&gt;&gt;&gt;&gt; tar -czf satish\\_LOG.tgz /vol/lib/riak/leveldb/\\*/LOG\\*
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Matthew
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; On Dec 4, 2014, at 4:02 PM, ender  wrote:
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; My RIak installation has been running successfully for about a year. 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; This week nodes suddenly started randomly crashing. The machines have 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; plenty of memory and free disk space, and looking in the ring 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; directory nothing appears to amiss:
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; [ec2-user@ip-10-196-72-247 ~]$ ls -l /vol/lib/riak/ring
&gt;&gt;&gt;&gt;&gt;&gt; &gt; total 80
&gt;&gt;&gt;&gt;&gt;&gt; &gt; -rw-rw-r-- 1 riak riak 17829 Nov 29 19:42 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak\\_core\\_ring.default.20141129194225
&gt;&gt;&gt;&gt;&gt;&gt; &gt; -rw-rw-r-- 1 riak riak 17829 Dec 3 19:07 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak\\_core\\_ring.default.20141203190748
&gt;&gt;&gt;&gt;&gt;&gt; &gt; -rw-rw-r-- 1 riak riak 17829 Dec 4 16:29 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak\\_core\\_ring.default.20141204162956
&gt;&gt;&gt;&gt;&gt;&gt; &gt; -rw-rw-r-- 1 riak riak 17847 Dec 4 20:45 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak\\_core\\_ring.default.20141204204548
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; [ec2-user@ip-10-196-72-247 ~]$ du -h /vol/lib/riak/ring
&gt;&gt;&gt;&gt;&gt;&gt; &gt; 84K /vol/lib/riak/ring
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; I have attached a tarball with the app.config file plus all the logs 
&gt;&gt;&gt;&gt;&gt;&gt; &gt; from the node at the time of the crash. Any help much appreciated!
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; Satish
&gt;&gt;&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt;&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak-users mailing list
&gt;&gt;&gt;&gt;&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt;&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt; 
&gt; 

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

