---
title: "Re: Riak CS 1.3 S3 access does not seem to mark s3 deleted file as	truly deleted"
description: ""
project: community
lastmod: 2013-05-22T02:24:27-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11147"
mailinglist_parent_id: "msg11146"
author_name: "Idan Shinberg"
project_section: "mailinglistitem"
sent_date: 2013-05-22T02:24:27-07:00
---


Hey Kelly

Thanks for getting back to me ...

You were right to bring up the point - these setting were indeed
applied gradually .

I have thus started from scratch with the same settings mentioned above in
place

I made 3 batch of 48 uploads of the same 32 MB files to 48 different keys
in s3
I Wound up with 48 keys in the S3 ( uploads overwrote old data ) , each is
32 MB of size , for a total of 144 uploads

BTW , I also forgot to mention n\\_val is set to 1 in default\\_bucket\\_props .
Bitcask dir was around 5.5 GB and after merges kicked in it shrunk to 3.4
GB

still , actual data-set size should be 48 x 32 MB , which is 1.5 GB .
I also noticed each time I upload a file , 2x of it's size is automatically
used , And I'm guessing that's related :-)

The Single Riak node is running on CentOS 6.3 with 1.3.1 packaged version...


Thanks

Idan Shinberg
idomoo


On Wed, May 22, 2013 at 2:26 AM, Kelly McLaughlin  wrote:

&gt; Idan,
&gt;
&gt; Bitcask can sometimes be slow to reclaim space after deleting objects from
&gt; Riak CS. Are the settings you included the settings that have been in place
&gt; during all of your uploads and deletions? I am surprised that just a few
&gt; tens of uploads of 32 MB objects used up 15 GB of space. Can you be more
&gt; specific on a count of uploads? Also do you have any error output in the
&gt; riak or riak cs log files that may be related? Finally, which packages are
&gt; you using for your testing?
&gt;
&gt; Kelly
&gt;
&gt;
&gt; On Tue, May 21, 2013 at 2:18 PM, Idan Shinberg 
&gt; wrote:
&gt;
&gt;&gt; Thus , I fear Riak never treats their data as "dead-bytes" and they never
&gt;&gt; get merged
&gt;&gt;
&gt;&gt; I created 2 buckets using s3cmd and made several tens of uploads of 32mb
&gt;&gt; sized files , deleting them right afterwards ( with proper s3cmd commands ,
&gt;&gt; of course) .
&gt;&gt;
&gt;&gt; I ended up with no buckets and no keys in my riak s3 database ,
&gt;&gt; however , directory /var/lib/riak/bitcask/ 64 partitions now occupy 15GB
&gt;&gt; worth of space
&gt;&gt;
&gt;&gt; several riak restarts did not trigger any merges , and my merge settings
&gt;&gt; are set to impose very though merge triggering criterias , So I'm guessing
&gt;&gt; the only reason the data is not being cleared is the fact that it's still
&gt;&gt; in use ...
&gt;&gt;
&gt;&gt; Relevant riak-cs config :
&gt;&gt;
&gt;&gt; \\* %% == Garbage Collection ==\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% The number of seconds to retain the block\\*
&gt;&gt; \\* %% for an object after it has been deleted.\\*
&gt;&gt; \\* %% This leeway time is set to give the delete\\*
&gt;&gt; \\* %% indication time to propogate to all replicas.\\*
&gt;&gt; \\* %% 86400 is 24-hours.\\*
&gt;&gt; \\* {leeway\\_seconds, 30},\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% How often the garbage collection daemon\\*
&gt;&gt; \\* %% waits in-between gc batches.\\*
&gt;&gt; \\* %% 900 is 15-minutes.\\*
&gt;&gt; \\* {gc\\_interval, 60},\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% How long a move to the garbage\\*
&gt;&gt; \\* %% collection to do list can remain\\*
&gt;&gt; \\* %% failed, before we retry it.\\*
&gt;&gt; \\* %% 21600 is 6-hours.\\*
&gt;&gt; \\* {gc\\_retry\\_interval,300},\\*
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; Relevant Riak Config
&gt;&gt;
&gt;&gt; \\*{riak\\_kv, [\\*
&gt;&gt; \\* %% Storage\\_backend specifies the Erlang module defining the
&gt;&gt; storage\\*
&gt;&gt; \\* %% mechanism that will be used on this node.\\*
&gt;&gt; \\* {add\\_paths,
&gt;&gt; ["/usr/lib64/riak-cs/lib/riak\\_cs-1.3.1/ebin"]},\\*
&gt;&gt; \\* {storage\\_backend, riak\\_cs\\_kv\\_multi\\_backend},\\*
&gt;&gt; \\* {multi\\_backend\\_prefix\\_list, [{&lt;&lt;"0b:"&gt;&gt;, be\\_blocks}]},\\*
&gt;&gt; \\* {multi\\_backend\\_default, be\\_default},\\*
&gt;&gt; \\* {multi\\_backend, [\\*
&gt;&gt; \\* {be\\_default, riak\\_kv\\_eleveldb\\_backend, [\\*
&gt;&gt; \\* {max\\_open\\_files, 50},\\*
&gt;&gt; \\* {data\\_root, "/var/lib/riak/leveldb"}\\*
&gt;&gt; \\* ]},\\*
&gt;&gt; \\* {be\\_blocks, riak\\_kv\\_bitcask\\_backend, [\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* {max\\_file\\_size, 16#4000000}, %% 64MB\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% Trigger a merge if any of the following are
&gt;&gt; true:\\*
&gt;&gt; \\* {frag\\_merge\\_trigger, 10}, %% fragmentation &gt;=
&gt;&gt; 10%\\*
&gt;&gt; \\* {dead\\_bytes\\_merge\\_trigger, 33554432}, %% dead
&gt;&gt; bytes &gt; 32 MB\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% Conditions that determine if a file will be
&gt;&gt; examined during a merge:\\*
&gt;&gt; \\* {frag\\_threshold, 5}, %% fragmentation &gt;= 5%\\*
&gt;&gt; \\* {dead\\_bytes\\_threshold, 8388608}, %% dead bytes
&gt;&gt; &gt; 8 MB\\*
&gt;&gt; \\* {small\\_file\\_threshold, 16#80000000}, %% file is
&gt;&gt; &lt; 2GB\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* {data\\_root, "/var/lib/riak/bitcask"}\\*
&gt;&gt; \\* ]}\\*
&gt;&gt; \\* ]},\\*
&gt;&gt;
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt; ...
&gt;&gt;
&gt;&gt; \\* {bitcask, [\\*
&gt;&gt; \\* %% Configure how Bitcask writes data to disk.\\*
&gt;&gt; \\* %% erlang: Erlang's built-in file API\\*
&gt;&gt; \\* %% nif: Direct calls to the POSIX C API\\*
&gt;&gt; \\* %%\\*
&gt;&gt; \\* %% The NIF mode provides higher throughput for certain\\*
&gt;&gt; \\* %% workloads, but has the potential to negatively impact\\*
&gt;&gt; \\* %% the Erlang VM, leading to higher worst-case latencies\\*
&gt;&gt; \\* %% and possible throughput collapse.\\*
&gt;&gt; \\* {io\\_mode, erlang},\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* {max\\_file\\_size, 16#4000000}, %% 64MB\\*
&gt;&gt; \\* {merge\\_window, always}, %% Span of hours during which
&gt;&gt; merge is acceptable.\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% Trigger a merge if any of the following are true:\\*
&gt;&gt; \\* {frag\\_merge\\_trigger, 10}, %% fragmentation &gt;= 10%\\*
&gt;&gt; \\* {dead\\_bytes\\_merge\\_trigger, 33554432}, %% dead bytes &gt; 32 MB
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* %% Conditions that determine if a file will be examined
&gt;&gt; during a merge:\\*
&gt;&gt; \\* {frag\\_threshold, 5}, %% fragmentation &gt;= 5%\\*
&gt;&gt; \\* {dead\\_bytes\\_threshold, 8388608}, %% dead bytes &gt; 8 MB\\*
&gt;&gt; \\* {small\\_file\\_threshold, 16#80000000}, %% file is &lt; 2GB\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* {data\\_root, "/var/lib/riak/bitcask"}\\*
&gt;&gt; \\*
&gt;&gt; \\*
&gt;&gt; \\* ]},\\*
&gt;&gt;
&gt;&gt; I do see merges taking place in riak's console.log , they're just not
&gt;&gt; making that much of a difference ...
&gt;&gt;
&gt;&gt; Any idea what I might be missing here ?
&gt;&gt;
&gt;&gt; Thanks
&gt;&gt;
&gt;&gt; Idan Shinberg
&gt;&gt; idomoo
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

