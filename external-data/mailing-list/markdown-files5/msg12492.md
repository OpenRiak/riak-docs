---
title: "Re: Riak on SAN"
description: ""
project: community
lastmod: 2013-10-03T07:28:08-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg12492"
mailinglist_parent_id: "msg12485"
author_name: "Jared Morrow"
project_section: "mailinglistitem"
sent_date: 2013-10-03T07:28:08-07:00
---


Chiming in with the completely anecdotal statement that we have customers
who run large Riak clusters on ZFS. As far as I know, we haven't gotten
any complaints due to ZFS. The only cautionary tale would be to not let
your zpool completely fill up because deletes take up storage due to the
append-only nature of ZFS.

-Jared


On Thu, Oct 3, 2013 at 8:11 AM, Heinz Nikolaus Gies wrote:

&gt; Hi Guido,
&gt; I don’t see how snappy compression renders ZFS useless, you might do some
&gt; things twice like crcing but it also protects on different layers. While
&gt; the ZFS crc protects data on the disks the in app crc could protect the
&gt; data ‘all’ the way up, compression wise you might not even turn on ZFS
&gt; compression and even if you do, you could still get a higher ratio given
&gt; that ZFS will use compression over the entire volume not ‘just’ the data in
&gt; the DB.
&gt;
&gt; That said there is a lot more to ZFS then compression and CRC ;) like
&gt; snapshots, cloning, ARC ^^
&gt;
&gt;
&gt; On 03 Oct 2013, at 9:56, Guido Medina  wrote:
&gt;
&gt; If using LevelDB backend, LevelDB has a nice compression (snappy),
&gt; including CRC checks and all sort of data corruption checks, I have read on
&gt; this mail list people that has required to disable snappy compression
&gt; because it renders ZFS useless (not much to compress after that)
&gt;
&gt; Hence, it is kind of related to using ZFS or not, if you go for ZFS
&gt; whatever variant you will have to support two sub-systems, if you let
&gt; LevelDB snappy compression on, you won't have to worry about it.
&gt;
&gt; As for backup, Basho provides a sort of cluster-to-cluster replication
&gt; tool, we built our own in Java, making backups per storage on every node
&gt; won't make much sense due to CAP/distributed nature, replicating the keys
&gt; to another cluster is what will make sense.
&gt;
&gt; Hope that helps and is understandable,
&gt;
&gt; Guido.
&gt;
&gt; On 03/10/13 13:54, Pedram Nimreezi wrote:
&gt;
&gt; Not sure what ZFS has to do with snappy compression, as it's a file system
&gt; not a compression algorithm..
&gt; feature wise, ZFS is quite possibly the most enterprise file system
&gt; around, including advanced data corruption prevention and remote backing
&gt; up..
&gt;
&gt; This would be a viable option in BSD/Solaris environments, at least for
&gt; making snapshots.
&gt; Might make a nice write up for the Basho blog..
&gt;
&gt; Backups for riak I think require a bit more consideration then file
&gt; system snapshot send,
&gt; and should include provisions for transferring data to smaller/larger
&gt; clusters, transfer
&gt; ring ownerships properly, etc.
&gt;
&gt;
&gt; On Thu, Oct 3, 2013 at 7:15 AM, Guido Medina wrote:
&gt;
&gt;&gt; And for ZFS? I wouldn't recommend it, after Riak 1.4 snappy LevelDB
&gt;&gt; compression does a nice job, why take the risk of yet another not so
&gt;&gt; enterprise ready compression algorithms.
&gt;&gt;
&gt;&gt; I could be wrong though,
&gt;&gt;
&gt;&gt; Guido.
&gt;&gt;
&gt;&gt;
&gt;&gt; On 03/10/13 12:11, Guido Medina wrote:
&gt;&gt;
&gt;&gt; I have heard some SAN's horrors stories too, Riak nodes are so cheap that
&gt;&gt; I don't see the point in even having any mirror on the node, here my points:
&gt;&gt;
&gt;&gt; 1. Erlang interprocess communication brings some network usage, why
&gt;&gt; yet another network usage on replicating the data? If the whole idea of
&gt;&gt; Riak is have your data replicated in different nodes.
&gt;&gt; 2. If a node goes down or die for whatever reason, bring up another
&gt;&gt; node and rebuild it.
&gt;&gt; 3. If you want to really replicate your cluster Riak offers the
&gt;&gt; enterprise replication which I'm quite sure will be less expensive than a
&gt;&gt; SAN and will warranty to have your cluster ready to go somewhere else as a
&gt;&gt; backup.
&gt;&gt; 4. I would even go further, SSDs are so cheap and Riak nodes are so
&gt;&gt; cheap now adays that I would even build a cluster using RAID 0 or RAID 5
&gt;&gt; SSDs (yes, no mirror with RAID 1, if too afraid, RAID 5), that will have a
&gt;&gt; great impact on performance. Again, if something goes wrong with 1 node,
&gt;&gt; refer to point 2.
&gt;&gt;
&gt;&gt; SANs and all those "legacy" backup and replication IMHO are meant for
&gt;&gt; other products, like an Oracle money eater DB server.
&gt;&gt;
&gt;&gt; HTH,
&gt;&gt; Guido.
&gt;&gt;
&gt;&gt; On 03/10/13 12:00, Brian Akins wrote:
&gt;&gt;
&gt;&gt; So, call me naive, but couldn't ZFS be used as Heinze suggested?
&gt;&gt;
&gt;&gt; I have some SAN horror stories - both operationally and from an
&gt;&gt; economic perspective.
&gt;&gt;
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing 
&gt;&gt; listriak-users@lists.basho.comhttp://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; --
&gt; /\\* Sincerely
&gt; --------------------------------------------------------------
&gt; Pedram Nimreezi - Chief Technology Officer \\*/
&gt;
&gt; // The hardest part of design … is keeping features out. - Donald Norman
&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

