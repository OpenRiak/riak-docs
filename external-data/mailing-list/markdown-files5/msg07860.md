---
title: "Re: Cannot get third node joined to cluster. Says it is already in	a cluster of it's own."
description: ""
project: community
lastmod: 2012-07-03T08:17:48-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07860"
mailinglist_parent_id: "msg07844"
author_name: "Ray Cote"
project_section: "mailinglistitem"
sent_date: 2012-07-03T08:17:48-07:00
---


Here's the answer I received via Riak Support:

According to the stats, nodes 1 and 2 are members of a cluster, sharing a ring 
and node 3 has connected to the same cluster but is part of a different ring.
We have noticed this issue when there are configuration errors while setting up 
nodes in a cluster or while trying to start a node that is already joined to a 
cluster.
Unfortunately, we do not have an easy fix to it but by deleting the ring info 
(rm -rf /var/lib/riak/ring/\\*) from node 3 and then restarting and trying to 
join it to the cluster again should resolve this issue.

Please let us know if you have further questions.

Thanks,
Sowjanya 



----- Original Message -----
&gt; From: "Ray Cote" 
&gt; To: "riak-users" 
&gt; Sent: Friday, June 29, 2012 3:57:43 PM
&gt; Subject: Cannot get third node joined to cluster. Says it is already in a 
&gt; cluster of it's own.
&gt; 
&gt; Hello all:
&gt; 
&gt; I've managed to get my new deployment into an odd state.
&gt; 
&gt; I have a three-node cluster.
&gt; After installation, I was running the riak-admin join commands.
&gt; Node #3 happend to be down because of a configuration error -- but
&gt; something seems to have been configured.
&gt; 
&gt; Now, when I run stats on my first node, I see
&gt; "nodename": "riak@192.168.231.231",
&gt; "connected\\_nodes": [
&gt; "riak@192.168.231.232",
&gt; "riak@192.168.231.233"
&gt; ],
&gt; "ring\\_members": [
&gt; "riak@192.168.231.231",
&gt; "riak@192.168.231.232"
&gt; ],
&gt; "ring\\_ownership":
&gt; "[{'riak@192.168.231.231',32},{'riak@192.168.231.232',32}]",
&gt; 
&gt; On the problemmatic ring, I see:
&gt; "connected\\_nodes": [
&gt; "riak@192.168.231.231",
&gt; "riak@192.168.231.232"
&gt; ],
&gt; "ring\\_members": [
&gt; "riak@192.168.231.233"
&gt; ],
&gt; "ring\\_ownership": "[{'riak@192.168.231.233',64}]",
&gt; 
&gt; My understanding is that all three should show in the ring\\_ownership.
&gt; 
&gt; Now, when I try to add node #3, I'm told it is already a member of a
&gt; cluster.
&gt; When I try to force-remove node #3, I'm told it is not a member of
&gt; the cluster.
&gt; When I try to use leave on node #3 I'm told it is the only member.
&gt; 
&gt; Any recommendations/thoughts on how to correct this?
&gt; (short of re-installing node #3)
&gt; 
&gt; Thanks
&gt; --Ray
&gt; 
&gt; When I try a riak-admin leave on node #3, it says it is the only
&gt; --
&gt; Ray Cote, President Appropriate Solutions, Inc.
&gt; We Build Software
&gt; www.AppropriateSolutions.com 603.924.6079
&gt; 

-- 
Ray Cote, President Appropriate Solutions, Inc. 
We Build Software 
www.AppropriateSolutions.com 603.924.6079 

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

