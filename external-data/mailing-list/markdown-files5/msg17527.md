---
title: "Re: Recovering Riak data if it can no longer load in memory"
description: ""
project: community
lastmod: 2016-07-12T13:20:55-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg17527"
mailinglist_parent_id: "msg17526"
author_name: "Vikram Lalit"
project_section: "mailinglistitem"
sent_date: 2016-07-12T13:20:55-07:00
---


Thanks much Matthew. Yes the server is low-memory given only development
right now - I'm using an AWS micro instance, so 1 GB RAM and 1 vCPU.

Thanks for the tip - let me try move the manifest file to a larger instance
and see how that works. More than reducing the memory footprint in dev, my
concern was more around reacting to a possible production scenario where
the db stops responding due to memory overload. Understood now that moving
to a larger instance should be possible. Thanks again.

On Tue, Jul 12, 2016 at 12:26 PM, Matthew Von-Maszewski 
wrote:

&gt; It would be helpful if you described the physical characteristics of the
&gt; servers: memory size, logical cpu count, etc.
&gt;
&gt; Google created leveldb to be highly reliable in the face of crashes. If
&gt; it is not restarting, that suggests to me that you have a low memory
&gt; condition that is not able to load leveldb's MANIFEST file. That is easily
&gt; fixed by moving the dataset to a machine with larger memory.
&gt;
&gt; There is also a special flag to reduce Riak's leveldb memory foot print
&gt; during development work. The setting reduces the leveldb performance, but
&gt; lets you run with less memory.
&gt;
&gt; In riak.conf, set:
&gt;
&gt; leveldb.limited\\_developer\\_mem = true
&gt;
&gt; Matthew
&gt;
&gt;
&gt; &gt; On Jul 12, 2016, at 11:56 AM, Vikram Lalit 
&gt; wrote:
&gt; &gt;
&gt; &gt; Hi - I've been testing a Riak cluster (of 3 nodes) with an ejabberd
&gt; messaging cluster in front of it that writes data to the Riak nodes. Whilst
&gt; load testing the platform (by creating 0.5 million ejabberd users via
&gt; Tsung), I found that the Riak nodes suddenly crashed. My question is how do
&gt; we recover from such a situation if it were to occur in production?
&gt; &gt;
&gt; &gt; To provide further context / details, the leveldb log files storing the
&gt; data suddenly became too huge, thus making the AWS Riak instances not able
&gt; to load them in memory anymore. So we get a core dump if 'riak start' is
&gt; fired on those instances. I had an n\\_val = 2, and all 3 nodes went down
&gt; almost simultaneously, so in such a scenario, we cannot even rely on a 2nd
&gt; copy of the data. One way to of course prevent it in the first place would
&gt; be to use auto-scaling, but I'm wondering is there a ex post facto / post
&gt; the event recovery that can be performed in such a scenario? Is it possible
&gt; to simply copy the leveldb data to a larger memory instance, or to curtail
&gt; the data further to allow loading in the same instance?
&gt; &gt;
&gt; &gt; Appreciate if you can provide inputs - a tad concerned as to how we
&gt; could recover from such a situation if it were to happen in production
&gt; (apart from leveraging auto-scaling as a preventive measure).
&gt; &gt;
&gt; &gt; Thanks!
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

