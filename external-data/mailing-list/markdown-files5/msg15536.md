---
title: "Re: RiakCS poor s3 upload speeds 2MB/s"
description: ""
project: community
lastmod: 2015-01-20T17:08:34-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg15536"
mailinglist_parent_id: "msg15535"
author_name: "Toby Corkindale"
project_section: "mailinglistitem"
sent_date: 2015-01-20T17:08:34-08:00
---


Hi Kota,
I had a bit of an off-list chat about this a while ago, plus continued
to investigate locally, and eventually achieved some faster speeds,
around 15MByte/sec writes.
Things that were changed:
 \\* Adjusted Riak CS GC to be spread out over the cluster much more.
 \\* Tweaked up the put buffers and concurrency further
 \\* Moved most of the files out of CS and into Amazon S3+Glacier
 \\* Switched from nginx to haproxy
 \\* simplified firewalling for internal clients

Each one of those changes made a small to modest improvement, but
overall combined to make a quite noticeable improvement.

I did notice something odd though -- despite moving most of the data
out of the cluster, the disk-space-in-use by Riak is still very large
compared to the amount stored. I mean, we moved more than 90% of the
data out of the cluster, yet the actual disk space used only halved.
For every gigabyte of file stored in CS, dozens of gigabytes are
actually on disk!

Either the garbage collection algorithm is very, very lazy, or somehow
something has gone a bit wrong in the past, which might have explained
part of the performance problems.

We're going to look at redeploying a new, fresh cluster based on Riak
2 in the not too distant future, once Riak CS looks like it's approved
for use there, and maybe that'll clear all of this up.

Toby

On 21 January 2015 at 11:07, Kota Uenishi  wrote:
&gt; Toby and David,
&gt;
&gt; Thank you for working on Riak CS and I apologize for being late responder.
&gt;
&gt; I believe the reason of being slow down is different between Toby's
&gt; and David's cluster.
&gt;
&gt; Toby's reason looks like that's just because of the data increasing.
&gt; How much data per vnode do you have in your cluster, Toby? Do you have
&gt; deletion in your workload?
&gt; Riak CS's garbage collection, deleting block keys in Riak and merging
&gt; Bitcask files make some load more than the exact amount of data
&gt; visible via CS (even taking the replication factor into account).
&gt; Also, if you turn on AAE, building AAE trees scans all the data stored
&gt; in Riak to fix unexpected bit rot or partial replication. I'd like you
&gt; to check the background load to underlying storage. If the performance
&gt; decrease is \\*not\\* due to such background load, maybe there's the same
&gt; dragon lurking under the water as David's cluster.
&gt;
&gt; One thing I can suggest from David's app.config, SSL is turned on -
&gt; Riak CS uses Erlang's built-in SSL library for https scheme which is
&gt; said to have not so good performance. I wonder those benchmarks were
&gt; done over https or just http.
&gt;
&gt; As far as I test Riak CS, local or cluster-wide, I haven't met such
&gt; bad performance less than 10MB/s in such a fresh state cluster. There
&gt; should be something wrong, either the setup or the software. Would you
&gt; mind sending us the result riak-debug and riak-cs-debug commands, if
&gt; you still can reproduce such situation. Those packs up the environment
&gt; info as much as it can.
&gt;
&gt; Thanks,
&gt; Kota
&gt;
&gt; On Thu, Nov 27, 2014 at 10:36 AM, Toby Corkindale  wrote:
&gt;&gt; Thanks, that's interesting to hear.
&gt;&gt; How have you been finding the stability and reliability to be with
&gt;&gt; leofs, over time?
&gt;&gt;
&gt;&gt;
&gt;&gt; I still wish I could just get our Riak CS cluster performing better;
&gt;&gt; it just seems so unreasonably slow at the moment, that I suspect
&gt;&gt; there's \\*something\\* holding it back. I can build a test cluster on my
&gt;&gt; desktop, and even with five virtual riak nodes on the one machine, I
&gt;&gt; still see 20-40x the performance, so it seems bizarre that dedicated
&gt;&gt; bare-metal servers would be so slow. (Although obviously there's much
&gt;&gt; more network latency between real machines, than a virtual cluster on
&gt;&gt; one desktop; and they have a lot more data in their bitcask databases)
&gt;&gt;
&gt;&gt;
&gt;&gt; However I've tried fiddling with all the Riak and Riak CS options..
&gt;&gt; ethtool offloads.. mount options.. sysctls.. MTU sizes.. even dropping
&gt;&gt; single nodes out of the cluster one at a time in case they were
&gt;&gt; somehow at fault.. seems like the only performance changes I can make
&gt;&gt; are negative.
&gt;&gt;
&gt;&gt; We're still double the speed of the original poster in this thread,
&gt;&gt; but.. that isn't saying much.
&gt;&gt;
&gt;&gt; Toby
&gt;&gt;
&gt;&gt;
&gt;&gt; On 26 November 2014 at 06:44, Heinz Nikolaus Gies  wrote:
&gt;&gt;&gt; If you’re evaluating RiakCS vs. Ceph you might want to toss LeoFS[1] in the
&gt;&gt;&gt; mix and give it a run. Just as RiakCS it is a dynamo inspired system build
&gt;&gt;&gt; in Erlang and comes with the same advantages and disadvantages. But unlike
&gt;&gt;&gt; RiakCS it is pretty much exclusive a Object Store so can take a few
&gt;&gt;&gt; different optimizations for this kind of work that might not be possible in
&gt;&gt;&gt; a general purpose database as Riak (this is my personal guess not a research
&gt;&gt;&gt; founded conclusion). The team is (much) smaller then bash (obviously) but
&gt;&gt;&gt; they’re a very nice and responsive bunch. I ended up using it as a s3
&gt;&gt;&gt; backend for Project-FiFo due to it’s performance characteristics. With
&gt;&gt;&gt; current releases I manage to get a sigle file upload speed of ~1.2GB/s using
&gt;&gt;&gt; gof3r[2] (this might be a client limitation but I haven’t had time to
&gt;&gt;&gt; investigate the details).
&gt;&gt;&gt;
&gt;&gt;&gt; [1] http://leo-project.net/leofs/
&gt;&gt;&gt; [2] https://github.com/rlmcpherson/s3gof3r/tree/master/gof3r
&gt;&gt;&gt; ---
&gt;&gt;&gt; Cheers,
&gt;&gt;&gt; Heinz Nikolaus Gies
&gt;&gt;&gt; he...@licenser.net
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; On Nov 25, 2014, at 6:08, Toby Corkindale  wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Hi,
&gt;&gt;&gt; I wondered if you managed to significantly improve your Riak CS
&gt;&gt;&gt; performance, or not?
&gt;&gt;&gt;
&gt;&gt;&gt; I just ask as we've been getting not-dissimilar performance out of
&gt;&gt;&gt; Riak CS too (4-5 mbyte/sec max per client, on bare metal hardware),
&gt;&gt;&gt; for quite a long time. (I swear it was faster originally, when there
&gt;&gt;&gt; was a lot less data in the whole system.)
&gt;&gt;&gt; This is after applying all the tweaks available -- networking stack,
&gt;&gt;&gt; filesystem mount options, assorted Erlang vm.args, and increased put
&gt;&gt;&gt; concurrency/buffer options.
&gt;&gt;&gt;
&gt;&gt;&gt; We put up with it because it's been just-about sufficient enough for
&gt;&gt;&gt; our needs and Riak CS has been reliable and easy to administer -- but
&gt;&gt;&gt; it's becoming more of an issue, and so I'm curious to know if other
&gt;&gt;&gt; people \\*do\\* manage to achieve \\*good\\* per-client speeds out of Riak CS
&gt;&gt;&gt; or if this is just how things always are?
&gt;&gt;&gt; And we're way off the mark, maybe we can find out why..
&gt;&gt;&gt;
&gt;&gt;&gt; Details of our setup:
&gt;&gt;&gt; 6 node cluster. RIng size of 64.
&gt;&gt;&gt; Riak 1.4.10
&gt;&gt;&gt; Riak CS 1.5.2
&gt;&gt;&gt; (installed from official Basho repos)
&gt;&gt;&gt;
&gt;&gt;&gt; Tests conducted using both multi-part and non-multi-part upload mode;
&gt;&gt;&gt; performance is similar with both. Tested against cluster when very
&gt;&gt;&gt; lightly loaded.
&gt;&gt;&gt; For the sake of testing, a 100M file is being used, that contains
&gt;&gt;&gt; random (hard to compress) data.
&gt;&gt;&gt;
&gt;&gt;&gt; Cheers,
&gt;&gt;&gt; Toby
&gt;&gt;&gt;
&gt;&gt;&gt; On 8 November 2014 at 01:41, David Meekin 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Hi,
&gt;&gt;&gt; I’ve setup a test 4 node RiakCS cluster on HP BL460c hardware and I can’t
&gt;&gt;&gt; seem to get S3 upload speeds above 2MB/s
&gt;&gt;&gt; I’m connecting direct to RiackCS on one of the nodes so there is no load
&gt;&gt;&gt; balancing software in place.
&gt;&gt;&gt; I have also installed s3cmd locally onto one of the nodes and the speeds
&gt;&gt;&gt; locally are the same.
&gt;&gt;&gt; These 4 nodes also run a test CEPH cluster with RadosGW and s3 uploads to
&gt;&gt;&gt; CEPH achieve 125MB/s
&gt;&gt;&gt; Any help would be appreciated as I’m currently evaluating both CEPH and
&gt;&gt;&gt; RiakCS.
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; Turning and turning in the widening gyre
&gt;&gt; The falcon cannot hear the falconer
&gt;&gt; Things fall apart; the center cannot hold
&gt;&gt; Mere anarchy is loosed upon the world
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt;
&gt; --
&gt; Kota UENISHI / @kuenishi
&gt; Basho Japan KK



-- 
Turning and turning in the widening gyre
The falcon cannot hear the falconer
Things fall apart; the center cannot hold
Mere anarchy is loosed upon the world

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

