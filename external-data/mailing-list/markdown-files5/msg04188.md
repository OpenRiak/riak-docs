---
title: "Re: In-Memory Performance"
description: ""
project: community
lastmod: 2011-08-02T18:20:06-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04188"
mailinglist_parent_id: "msg04187"
author_name: "Eric Moritz"
project_section: "mailinglistitem"
sent_date: 2011-08-02T18:20:06-07:00
---


 You may also want to try the leveldb backend that is in Riak's
master branch. It is faster than Innodb but doesn't store all the keys
in memory like bitcask does.

 I am not sure how stable or mature that backend is so if you need
a solution yesterday using leveldb may be off the table. The Basho
folks can address the timetable and stability of the leveldb backend
better than I can.

If it ends up being close to as fast as the memory backend and you get
persistence it may be your best bet to get what you need from Riak.
The downside is it is a bleeding edge feature.

Eric.


On Tue, Aug 2, 2011 at 8:50 PM, Matt Savona  wrote:
&gt; Oh wow. You're right...thank you /very/ much for catching that. I
&gt; don't know what gave me the impression that the default was R=1 (could
&gt; have sworn I read it somewhere). Can't wait to try this out when I get
&gt; into the office tomorrow hopefully it speeds things up a bit.
&gt;
&gt; I'll post some revised numbers once I run my test again.
&gt;
&gt; - Matt
&gt;
&gt; On Tue, Aug 2, 2011 at 8:32 PM, Eric Moritz  wrote:
&gt;&gt; Unless you changed R for the bucket, the default that ships with Riak
&gt;&gt; is 2.  It's actually "n\\_val / 2 + 1" also known as the quorum
&gt;&gt; .  n\\_val is 3 by
&gt;&gt; default resulting in R=2.
&gt;&gt;
&gt;&gt; Eric.
&gt;&gt;
&gt;&gt; On Tue, Aug 2, 2011 at 8:11 PM, Matt Savona  wrote:
&gt;&gt;&gt; Hi Eric,
&gt;&gt;&gt;
&gt;&gt;&gt; I this test, R=1 (the default).
&gt;&gt;&gt;
&gt;&gt;&gt; Thanks!
&gt;&gt;&gt;
&gt;&gt;&gt; - Matt
&gt;&gt;&gt;
&gt;&gt;&gt; On Tue, Aug 2, 2011 at 4:35 PM, Eric Moritz  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;&gt; When you were doing the reads, did you set the r-value to 1?  This
&gt;&gt;&gt;&gt; will speed up reads in a read heavy app because only one node has to
&gt;&gt;&gt;&gt; be in agreement about the object.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Eric.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; On Tue, Aug 2, 2011 at 11:22 AM, Matt Savona  wrote:
&gt;&gt;&gt;&gt;&gt; Hi all,
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; My colleagues and I are evaluating Riak as a persistent, replicated K-V 
&gt;&gt;&gt;&gt;&gt; store.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; I have a fairly simple (and not so scientific) test that reads and
&gt;&gt;&gt;&gt;&gt; writes 5000 objects that are 32K in size. I am particularly interested
&gt;&gt;&gt;&gt;&gt; in squeezing every last bit of performance out of Riak in a very
&gt;&gt;&gt;&gt;&gt; read-heavy environment. I want to avoid hitting disk for reads as much
&gt;&gt;&gt;&gt;&gt; as possible; our entire content set is much larger than could ever be
&gt;&gt;&gt;&gt;&gt; stored in RAM, but preferably hot/active objects will remain resident
&gt;&gt;&gt;&gt;&gt; in memory until various conditions may force them to be evicted. While
&gt;&gt;&gt;&gt;&gt; the content set is quite large, the number of active keys represent a
&gt;&gt;&gt;&gt;&gt; very small portion of the data which could easily fit in RAM.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; I've been running the same test against Riak given various
&gt;&gt;&gt;&gt;&gt; combinations of backends and access protocols (HTTP vs. PB).
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; My numbers can be seen in this screenshot:
&gt;&gt;&gt;&gt;&gt; http://img824.imageshack.us/img824/3185/riakperformance.png
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; It is quite evident (and perhaps obvious) that Protocol Buffer
&gt;&gt;&gt;&gt;&gt; performance is noticeably better than HTTP in most cases.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; What is confusing to me is the performance of purely in-memory
&gt;&gt;&gt;&gt;&gt; backends. Notably, GB Trees and LRU Cache (and even Innostore), at
&gt;&gt;&gt;&gt;&gt; best took 14s to retrieve 5000 32K objects. The exact same test
&gt;&gt;&gt;&gt;&gt; against Membase took just 6s.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Perhaps I'm not comparing apples to apples (Riak in-memory versus
&gt;&gt;&gt;&gt;&gt; Membase). Do my tests look reasonable and do the numbers look roughly
&gt;&gt;&gt;&gt;&gt; in-line with expectations? Is there any way to squeeze more juice out
&gt;&gt;&gt;&gt;&gt; of Riak? A purely in-memory/non-persistent backend will not suffice
&gt;&gt;&gt;&gt;&gt; for our ultimate needs, but for testing purposes I'm just trying to
&gt;&gt;&gt;&gt;&gt; see if I can get read performance more in line with what we're seeing
&gt;&gt;&gt;&gt;&gt; with Membase. We love everything about it, but we haven't yet hit the
&gt;&gt;&gt;&gt;&gt; performance we were hoping for.
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; Thanks in advance!
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; - Matt
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

