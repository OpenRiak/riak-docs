---
title: "Re: Slow performance using linkwalk, help wanted"
description: ""
project: community
lastmod: 2010-11-09T07:40:38-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01513"
mailinglist_parent_id: "msg01512"
author_name: "Kevin Smith"
project_section: "mailinglistitem"
sent_date: 2010-11-09T07:40:38-08:00
---


Jan - 

I am hacking on it a bit to more closely match your use case. As soon as I have 
it done I will send it and the test generation script I'm using to populate 
test data.

--Kevin
On Nov 9, 2010, at 10:35 AM, Jan Buchholdt wrote:

&gt; Kevin -
&gt; 
&gt; The test client is part of a bigger system and would be a bit too much top 
&gt; send to you. The method that is calling Riak looks like this:
&gt; 
&gt; import com.basho.riak.client.\\*;
&gt; .
&gt; .
&gt; public List lookupDocuments(String personId, String url) {
&gt; RiakClient riak = new RiakClient(url);
&gt; 
&gt; WalkResponse walkResponse = riak.walk("person", personId, 
&gt; "document,\\_,\\_");
&gt; if (walkResponse.isSuccess()) {
&gt; List out = new ArrayList();
&gt; List extends List&lt;RiakObject&gt; steps = walkResponse.getSteps();
&gt; if (steps.size() != 1) {
&gt; throw new RuntimeException("Expected to walk one link. Walked 
&gt; " + steps.size());
&gt; }
&gt; List step = steps.get(0);
&gt; for (RiakObject o : step) {
&gt; try {
&gt; String chars = o.getValue();
&gt; Builder builder = Protos.Document.newBuilder();
&gt; JsonFormat2.merge(chars, builder);
&gt; out.add(((Document) builder.build()).getDocument());
&gt; } catch (ParseException e) {
&gt; throw new DocumentServiceException("Error parsing 
&gt; document", e);
&gt; }
&gt; }
&gt; return out;
&gt; } else {
&gt; throw new RuntimeException("Walk error: " + 
&gt; walkResponse.getHttpHeaders());
&gt; }
&gt; }
&gt; 
&gt; It could be interesting to repeat your test on our cluster, to see if we get 
&gt; the same numbers as you do. Is it possible for you to send the code behind 
&gt; your test?
&gt; 
&gt; --
&gt; Jan Buchholdt
&gt; Software Pilot
&gt; Trifork A/S
&gt; Cell +45 50761121
&gt; 
&gt; 
&gt; 
&gt; On 2010-11-09 15:47, Karsten Thygesen wrote:
&gt;&gt; On Nov 9, 2010, at 14:58 , Kevin Smith wrote:
&gt;&gt; 
&gt;&gt;&gt; On Nov 9, 2010, at 5:01 AM, Karsten Thygesen wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Hi
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; OK, we will use a larger ringsize next time and will consider a data 
&gt;&gt;&gt;&gt; reload.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Regarding the metrics: the servers are dedicated to Riak use and it not 
&gt;&gt;&gt;&gt; used for anything else. They are new HP servers with 8 cores each and 
&gt;&gt;&gt;&gt; 4x146GB 10K RPM SAS disks in a contatenated mirror setup. We use Solaris 
&gt;&gt;&gt;&gt; with ZFS as filesystem and I have turned off atime update in the data 
&gt;&gt;&gt;&gt; partition.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; The pool is built as such:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; pool: pool01
&gt;&gt;&gt;&gt; state: ONLINE
&gt;&gt;&gt;&gt; scrub: scrub completed after 0h0m with 0 errors on Tue Oct 26 21:25:05 2010
&gt;&gt;&gt;&gt; config:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; NAME STATE READ WRITE CKSUM
&gt;&gt;&gt;&gt; pool01 ONLINE 0 0 0
&gt;&gt;&gt;&gt; mirror-0 ONLINE 0 0 0
&gt;&gt;&gt;&gt; c0t0d0s7 ONLINE 0 0 0
&gt;&gt;&gt;&gt; c0t1d0s7 ONLINE 0 0 0
&gt;&gt;&gt;&gt; mirror-1 ONLINE 0 0 0
&gt;&gt;&gt;&gt; c0t2d0 ONLINE 0 0 0
&gt;&gt;&gt;&gt; c0t3d0 ONLINE 0 0 0
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; errors: No known data errors
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; so it is as fast as possible.
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; However - we use the ZFS default blocksize, which is 128Kb - is that 
&gt;&gt;&gt;&gt; optimal with bitcask as backend? It is rather large, but what is optimal 
&gt;&gt;&gt;&gt; with bitcask?
&gt;&gt;&gt; I don't have much experience tuning Solaris or ZFS for Riak. This is a 
&gt;&gt;&gt; question best asked of Ryan and I will make sure he sees this.
&gt;&gt; Thanks!
&gt;&gt; 
&gt;&gt;&gt;&gt; The cluster is 4 servers with gigabit connection located in the same 
&gt;&gt;&gt;&gt; datacenter on the same switch. The loadbalancer is a Zeus ZTM, which does 
&gt;&gt;&gt;&gt; quote a few http optimizations including extended reuse of http 
&gt;&gt;&gt;&gt; connections and we usually see far better response times using the 
&gt;&gt;&gt;&gt; loadbalancer than using a node directly.
&gt;&gt;&gt; Hmmm. Can you share what the performance times are like for direct cluster 
&gt;&gt;&gt; access?
&gt;&gt; In this case, there is no measurable difference whenever we ask a cluster 
&gt;&gt; node directly or we go through the loadbalancer. The largest difference is 
&gt;&gt; when we hit it with a lot of small requests, but that is not the case here.
&gt;&gt; 
&gt;&gt;&gt;&gt; When we run the test, each riak node is only about 100% cpu loaded (which 
&gt;&gt;&gt;&gt; on solaris means, that it only uses one of the 8 cores). We have seen 
&gt;&gt;&gt;&gt; spikes in the 160% area, but everything below 800% is not cpu bound. So 
&gt;&gt;&gt;&gt; all-in-all, the cpuload is between 5 and 10%.
&gt;&gt;&gt; Can you send me the code you're using for the performance test? I'd like to 
&gt;&gt;&gt; run the exact code on my test hardware and see if that reveals anything.
&gt;&gt; Jan, can you please provide the test client?
&gt;&gt; 
&gt;&gt;&gt; Also, low CPU usage might indicate you are IO bound. Do you know if Riak 
&gt;&gt;&gt; processes are spending much time waiting for IO to complete?
&gt;&gt;&gt; 
&gt;&gt; It does not seem so. The servers are not IO bound, there is plenty of 
&gt;&gt; network capacity and the disks is only around 10% loaded.
&gt;&gt; 
&gt;&gt; My largest suspicion is on the datamodel - when having a 4-node cluster and 
&gt;&gt; doing a linkwalk, which need to combine around 5-600 documents, it will take 
&gt;&gt; quite some time, but we still feel, that the numbers is very high.
&gt;&gt; 
&gt;&gt; Perhaps we should consider a datamodel, where we collect, say, 100 documents 
&gt;&gt; in a basket and the only have to linkwalk 4-5 baskets to return an answer? 
&gt;&gt; Tempting, performancewise, but it makes it a lot harder to maintain the data 
&gt;&gt; afterwards as we can not just use map-reduce and similar technologies to 
&gt;&gt; handle data...
&gt;&gt; 
&gt;&gt; Karsten
&gt;&gt; 
&gt;&gt;&gt; --Kevin
&gt;&gt;&gt; 
&gt;&gt;&gt; 


\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

