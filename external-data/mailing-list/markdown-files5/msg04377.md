---
title: "Re: Random server restarts, swap and moving nodes to new hardware"
description: ""
project: community
lastmod: 2011-08-16T07:32:34-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04377"
mailinglist_parent_id: "msg04376"
author_name: "Jeff Pollard"
project_section: "mailinglistitem"
sent_date: 2011-08-16T07:32:34-07:00
---


Hey Sean,

Thanks very much for the reply. I'll certainly try going to 10.10 with the
upgrade, that's good info.

Re EBS: were you saying to attach the EBS volume to the new node and use the
EBS volume as the data volume? We had been using EBS as a backup volume,
but using ephemeral storage for the actual data directory. We did this
primarily for I/O performance reasons and also cause EBS seems to have had a
bad operations track record at AWS. In my steps from my previous email, our
"shared location" actually was EBS, but we were planning on offloading the
files to the ephemeral disk and using that as the data volume for Riak.
 Does that make sense?

On Tue, Aug 16, 2011 at 7:18 AM, Sean Cribbs  wrote:

&gt; Jeff,
&gt;
&gt; We highly recommend you upgrade to 10.10 or later. 10.04 has some known
&gt; problems when running under Xen (especially on EC2) -- in some cases under
&gt; load, the network interface will break, making the node temporarily
&gt; inaccessible.
&gt;
&gt; When you do upgrade, the simplest way (if possible) would be to remount the
&gt; attached EBS volumes where your Riak data is stored onto the new nodes.
&gt; Otherwise, the steps you list are correct.
&gt;
&gt; Regarding swap, whether you have it on or not is a personal decision. Riak
&gt; will "do the right thing" and exit when it can't allocate more memory,
&gt; allowing you to figure out what went wrong -- as opposed to grinding the
&gt; machine into IO oblivion while consuming more and more swap. That said, in
&gt; some deployments (notably not on EC2), swap can be helpful.
&gt;
&gt; Hope that helps,
&gt;
&gt; --
&gt; Sean Cribbs 
&gt; Developer Advocate
&gt; Basho Technologies, Inc.
&gt; http://www.basho.com/
&gt;
&gt; On Tue, Aug 16, 2011 at 3:46 AM, Jeff Pollard wrote:
&gt;
&gt;&gt; Hello everyone,
&gt;&gt;
&gt;&gt; We've got a very interesting problem. We're hosting our 5-node cluster on
&gt;&gt; EC2 running Ubuntu 10.04 LTS (Lucid Lynx) Server 
&gt;&gt; 64-bit using
&gt;&gt; m2.xlarge instance types, and over the past 5 days we've had two EC2 servers
&gt;&gt; randomly restart on us. We've checked the logs and there was nothing that
&gt;&gt; we saw that indicated why they restarted. One second they were happily
&gt;&gt; logging and the next second the server was in the process of rebooting.
&gt;&gt; This is particularly bad because every time the node comes back up we get
&gt;&gt; merge errors due to an existing bug in Riak and have to restore from a
&gt;&gt; recent backup.
&gt;&gt;
&gt;&gt; Just today we noticed that the EC2 servers did not have swap enabled
&gt;&gt; (apparently the norm for xlarge+ instances), which we thought might have
&gt;&gt; been our problem? My knowledge of what happens when swap is off is pretty
&gt;&gt; poor - but I have been told that the Linux OOM killer should still be
&gt;&gt; invoked and start trying to kill processes, rather than the server simply
&gt;&gt; restarting. Is that correct? Also, how would Riak hypothetically handle
&gt;&gt; swap being off on a system? We're using Bitcask if that helps.
&gt;&gt;
&gt;&gt; Secondly, one of our ops guys here thinks the issue might be related to a
&gt;&gt; bug  (?) that others
&gt;&gt; Ubuntu users of the same version seem to have. In fact, we do see the same
&gt;&gt; "INFO: task cron:15047 blocked for more than 120 seconds: line in our log
&gt;&gt; file. We're also running a AMI that isn't the official one from Canonical,
&gt;&gt; so the thought being an upgrade to the official AMI would help.
&gt;&gt;
&gt;&gt; If we do want to upgrade, it will mean moving each cluster node to new
&gt;&gt; hardware. I wanted to ask the list to make sure we were doing it correctly.
&gt;&gt; Here is the plan to transfer a node to new hardware -- note that these
&gt;&gt; steps will be done on one node at a time, and we'll make sure the cluster
&gt;&gt; has stabilized after doing one node before moving on to the next one.
&gt;&gt;
&gt;&gt; 1. Stop riak on old server.
&gt;&gt; 2. Copy data directory (including bitcask, mr\\_queue and ring folders)
&gt;&gt; to a shared location.
&gt;&gt; 3. Shutdown old server.
&gt;&gt; 4. Boot new replacement server, installing (but not starting) Riak.
&gt;&gt; 5. Transfer data directory from shared location to data folder on new
&gt;&gt; node.
&gt;&gt; 6. Start riak.
&gt;&gt;
&gt;&gt; My main concern is if the ring state will transfer to a new node safely,
&gt;&gt; assuming the new server has the same hostname and node name as the old
&gt;&gt; server? The new server will have a different IP address, but all our node
&gt;&gt; names in our cluster use hostnames, and those will not be changing.
&gt;&gt;
&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; riak-users mailing list
&gt;&gt; riak-users@lists.basho.com
&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;
&gt;&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

