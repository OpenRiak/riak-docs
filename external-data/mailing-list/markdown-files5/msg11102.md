---
title: "Re: Servers keep dying. How to understand why?"
description: ""
project: community
lastmod: 2013-05-17T06:27:10-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg11102"
mailinglist_parent_id: "msg11099"
author_name: "Christian Dahlqvist"
project_section: "mailinglistitem"
sent_date: 2013-05-17T06:27:10-07:00
---


Hi Julian,

You will need to update the app.config file and restart the servers in order 
for the changes to take effect.

Best regards,

Christian



On 17 May 2013, at 14:05, Julien Genestoux  wrote:

&gt; Great! Thanks Christian, is that something I can change at runtime or do I 
&gt; have to stop the server?
&gt; Also, would it make sense to change the backend if we have a lot of delete? 
&gt; 
&gt; Thanks,
&gt; 
&gt; On Fri, May 17, 2013 at 2:45 PM, Christian Dahlqvist  
&gt; wrote:
&gt; Hi Julien,
&gt; 
&gt; I believe from an earlier email that you are using bitcask as a backend. This 
&gt; works with immutable append-only files, and data that is deleted or 
&gt; overwritten will stay in the files and take up disk space until the file is 
&gt; closed and can be merged. The max file size is by default 2GB, but this and 
&gt; other parameters determining how and when merging of closed files is 
&gt; performed can be tuned. Please see 
&gt; http://docs.basho.com/riak/latest/tutorials/choosing-a-backend/Bitcask/ for 
&gt; further details.
&gt; 
&gt; If you wish to reduce the amount of disk space used, you may want to set a 
&gt; smaller max file size in order to allow merging to occur more frequently.
&gt; 
&gt; Best regards,
&gt; 
&gt; Christian
&gt; 
&gt; 
&gt; 
&gt; On 17 May 2013, at 13:06, Julien Genestoux  wrote:
&gt; 
&gt;&gt; Christian, All
&gt;&gt; 
&gt;&gt; Our servers still have not died... but we see another strange behavior: our 
&gt;&gt; data store needs a lot more space that what we expect.
&gt;&gt; 
&gt;&gt; Based on the status command, the average size of our object 
&gt;&gt; (node\\_get\\_fsm\\_objsize\\_mean) is about 1500 bytes.
&gt;&gt; We have 2 buckets, but both of them have a n value of 3. 
&gt;&gt; 
&gt;&gt; When we count the values in each of the buckets (using the following 
&gt;&gt; mapreduce)
&gt;&gt; curl -XPOST http://192.168.134.42:8098/mapred -H 'Content-Type: 
&gt;&gt; application/json' -d 
&gt;&gt; '{"inputs":"BUCKET","query":[{"reduce":{"language":"erlang","module":"riak\\_kv\\_mapreduce","function":"reduce\\_count\\_inputs","arg":{"do\\_prereduce":true}}}],"timeout":
&gt;&gt; 100000}'
&gt;&gt; 
&gt;&gt; We get 194556 for one and 1572661 for the other one (these numbers are 
&gt;&gt; consistent with what we expected), so if our math is right, we do need a 
&gt;&gt; total disk of 
&gt;&gt; 3 \\* (194556 + 1572661 ) \\* 1500 bytes = 7.4 GB.
&gt;&gt; 
&gt;&gt; Now, though, when I inspect the storage actually occupied on our hard 
&gt;&gt; drives, we see something weird:
&gt;&gt; (this is the du output)
&gt;&gt; riak1. 2802888 /var/lib/riak
&gt;&gt; riak2. 4159976 /var/lib/riak
&gt;&gt; riak5. 4603312 /var/lib/riak
&gt;&gt; riak3. 4915180 /var/lib/riak
&gt;&gt; riak4. 37466784 /var/lib/riak
&gt;&gt; 
&gt;&gt; As you can see not all nodes have the same "size". What's even weirder is 
&gt;&gt; that up until a couple hours ago, they were all growing "together" and close 
&gt;&gt; to what the riak4 node shows. Could this be due to the "delete" policy? It 
&gt;&gt; turns out that we delete a lot of items (is there a way to get the list of 
&gt;&gt; commands sent to a node/cluster?)
&gt;&gt; 
&gt;&gt; Thanks!
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Wed, May 15, 2013 at 11:29 PM, Julien Genestoux 
&gt;&gt;  wrote:
&gt;&gt; Christian, all,
&gt;&gt; 
&gt;&gt; Not sure what kind of magic happend, but no server died in the last 2 
&gt;&gt; days... and counting.
&gt;&gt; We have not changed a single line of code, which is quite odd...
&gt;&gt; I'm still monitoring everything and hope (sic!) for a failure soon so we can 
&gt;&gt; fix the problem!
&gt;&gt; 
&gt;&gt; Thanks
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; --
&gt;&gt; Got a blog? Make following it simple: https://www.subtome.com/
&gt;&gt; 
&gt;&gt; Julien Genestoux,
&gt;&gt; http://twitter.com/julien51
&gt;&gt; 
&gt;&gt; +1 (415) 830 6574
&gt;&gt; +33 (0)9 70 44 76 29
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Tue, May 14, 2013 at 12:31 PM, Julien Genestoux 
&gt;&gt;  wrote:
&gt;&gt; Thanks Christian. 
&gt;&gt; We do indeed use mapreduce but it's a fairly simple function:
&gt;&gt; We retrieve a first object whose value is an array of at most 10 ids and 
&gt;&gt; then we fetch all the values for these 10 ids.
&gt;&gt; However, this mapreduce job is quite rare (maybe 10 times a day at most at 
&gt;&gt; this point...) so I don't think that's our issue.
&gt;&gt; I'll try to run the cluster without any call to that to see if that's 
&gt;&gt; better, but I'd be very surprised. Also, we were doing this already even 
&gt;&gt; before we allowed for multiple value and the cluster was stable back then.
&gt;&gt; We do not do key listing or anything like that.
&gt;&gt; 
&gt;&gt; I'll try looking at the statistics too.
&gt;&gt; 
&gt;&gt; Thanks,
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On Tue, May 14, 2013 at 11:50 AM, Christian Dahlqvist  
&gt;&gt; wrote:
&gt;&gt; Hi Julien,
&gt;&gt; 
&gt;&gt; The node appear to have crashed due to inability to allocate memory. How are 
&gt;&gt; you accessing your data? Are you running any key listing or large MapReduce 
&gt;&gt; jobs that could use up a lot of memory?
&gt;&gt; 
&gt;&gt; In order to ensure that you are efficiently resolving siblings I would 
&gt;&gt; recommend you monitor the statistics in Riak 
&gt;&gt; (http://docs.basho.com/riak/latest/cookbooks/Statistics-and-Monitoring/). 
&gt;&gt; Specifically look at node\\_get\\_fsm\\_objsize\\_\\* and node\\_get\\_fsm\\_siblings\\_\\* 
&gt;&gt; statistics in order to identify objects that are very large or have lots of 
&gt;&gt; siblings.
&gt;&gt; 
&gt;&gt; Best regards,
&gt;&gt; 
&gt;&gt; Christian
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On 13 May 2013, at 16:44, Julien Genestoux  
&gt;&gt; wrote:
&gt;&gt; 
&gt;&gt;&gt; Christian, All,
&gt;&gt;&gt; 
&gt;&gt;&gt; Bad news: my laptop is completely dead. Good news: I have a new one, and 
&gt;&gt;&gt; it's now fully operational (backups FTW!).
&gt;&gt;&gt; 
&gt;&gt;&gt; The log files have finally been uploaded: 
&gt;&gt;&gt; https://www.dropbox.com/s/j7l3lniu0wogu29/riak-died.tar.gz
&gt;&gt;&gt; 
&gt;&gt;&gt; I have attached to that mail our config.
&gt;&gt;&gt; 
&gt;&gt;&gt; The machine is a virtual Xen instance at Linode with 4GB of memory. I know 
&gt;&gt;&gt; it's probably not the very best setup, but 1) we're on a budget and 2) we 
&gt;&gt;&gt; assumed that would fit our needs quite well.
&gt;&gt;&gt; 
&gt;&gt;&gt; Just to put things in more details. Initially we did not use allow\\_mult and 
&gt;&gt;&gt; things worked out fine for a couple of days. As soon as we enabled 
&gt;&gt;&gt; allow\\_mult, we were not able to run the cluster for more then 5 hours 
&gt;&gt;&gt; without seeing failing nodes, which is why I'm convinced we must be doing 
&gt;&gt;&gt; something wrong. The question is: what? 
&gt;&gt;&gt; 
&gt;&gt;&gt; Thanks
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On Sun, May 12, 2013 at 8:07 PM, Christian Dahlqvist  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; Hi Julien,
&gt;&gt;&gt; 
&gt;&gt;&gt; I was not able to access the logs based on the link you provided.
&gt;&gt;&gt; 
&gt;&gt;&gt; Could you please attach a copy of your app.config file so we can get a 
&gt;&gt;&gt; better understanding of the configuration of your cluster? Also, what is 
&gt;&gt;&gt; the specification of the machines in the cluster?
&gt;&gt;&gt; 
&gt;&gt;&gt; How much data do you have in the cluster and how are you querying it?
&gt;&gt;&gt; 
&gt;&gt;&gt; Best regards,
&gt;&gt;&gt; 
&gt;&gt;&gt; Christian
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; On 12 May 2013, at 19:11, Julien Genestoux  
&gt;&gt;&gt; wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Hi,
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; We are running a cluster of 5 servers, or at least trying to, because 
&gt;&gt;&gt;&gt; nodes seem to be dying 'randomly'
&gt;&gt;&gt;&gt; without us knowing any reason why. We don't have a great Erlang guy 
&gt;&gt;&gt;&gt; aboard, and the error logs are not
&gt;&gt;&gt;&gt; that verbose.
&gt;&gt;&gt;&gt; So I've just .tgz the whole log directory and I was hoping somebody could 
&gt;&gt;&gt;&gt; give us a clue.
&gt;&gt;&gt;&gt; It's there: https://www.dropbox.com/s/z9ezv0qlxgfhcyq/riak-died.tar.gz 
&gt;&gt;&gt;&gt; (might not be fully uploaded to dropbox yet!)
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; I've looked at the archive and some people said their server was dying 
&gt;&gt;&gt;&gt; because some object's size was just 
&gt;&gt;&gt;&gt; too big to allocate the whole memory. Maybe that's what we're seeing?
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; As one of our buckets is set with allow\\_mult, I am tempted to think that 
&gt;&gt;&gt;&gt; some object's size may be exploding.
&gt;&gt;&gt;&gt; However, we do actually try to resolve conflicts in our code. Any idea how 
&gt;&gt;&gt;&gt; to confirm and then debug that we 
&gt;&gt;&gt;&gt; have an issue there?
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Thanks a lot for your precious help...
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Julien
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt; 
&gt; 

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

