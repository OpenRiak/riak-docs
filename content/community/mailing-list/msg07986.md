---
title: "Re: Range Loop Timeout Error after (after disk space over limit)"
description: ""
project: community
lastmod: 2012-07-18T10:03:00-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07986"
mailinglist_parent_id: "msg07959"
author_name: "Arnaud Wetzel"
project_section: "mailinglistitem"
sent_date: 2012-07-18T10:03:00-07:00
---


Ryan,
Increasing "ulimit -n" (current value is 4096, I have tested from 1024 to
200000) does not change anything, always the same errors :
{timeout,range\\_loop}
lookup/range failure:
{{badfun,#Fun},[{mi\\_server,iterate,6},{mi\\_server,lookup,8}]}

I cannot find the command "repair" that you talk about in your email (on
riak1.2.0-rc1), is it a function directly in an erlang module and not
accessible yet with riak-admin ?

Thank you very much.

-- 
Arnaud Wetzel
KBRW Ad-Venture
13 rue st Anastase, 75003 Paris

2012/7/16 Ryan Zezeski 

&gt; Arnaud,
&gt;
&gt; The 'stream\\_timeout' and 'emfile' should be correlated. Whenever you see
&gt; the 'emfile' you should see a corresponding timeout. The index server
&gt; errors causing the result collector to timeout later. First, adjust your
&gt; file descriptor limit and then go from there.
&gt;
&gt; For the 1.2 release a "repair" command has been added to rebuild KV or
&gt; index data for a given partition. In releases before that you must reindex
&gt; all your data. You don't have to worry about removing the current indexes
&gt; as merge index will garbage collect that for you as it merges. As I said,
&gt; first I would fix the 'emfile' issue and then see if further action is
&gt; needed.
&gt;
&gt; -Z
&gt;
&gt; P.S. If you want to be absolutely sure what your FD limit is in Riak you
&gt; can `riak attach` and then `os:cmd("ulimit -n").` Make sure to use Ctrl-D
&gt; to exit from the Riak shell.
&gt;
&gt; On Mon, Jul 16, 2012 at 5:21 AM, Arnaud Wetzel wrote:
&gt;
&gt;&gt; Hi,
&gt;&gt; Friday evening one of our riak node has reach his disk space limit during
&gt;&gt; indexing in riak-search. Then after adding some nodes, some requests fail,
&gt;&gt; and it is impossible to find the correlation between requests with error or
&gt;&gt; those who succeed.
&gt;&gt; The errors are :
&gt;&gt;
&gt;&gt; {{nocatch,stream\\_timeout},[{riak\\_search\\_op\\_utils,gather\\_stream\\_results,4}]}
&gt;&gt; {timeout,range\\_loop}
&gt;&gt;
&gt;&gt; and sometimes (not always) :
&gt;&gt;
&gt;&gt; {{badmatch,{error,emfile}},[{mi\\_segment,iterate\\_by\\_keyinfo,7},{mi\\_server,'-lookup/8-lc$^1/1-1-',4},{mi\\_server,'-lookup/8-lc$^1/1-1-',4},{mi\\_server,lookup,8}]}
&gt;&gt;
&gt;&gt; So anyone else has experienced these errors ? Is it possible that they
&gt;&gt; come from the disk over limit error ? How can I try to repair merge index
&gt;&gt; data ? If it is not possible, what is the good process to delete entirely
&gt;&gt; all the indexes (only indexes, keeping riak datas).
&gt;&gt;
&gt;&gt; Thank you very much.
&gt;&gt;
&gt;&gt; Regards.
&gt;&gt;
&gt;&gt; --
&gt;&gt; Arnaud Wetzel
&gt;&gt; KBRW Ad-Venture
&gt;&gt; 13 rue st Anastase, 75003 Paris
&gt;
