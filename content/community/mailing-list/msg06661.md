---
title: "Re: questions about search"
description: ""
project: community
lastmod: 2012-02-20T16:48:26-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06661"
mailinglist_parent_id: "msg06647"
author_name: "Ryan Zezeski"
project_section: "mailinglistitem"
sent_date: 2012-02-20T16:48:26-08:00
---


Jason,

In general Riak Search is far from a Solr/Lucene clone. It's main relation
is that it supports the Lucene syntax and has an HTTP interface that
roughly looks like Solr but doesn't support a lot of it's features and also
has different semantics in some cases.

If you rely on specific Lucene/Solr functionality, such as joins or
specific analyzers then Riak Search is probably not going to fit the bill.
 Some Riak users have chosen to integrate with external solutions such as
Solr or Elasticsearch. As you mention this poses potential consistency
issues and more deployment work, but perhaps you can work around those
things.

More comments inline...

On Mon, Feb 20, 2012 at 1:08 AM, Jason Toy  wrote:

&gt; I'm considering moving a fairly large data instance to riak because of
&gt; the distributed nature and because of full integration with search.
&gt; Avoiding the work of keeping solr and a datastore in sync sounds great.
&gt; I've gone through the wiki pages regarding search and I have a couple of
&gt; questions.
&gt;
&gt;
&gt; - Are the search scores returned from the solr/search interface
&gt; accessible to the client running the search?
&gt;

This probably depends on the client but I don't see why the score shouldn't
be exposed.


&gt;
&gt; - Is the scoring system built to be modifying by developers? In our
&gt; current system, we have a modified solr scoring system to model our needs.
&gt; If I did want to modify it, would it coded in java or erlang?
&gt;

No, it's hardcoded in Erlang. There is currently no way to customize it
like you can in Lucene.


&gt;
&gt;
&gt; - I have searched around and I have not seen many case studies of using
&gt; riak search with large amounts of keys. I'm not even sure what large means
&gt; for riak. Our total data size of indexed data is about 500 million docs
&gt; and growing. Most docs are small, about 64kb in size, but we also have a
&gt; couple million docs that are multi mbs.
&gt;

The concern isn't so much the number of objects you store/index as it is
the number of objects that match any given query. For example, an AND
operator with a large result set on one side can cause serious performance
issues because of Search's distributed nature (it has to stream/merge sort
the postings from both sides). This can be alleviated with inline fields
but at a cost of a larger index. Also, the size of the object shouldn't
affect Search because it's streaming postings in most cases but there is a
practical limit with Riak in general. We say don't go past 40MB or so but
I would say the practical limit is much, much lower. Giving you a hard
number would be foolish on my part because something like that is going to
depend greatly on your hardware/software stack. You need to benchmark with
real data and real load to know for sure. But to be pragmatic, I'd
probably say in the single digit MBs.


&gt;
&gt; - According to this page:
&gt; http://wiki.basho.com/Riak-Search---Querying.html#Query-Scoring there is
&gt; no actual idf score? How are documents actually ranked then if no idf is
&gt; used? if docs get matched on a query on different nodes, how is the order
&gt; of results reassembled without using know the total number of documents in
&gt; a collection?
&gt;

I'm going to punt on this for now. I'll try to get back to you with an
answer later.


&gt;
&gt;
&gt; - does riak search have the ability to do a join? A feature we heavily
&gt; use from the lucene unstable branch is the ability to do a "hash join" (
&gt; https://issues.apache.org/jira/browse/SOLR-2272).
&gt; Our use case is we have documents of type User who have BlogPosts.
&gt; We want to match all the BlogPosts that mentioned "tires" and where their
&gt; User's description mentions " taxi driver". We can't index all the
&gt; User data into each Blog Post because we have ~400+ million blog posts and
&gt; ~2+ millions of Users with both growing. We need the search to be in
&gt; realtime so its not a situation where we could do background processing.
&gt; Is there a way to model this with riak search?
&gt;

No. To satisfy this query you'd have to denormalize and put some user data
in the blog post index (probably as an inline field).


&gt; - Is this a bug in riak search and has this been solved?
&gt; http://lists.basho.com/pipermail/riak-users\\_lists.basho.com/2012-January/007114.html
&gt;

No, it has not been addressed.


&gt; - can indexing and indexes be used together? I see there is support for
&gt; doing exact/range queries in search if riak already can index dates?
&gt;

Are you asking if you can use 2i and Search together? If so, yes.

Search can do everything 2i can do. The main difference at this point is
the API and the query engine. Search uses term-based partitioning whereas
2i is document-based. Both have their pros/cons, but the main thing to
take away is Search only has to query one node for a term query, 2i has to
query 1/N of the nodes. I've talked about this before on the mailing list.
 I can dig up the threads if you want more information.


&gt;
&gt; -finally is there a way to measure what kind of ram/hardware will be
&gt; needed to support the indexes?
&gt;

Capacity planning is tricky, to say the least. Both 2i and Search use
sequential log, generational merging techniques (2i uses leveldb, Search
uses our in-house index merge\\_index). Estimating disk/memory overhead for
a given document in Search is also difficult since it relies on the data,
the analyzer and other field options. It should be fairly easy to add an
API to Search to take a document, do a dry-run, and tell you disk/memory
overhead, but currently there is no such thing. We do have some general
capacity planning pages but nothing specifically on Search.

http://wiki.basho.com/Cluster-Capacity-Planning.html

http://wiki.basho.com/System-Requirements.html

http://wiki.basho.com/Bitcask-Capacity-Planning.html

-Ryan
