---
title: "Re: High volume data series storage and queries"
description: ""
project: community
lastmod: 2011-08-09T18:32:11-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04310"
mailinglist_parent_id: "msg04280"
author_name: "Paul O"
project_section: "mailinglistitem"
sent_date: 2011-08-09T18:32:11-07:00
---


Alexander, the whole batching strategy I described in my initial post is
trying to help the problem better map to a kv store such as Riak. The plan
is for each batch of MaxN events to be stored under a single key, hence
avoiding the problem of storing too few tiny values. I'm still surprised of
a 450 bytes per value overhead.

I do appreciate your reasoning around this, though.

In the end Ciprian's earlier suggestion (Riak core + custom storage) would
seem to win the day. Not sure if the tradeoff would pay off immediately,
though, so I might end up having some strategy for the initial volume
expectations with a migration plan to a more advanced solution sometimes
down the road, I guess.

Regards,

Paul

On Tue, Aug 9, 2011 at 10:43 AM, Alexander Sicular wrote:

&gt; A couple of thoughts:
&gt;
&gt; -disk io
&gt; -total keys versus memory
&gt; -data on disk overhead
&gt;
&gt; As Jeremiah noted, disk io is crucial. Thankfully, Riak's distributed mesh
&gt; gives you access to a number of spindles limited only by your budget. I
&gt; think that is a critical bonus of a distributed system like Riak that is
&gt; often not fully appreciated. Here Riak is a win for you.
&gt;
&gt; Bitcask needs all keys to fit in memory. We are talking something like:
&gt;
&gt; (key length + overhead) \\* number of keys \\* replicas &lt; cluster max available
&gt; ram.
&gt;
&gt; There is a tool on the wiki which should help figure this out. What that
&gt; basically means for you is that you will have to batch your data by some
&gt; sensor/time granularity metric. Let's say every minute. At 10hz that is a
&gt; 600x reduction in total keys. Of course, this doesn't come for free. Your
&gt; application middleware will have to accommodate. That means you could lose
&gt; up to whatever your time granularity batch is. Ie. You could lose a minute
&gt; of sensor data should your application fail. Here Riak is neutral to
&gt; negative.
&gt;
&gt; Riak data structure is not friendly towards small values. Sensor data
&gt; generally spit out integers or other small data tuples. If you search the
&gt; list archives you will find a magnificent data overhead writeup. IIRC, it
&gt; was something on the order of 450b. What that basically tells you is that
&gt; you can't use bitcask for small values if disk space is a concern, as I
&gt; imagine it to be in this case. Also, sensor data is generally write only,
&gt; ie. never deleted or modified, so compaction should not be a concern when
&gt; using bitcask. Here Riak is a strong negative.
&gt;
&gt; Data retrieval issues aside (which between Riak Search/secondary
&gt; indexes/third party indexes should not be a major concern), I am of the
&gt; opinion that Riak is not a good fit for high frequency sensor data
&gt; applications.
&gt;
&gt; Cheers,
&gt; Alexander
&gt;
&gt; Sent from my rotary phone.
&gt; On Aug 8, 2011 9:40 PM, "Paul O"  wrote:
&gt; &gt; Quite a few interesting points, thanks!
&gt; &gt;
&gt; &gt; On Mon, Aug 8, 2011 at 5:53 PM, Jeremiah Peschka &lt;
&gt; jeremiah.pesc...@gmail.com
&gt; &gt;&gt; wrote:
&gt; &gt;
&gt; &gt;&gt; Responses inline
&gt; &gt;&gt;
&gt; &gt;&gt; On Aug 8, 2011, at 1:25 PM, Paul O wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Will any existing data be imported? If this is totally greenfield, then
&gt; &gt;&gt; you're free to do whatever zany things you want!
&gt; &gt;
&gt; &gt;
&gt; &gt; Almost totally greenfield, yes. Some data will need to be imported but
&gt; it's
&gt; &gt; already in the format described.
&gt; &gt;
&gt; &gt; Ah, so you need IOPS throughput, not storage capacity. On the hardware
&gt; side
&gt; &gt;&gt; make sure your storage subsystem can keep up - don't cheap out on disks
&gt; just
&gt; &gt;&gt; because you have a lot of nodes. A single rotational HDD can only handle
&gt; &gt;&gt; about 180 IOPS on average. There's a lot you can do on the storage
&gt; backend
&gt; &gt;&gt; to make sure you're able to keep up there.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Indeed, storage capacity is also an issue but IOPS would be important,
&gt; too.
&gt; &gt; I assume that sending batches to Riak (opaque blobs) would help a lot
&gt; with
&gt; &gt; the quantity of writes, but it's still a very important point.
&gt; &gt;
&gt; &gt; You may want to look into ways to force Riak to clean up the bitcask
&gt; files.
&gt; &gt;&gt; I don't entirely remember how it's going to handle cleaning up deleted
&gt; &gt;&gt; records, but you might run into some tricky situations where compactions
&gt; &gt;&gt; aren't occurring.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Hm, any references regarding that? It would be a major snag in the whole
&gt; &gt; schema Riak doesn't properly reclaim space for deleted records.
&gt; &gt;
&gt; &gt; Riak is pretty constant time for Bitcask. The tricky part with the amount
&gt; of
&gt; &gt;&gt; data you're describing is that Bitcask requires (I think) that all keys
&gt; fit
&gt; &gt;&gt; into memory. As your data volume increases, you'll need to do a
&gt; combination
&gt; &gt;&gt; of scaling up and scaling out. Scale up RAM in the nodes and then add
&gt; &gt;&gt; additional nodes to handle load. RAM will help with data volume, more
&gt; nodes
&gt; &gt;&gt; will help with write throughput.
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Indeed, for high frequency sources that would create lots of bundles even
&gt; &gt; the MaxN to 1 reduction for key names might still generate loads of keys.
&gt; &gt; Any idea how much RAM Riak requires per record, or a reference that would
&gt; &gt; point me to it?
&gt; &gt;
&gt; &gt; Since you're searching on time series, mostly, you could build time
&gt; indexes
&gt; &gt;&gt; in your RDBMS. The nice thing is that querying temporal data is well
&gt; &gt;&gt; documented in the relational world, especially in the data warehousing
&gt; &gt;&gt; world. In your case, I'd create a dates table and have a foreign key
&gt; &gt;&gt; relating to my RDBMS index table to make it easy to search for dates.
&gt; &gt;&gt; Querying your time table will be fast which reduces the need for scans
&gt; in
&gt; &gt;&gt; your index table.
&gt; &gt;&gt;
&gt; &gt;&gt; EXAMPLE:
&gt; &gt;&gt;
&gt; &gt;&gt; CREATE TABLE timeseries (
&gt; &gt;&gt; time\\_key INT,
&gt; &gt;&gt; date TIMESTAMP,
&gt; &gt;&gt; datestring VARCHAR(30),
&gt; &gt;&gt; year SMALLINT,
&gt; &gt;&gt; month TINYINT,
&gt; &gt;&gt; day TINYINT,
&gt; &gt;&gt; day\\_of\\_week TINYINT
&gt; &gt;&gt; -- etc
&gt; &gt;&gt; );
&gt; &gt;&gt;
&gt; &gt;&gt; CREATE TABLE riak\\_index (
&gt; &gt;&gt; id INT NOT NULL,
&gt; &gt;&gt; time\\_key INT NOT NULL REFERENCES timeseries(time\\_key),
&gt; &gt;&gt; riak\\_key VARCHAR(100) NOT NULL
&gt; &gt;&gt; );
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; SELECT ri.riak\\_key
&gt; &gt;&gt; FROM timeseries ts
&gt; &gt;&gt; JOIN riak\\_index ri ON ts.time\\_key = ri.time\\_key
&gt; &gt;&gt; WHERE ts.date BETWEEN '20090702' AND '20100702';
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; My plan was to have the riak\\_index contain something like: (id,
&gt; start\\_time,
&gt; &gt; end\\_time, source\\_id, record\\_count.)
&gt; &gt;
&gt; &gt; Without going too much into RDBMS fun, this pattern can get your RDBMS
&gt; &gt;&gt; running pretty quickly and then you can combine that with Riak's
&gt; performance
&gt; &gt;&gt; and have a really good idea of how quick any query will be.
&gt; &gt;
&gt; &gt;
&gt; &gt; That's roughly the plan, thanks again for your contributions to the
&gt; &gt; discussion!
&gt; &gt;
&gt; &gt; Paul
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

