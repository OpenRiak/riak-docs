---
title: "Re: have a new node take over the role of a downed,	unrecoverable node?"
description: ""
project: community
lastmod: 2010-10-16T18:53:03-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01317"
mailinglist_parent_id: "msg01316"
author_name: "Leonid Riaboshtan"
project_section: "mailinglistitem"
sent_date: 2010-10-16T18:53:03-07:00
---


&gt;&gt; However, you'll need to reip on all machines.

Hmm, isn't stuff like that should be treated automaticly by Riak? I mean I
have a cluster where nodes leave, nodes come. And after each come/leave I
need to do something to nodes in entire cluster to entroduce/remove new/old
node and repartion the data?

And question sounds rather strange to me, what is the node role in system
where all nodes are equal? It's everywhere said that Riak will
automatically re-balance data as nodes join and leave the cluster. It's not
the case when node becomes unreachable and cluster would repartion data to
keep it solid (like keeping n\\_val for keys)?

Or something else should watch for nodes states and tell cluster that node
is down?

It's also said that:
The ring state is shared around the cluster by means of a "gossip protocol".
Whenever a node changes its claim on the ring, it announces its change via
this protocol. It also periodically re-announces what it knows about the
ring, in case any nodes missed previous updates.

Isn't cluster checking on unavailable nodes that way too?

I'm not offending anyone, just trying to make things more clear for myself.

On Sun, Oct 17, 2010 at 4:56 AM, Jesse Newland wrote:

&gt; Thanks Sean!
&gt;
&gt; Regards -
&gt;
&gt; Jesse Newland
&gt; ---
&gt; je...@railsmachine.com
&gt; 404.216.1093
&gt;
&gt; On Oct 16, 2010, at 7:01 PM, Sean Cribbs wrote:
&gt;
&gt; &gt; Sorry, I wasn't completely clear. You can make any node "leave" from the
&gt; console. e.g.
&gt; &gt;
&gt; &gt; riak\\_core\\_gossip:remove\\_from\\_cluster('r...@some-host.com').
&gt; &gt;
&gt; &gt; Sean Cribbs 
&gt; &gt; Developer Advocate
&gt; &gt; Basho Technologies, Inc.
&gt; &gt; http://basho.com/
&gt; &gt;
&gt; &gt; On Oct 16, 2010, at 5:05 PM, Alexander Sicular wrote:
&gt; &gt;
&gt; &gt;&gt; This has come up before. "Leave" is what is currently available and
&gt; &gt;&gt; needs to be run on the node that wants to leave. This, of course,
&gt; &gt;&gt; means the node needs to be available. What you really want is a kick
&gt; &gt;&gt; like "remove" or something that doesn't exist yet, afaik. I think
&gt; &gt;&gt; there is a ticket open.
&gt; &gt;&gt;
&gt; &gt;&gt; -alexander
&gt; &gt;&gt;
&gt; &gt;&gt; On 2010-10-16, Jesse Newland  wrote:
&gt; &gt;&gt;&gt; The description of leave on the wiki mentions that it "causes the node
&gt; to
&gt; &gt;&gt;&gt; leave the cluster it participates in" - I assume "the node" refers to
&gt; the
&gt; &gt;&gt;&gt; node this command is run on? How would I "leave" a node that I can't
&gt; run
&gt; &gt;&gt;&gt; this command on anymore?
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; Regards -
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; Jesse Newland
&gt; &gt;&gt;&gt; ---
&gt; &gt;&gt;&gt; je...@railsmachine.com
&gt; &gt;&gt;&gt; 404.216.1093
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; On Oct 16, 2010, at 3:16 PM, Sean Cribbs wrote:
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; `leave` is exactly what you want to do then. Once the old node has
&gt; left
&gt; &gt;&gt;&gt;&gt; (use `ringready` to track its exit), add the new neode.
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; If the EBS volume containing the node's data was not lost, you could
&gt; mount
&gt; &gt;&gt;&gt;&gt; it onto the new node to save some recovery time, and then reip.
&gt; However,
&gt; &gt;&gt;&gt;&gt; you'll need to reip on all machines.
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; Sean Cribbs 
&gt; &gt;&gt;&gt;&gt; Developer Advocate
&gt; &gt;&gt;&gt;&gt; Basho Technologies, Inc.
&gt; &gt;&gt;&gt;&gt; http://basho.com/
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt; On Oct 16, 2010, at 2:54 PM, Jesse Newland wrote:
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; I'm running through some disaster scenarios before bringing a riak
&gt; &gt;&gt;&gt;&gt;&gt; cluster into production, and have run into a scenario that I can't
&gt; work
&gt; &gt;&gt;&gt;&gt;&gt; through the proper resolution for just yet:
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; Say an ec2 instance that was a part of a ring went away quickly, and
&gt; data
&gt; &gt;&gt;&gt;&gt;&gt; from it was unrecoverable.
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; How might I go about telling the rest of the ring that a new instance
&gt; &gt;&gt;&gt;&gt;&gt; that I've brought up should take over the vnodes that were on that
&gt; old
&gt; &gt;&gt;&gt;&gt;&gt; instance? This sounds like a job for `riak-admin reip`, but after
&gt; running
&gt; &gt;&gt;&gt;&gt;&gt; `reip downed\\_node new\\_node`, `riak-admin ringready` still shows that
&gt; the
&gt; &gt;&gt;&gt;&gt;&gt; old nodes are a part of the ring and down. I guess what I'd like to
&gt; do is
&gt; &gt;&gt;&gt;&gt;&gt; a posthumeous `leave`?
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; Thoughts?
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; Regards -
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; Jesse Newland
&gt; &gt;&gt;&gt;&gt;&gt; ---
&gt; &gt;&gt;&gt;&gt;&gt; je...@railsmachine.com
&gt; &gt;&gt;&gt;&gt;&gt; 404.216.1093
&gt; &gt;&gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt;&gt;&gt;&gt;&gt; riak-users mailing list
&gt; &gt;&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt; &gt;&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; &gt;&gt;&gt;&gt;
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; --
&gt; &gt;&gt; Sent from my mobile device
&gt; &gt;
&gt;
&gt;

