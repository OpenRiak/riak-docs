---
title: "Re: Performance issues with small dataset"
description: ""
project: community
lastmod: 2011-01-12T23:58:44-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01969"
mailinglist_parent_id: "msg01967"
author_name: "Alexander Staubo"
project_section: "mailinglistitem"
sent_date: 2011-01-12T23:58:44-08:00
---


On Thu, Jan 13, 2011 at 03:08, Alexander Sicular  wrote:
&gt; Item number one: if you are using stock riak then you are also using the
&gt; stock nval (number of replicas) of 3. This means that your 1000 k/v write is
&gt; actually 3000 items written to disk.

Reducing n\\_value does not improve m/r times noticeably for my test,
and reduces list performance only slightly.

&gt; There are more caveats but I'll end with three. For any critically
&gt; performant system you must use the protocol buffers interface

Understandable, but probably not relevant in this case since there is
so little data involved.

&gt; and you must juggle connections.

Do you mean pooling? If not, what do you mean?

&gt; Additionally, anonymous JavaScript functions have a
&gt; penalty associated.

Does this entail pre-defining them somewhere? I can't find any
documentation on this, can you point me to the relevant place?

&gt; Lastly you should also upgrade from JavaScript m/r
&gt; functions to erlang. There is performance impedance when pushing json from
&gt; the native erlang interface into the JavaScript vm.

Basho claims it's insignificant, though: "There is a slight overhead
when encoding the Riak object to JSON but otherwise the performance
[of Erlang named functions vs. JS named functions] is comparable." [1]

[1] http://blog.basho.com/2010/07/27/webinar-recap---mapreduce-querying-in-riak/

&gt; Riak has many benefits but bleeding single node performance is not one of
&gt; them. Predictable, scaleable units of performance per node throughout a
&gt; cluster is.

Unfortunately, even if additional nodes yield linear performance
gains, the m/r overhead seems very large -- if I'm getting 1.5 seconds
to process 1,000 items on one node, it seems apparent that I should
get roughtly 1.5 seconds to process 3,000 items on 3 nodes, which
still is awfully slow.

Do you know how Riak compares to HBase, MongoDB or Cassandra for large
dataset processing and analysis with m/r, when talking hundreds of
millions, or even billions of keys? It would seem that key traversal
performance would preventing Riak from competing in that space. Maybe
you could do something with Riak Search, but I'm not sure if it would
comparable.

