---
title: "Re: Whole cluster times out if one node is gone"
description: ""
project: community
lastmod: 2010-11-29T09:40:22-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01652"
mailinglist_parent_id: "msg01646"
author_name: "Jay Adkisson"
project_section: "mailinglistitem"
sent_date: 2010-11-29T09:40:22-08:00
---


Hey Dan/Sean,

Thanks for the response. sasl-error.log on node A is completely empty, and
I see this pattern in erlang.log:

===== ALIVE Tue Nov 23 12:46:57 PST 2010

===== Tue Nov 23 12:57:36 PST 2010

=ERROR REPORT==== 23-Nov-2010::12:57:36 ===
\\*\\* Node 'riak@' not responding \\*\\*
\\*\\* Removing (timedout) connection \\*\\*

=INFO REPORT==== 23-Nov-2010::12:58:41 ===
Starting handoff of partition riak\\_kv\\_vnode
251195593916248939066258330623111144003363405824 to 'riak@'

=INFO REPORT==== 23-Nov-2010::12:58:41 ===
Handoff of partition riak\\_kv\\_vnode
251195593916248939066258330623111144003363405824 to 'riak@'
completed: sent 1 objects in 0.02 seconds
=INFO REPORT==== 23-Nov-2010::12:59:18 ===
Starting handoff of partition riak\\_kv\\_vnode
707914855582156101004909840846949587645842325504 to 'riak@'

=INFO REPORT==== 23-Nov-2010::12:59:18 ===
Handoff of partition riak\\_kv\\_vnode
707914855582156101004909840846949587645842325504 to 'riak@'
completed: sent 5 objects in 0.03 seconds
=INFO REPORT==== 23-Nov-2010::12:59:20 ===
Starting handoff of partition riak\\_kv\\_vnode
525227150915793236229449236757414210188850757632 to 'riak@'



This is my testing process: I'm doing an initial load into riak of small
image files between 1 and 150K, throttled to two images per second, with
W=1. In a different terminal, I'm running a wget every second against node
A of one particular image I already know to be in the cluster, again with
R=1. I'm using R,W=1 because I figured that would reduce the chance of
timing out, and with my data pattern, nothing I write to the cluster will
ever change, so I really don't need to wait for a quorum.

In response to Sean,

&gt; 1) Riak detects node outage the same way any Erlang system does - when a
&gt; message fails to deliver, or the heartbeat maintained by epmd fails. The
&gt; default timeout in epmd is 1 minute, which is probably why you're seeing it
&gt; take 1 minute to be detected.
&gt;
Thanks, this is enlightening.

2) If it takes too long (the vnode is overloaded, perhaps, or is just
&gt; starting up as a hint partition) to retrieve from any node, the request can
&gt; time out.
&gt;
That makes sense, but I still wonder why this happens even when the quorum
is already met by the machines that are responding normally?


&gt; 3) You could probably configure epmd to timeout sooner, but then you become
&gt; more vulnerable to temporary partitions. YMMV
&gt;
I may try that - it might be a good fit with my data pattern.

Thanks again,
--Jay


On Mon, Nov 29, 2010 at 4:44 AM, David Smith  wrote:

&gt; On Tue, Nov 23, 2010 at 3:33 PM, Jay Adkisson  wrote:
&gt; &gt; (many profuse apologies to Dan - hit "reply" instead of "reply all")
&gt; &gt; Alrighty, I've done a little more digging. When I throttle the writes
&gt; &gt; heavily (2/sec) and set R and W to 1 all around, the cluster works just
&gt; fine
&gt; &gt; after I restart the node for about 15-20 seconds. Then the read request
&gt; &gt; hangs for about a minute, until node D disappears from connected\\_nodes in
&gt; &gt; riak-admin status, at which point it returns the desired value (although
&gt; &gt; sometimes I get a 503):
&gt;
&gt; Are you seeing any error messages in log/erlang.log.\\* or
&gt; log/sasl-error.log?
&gt;
&gt; Can you expound on your use case a little -- are you doing a large
&gt; insert, or just a random read/write mix? Did you pre-populate the
&gt; dataset? Why are you using r=1, instead of relying on quorom for
&gt; reads?
&gt;
&gt; How are you running the riak-admin status to measure the 15-20 seconds?
&gt;
&gt; Thanks.
&gt;
&gt; D.
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

