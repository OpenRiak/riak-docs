---
title: "Re: keys=stream"
description: ""
project: community
lastmod: 2010-05-12T20:17:44-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg00344"
mailinglist_parent_id: "msg00342"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2010-05-12T20:17:44-07:00
---


If the problem is with net/http then we need to fix that backend, not apply 
hacks to the generic portions. You can verify that Riak will return valid JSON 
objects in each chunk by adding --raw to the curl command. Here's what I get 
after loading the Fast Track stock data: http://gist.github.com/399450 

Sean Cribbs 
Developer Advocate
Basho Technologies, Inc.
http://basho.com/

On May 12, 2010, at 10:55 PM, Adam Hunter wrote:

&gt; This is a confirmed bug and will be fixed soon. You can check out 
&gt; http://github.com/adamhunter/ripple/blob/associations/lib/riak/bucket.rb : 65 
&gt; for a temporary hack.
&gt; 
&gt; Thanks,
&gt; 
&gt; Adam
&gt; 
&gt; On May 12, 2010, at 10:17 PM, Andrew Harvey wrote:
&gt; 
&gt;&gt; I've just run into this one as well.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Not sure if it's a curb thing or what, but it's making me a sad panda. We 
&gt;&gt; have 500k+ keys in our bucket, and I'm being returned chunks of invalid json 
&gt;&gt; so nothing is being yielded to my block. Needless to say, the task I'm doing 
&gt;&gt; here I'd prefer to do in a MapReduce, but unfortunately I need to get 
&gt;&gt; everything out into ruby-land for the moment.
&gt;&gt; 
&gt;&gt; Andrew
&gt;&gt; 
&gt;&gt; 
&gt;&gt; On 04/05/2010, at 11:46 PM, Sean Cribbs wrote:
&gt;&gt; 
&gt;&gt;&gt; This looks like a bug. I'll add an issue to the github tracker.
&gt;&gt;&gt; 
&gt;&gt;&gt; Sean Cribbs 
&gt;&gt;&gt; Developer Advocate
&gt;&gt;&gt; Basho Technologies, Inc.
&gt;&gt;&gt; http://basho.com/
&gt;&gt;&gt; 
&gt;&gt;&gt; On May 4, 2010, at 9:29 AM, Adam Hunter wrote:
&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; Just curb, I couldn't get net/http to work when doing chunked (something 
&gt;&gt;&gt;&gt; about read\\_body being called twice).
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; On May 4, 2010, at 9:28 AM, Sean Cribbs wrote:
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Are you using curb or net/http?
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; Sean Cribbs 
&gt;&gt;&gt;&gt;&gt; Developer Advocate
&gt;&gt;&gt;&gt;&gt; Basho Technologies, Inc.
&gt;&gt;&gt;&gt;&gt; http://basho.com/
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; On May 4, 2010, at 9:26 AM, Adam Hunter wrote:
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; The problem I was running into was some of the chunks were only part of 
&gt;&gt;&gt;&gt;&gt;&gt; the json object. Decoded it would be something like this:
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; chunk 1: {'keys':[1,2,3,4
&gt;&gt;&gt;&gt;&gt;&gt; chunk 2: 5,6,7,8,9]}
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; I was running this on a bucket with about 11k keys. Using ripple I 
&gt;&gt;&gt;&gt;&gt;&gt; could only get about 150 keys back this way because all the other chunks 
&gt;&gt;&gt;&gt;&gt;&gt; were not valid json. I hacked around this for now by checking to see if 
&gt;&gt;&gt;&gt;&gt;&gt; the chunk ends in ]}, otherwise I accumulate chunks until I have a full 
&gt;&gt;&gt;&gt;&gt;&gt; json object.
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Thanks,
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; Adam
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; On May 4, 2010, at 9:22 AM, Sean Cribbs wrote:
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; This behavior is unchanged since its implementation in 0.8 or 0.9. To 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; better demonstrate what that statement means, here's the joined output 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; of a streamed keys response:
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; {"props":{"name":"foo","n\\_val":3,"allow\\_mult":false,"precommit":[],"postcommit":[],"chash\\_keyfun":{"mod":"riak\\_core\\_util","fun":"chash\\_std\\_keyfun"},"linkfun":{"mod":"riak\\_kv\\_wm\\_link\\_walker","fun":"mapreduce\\_linkfun"},"old\\_vclock":86400,"young\\_vclock":20,"big\\_vclock":50,"small\\_vclock":10}}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}{"keys":[]}
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; If your client library supports per-chunk processing, each of those 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; {"keys":[]} objects will be an encoded chunk. The Ruby client and most 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; of the other clients support this.
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sean Cribbs 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Developer Advocate
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Basho Technologies, Inc.
&gt;&gt;&gt;&gt;&gt;&gt;&gt; http://basho.com/
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt; On May 3, 2010, at 9:28 PM, Adam Hunter wrote:
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi All,
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I apologize if this has been covered already.
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; In the wiki it says "If keys=stream, the response will be transferred 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; using chunked-encoding, where each chunk is a JSON object" (on 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; http://wiki.basho.com/display/RIAK/REST+API)
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; This doesn't seem to be the case, sometimes a json object is broken 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; into several chunks. Is this behavior correct?
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thanks,
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Adam
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt;&gt; 
&gt;&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; 
&gt;&gt;&gt; Click here to report this email as spam.
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Andrew Harvey / Developer 
&gt;&gt; lexer
&gt;&gt; 
&gt;&gt; m/ 
&gt;&gt; t/ +61 2 9019 6379
&gt;&gt; w/ http://lexer.com.au
&gt;&gt; 
&gt;&gt; Help put an end to whaling. Visit www.givewhalesavoice.com.au
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; Please consider the environment before printing this email
&gt;&gt; This email transmission is confidential and intended solely for the person 
&gt;&gt; or organisation to whom it is addressed. If you are not the intended 
&gt;&gt; recipient, you must not copy, distribute or disseminate the information, or 
&gt;&gt; take any action in relation to it and please delete this e-mail. Any views 
&gt;&gt; expressed in this message are those of the individual sender, except where 
&gt;&gt; the send specifically states them to be the views of any organisation or 
&gt;&gt; employer. If you have received this message in error, do not open any 
&gt;&gt; attachment but please notify the sender (above). This message has been 
&gt;&gt; checked for all known viruses powered by McAfee.
&gt;&gt; 
&gt;&gt; For further information visit 
&gt;&gt; http://www.mcafee.com/us/threat\\_center/default.asp
&gt;&gt; Please rely on your own virus check as no responsibility is taken by the 
&gt;&gt; sender for any damage rising out of any virus infection this communication 
&gt;&gt; may contain.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; This message has been scanned for malware by Websense. www.websense.com
&gt;&gt; 
&gt; 

