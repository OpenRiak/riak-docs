---
title: "Re: riak on SSDs - how to manage potential SSD failures"
description: ""
project: community
lastmod: 2012-11-27T10:37:50-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg09392"
mailinglist_parent_id: "msg09377"
author_name: "Alex Babkin"
project_section: "mailinglistitem"
sent_date: 2012-11-27T10:37:50-08:00
---


Thank you for quick response Matt

So you are saying that i will have facilities in Riak 1.3 to handle these
errors in application layer? automatically by riak?

Alex


On Mon, Nov 26, 2012 at 2:09 PM, Matthew Von-Maszewski
wrote:

&gt; Alex,
&gt;
&gt; The eleveldb backend creates a CRC for every item placed on the disk. You
&gt; can activate the test of the CRC on every read by adding:
&gt;
&gt; {verify\\_checksums, true},
&gt;
&gt; to the "{eleveldb " portion of app.config. With riak 1.2, you must
&gt; manually monitor each vnode directory for the lost/BLOCKS.bad file changing
&gt; size. It only increases upon read operations detecting a CRC and/or
&gt; compression corruption error.
&gt;
&gt; Manually monitoring the BLOCKS.bad file is tacky (my apologies). The
&gt; upcoming 1.3 release will populate riak admin with a counter of errors
&gt; seen. But that code is still weeks from release.
&gt;
&gt; Matthew
&gt;
&gt; On Nov 26, 2012, at 1:25 PM, Alex Babkin  wrote:
&gt;
&gt; &gt; Hi all
&gt; &gt;
&gt; &gt; first post here, so please be kind :)
&gt; &gt;
&gt; &gt; I have plans to build an experimental riak cluster out of cheap ARM
&gt; computing parts and consumer grade SSDs to measure performance and
&gt; experiment to assess production viability
&gt; &gt; I plan to use levelDB as the backend
&gt; &gt;
&gt; &gt; One thing to be concerned of, in light of various SSD failure stories,
&gt; is of course a scenario of SSD failure and also the way it fails (some
&gt; parts of SSD space just aren't writable anymore, but still readable, i.e
&gt; stuck at some constant value). This may potentially result in a scenario
&gt; where a replicated record on two clusters, one with working SSD and one
&gt; with faulty, will have different data. Will riak try to account for this
&gt; scenario?
&gt; &gt;
&gt; &gt; I'm trying to think of ways to mitigate this risk of nodes failing due
&gt; to these SSD failures or at least get an early indication of a failure
&gt; (however insignificant it may be).
&gt; &gt; Guess my first question should be "Does riak provide any form of
&gt; checksums or what not on the data it reads/writes, or it blindly trusts
&gt; that the backend/filesystem reads/writes data correctly?"
&gt; &gt;
&gt; &gt; If not, are there any other tricks people use to trigger some alarm
&gt; bells that an SSD is 'going' ?
&gt; &gt;
&gt; &gt; Thanks
&gt; &gt; Alex
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

