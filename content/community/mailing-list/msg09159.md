---
title: "Re: Deleting items from search index increases disk usage"
description: ""
project: community
lastmod: 2012-11-02T08:07:37-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg09159"
mailinglist_parent_id: "msg09105"
author_name: "Jeremy Raymond"
project_section: "mailinglistitem"
sent_date: 2012-11-02T08:07:37-07:00
---


I ran the compaction 3 times. Each time freeing ~ 1GB of disk space.
Further compactions now return immediately showing no segmented compacted
and no bytes compacted.

The docs for merge\\_index:compact/1 state that this function "Performs
compaction of segments if needed". If this function decided that no
compaction was needed does that mean that all the tombstones are gone?
There is no more disk space that could possibly be freed?

--
Jeremy


On Fri, Nov 2, 2012 at 9:52 AM, Jeremy Raymond  wrote:

&gt; Here is the new listing of the segments:
&gt; https://gist.github.com/4001468. Some files changed and some didn't.
&gt; Not really sure how to interpret the differences.
&gt;
&gt; I'll run the repeated compaction calls and grab the directory listing
&gt; after each iteration and see if that frees any space.
&gt;
&gt; --
&gt; Jeremy
&gt;
&gt;
&gt; On Thu, Nov 1, 2012 at 4:32 PM, Ryan Zezeski  wrote:
&gt; &gt; Jeremy,
&gt; &gt;
&gt; &gt; I was looking at the merge index code and I think the issue is that the
&gt; &gt; method by which segments are chosen for compaction may be very slow to
&gt; get
&gt; &gt; to the larger segments.
&gt; &gt;
&gt; &gt; 1. Merge Index only schedules merging when a buffer is rolled-over to a
&gt; &gt; segment. This means there will \\_always\\_ be at least one small segment in
&gt; &gt; the list of potential segments to merge.
&gt; &gt;
&gt; &gt; 2. To determine which segments to merge the mean of all segment sizes is
&gt; &gt; taken.
&gt; &gt;
&gt; &gt; Over time the mean will skew left of the bulk of the distribution. This
&gt; &gt; means most compactions will touch only recent, smaller segments and it
&gt; will
&gt; &gt; take many iterations before one of the larger ones is included. To help
&gt; &gt; verify this you could list all you segment sizes again and compare them
&gt; with
&gt; &gt; the last run. My guess is you'll have about the same number of segments
&gt; but
&gt; &gt; the smallest one will have grown a bit. It depends how much unique data
&gt; you
&gt; &gt; re-indexed.
&gt; &gt;
&gt; &gt; Depending on the distribution of your segment sizes I think it might be
&gt; &gt; possible to reclaim some of this space via repeated compaction calls. It
&gt; &gt; turns out there is a way to manually invoke compaction. It's just not
&gt; easy
&gt; &gt; to get too. Try running the following gist on one of your nodes
&gt; &gt; https://gist.github.com/3996286. Try running merge\\_index:compact over
&gt; and
&gt; &gt; over again and each time check for changes in the segment file sizes.
&gt; &gt;
&gt; &gt;
&gt; &gt; -Z
&gt; &gt;
&gt; &gt;
&gt; &gt; On Thu, Nov 1, 2012 at 11:25 AM, Jeremy Raymond 
&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; I reindexed a bunch of items that are still in the search index but no
&gt; &gt;&gt; disk space was reclaimed. Is there any Riak console Erlang voodoo I
&gt; &gt;&gt; can do to convince Riak Search that now would be a good time to
&gt; &gt;&gt; compact the merge\\_index?
&gt; &gt;&gt;
&gt; &gt;&gt; --
&gt; &gt;&gt; Jeremy
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; On Tue, Oct 30, 2012 at 4:26 PM, Jeremy Raymond 
&gt; &gt;&gt; wrote:
&gt; &gt;&gt; &gt; I've posted the list of buffer files [1] and segment files [2].
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; The current data set I have in Riak is static, so no new items are
&gt; &gt;&gt; &gt; being written. So this looks like the reason as to why compaction
&gt; &gt;&gt; &gt; isn't happening since there is no time based trigger on the merge
&gt; &gt;&gt; &gt; index. To get compaction to kick in, I should be able to to just
&gt; &gt;&gt; &gt; reindex (by reading and rewriting) some of the existing items in
&gt; &gt;&gt; &gt; buckets that are still indexed? Earlier today I upgraded to Riak 1.2
&gt; &gt;&gt; &gt; and ran a Search read repair [3] in an attempt to kick of compaction.
&gt; &gt;&gt; &gt; Compaction didn't kick in, but instead disk consumption increased
&gt; &gt;&gt; &gt; again. Should Search Repair trigger compaction or only writing objects
&gt; &gt;&gt; &gt; to the KV store?
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; [1]:https://gist.github.com/3982718
&gt; &gt;&gt; &gt; [2]:https://gist.github.com/3982730
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; [3]:
&gt; http://docs.basho.com/riak/latest/cookbooks/Repairing-Search-Indexes/#Running-a
&gt; &gt;&gt; &gt; Repair
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; --
&gt; &gt;&gt; &gt; Jeremy
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt;
&gt; &gt;&gt; &gt; On Tue, Oct 30, 2012 at 3:47 PM, Ryan Zezeski 
&gt; &gt;&gt; &gt; wrote:
&gt; &gt;&gt; &gt;&gt; find /var/lib/riak/merge\\_index -name 'buffer.\\*' | xargs ls -lah
&gt; &gt;&gt; &gt;&gt;
&gt; &gt;&gt; &gt;&gt; find /var/lib/riak/merge\\_index -name 'segment.\\*' | xargs ls -lah
&gt; &gt;
&gt; &gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

