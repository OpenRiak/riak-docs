---
title: "Re: innostore performance tuning"
description: ""
project: community
lastmod: 2011-08-30T09:56:28-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04513"
mailinglist_parent_id: "msg04511"
author_name: "Jonathan Langevin"
project_section: "mailinglistitem"
sent_date: 2011-08-30T09:56:28-07:00
---


He's already running Raid 10\\*

 
 Jonathan Langevin
Systems Administrator
Loom Inc.
Wilmington, NC: (910) 241-0433 - jlange...@loomlearning.com -
www.loomlearning.com - Skype: intel352
\\*


On Tue, Aug 30, 2011 at 12:51 PM, Jeremiah Peschka &lt;
jeremiah.pesc...@gmail.com&gt; wrote:

&gt; InnoStore is going to insert the data in key order. When you attempt to
&gt; insert a record that would fit in between two keys (inserting "apple"
&gt; between "aardvark" and "Byzantium") you're probably going to get a page
&gt; split, just like in an RDBMS. The data needs to be re-shuffled in order to
&gt; write it in key order. Despite using MVCC, InnoDB is an index ordered table.
&gt; Data is written in key order. LevelDB shouldn't have the ordered write
&gt; issues that InnoStore has.
&gt;
&gt; The procedure to bulk load your data is going to be the same as bulk
&gt; loading data for any large Data Warehouse - ordered inserts will help you.
&gt;
&gt; If there's a way to load your data in smaller ordered chunks, that's going
&gt; to help you out too.
&gt;
&gt; Some other options would be to increase the buffer\\_pool\\_size for InnoStore.
&gt; InnoDB will use RAM as a disk cache to avoid disk hits. This would be a
&gt; "Good Thing". Since you're writing in 8k chunks, roughly, you could also
&gt; increase the page size. This would be something to experiment with, but
&gt; increasing database page size could improve write performance. Odds are if
&gt; your average record size is 8kb, then you're writing multiple pages per
&gt; record (key + value), which is causing even more I/O (two or more page reads
&gt; per object). Some filesystem tuning could be in order. SQL Server, for
&gt; instance, performs sequential reads in 64k chunks. The best practice for
&gt; disk performance there is to format NTFS to use 64k blocks. The throughput
&gt; between the defaults and 64k reads is amazing.
&gt;
&gt; Also, you may want to look at your storage configuration in the back end.
&gt; If you have that much data, are you using a SAN or DAS? Both of these can
&gt; help get additional write performance, especially if you adjust the storage
&gt; device to cache writes in a battery backed cache. What kind of drive
&gt; configuration do you have? You can get tremendous write performance
&gt; improvements by moving to RAID10.
&gt;
&gt; ---
&gt; Jeremiah Peschka - Founder, Brent Ozar PLF, LLC
&gt; Microsoft SQL Server MVP
&gt;
&gt; On Aug 30, 2011, at 9:34 AM, David Koblas wrote:
&gt;
&gt; &gt; Yes - but the thought of sorting 800M records which are all about 8k in
&gt; size is a little daunting... Something like a 6TB sort... Plus it doesn't
&gt; answer the ongoing insert problem, which is 20 keys/sec isn't functional.
&gt; &gt;
&gt; &gt; --david
&gt; &gt;
&gt; &gt; On 8/30/11 9:27 AM, Kresten Krab Thorup wrote:
&gt; &gt;&gt; If you can insert the objects in ascending key order, then innostore
&gt; will be much faster than a random insert.
&gt; &gt;&gt;
&gt; &gt;&gt; Mobile: + 45 2343 4626 | Skype: krestenkrabthorup | Twitter: @drkrab
&gt; &gt;&gt; Trifork A/S | Margrethepladsen 4 | DK- 8000 Aarhus C | Phone : +45
&gt; 8732 8787 | www.trifork.com
&gt; &gt;&gt;
&gt; &gt;&gt; Trifork organizes the world class conference on software development:
&gt; GOTO Aarhus - check it out!
&gt; &gt;&gt;
&gt; &gt;&gt; [cid:part1.09040606.08080401@trifork.com]
&gt; &gt;&gt;
&gt; &gt;&gt; On Aug 30, 2011, at 6:14 PM, David Koblas wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; I'm currently working on importing a very large dataset (800M) into Riak
&gt; and running into some serious performance problems. Hopefully this is just
&gt; configuration issues and nothing deeper...
&gt; &gt;&gt;
&gt; &gt;&gt; Hardware -
&gt; &gt;&gt; \\* 8 proc box
&gt; &gt;&gt; \\* 32 Gb ram
&gt; &gt;&gt; \\* 5TB disk - RAID10
&gt; &gt;&gt;
&gt; &gt;&gt; Have a cluster of 4 for these boxes all running riak - riak
&gt; configuration options that are different from stock:
&gt; &gt;&gt;
&gt; &gt;&gt; \\* Listening on all IP address "0.0.0.0"
&gt; &gt;&gt; \\* {storage\\_backend, riak\\_kv\\_innostore\\_backend},
&gt; &gt;&gt; \\* innostore section - {buffer\\_pool\\_size, 17179869184}, %% 16GB
&gt; &gt;&gt; \\* innostore section - {flush\\_method, "O\\_DIRECT"}
&gt; &gt;&gt;
&gt; &gt;&gt; What I see is that the performance of my import script runs at about
&gt; 200...300 keys per/second for keys that it's seen recently (e.g. re-runs)
&gt; then drops to 20ish keys per/sec for new keys.
&gt; &gt;&gt; STATS: 1000 keys handled in 3 seconds 250.75 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 3 seconds 258.20 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 4 seconds 240.11 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 5 seconds 177.63 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 4 seconds 246.26 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 5 seconds 184.79 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 5 seconds 195.95 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 47 seconds 21.02 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 44 seconds 22.63 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 42 seconds 23.64 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 43 seconds 22.88 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 45 seconds 22.12 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 43 seconds 22.83 keys/sec
&gt; &gt;&gt; STATS: 1000 keys handled in 43 seconds 23.11 keys/sec
&gt; &gt;&gt; Of course with 800M records to import a performance of 20 keys/sec is
&gt; not useful, plus as time goes on having an insert rate at that level is
&gt; going to be problematic.
&gt; &gt;&gt;
&gt; &gt;&gt; Questions -
&gt; &gt;&gt; Is there additional things to change for imports and datasets on this
&gt; scale?
&gt; &gt;&gt; Is there a way to get additional debugging to see where the
&gt; performance issues are?
&gt; &gt;&gt;
&gt; &gt;&gt; Thanks,
&gt; &gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt;&gt; riak-users mailing list
&gt; &gt;&gt; riak-users@lists.basho.com
&gt; &gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; &gt;&gt;
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; &gt; riak-users mailing list
&gt; &gt; riak-users@lists.basho.com
&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

