---
title: "Re: riak-users Digest, Vol 33, Issue 30"
description: ""
project: community
lastmod: 2012-04-20T10:11:27-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07261"
author_name: "Elias Levy"
project_section: "mailinglistitem"
sent_date: 2012-04-20T10:11:27-07:00
---


On Fri, Apr 20, 2012 at 9:01 AM,  wrote:

&gt; Eventually this becomes the primary workload of the cluster and individual
&gt; deletion latencies grow (more detailed measurements on the shape of this
&gt; degradation are forthcoming if that is helpful).
&gt;

Are you in EC2 or metal?

How are you deleting the values? One call per key?

We perform our deletes using MR and a Erlang reduce function. If you set
the pre-reduce option, this will keep the delete within the node that holds
the value.

-module(reduce\\_functions).

-export([delete/2]).

% Data is a list of bucket and key pairs, intermixed with the counts of
deleted

% objects. Returns a count of deleted objects.

delete(List, \\_None) -&gt;

 {ok, C} = riak:local\\_client(),

 Delete = fun(Bucket, Key) -&gt;

 case C:delete(Bucket, Key, 0) of

 ok -&gt; 1;

 \\_ -&gt; 0

 end

 end,

 F = fun(Elem, Acc) -&gt;

 case Elem of

 {{Bucket, Key}, \\_KeyData} -&gt;

 Acc + Delete(Bucket, Key);

 {Bucket, Key} -&gt;

 Acc + Delete(Bucket, Key);

 [Bucket, Key] -&gt;

 Acc + Delete(Bucket, Key);

 \\_ -&gt;

 Acc + Elem

 end

 end,

 [lists:foldl(F, 0, List)].


&gt; We are using riak 1.1 directly from
&gt; https://github.com/basho/riak/tree/1.1with the eleveldb backend. The
&gt; eleveldb specific configuration follows, but
&gt; fiddling with these settings hasn't noticeably impacted behavior we've
&gt; seen. Planning to set delete\\_mode to immediate and see if that helps.
&gt;
&gt; Here's some other info that might be helpful but feel free to ask for
&gt; anything else.
&gt;
&gt; N = 3 (changing to 2) on 9 physical nodes w 32GB memory each
&gt;
&gt; Our leveldb config looks like this:
&gt;
&gt; %% eLevelDB Config
&gt; {eleveldb, [
&gt; {data\\_root, "/srv/riak/leveldb"},
&gt; {max\\_open\\_files, 400},
&gt; {block\\_size, 262144},
&gt; {cache\\_size, 1932735280},
&gt; {sync, false}
&gt; ]},
&gt;
&gt;
You can also increase the leveldb write\\_buffer\\_size config option.

 %% Amount of data to build up in memory (backed by an
unsorted

 %% log on disk) before converting to a sorted on-disk file.

 %% Larger values increase performance, especially during
bulk

 %% loads. Up to two write buffers may be held in memory at
the

 %% same time, so you may wish to adjust this parameter to

 %% control memory usage. Also, a larger write buffer will

 %% result in a longer recovery time the next time the
database

 %% is opened. Default is: 4MB.

Elias
