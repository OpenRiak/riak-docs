---
title: "Re: In-Memory Performance"
description: ""
project: community
lastmod: 2011-08-02T17:50:37-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04187"
mailinglist_parent_id: "msg04186"
author_name: "Matt Savona"
project_section: "mailinglistitem"
sent_date: 2011-08-02T17:50:37-07:00
---


Oh wow. You're right...thank you /very/ much for catching that. I
don't know what gave me the impression that the default was R=1 (could
have sworn I read it somewhere). Can't wait to try this out when I get
into the office tomorrow hopefully it speeds things up a bit.

I'll post some revised numbers once I run my test again.

- Matt

On Tue, Aug 2, 2011 at 8:32 PM, Eric Moritz  wrote:
&gt; Unless you changed R for the bucket, the default that ships with Riak
&gt; is 2.  It's actually "n\\_val / 2 + 1" also known as the quorum
&gt; .  n\\_val is 3 by
&gt; default resulting in R=2.
&gt;
&gt; Eric.
&gt;
&gt; On Tue, Aug 2, 2011 at 8:11 PM, Matt Savona  wrote:
&gt;&gt; Hi Eric,
&gt;&gt;
&gt;&gt; I this test, R=1 (the default).
&gt;&gt;
&gt;&gt; Thanks!
&gt;&gt;
&gt;&gt; - Matt
&gt;&gt;
&gt;&gt; On Tue, Aug 2, 2011 at 4:35 PM, Eric Moritz  wrote:
&gt;&gt;&gt; When you were doing the reads, did you set the r-value to 1?  This
&gt;&gt;&gt; will speed up reads in a read heavy app because only one node has to
&gt;&gt;&gt; be in agreement about the object.
&gt;&gt;&gt;
&gt;&gt;&gt; Eric.
&gt;&gt;&gt;
&gt;&gt;&gt; On Tue, Aug 2, 2011 at 11:22 AM, Matt Savona  wrote:
&gt;&gt;&gt;&gt; Hi all,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; My colleagues and I are evaluating Riak as a persistent, replicated K-V 
&gt;&gt;&gt;&gt; store.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I have a fairly simple (and not so scientific) test that reads and
&gt;&gt;&gt;&gt; writes 5000 objects that are 32K in size. I am particularly interested
&gt;&gt;&gt;&gt; in squeezing every last bit of performance out of Riak in a very
&gt;&gt;&gt;&gt; read-heavy environment. I want to avoid hitting disk for reads as much
&gt;&gt;&gt;&gt; as possible; our entire content set is much larger than could ever be
&gt;&gt;&gt;&gt; stored in RAM, but preferably hot/active objects will remain resident
&gt;&gt;&gt;&gt; in memory until various conditions may force them to be evicted. While
&gt;&gt;&gt;&gt; the content set is quite large, the number of active keys represent a
&gt;&gt;&gt;&gt; very small portion of the data which could easily fit in RAM.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I've been running the same test against Riak given various
&gt;&gt;&gt;&gt; combinations of backends and access protocols (HTTP vs. PB).
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; My numbers can be seen in this screenshot:
&gt;&gt;&gt;&gt; http://img824.imageshack.us/img824/3185/riakperformance.png
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; It is quite evident (and perhaps obvious) that Protocol Buffer
&gt;&gt;&gt;&gt; performance is noticeably better than HTTP in most cases.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; What is confusing to me is the performance of purely in-memory
&gt;&gt;&gt;&gt; backends. Notably, GB Trees and LRU Cache (and even Innostore), at
&gt;&gt;&gt;&gt; best took 14s to retrieve 5000 32K objects. The exact same test
&gt;&gt;&gt;&gt; against Membase took just 6s.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Perhaps I'm not comparing apples to apples (Riak in-memory versus
&gt;&gt;&gt;&gt; Membase). Do my tests look reasonable and do the numbers look roughly
&gt;&gt;&gt;&gt; in-line with expectations? Is there any way to squeeze more juice out
&gt;&gt;&gt;&gt; of Riak? A purely in-memory/non-persistent backend will not suffice
&gt;&gt;&gt;&gt; for our ultimate needs, but for testing purposes I'm just trying to
&gt;&gt;&gt;&gt; see if I can get read performance more in line with what we're seeing
&gt;&gt;&gt;&gt; with Membase. We love everything about it, but we haven't yet hit the
&gt;&gt;&gt;&gt; performance we were hoping for.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks in advance!
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; - Matt
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;

