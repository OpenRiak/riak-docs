---
title: "Re: [ANN] Riak Release 0.11.0"
description: ""
project: community
lastmod: 2010-06-11T11:37:13-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg00569"
mailinglist_parent_id: "msg00566"
author_name: "Jason J. W. Williams"
project_section: "mailinglistitem"
sent_date: 2010-06-11T11:37:13-07:00
---


Hi David,

That helps. I assumed it was non-blocking, but that compaction is a
pretty disk intensive operation while it's occurring. Just because
it's occurring on a single partition, the compaction I/O load will
affect the partitions on the same disk.

-J

On Fri, Jun 11, 2010 at 12:27 PM, David Smith  wrote:
&gt; Well, compaction does not mean that a partition is unavailable -- that is to
&gt; say, compaction happens in a non-blocking manner. So worst, case you'lll
&gt; have disk-related latency hits for a given partition, but requests should
&gt; still be getting served. Also, a single node only compacts a single
&gt; partition at a time.
&gt; FWIW, in my own testing, with a 50/50 read/write mix, compaction (based on
&gt; fragmentation %) typically doesn't happen that often, particularly when you
&gt; have a cluster of machines.
&gt; Hope that helps.
&gt; D.
&gt;
&gt; On Fri, Jun 11, 2010 at 12:20 PM, Jason J. W. Williams
&gt;  wrote:
&gt;&gt;
&gt;&gt; Is it smart enough to coordinate with the other partitions to ensure
&gt;&gt; not more than 25% (just a plug number) of the partitions are
&gt;&gt; compacting at the same time? It would seem to me there's the
&gt;&gt; possibility for a performance drop if you had the perfect storm of too
&gt;&gt; many shards compacting at the same time.
&gt;&gt;
&gt;&gt; -J
&gt;&gt;
&gt;&gt; On Fri, Jun 11, 2010 at 4:54 AM, Justin Sheehy  wrote:
&gt;&gt; &gt; Hi, Germain.
&gt;&gt; &gt;
&gt;&gt; &gt; On Fri, Jun 11, 2010 at 11:07 AM, Germain Maurice
&gt;&gt; &gt;  wrote:
&gt;&gt; &gt;
&gt;&gt; &gt;&gt; Because of its append-only nature, stale data are created, so, how does
&gt;&gt; &gt;&gt; Bitcask to remove stale data ?
&gt;&gt; &gt;
&gt;&gt; &gt; An excellent question, and one that we haven't yet written enough about.
&gt;&gt; &gt;
&gt;&gt; &gt;&gt; With CouchDB the compaction process on our data never succeed, too much
&gt;&gt; &gt;&gt; data.
&gt;&gt; &gt;&gt; I really don't like to have to launch manually this kind of process.
&gt;&gt; &gt;
&gt;&gt; &gt; Bitcask's merging (compaction) process is automated and very tunable.
&gt;&gt; &gt; These parameters are the most relevant in your bitcask section of
&gt;&gt; &gt; app.config:
&gt;&gt; &gt;
&gt;&gt; &gt; (see the whole thing at
&gt;&gt; &gt; http://hg.basho.com/bitcask/src/tip/ebin/bitcask.app)
&gt;&gt; &gt;
&gt;&gt; &gt; %% Merge trigger variables. Files exceeding ANY of these
&gt;&gt; &gt; %% values will cause bitcask:needs\\_merge/1 to return true.
&gt;&gt; &gt; %%
&gt;&gt; &gt; {frag\\_merge\\_trigger, 60},              % &gt;= 60% fragmentation
&gt;&gt; &gt; {dead\\_bytes\\_merge\\_trigger, 536870912}, % Dead bytes &gt; 512 MB
&gt;&gt; &gt;
&gt;&gt; &gt; %% Merge thresholds. Files exceeding ANY of these values
&gt;&gt; &gt; %% will be included in the list of files marked for merging
&gt;&gt; &gt; %% by bitcask:needs\\_merge/1.
&gt;&gt; &gt; %%
&gt;&gt; &gt; {frag\\_threshold, 40},                  % &gt;= 40% fragmentation
&gt;&gt; &gt; {dead\\_bytes\\_threshold, 134217728},     % Dead bytes &gt; 128 MB
&gt;&gt; &gt; {small\\_file\\_threshold, 10485760},      % File is &lt; 10 MB
&gt;&gt; &gt;
&gt;&gt; &gt; Every few minutes, the Riak storage backend for a given partition will
&gt;&gt; &gt; send a message to bitcask, requesting that it queue up a possible
&gt;&gt; &gt; merge job.  (only one partition will be in the merge process at once
&gt;&gt; &gt; as a result of that queue)  The bitcask application will examine that
&gt;&gt; &gt; partition when that request reaches the front of the queue.  If any of
&gt;&gt; &gt; the trigger values have been exceeded, then all of the files in that
&gt;&gt; &gt; partition which exceed any threshold values will be run through
&gt;&gt; &gt; compaction.
&gt;&gt; &gt;
&gt;&gt; &gt; This allows you a great deal of flexibility in your demands, and also
&gt;&gt; &gt; provides reasonable amortization of the cost since each partition is
&gt;&gt; &gt; processed independently.
&gt;&gt; &gt;
&gt;&gt; &gt; -Justin
&gt;&gt; &gt;
&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; &gt;
&gt;
&gt;

