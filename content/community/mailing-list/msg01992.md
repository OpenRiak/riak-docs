---
title: "Re: newbie questions: sorted keys, ADT primitives,	and link manipulation"
description: ""
project: community
lastmod: 2011-01-16T00:45:56-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01992"
mailinglist_parent_id: "msg01990"
author_name: "Eric Moritz"
project_section: "mailinglistitem"
sent_date: 2011-01-16T00:45:56-08:00
---


I have also been toying with the idea of a linked list using a "next"
links on entries. Theoretically I could use link walking to get the
next 19 entries given a "HEAD" entry. It feels like a maintenance
nightmare though.

On Sat, Jan 15, 2011 at 7:23 PM, Gary William Flake  wrote:
&gt; I am building a backend for a web service and Riak looks to be a strong fit
&gt; for my needs at this point.  However, there is one really simple requirement
&gt; that I can't figure out how to implement on Riak with any sort of
&gt; efficiency.  To simplify the question, suppose that I want a twitter-like
&gt; service that has billions of smallish documents that enter into the backend
&gt; over a period of time.  Typical read pattern will be:
&gt; 1. List the last N documents
&gt; 2. Given a document, see the N that came before this one.
&gt; 3. From a random point, see the N documents before this one.
&gt; Hence, what I really want is to be able to access the documents in sorted
&gt; order by timestamp.  I know that I can do all of this with a map/reduce job,
&gt; but this solution literally requires the backend to scan each and every
&gt; document which seems less than ideal.
&gt; Is there a generally accepted "right" way to do this on Riak?  Or is there
&gt; no known way to do this gracefully, and I need to be prepared to roll my own
&gt; secondary indices?  Or, can this be handled with a Riak Search range query?
&gt; ###
&gt; The second topic is concerned with finding an elegant way to address the
&gt; first question.  One way to solve the problem above is to use a bucket as a
&gt; poor man's list.  At the application layer, when I insert a new document, I
&gt; could create a new k:v pair in my "list" bucket with the key being an
&gt; integer corresponding to this document's position in the corpus, and the
&gt; value being the actual key in the document bucket.  With this scheme, I
&gt; could satisfy the scenario above with the following observations:
&gt; 1. Once I have the list key for a document, I could find the N before it in
&gt; O(N) time which is an improvement over the map/reduce solution which is
&gt; O(size of corpus) / O(cluster size).
&gt; 2. This solution assumes atomicity that doesn't exist in practice (e.g., the
&gt; operations "new id &lt;- number of docs", and "add a new doc with key new id"
&gt; have to complete as an atomic operation if multiple clients are attempting
&gt; an insert).
&gt; 3. This solution also wants a multiget styled function to map index values
&gt; to true document keys, and then to get the resulting document.
&gt; I know what you are thinking: just use a serialized JSON array as the value
&gt; of the list that you want, then just get it, deserialize it, mutate it, then
&gt; update its value.  But this is horrific because each insertion takes
&gt; O(corpus size) time.
&gt; Bottom line: life sucks no matter which route we take.
&gt; What I think is needed are redis styled objects that support O(1) atomic
&gt; operations.  For example, if I simply had a k:v pair where the value was a
&gt; list which supported insert/delete front/rear, then we are golden.
&gt; ###
&gt; This brings me to my third question / observation.  In scanning over the
&gt; archives of this list, I see that others have requested this feature before,
&gt; but I haven't seen any mention of the feature being considered.  (Please,
&gt; please!  I hope I am wrong).
&gt; So, I want to offer what I think is the minimal feature request that
&gt; supports the scenarios that I am trying to achieve.  Basically, I want to
&gt; build off of links, allowing them to generalize into container types.  My
&gt; assumptions:
&gt; 1. Links have a natural order in that they alway come out in the same order
&gt; that they are created (at least that's what the python client API states,
&gt; but I can't confirm it in the Riak docs).
&gt; 2. Links seem to support mutation operations, meaning that I can add a link
&gt; and remove a link in O(1) time (and not in time proportional to the number
&gt; of links on the record).
&gt; If both of these are true, then all that is needed is to add simple O(1)
&gt; mutation operations allowing one to treat a records links as a special
&gt; container that references to other records.  Insert/delete front/rear will
&gt; give you stacks and queues.  A small addition to the API would support sets.
&gt; ###
&gt; That's all for now.  I hope someone can chime in with something to add on
&gt; top.  My real hope is that I've misunderstood the capabilities of Riak and
&gt; that what I want to do can be done today.  But if that's not the case, I am
&gt; curious if others have the same needs and if they know how to work around
&gt; them.
&gt; Thanks,
&gt; -- GWF
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
