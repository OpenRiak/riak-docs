---
title: "Re: standby cluster experiment"
description: ""
project: community
lastmod: 2011-12-19T21:10:15-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06005"
mailinglist_parent_id: "msg05998"
author_name: "John Loehrer"
project_section: "mailinglistitem"
sent_date: 2011-12-19T21:10:15-08:00
---


Yeah, I'll probably end up doing something like that. I even thought of having 
haproxy monitor special keys in riak:

 http://riakcluster:8098/riak/serverstatus/

I can then have each node delete its own key during snapshot mode and add it 
back when done. The only tricky thing about it is creating a clean way to 
cycle through and back up each node in turn. That is part of what I liked so 
much about the idea of a hot backup with lvm ... no need to take the node out 
of rotation. The lvm snapshot creation is near instant and cheap, and then the 
rsync backup I was using could be niced to be very low priority but very quick. 
If only I could somehow tell leveldb to quickly pause or close out any open log 
files or somehow get it to repair on startup in the standby node.

In any case, I have a workable if not ideal solution. Thanks for the help.

~ John

----- Quoted Response -----

&gt; Haproxy has a standby system you can use to remove a node from rotation 
&gt; politely, allowing existing requests to finish. You can remove them from 
&gt; haproxy directly at the command line (or using http-check 
&gt; disable-on-404, but that doesn't really make sense for riak)
