---
title: "Re: riak_core question when a node dies"
description: ""
project: community
lastmod: 2012-03-28T10:00:43-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07068"
mailinglist_parent_id: "msg07067"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2012-03-28T10:00:43-07:00
---


Jon,

Generally I would use the riak\\_core\\_apl module to calculate the preflist
for your request. It takes into account node visibility and service
availability. Use riak\\_core\\_node\\_watcher:service\\_up to announce that your
app is available after registering with riak\\_core.

When doing some "split brain" testing/simulation for gen\\_leader we would do
something like the following on a node we wanted to partition:

1&gt; erlang:set\\_cookie(node(), riak2).
2&gt; erlang:disconnect\\_node('dev3@127.0.0.1'),
erlang:disconnect\\_node('dev4@127.0.0.1').

Basically, set the cookie so it can't connect to the other nodes, then
manually disconnect. That might help you simulate node-outage.

On Wed, Mar 28, 2012 at 12:49 PM, Jon Brisbin  wrote:

&gt; I'm testing the example code that dispatches a web request from misultin
&gt; into a riak\\_core ring of vnodes. It works fantastic when all nodes are up!
&gt; :)
&gt;
&gt; Doing "ab -k -c 200 -n 10000 http://localhost:3000/" yields a
&gt; none-to-shabby performance (dispatching at random into all available vnodes
&gt; on two separate riak\\_core processes):
&gt;
&gt; Concurrency Level: 200
&gt; Time taken for tests: 1.446 seconds
&gt; Complete requests: 10000
&gt; Failed requests: 0
&gt; Write errors: 0
&gt; Keep-Alive requests: 10000
&gt; Total transferred: 1600480 bytes
&gt; HTML transferred: 120036 bytes
&gt; Requests per second: 6914.04 [#/sec] (mean)
&gt; Time per request: 28.927 [ms] (mean)
&gt; Time per request: 0.145 [ms] (mean, across all concurrent requests)
&gt; Transfer rate: 1080.64 [Kbytes/sec] received
&gt;
&gt; Connection Times (ms)
&gt; min mean[+/-sd] median max
&gt; Connect: 0 0 1.0 0 12
&gt; Processing: 4 28 9.8 27 78
&gt; Waiting: 4 28 9.8 27 78
&gt; Total: 4 28 10.1 27 83
&gt;
&gt; Percentage of the requests served within a certain time (ms)
&gt; 50% 27
&gt; 66% 31
&gt; 75% 34
&gt; 80% 36
&gt; 90% 41
&gt; 95% 47
&gt; 98% 53
&gt; 99% 58
&gt; 100% 83 (longest request)
&gt;
&gt; If I were really zealous, I'd set up haproxy to load balance between these
&gt; two misultin servers and get double failover.
&gt;
&gt; I'm trying to catch the situation of going into the console of one of my
&gt; nodes and hitting "CTL-C" to kill that process. I'm not sure what the best
&gt; way is to handle this. Check before I dispatch to make sure the node is up?
&gt; Keep a watch of some other kind that, when it sees that node go down and if
&gt; it's trying to dispatch to that node, it tries to find another one?
&gt;
&gt; Essentially, I'm trying to prevent misultin from completely bailing on the
&gt; request because the sync\\_spawn\\_command blows up trying to do a
&gt; gen\\_server:call to a non-existent node. I'd like to retry to dispatch to a
&gt; different node if one happens to have crashed while I'm serving requests (I
&gt; don't want to loose a request, essentially).
&gt;
&gt; Thanks!
&gt;
&gt; Jon Brisbin
&gt; http://about.me/jonbrisbin
&gt;
&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;


-- 
Sean Cribbs 
Software Engineer
Basho Technologies, Inc.
http://basho.com/
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

