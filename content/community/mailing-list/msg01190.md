---
title: "Re: bitcask 42?"
description: ""
project: community
lastmod: 2010-10-04T16:14:17-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01190"
mailinglist_parent_id: "msg01175"
author_name: "Alexander Sicular"
project_section: "mailinglistitem"
sent_date: 2010-10-04T16:14:17-07:00
---


If you have a server that has raided disk and you don't have a battery
backed raid controller you fail at buying servers as it's virtually
the only piece of hardware that makes a server a server.

On 2010-10-04, Nico Meyer  wrote:
&gt; One should also mention, that the overall performance of bitcask might
&gt; presumably become worse with a larger number of partitions per node.
&gt; If there is only one partition writing is basically linear on the disk,
&gt; an therefore extremely fast. If you on the other hand linearly write to
&gt; a large number of files at the same time, the disk access pattern starts
&gt; to look more random.
&gt; It all very much depends on how you IO subsystem can handle appending to
&gt; many files in parallel. For example a RAID controller with a large
&gt; battery backed cache should help a lot.
&gt;
&gt; Cheers,
&gt; Nico
&gt;
&gt; Am Freitag, den 01.10.2010, 14:56 -0700 schrieb Dan Reverri:
&gt;&gt; The value of ring\\_creation\\_size dictates how many partitions your Riak
&gt;&gt; cluster will manage. These partitions are distributed amongst the
&gt;&gt; nodes of your cluster. Each node in the cluster with manage a portion
&gt;&gt; of the ring ( ring\\_creation\\_size / number of nodes ). A larger ring
&gt;&gt; means each node will be responsible for more partitions which means
&gt;&gt; each node will open more files (ulimit -n).
&gt;&gt;
&gt;&gt;
&gt;&gt; Thanks,
&gt;&gt; Dan
&gt;&gt;
&gt;&gt; Daniel Reverri
&gt;&gt; Developer Advocate
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; d...@basho.com
&gt;&gt;
&gt;&gt;
&gt;&gt; On Fri, Oct 1, 2010 at 12:51 PM, Mojito Sorbet 
&gt;&gt; wrote:
&gt;&gt; On Fri, 2010-10-01 at 09:24 -0700, Dan Reverri wrote:
&gt;&gt;
&gt;&gt; &gt; Projects will typically define an upper bound for a
&gt;&gt; cluster's size
&gt;&gt; &gt; based on available datacenter space, available power, cost,
&gt;&gt; etc.
&gt;&gt; &gt; Choosing a ring\\_creation\\_size value based on this upper
&gt;&gt; bound will
&gt;&gt; &gt; allow you to start small and grow into your cluster.
&gt;&gt;
&gt;&gt;
&gt;&gt; Ok, but these days there is no fixed size "data center". If I
&gt;&gt; need more
&gt;&gt; resources I can add them dynamically from Amazon or an
&gt;&gt; equivalent cloud
&gt;&gt; provider. If I accidentally create the next Facebook and it
&gt;&gt; keeps
&gt;&gt; growing, it would be nice not to have to backup and restore
&gt;&gt; the whole
&gt;&gt; thing as it grows into multiple hundreds of terrabytes,
&gt;&gt; especially
&gt;&gt; considering the downtime required.
&gt;&gt;
&gt;&gt; What is the penalty for making the ring size a lot bigger than
&gt;&gt; the
&gt;&gt; initial number of nodes would require?
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt;


-- 
Sent from my mobile device

