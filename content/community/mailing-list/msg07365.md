---
title: "Re: Geospatial advice?"
description: ""
project: community
lastmod: 2012-05-01T12:19:29-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07365"
mailinglist_parent_id: "msg07363"
author_name: "Mark Rose"
project_section: "mailinglistitem"
sent_date: 2012-05-01T12:19:29-07:00
---


Trade offs. I dislike rewriting stuff that doesn't scale. I love the idea
of just throwing another box into a cluster and having it "just work"
without rebalancing issues, etc. I'm tired of dealing with shards, complex
replication setups, etc.

I will also be using heavily for logging, URL shortening, social share
registering, etc., and I'd rather stick to one datastore.

I agree it's a bit of a round peg in a ovoid hole when it comes to
geospatial + mapreduce queries, but I imagine it won't be long until
geospatial indexes arrive at Riak as well, and then I can switch to those.
:-)

-Mark

On Tue, May 1, 2012 at 2:25 PM, Alexander Sicular wrote:

&gt; Hey, I'm as up for a good and clever hack as anybody. But the question is
&gt; just because you can, should you? Who will maintain your hack after your'e
&gt; dead? I'm still maintaing crap I wrote years ago. Even though I'm paid,
&gt; sometimes I would rather not have the headache. Why would you use a product
&gt; that specifically does not support such hackery? Scaling postgres or mongo
&gt; are known and solvable problems especially concerning bounded data sets,
&gt; likes, say, all points on a globe. Now if you were storing checkins, that
&gt; would be a different problem. One suitable for, say, Riak.
&gt;
&gt; On Tue, May 1, 2012 at 14:09, Mark Rose  wrote:
&gt;
&gt;&gt; Well, I'd be indexing items over the entire globe. I'd be be looking at
&gt;&gt; resolutions from an entire world view down to city block. I'm thinking of
&gt;&gt; using geohashes as an index to restrict the result set, then further
&gt;&gt; filtering and sorting by mapreducing the remaining items. So I only need
&gt;&gt; enough granularity to reduce the number of items to a reasonable amount. At
&gt;&gt; the world view level, I'd filter out most results using mapreduce, but the
&gt;&gt; local-level queries would be far more common so an index would be highly
&gt;&gt; advantageous. The geometry I'd want to query would be a window that
&gt;&gt; arbitrarily overlaps one or more geohash regions. Basically, think plotting
&gt;&gt; items in say, Google Maps.
&gt;&gt;
&gt;&gt; Can you use a secondary index inside mapreduce? I haven't seen any
&gt;&gt; examples of it. I have only seen a secondary index being used to feed a
&gt;&gt; mapreduce. I am new to Riak.
&gt;&gt;
&gt;&gt; I imagine my number of points would be at most 100 items per square km,
&gt;&gt; but typically less than 1 per square km. A 1 km resolution would be
&gt;&gt; sufficient. A 32 bit geohash would cover that fine. Vast regions of the
&gt;&gt; Earth would contain no points at all.
&gt;&gt;
&gt;&gt; -Mark
&gt;&gt;
&gt;&gt;
&gt;&gt; On Tue, May 1, 2012 at 1:16 PM, Sean Cribbs  wrote:
&gt;&gt;
&gt;&gt;&gt; In contrast to Alexander's assessment, I'd say "it depends". I have
&gt;&gt;&gt; built some geospatial indexes on top of Riak using a geohashing scheme
&gt;&gt;&gt; based on the Hilbert space-filling curve. However, I had to choose specific
&gt;&gt;&gt; levels of "zoom" and precompute them. Now that we have secondary indexes,
&gt;&gt;&gt; you could perhaps bypass the precomputation step. In general, if you know
&gt;&gt;&gt; the geometry of the space you want to query, you can fairly trivially
&gt;&gt;&gt; compute the names of the geohashes you need to look up and then either
&gt;&gt;&gt; fetch individual keys for those (if you precompute them), or use MapReduce
&gt;&gt;&gt; to fetch a range of them. It's not automatic, for sure, but the greatest
&gt;&gt;&gt; complexity will be in deciding which granularities of index to support.
&gt;&gt;&gt;
&gt;&gt;&gt; On Tue, May 1, 2012 at 12:44 PM, Alexander Sicular 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; My advice is to not use Riak. Check mongo or Postgres.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; @siculars on twitter
&gt;&gt;&gt;&gt; http://siculars.posterous.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Sent from my iRotaryPhone
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; On May 1, 2012, at 9:18, Mark Rose  wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; &gt; Hello everyone!
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; I'm going to be implementing Riak as a storage engine for geographic
&gt;&gt;&gt;&gt; data. Research has lead me to using geohashing as a useful way to filter
&gt;&gt;&gt;&gt; out results outside of a region of interest. However, I've run into some
&gt;&gt;&gt;&gt; stumbling blocks and I'm looking for advice on the best way to proceed.
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; Querying efficiently by geohash involves querying several regions
&gt;&gt;&gt;&gt; around a point. From what I can tell, Riak offers no way to query a
&gt;&gt;&gt;&gt; secondary index with multiple ranges. Having to query a several ranges,
&gt;&gt;&gt;&gt; merge them in the application layer, then pass them off to mapreduce seems
&gt;&gt;&gt;&gt; rather silly (and could mean passing GBs of data). Alternatively, I could
&gt;&gt;&gt;&gt; start straight with mapreduce, but key filtering seems to work only with
&gt;&gt;&gt;&gt; the primary key, which would force me into using the geohashed location as
&gt;&gt;&gt;&gt; the primary key (which would lead to collisions if two things existed at
&gt;&gt;&gt;&gt; the same point). I'd also like to avoid using the primary key as the
&gt;&gt;&gt;&gt; geohash as if the item moves I'd have to change all the references to it.
&gt;&gt;&gt;&gt; Lastly, I could do a less efficient mapreduce over a less precise geohash,
&gt;&gt;&gt;&gt; but this doesn't solve the issue of the equator (anything near the equator
&gt;&gt;&gt;&gt; would require mapreducing the entire dataset).
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; Is there any way to query multiple ranges with a secondary index and
&gt;&gt;&gt;&gt; pass that off to mapreduce? Or should I just stick with the less efficient
&gt;&gt;&gt;&gt; mapreduce, and when near the equator, run two queries and later merge them?
&gt;&gt;&gt;&gt; Or am I going about this the wrong way?
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; In any case, the final stage of my queries will involve mapreduce as
&gt;&gt;&gt;&gt; I'll need to further filter the items found in a region.
&gt;&gt;&gt;&gt; &gt;
&gt;&gt;&gt;&gt; &gt; Thank you,
&gt;&gt;&gt;&gt; &gt; Mark
&gt;&gt;&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt; &gt; riak-users mailing list
&gt;&gt;&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; Sean Cribbs 
&gt;&gt;&gt; Software Engineer
&gt;&gt;&gt; Basho Technologies, Inc.
&gt;&gt;&gt; http://basho.com/
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

