---
title: "Re: Importing data to Riak"
description: ""
project: community
lastmod: 2011-11-15T09:08:18-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05583"
mailinglist_parent_id: "msg05573"
author_name: "Nitish Sharma"
project_section: "mailinglistitem"
sent_date: 2011-11-15T09:08:18-08:00
---


Hi,
I tried importing the data using Python library (with protocol buffers).
After storing several objects, I get thread exception with timeout errors.
Following is the traceback:

 File "/usr/lib/python2.7/threading.py", line 552, in \\_\\_bootstrap\\_inner
 self.run()
 File "/usr/lib/python2.7/threading.py", line 505, in run
 self.\\_\\_target(\\*self.\\_\\_args, \\*\\*self.\\_\\_kwargs)
 File "python\\_load\\_data.py", line 23, in worker
 new\\_obj.store()
 File
"/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/riak\\_object.py",
line 296, in store
 Result = t.put(self, w, dw, return\\_body)
 File
"/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/transports/pbc.py",
line 188, in put
 msg\\_code, resp = self.recv\\_msg()
 File
"/usr/local/lib/python2.7/dist-packages/riak-1.3.0-py2.7.egg/riak/transports/pbc.py",
line 370, in recv\\_msg
 raise Exception(msg.errmsg)
Exception: timeout

The cluster consists of 3 nodes (Ubuntu 10.04).
Any Suggestions?

Cheers
Nitish

On Mon, Nov 14, 2011 at 2:20 PM, Andres Jaan Tack  wrote:

&gt; I was able to achieve similar results. I wrote a Ruby process that would
&gt; keep at most n (I think n = 10) things at once and reached 2,500ish req/s
&gt; on my macbook pro.
&gt;
&gt; I loaded data to a cluster of six Riak nodes by running several of these
&gt; processes at once and attaching each to a different Riak node, and I hit
&gt; 18,000 req/s. I'm not sure whether loading different nodes affected the
&gt; speed or not, now that I think of it.
&gt;
&gt;
&gt; 2011/11/14 Russell Brown 
&gt;
&gt;&gt;
&gt;&gt; On 14 Nov 2011, at 11:47, Nitish Sharma wrote:
&gt;&gt;
&gt;&gt; &gt; Hi,
&gt;&gt; &gt; This is more sort of a discussion than a question. I am just trying to
&gt;&gt; see the trend in how users import their data to Riak.
&gt;&gt; &gt; For the data I am using, I was able to achieve almost 150
&gt;&gt; records/second with PHP library, and 400 records/second with node.js
&gt;&gt; (fairly new with node; was hitting memory wall when trying to import 1
&gt;&gt; million records).
&gt;&gt; &gt; What are some hacks/tricks/tweaks to import large amount of data to
&gt;&gt; Riak?
&gt;&gt;
&gt;&gt; New keys, new data, straight in for the first time, no fetch before
&gt;&gt; store? I've had reasonable results creating a \\*number\\* of threads and using
&gt;&gt; the Java Raw PB client to write.
&gt;&gt;
&gt;&gt; For example, maybe have a 1 or a couple of threads that reads data (from
&gt;&gt; Oracle, a file, what-have-you) and puts it on a queue, and have a bunch of
&gt;&gt; threads that pull data off the queue, create a riak object and store it.
&gt;&gt; From my laptop I've got up to 2500 writes a second like this, and it was
&gt;&gt; just ad hoc, throw away code with 4 threads against a small 3 node cluster
&gt;&gt; (running on desktops.)
&gt;&gt;
&gt;&gt; I imagine others on the list have more direct, real world examples?
&gt;&gt;
&gt;&gt; Cheers
&gt;&gt;
&gt;&gt; Russell
&gt;&gt;
&gt;&gt; &gt;
&gt;&gt; &gt; Cheers
&gt;&gt; &gt; Nitish
&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;

&gt;
&gt;
