---
title: "Re: Key Filter Timeout"
description: ""
project: community
lastmod: 2011-10-23T21:59:15-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05259"
author_name: "Jim Adler"
project_section: "mailinglistitem"
sent_date: 2011-10-23T21:59:15-07:00
---


Thanks Kelly. Much appreciated! I'll try your suggestions and get back.

Jim

From: Kelly McLaughlin 
Date: Sun, 23 Oct 2011 22:02:52 -0600
To: Jim Adler 
Cc: "riak-users@lists.basho.com" 
Subject: Re: Key Filter Timeout

Jim,

A couple of things to note. First, bitcask stores all keys in memory, but
eleveldb does not necessarliy, so the performance of your disks could be a
factor. Not saying it is, but just a difference to be aware of between
bitcask and eleveldb.

Second, the latest error you shared was a timeout from the mapreduce
operation. You can increase the timeout for the operation by modifying your
original query like this:

curl -v -d 
'{"inputs":{"bucket":"nodes","key\\_filters":[["eq","user\\_id-xxxxxxx-info"]]},
"query":[{"reduce":{"language":"erlang","module":"riak\\_kv\\_mapreduce","functi
on":"reduce\\_identity"}}], "timeout", 120}' -H "Content-Type:
application/json" http://xx.xx.xx.xx:8098/mapred

Finally, you're using a reduce phase in the query when I think you might be
better served by a map phase which will allow you to get more
parallelization during the query execution. Try using a map phase with the
map\\_identity function instead of reduce\\_identity and I suspect you will get
better results. Hope that helps and please respond if you have any further
questions or problems. Cheers.

Kelly


On Oct 23, 2011, at 5:40 PM, Jim Adler wrote:

&gt; A little context on my use-case here. I've got about 8M keys in this 3 node
&gt; cluster. I need to clean out some bad keys and some bad data. So, I'm using
&gt; the key filter and search functionality to accomplish this (I tend to use the
&gt; riak python client). But, to be honest, I'm having a helluva time getting
&gt; these basic tasks accomplished before I ramp to hundreds of millions of keys.
&gt; 
&gt; Thanks for any help.
&gt; 
&gt; Jim
&gt; 
&gt; From: Kelly McLaughlin 
&gt; Date: Sun, 23 Oct 2011 14:13:09 -0600
&gt; To: Jim Adler 
&gt; Cc: "riak-users@lists.basho.com" 
&gt; Subject: Re: Key Filter Timeout
&gt; 
&gt; Jim,
&gt; 
&gt; Looks like you are possibly using both the legacy key listing option and the
&gt; legacy map reduce. Assuming all your nodes are on Riak 1.0, check your
&gt; app.config files on all nodes and make sure mapred\\_system is set to pipe and
&gt; legacy\\_keylisting is set to false. If that's not already the case you should
&gt; see better performance. If you are still getting the same or similar errors
&gt; with those setting in place, please respond with what they are so we can look
&gt; into it more. Thanks.
&gt; 
&gt; Kelly
&gt; 
&gt; On Oct 23, 2011, at 12:38 PM, Jim Adler wrote:
&gt; 
&gt;&gt; I'm trying to run a very simplified key filter that's timing out. I've got
&gt;&gt; about 8M keys in a 3-node cluster, 15 GB memory, num\\_partitions=256, LevelDB
&gt;&gt; backend.
&gt;&gt; 
&gt;&gt; I'm thinking this should be pretty quick. What am I doing wrong?
&gt;&gt; 
&gt;&gt; Jim
&gt;&gt; 
&gt;&gt; Here's the query:
&gt;&gt; 
&gt;&gt; curl -v -d 
&gt;&gt; '{"inputs":{"bucket":"nodes","key\\_filters":[["eq","user\\_id-xxxxxxx-info"]]},"
&gt;&gt; query":[{"reduce":{"language":"erlang","module":"riak\\_kv\\_mapreduce","function
&gt;&gt; ":"reduce\\_identity"}}]}' -H "Content-Type: application/json"
&gt;&gt; http://xx.xx.xx.xx:8098/mapred
&gt;&gt; 
&gt;&gt; Here's the log:
&gt;&gt; 
&gt;&gt; 18:25:08.892 [error] gen\\_fsm &lt;0.20795.0&gt; in state executing terminated with
&gt;&gt; reason: {error,flow\\_timeout}
&gt;&gt; 18:25:08.961 [error] CRASH REPORT Process &lt;0.20795.0&gt; with 2 neighbours
&gt;&gt; crashed with reason: {error,flow\\_timeout}
&gt;&gt; 18:25:08.963 [error] Supervisor luke\\_flow\\_sup had child undefined started
&gt;&gt; with {luke\\_flow,start\\_link,undefined} at &lt;0.20795.0&gt; exit with reason
&gt;&gt; {error,flow\\_timeout} in context child\\_terminated
&gt;&gt; 18:25:08.966 [error] gen\\_fsm &lt;0.20798.0&gt; in state waiting\\_kl terminated with
&gt;&gt; reason: {error,flow\\_timeout}
&gt;&gt; 18:25:08.971 [error] CRASH REPORT Process &lt;0.20798.0&gt; with 0 neighbours
&gt;&gt; crashed with reason: {error,flow\\_timeout}
&gt;&gt; 18:25:08.980 [error] Supervisor riak\\_kv\\_keys\\_fsm\\_legacy\\_sup had child
&gt;&gt; undefined started with {riak\\_kv\\_keys\\_fsm\\_legacy,start\\_link,undefined} at
&gt;&gt; &lt;0.20798.0&gt; exit with reason {error,flow\\_timeout} in context child\\_terminated
&gt;&gt; 18:25:08.983 [error] Supervisor luke\\_phase\\_sup had child undefined started
&gt;&gt; with {luke\\_phase,start\\_link,undefined} at &lt;0.20797.0&gt; exit with reason
&gt;&gt; {error,flow\\_timeout} in context child\\_terminated
&gt;&gt; 18:25:08.996 [error] Supervisor luke\\_phase\\_sup had child undefined started
&gt;&gt; with {luke\\_phase,start\\_link,undefined} at &lt;0.20796.0&gt; exit with reason
&gt;&gt; {error,flow\\_timeout} in context child\\_terminated
&gt;&gt; 
&gt;&gt; 
&gt; 

