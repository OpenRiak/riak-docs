---
title: "Re: Riak Search"
description: ""
project: community
lastmod: 2012-10-16T10:01:24-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08937"
mailinglist_parent_id: "msg08933"
author_name: "gordyt"
project_section: "mailinglistitem"
sent_date: 2012-10-16T10:01:24-07:00
---


Pavel as an alternative to re-writing the objects to cause them to be indexed, 
you may invoke what I call a map operation with side-effects.

You define an Erlang map-phase function as follows:


map\\_reindex({error,notfound}, \\_, \\_) -&gt;
 [];
map\\_reindex(RiakObject, \\_, \\_) -&gt;
 riak\\_search\\_kv\\_hook:precommit(RiakObject),
 [].


You want to run that against all of the keys in the bucket by posting a mapred 
job like this:

{
 "inputs": "",
 "query": [
 {
 "map": {
 "function": "map\\_reindex", 
 "language": "erlang",
 "module": ""
 }
 }
 ],
 "timeout": 
}


We have used this technique to re-index rather large clusters and it runs 
quickly because you are doing it in parallel across all of the nodes in the 
cluster.

-- gordon

On Oct 16, 2012, at 07:44 , Ryan Zezeski  wrote:

&gt; 
&gt; 
&gt; On Sun, Oct 14, 2012 at 12:33 AM, Pavel Kogan  wrote:
&gt; 
&gt; 1) Is search enabling has any impact on read latency/throughput?
&gt; 
&gt; If you are reading and searching at the same time there is a good chance it 
&gt; will. It will cause more disk seeks.
&gt; 
&gt; 2) Is search enabling has any impact on RAM usage?
&gt; 
&gt; Yes, the index engine behind Riak Search makes heavy usage of Erlang ETS 
&gt; tables. Each partition has an in-memory buffer as well as an in-memory 
&gt; offset table for every segment. It also uses a temporary ETS table for every 
&gt; write to store posting data. The ETS system limit can even become an issue 
&gt; in overload scenarios.
&gt; 
&gt; 3) In production we have no search enabled. What is the best way to 
&gt; enable search without stop production? I thought about something like:
&gt; 1) Enable search node after node.
&gt; 
&gt; You could change the app env dynamically but that's only half the problem. 
&gt; The other half is then starting the Riak Search application. I think 
&gt; application:start(merge\\_index) followed by application:start(riak\\_search) 
&gt; should work but I'm not 100% sure and this has not been tested. You'll also 
&gt; want to make sure to edit all app.configs so that it is persistent.
&gt; 
&gt; 
&gt; 2) Execute some night script that runs on all keys and overwrite them back
&gt; with proper mime type.
&gt; 
&gt; Yes, you'll want to install the commit hook on the buckets you wish to index. 
&gt; Then you'll want to do a streaming list-keys or bucket map-reduce and 
&gt; re-write the data.
&gt; 
&gt; 
&gt; 4) If we see that search overhead is something we can't handle, is there 
&gt; simple
&gt; way to disable it without stop production?
&gt; 
&gt; I think the best course of action in this case would be to disable the commit 
&gt; hook. But you would have to keep track of anything written during this time 
&gt; and re-write it after re-installing the hook. If you don't then you'll have 
&gt; to re-index everything because you don't know what you missed.
&gt; 
&gt; 5) In what case we would need repair? It is said - on replica loss, but if I 
&gt; understand 
&gt; correct we have 3 replicas on different nodes don't we? If it happens how 
&gt; difficult and
&gt; long would it be for large cluster (about 100 nodes)?
&gt; 
&gt; Repair is on a per partition basis. Number of nodes doesn't come into play. 
&gt; Repair is very specific in that it requires the adjacent partitions to be in 
&gt; a good, convergent state. If they aren't then repair isn't much help. 
&gt; 
&gt; A lot of these entropy issues go away in Yokozuna. Repairing indexes is done 
&gt; automatically, in the background, in an efficient manner. There is no need 
&gt; to re-write data or run manual repair commands.
&gt; 
&gt; -Z

