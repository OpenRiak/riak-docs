---
title: "Re: unix sockets, pbuffer load balance, many bucket approach,	score consistency?"
description: ""
project: community
lastmod: 2010-12-31T12:17:29-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01867"
mailinglist_parent_id: "msg01866"
author_name: "Alexander Sicular"
project_section: "mailinglistitem"
sent_date: 2010-12-31T12:17:29-08:00
---

I'll take a stab... Inline.


@siculars on twitter
http://siculars.posterous.com

Sent from my iPhone

On Dec 31, 2010, at 14:15, David Hollander  wrote:


I am developing a python web application and have several questions:

1. Can Riak use unix sockets in addition to TCP?


I think the closest you can get to raw sockets is via the native 
erlang interface.


2. Load-balancing a REST interface with nginx would be 
straightforward.
However, if using protocol buffers with the python client should I 
also

be implementing load balancing? Should I use a function to cycle the
port\\client connection used?

Maybe ha proxy would shuffle pbuff. Not sure. But I've done it in 
nodejs (http/pb) by cycling as you indicated.

3. Is there a limit to the number of buckets? What is the big O access
time for a bucket as number of buckets in the database increases? Is 
it

a constant time hashmap? I am considering programmatically generating
many bucket names to partition keys into groups I would map-reduce 
over.
Rather than put everything in one bucket and map-reduce over 
unnecessary

keys.

There is no limit to the number of buckets. Buckets are a virtual 
concept primarily used for namespacing and as a way to isolate 
deviations from default settings (think nval, hooks, backends). 
Currently all keys in the system are considered when doing an m/r over 
a bucket. Afaik, there are plans to fix this in future versions. I 
would still take the time to engineer a meaningful bucket key naming 
scheme because in the next release there will be all sorts of key 
selection goodness that will help with current limitations. Recall 
that with the default bitcask backend all keys are kept in ram with 
values on disk.


4. Eventual consistency: let's imagine a site has a popular item 
with a

score data key where the value is incremented by voting. Let's say the
score is 0, and it receives two votes incrementing it by +1 at similar
times. If these update commands are sent to different nodes, is it
possible for the vote to ultimately read 1 instead of the desired 2? 
If

so, would always sending the update commands to the same node prevent
this?

I have a problem relying on a system like riak for autoincrement use 
cases for a number of reasons. It's one thing if you can accept a 
situation of "more or less" accurate. But if you need to be exact I am 
of the opinion that riak is not the system to do it. Sending all 
requests to one node will not have the desired effect.


Thanks

