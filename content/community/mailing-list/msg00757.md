---
title: "Re: Expected vs Actual Bucket Behavior"
description: ""
project: community
lastmod: 2010-07-20T15:19:44-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg00757"
mailinglist_parent_id: "msg00749"
author_name: "Christopher Villalobos"
project_section: "mailinglistitem"
sent_date: 2010-07-20T15:19:44-07:00
---


Just a thought (and probably wrong) but couldn't you create an index
key inside your bucket and depending on the language append a list of
the key name sans index\\_key and just query that. It would do the
double write and you could verify that the new key is inserted.

Again probably bad but it's at least $0.02.

Christopher Villalobos

On Jul 20, 2010, at 6:00 PM,  wrote:

&gt; Send riak-users mailing list submissions to
&gt; riak-users@lists.basho.com
&gt;
&gt; To subscribe or unsubscribe via the World Wide Web, visit
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt; or, via email, send a message with subject or body 'help' to
&gt; riak-users-requ...@lists.basho.com
&gt;
&gt; You can reach the person managing the list at
&gt; riak-users-ow...@lists.basho.com
&gt;
&gt; When replying, please edit your Subject line so it is more specific
&gt; than "Re: Contents of riak-users digest..."
&gt;
&gt;
&gt; Today's Topics:
&gt;
&gt; 1. Re: Expected vs Actual Bucket Behavior (Justin Sheehy)
&gt; 2. [ANN] Basho Riak 0.12.0 (Rusty Klophaus)
&gt; 3. Re: Expected vs Actual Bucket Behavior (Eric Filson)
&gt;
&gt;
&gt; ----------------------------------------------------------------------
&gt;
&gt; Message: 1
&gt; Date: Tue, 20 Jul 2010 15:02:55 -0400
&gt; From: Justin Sheehy 
&gt; To: Eric Filson 
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Expected vs Actual Bucket Behavior
&gt; Message-ID:
&gt; 
&gt; Content-Type: text/plain; charset=ISO-8859-1
&gt;
&gt; Hi, Eric! Thanks for your thoughts.
&gt;
&gt; On Tue, Jul 20, 2010 at 12:39 PM, Eric Filson  wrote:
&gt;
&gt;&gt; I would think that this requirement,
&gt;&gt; retrieving all objects in a bucket, to be a \\_very\\_ common
&gt;&gt; place?occurrence?for modern web development and perhaps (depending on
&gt;&gt; requirements) \\_the\\_ most common function aside from retrieving a single k/v
&gt;&gt; pair.
&gt;
&gt; I tend to see people that mostly try to write applications that don't
&gt; select everything from a whole bucket/table/whatever as a very
&gt; frequent occurrence, but different people have different requirements.
&gt; Certainly, it is sometimes unavoidable.
&gt;
&gt;&gt; In my mind, this seems to leave the only advantage to buckets in this
&gt;&gt; application to be namespacing... While certainly important, I'm fuzzy on
&gt;&gt; what the downside would be to allowing buckets to exist as a separate
&gt;&gt; partition/pseudo-table/etc... so that?retrieving?all objects in a bucket
&gt;&gt; would not need to read all objects in the entire system
&gt;
&gt; The namespacing aspect is a huge advantage for many people. Besides
&gt; the obvious way in which that allows people to avoid collisions, it is
&gt; a powerful tool for data modeling. For example, sets of 1-to-1
&gt; relationships can be very nicely represented as something like
&gt; "bucket1/keyA, bucket2/keyA, bucket3/keyA", which allows related items
&gt; to be fetched without any intermediate queries at all.
&gt;
&gt; One of the things that many users have become happily used to is that
&gt; buckets in Riak are generally "free"; they come into existence on
&gt; demand, and you can use as many of them as you want in the above or
&gt; any other fashion. This is in essence what conflicts with your
&gt; desire. Making buckets more fundamentally isolated from each other
&gt; would be difficult without incurring some incremental cost per bucket.
&gt;
&gt;&gt; I might recommend a hybrid
&gt;&gt; solution (based in my limited knowledge of Riak)... What about allowing a
&gt;&gt; bucket property named something like "key\\_index" that points to a key
&gt;&gt; containing a value of "keys in bucket". ?Then, when calling GET
&gt;&gt; /riak/bucket, Riak would use the key\\_index to immediately reduce its result
&gt;&gt; set before applying m/r funcs. ?While I understand this is essentially what
&gt;&gt; a developer would do, it would certainly alleviate some code requirements
&gt;&gt; (application side) as well as make the behavior of retrieving a bucket's
&gt;&gt; contents more "expected" and efficient.
&gt;
&gt; A much earlier incarnation of Riak actually stored bucket keylists
&gt; explicitly in a fashion somewhat like what you describe. We removed
&gt; this as one of our biggest goals is predictable and understandable
&gt; behavior in a distributed systems sense, and a model like this one
&gt; turns each write operation into at least two operations. This isn't
&gt; just a performance issue, but also adds complexity. For instance, it
&gt; is not immediately obvious what should be returned to the client if a
&gt; data item write succeeds, but the read/write of the index fails?
&gt;
&gt; Most people using distributed data systems (including but not limited
&gt; to Riak) do explicit data modeling, using things like key identity as
&gt; above, or objects that contain links to each other (Riak has great
&gt; support for this) or other data modeling means to plan out their
&gt; expected queries in advance.
&gt;
&gt;&gt; Anyway, information is pretty limited on riak right now, seeing as how it's
&gt;&gt; so new, but talk in my development circles is very positive and lively.
&gt;
&gt; Please do let us know any aspects of information on Riak that you
&gt; think are missing. We think that between the wiki, the web site, and
&gt; various other materials, the information is pretty good. Riak's been
&gt; open source for about a year, and in use longer than that; while there
&gt; are many things much older than Riak, we don't see relative youth as a
&gt; reason not to do things right.
&gt;
&gt; Thanks again for your thoughts, and I hope that this helps with your
&gt; understanding.
&gt;
&gt; -Justin
&gt;
&gt;
&gt;
&gt; ------------------------------
&gt;
&gt; Message: 2
&gt; Date: Tue, 20 Jul 2010 15:05:56 -0400
&gt; From: Rusty Klophaus 
&gt; To: riak-users 
&gt; Subject: [ANN] Basho Riak 0.12.0
&gt; Message-ID:
&gt; 
&gt; Content-Type: text/plain; charset="iso-8859-1"
&gt;
&gt; Hello, Riak users. We are excited to announce the release of Riak version 
&gt; 0.12!
&gt;
&gt; Pre-built installations and source tarballs are available at:
&gt; http://downloads.basho.com/
&gt;
&gt; Release notes are at (also copied below):
&gt; http://downloads.basho.com/riak/riak-0.12/riak-0.12.0.txt
&gt;
&gt; Cheers,
&gt; The Basho Riak Team
&gt;
&gt; -------------------------
&gt; Riak 0.12.0 Release Notes
&gt; -------------------------
&gt;
&gt; Riak now uses a new and improved mechanism for determining whether a
&gt; node is fully online and ready to participate in Riak operations. This
&gt; is especially important in failure recovery situations, as it allows
&gt; the storage backend to complete a full integrity check and repair
&gt; process. (134)
&gt;
&gt; Applications can now use the keywords "one", "quorum" (or "default"),
&gt; and "all" in place of number values to set R, W, and DW quorum settings.
&gt; This allows developers to specify intended consistency levels more
&gt; clearly. (211, 276, 277, 322)
&gt;
&gt; The multi backend has been fixed so bitcask can be used with the
&gt; other backends (274). If innostore is installed it must be upgraded to 1.0.1
&gt; if it will be used with the multi backend.
&gt;
&gt; Enhancements
&gt; ------------
&gt; 82 - HTTP API now returns 400 when quorum parameters exceed N-val.
&gt; 83 - Default quorum parameters are now configurable in HTTP and Protobuf 
&gt; APIs.
&gt; 97 - Riak now calls a BackendModule:stop/1 function, allowing cleanup
&gt; during shutdown.
&gt; 190 - HTTP API now returns 503 when Riak operation times out.
&gt; 192 - HTTP API no longer list keys on a bucket by default.
&gt; 283 - HTTP API now returns 404 when an object is missing, regardless
&gt; of accept header. (202)
&gt; 216 - The "/stats" page now includes read-repair stats.
&gt; 219 - A node now verifies that the ring\\_creation\\_size matches before
&gt; joining a cluster.
&gt; 230 - Upgrade to latest version of Mochiweb.
&gt; 237 - Added a 'mapByFields' built-in Map/Reduce function.
&gt; 246 - Improved error reporting in post-commit hooks.
&gt; 251 - More descriptive error message on malformed link walking operations.
&gt; 256 - The /stats endpoint now shows Riak version number.
&gt; 259 - Improve python client packaging. Publish on PyPI.
&gt; 267 - Updated bucket defaults to improve replica distribution across
&gt; physical nodes.
&gt; 274 - Improvements to storage backend interface layer.
&gt; 365 - Use updated "rebar eunit" task for running tests.
&gt;
&gt; Bugs Fixed
&gt; ----------
&gt; 26 - The 'devrel' target now builds on CentOS.
&gt; 27 - Fixed 'riak-admin' problem on some architectures, including Solaris.
&gt; 138 - Fixed platform specific problems in Riak 'init.d' script.
&gt; 205 - Fixed Bitcask errors on 32-bit Erlang. (331, 344)
&gt; 229 - Fixed 'riak stop' error on Mac OSX Snow Leopard 10.6.3.
&gt; 240 - Python client now properly escapes "/" in Buckets and Keys.
&gt; 253 - Correctly pass missing object (not\\_found) results between
&gt; Map/Reduce phases.
&gt; 274 - Correctly forward 'info' messages from multi\\_backend to child backends.
&gt; 278 - Make Riak backup work correctly in all cases when objects are
&gt; deleted while backup is in progress.
&gt; 280 - Fixed corner cases causing timestamp collision in Bitcask.
&gt; 281 - Fixed premature tombstone collection in Bitcask.
&gt; 301 - Fixed chunked mapreduce results to use correct line breaks (\\r\\n).
&gt; 305 - Fixed possible race condition between get and Bitcask merge.
&gt; 382 - Update Map/Reduce to honor timeout setting.
&gt; 361 - Cleaned up Dialyzer warnings. (373, 374, 376, 381, 389)
&gt; 382 - Update Map/Reduce to honor timeout setting.
&gt; 402 - Make Bitcask data and hint files more resistant to corruption.
&gt;
&gt; Riak has been updated with the necessary changes to compile
&gt; on Erlang R14A, but has not been thoroughly tested on R14A.
&gt; Please continue to run Riak on R13B04 in production. (263, 264, 269)
&gt;
&gt; All bug and issue numbers reference https://issues.basho.com.
&gt; -------------- next part --------------
&gt; An HTML attachment was scrubbed...
&gt; URL: 
&gt; 
&gt;
&gt; ------------------------------
&gt;
&gt; Message: 3
&gt; Date: Tue, 20 Jul 2010 18:00:14 -0400
&gt; From: Eric Filson 
&gt; To: Justin Sheehy 
&gt; Cc: riak-users@lists.basho.com
&gt; Subject: Re: Expected vs Actual Bucket Behavior
&gt; Message-ID:
&gt; 
&gt; Content-Type: text/plain; charset="iso-8859-1"
&gt;
&gt; On Tue, Jul 20, 2010 at 3:02 PM, Justin Sheehy  wrote:
&gt;
&gt;&gt; Hi, Eric! Thanks for your thoughts.
&gt;&gt;
&gt;&gt; On Tue, Jul 20, 2010 at 12:39 PM, Eric Filson  wrote:
&gt;&gt;
&gt;&gt;&gt; I would think that this requirement,
&gt;&gt;&gt; retrieving all objects in a bucket, to be a \\_very\\_ common
&gt;&gt;&gt; place occurrence for modern web development and perhaps (depending on
&gt;&gt;&gt; requirements) \\_the\\_ most common function aside from retrieving a single
&gt;&gt; k/v
&gt;&gt;&gt; pair.
&gt;&gt;
&gt;&gt; I tend to see people that mostly try to write applications that don't
&gt;&gt; select everything from a whole bucket/table/whatever as a very
&gt;&gt; frequent occurrence, but different people have different requirements.
&gt;&gt; Certainly, it is sometimes unavoidable.
&gt;&gt;
&gt;
&gt; Indeed, in my case it is :(
&gt;
&gt;
&gt;&gt;
&gt;&gt;&gt; In my mind, this seems to leave the only advantage to buckets in this
&gt;&gt;&gt; application to be namespacing... While certainly important, I'm fuzzy on
&gt;&gt;&gt; what the downside would be to allowing buckets to exist as a separate
&gt;&gt;&gt; partition/pseudo-table/etc... so that retrieving all objects in a bucket
&gt;&gt;&gt; would not need to read all objects in the entire system
&gt;&gt;
&gt;&gt; The namespacing aspect is a huge advantage for many people. Besides
&gt;&gt; the obvious way in which that allows people to avoid collisions, it is
&gt;&gt; a powerful tool for data modeling. For example, sets of 1-to-1
&gt;&gt; relationships can be very nicely represented as something like
&gt;&gt; "bucket1/keyA, bucket2/keyA, bucket3/keyA", which allows related items
&gt;&gt; to be fetched without any intermediate queries at all.
&gt;&gt;
&gt;
&gt; I agree however, the same thing can be accomplished by prefixing your keys
&gt; with a "namespace"...
&gt;
&gt; bucket\\_1\\_keyA, bucket\\_2\\_keyA, bucket\\_3\\_keyA
&gt;
&gt; Obviously, buckets in Riak have additional functionality and allow for some
&gt; more complex but easier to use m/r functions across multiple buckets,
&gt; etc...
&gt;
&gt;
&gt;&gt;
&gt;&gt; One of the things that many users have become happily used to is that
&gt;&gt; buckets in Riak are generally "free"; they come into existence on
&gt;&gt; demand, and you can use as many of them as you want in the above or
&gt;&gt; any other fashion. This is in essence what conflicts with your
&gt;&gt; desire. Making buckets more fundamentally isolated from each other
&gt;&gt; would be difficult without incurring some incremental cost per bucket.
&gt;&gt;
&gt;
&gt; For me, I am more than willing to add a small amount of overhead to the
&gt; storage engine for increased functionality and reduced overhead on the
&gt; application layer. Again this is obviously application specific and I'm not
&gt; saying it should all be converted over for all buckets exiting in their own
&gt; space for every implementation but certainly a different storage engine or
&gt; configuration option to allow this level/type of access would be nice :)
&gt;
&gt;
&gt;&gt;&gt; I might recommend a hybrid
&gt;&gt;&gt; solution (based in my limited knowledge of Riak)... What about allowing a
&gt;&gt;&gt; bucket property named something like "key\\_index" that points to a key
&gt;&gt;&gt; containing a value of "keys in bucket". Then, when calling GET
&gt;&gt;&gt; /riak/bucket, Riak would use the key\\_index to immediately reduce its
&gt;&gt; result
&gt;&gt;&gt; set before applying m/r funcs. While I understand this is essentially
&gt;&gt; what
&gt;&gt;&gt; a developer would do, it would certainly alleviate some code requirements
&gt;&gt;&gt; (application side) as well as make the behavior of retrieving a bucket's
&gt;&gt;&gt; contents more "expected" and efficient.
&gt;&gt;
&gt;&gt; A much earlier incarnation of Riak actually stored bucket keylists
&gt;&gt; explicitly in a fashion somewhat like what you describe. We removed
&gt;&gt; this as one of our biggest goals is predictable and understandable
&gt;&gt; behavior in a distributed systems sense, and a model like this one
&gt;&gt; turns each write operation into at least two operations. This isn't
&gt;&gt; just a performance issue, but also adds complexity. For instance, it
&gt;&gt; is not immediately obvious what should be returned to the client if a
&gt;&gt; data item write succeeds, but the read/write of the index fails?
&gt;&gt;
&gt;
&gt; Haha, these are the exact reasons I would cite as a developer for using a
&gt; similar method on Riak's side... without the option of auto bucket indexing
&gt; it effectively places this double write into the application side where it
&gt; requires more cycles and more data across the wire. Instead of doing a
&gt; single write, from the application side, and allowing Riak to handle this,
&gt; you have to GET index\\_key, UPDATE index\\_key, ADD new\\_key... So rather than
&gt; having a single transaction with Riak, you have to have three transactions
&gt; with Riak + Application functionality. Inherently, this adds another level
&gt; of complexity into the application code base for something that could be
&gt; done more efficiently by the DB engine itself.
&gt;
&gt; I would think a separate error number and message would suffice as a return
&gt; error, obviously though, this would require developers being made aware so
&gt; they can code for the exception.
&gt;
&gt; Also, this would be optional, if the index\\_key wasn't set for the bucket
&gt; then this setup wouldn't be used. This would at least make the system more
&gt; flexible to the application requirements and developer preferences.
&gt;
&gt;
&gt;&gt; Most people using distributed data systems (including but not limited
&gt;&gt; to Riak) do explicit data modeling, using things like key identity as
&gt;&gt; above, or objects that contain links to each other (Riak has great
&gt;&gt; support for this) or other data modeling means to plan out their
&gt;&gt; expected queries in advance.
&gt;&gt;
&gt;&gt;&gt; Anyway, information is pretty limited on riak right now, seeing as how
&gt;&gt; it's
&gt;&gt;&gt; so new, but talk in my development circles is very positive and lively.
&gt;&gt;
&gt;&gt; Please do let us know any aspects of information on Riak that you
&gt;&gt; think are missing. We think that between the wiki, the web site, and
&gt;&gt; various other materials, the information is pretty good. Riak's been
&gt;&gt; open source for about a year, and in use longer than that; while there
&gt;&gt; are many things much older than Riak, we don't see relative youth as a
&gt;&gt; reason not to do things right.
&gt;&gt;
&gt;&gt; Thanks again for your thoughts, and I hope that this helps with your
&gt;&gt; understanding.
&gt;
&gt;
&gt; Some very valuable information, for me, would be seeing a breakdown of how
&gt; Riak scales out...
&gt;
&gt; Something like showing how many keys in how many buckets takes how long with
&gt; how many nodes... (extended by, now with 2 more machines, now with more
&gt; complex m/r funcs, now with twice as many keys, etc...) I know this largely
&gt; depends on whatever map/reduce functions are being run however even a simple
&gt; example would be nice to see. As it is I have no idea how many queries per
&gt; second of what type I can run with how many active nodes? Again, I realize
&gt; this is something that needs to be benchmarked for any sort of accuracy but
&gt; I'm speaking more of targeting developers, like myself, who are looking into
&gt; this as a newer technology that may work for them. It is a very large
&gt; commitment of time and resources to design and implement something then
&gt; benchmark it in order to obtain the "if it will work for this application
&gt; efficiently" answer. Having some baseline stats from which to start may
&gt; prompt more developers to explore Riak as a storage solution.
&gt;
&gt; And one more thanks for hearing me out and your feedback. I'd also like to
&gt; reiterate that I'm coming from a limited nosql background... however I feel
&gt; that's the case with the majority of developers out there today. My
&gt; recommendations for options are based on the real world application design
&gt; challenges I've personally been presented with over my career and that I
&gt; feel may be common to many other developers as well. Obviously, even adding
&gt; a single option such that I've mentioned is a massive undertaking on Basho's
&gt; part but they are definitely pieces of functionality that would make me say,
&gt; "done, Riak it is". Rather than... is there something else which would
&gt; better suit my needs... and when vying for adoption rate that's a major
&gt; factor :)
&gt; -------------- next part --------------
&gt; An HTML attachment was scrubbed...
&gt; URL: 
&gt; 
&gt;
&gt; ------------------------------
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
&gt; End of riak-users Digest, Vol 12, Issue 24
&gt; \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*

\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

