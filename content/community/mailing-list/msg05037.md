---
title: "Re: Have Riak servers in separate cluster behind a load balancer, or	on same machines as web server?"
description: ""
project: community
lastmod: 2011-10-04T16:00:06-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05037"
mailinglist_parent_id: "msg05036"
author_name: "Greg Stein"
project_section: "mailinglistitem"
sent_date: 2011-10-04T16:00:06-07:00
---


I'm with Kyle on this one. Even better, my 'newhttp' branch on Github
enables this kind of multiple-connection and automatic fail-over.

That branch does have a basic sketch for automatic addition/removal of
Riak nodes as you manipulate your cluster. I'll need it one day, but
not "now", so I haven't finished it yet (the monitor.py background
thread).

Regarding security: it is the same for option A and B and C (you're
just shifting stuff around, but it is pretty much all the same). Put
your webservers in one security group, and the Riak nodes in another.
Open the Riak ports \\*only\\* to the webserver security group and to each
other.

Avoiding two services on one machine (e.g web + riak) is also much
easier to manage/maintain. Just have web machines and riak machines.

Cheers,
-g

On Tue, Oct 4, 2011 at 17:09, Aphyr  wrote:
&gt; Option C: Deploy your web servers with a list of hosts to connect to. Have
&gt; the clients fail over when a riak node goes down. Lower latency without
&gt; sacrificing availability. If you're using protobufs, this may not be as big
&gt; of an issue.
&gt;
&gt; --Kyle
&gt;
&gt; On 10/04/2011 02:04 PM, O'Brien-Strain, Eamonn wrote:
&gt;&gt;
&gt;&gt; I am contemplating two different architectures for deploying Riak nodes
&gt;&gt; and web servers.
&gt;&gt;
&gt;&gt; Option A:  Riak nodes are in their own cluster of dedicated machines
&gt;&gt; behind a load balancer.  Web servers talk to the Riak nodes via the load
&gt;&gt; balancer. (See diagram http://eamonn.org/i/riak-arch-A.png )
&gt;&gt;
&gt;&gt; Option B: Each web server machine also has a Riak node, and there are also
&gt;&gt; some Riak-only machines.  Each web server only talks to its own localhost
&gt;&gt; Riak node. (See diagram http://eamonn.org/i/riak-arch-B.png )
&gt;&gt;
&gt;&gt;
&gt;&gt; All machines will deployed as elastic cloud instances.  I will want to
&gt;&gt; spin up and spin down instances, particularly the web servers, as demand
&gt;&gt; varies.  Both load balancers are non-sticky.  Web servers are currently
&gt;&gt; talking to Riak via HTTP (though might change that to protocol buffers in
&gt;&gt; the future).  Currently Riak is configured with the default options.
&gt;&gt;
&gt;&gt; Here is my thinking of the comparative advantages:
&gt;&gt;
&gt;&gt; Option A:
&gt;&gt;
&gt;&gt;  - Better for security, because can lock down the Riak load balancer to
&gt;&gt; only open a single port and only for connections from the web servers.
&gt;&gt;  - Less churn for Riak of nodes entering and leaving the Riak cluster (as
&gt;&gt; web servers spin up and down)
&gt;&gt;  - More flexibility in scaling storage and web tiers independently of each
&gt;&gt; other
&gt;&gt;
&gt;&gt; Option B:
&gt;&gt;
&gt;&gt;  - Faster localhost connection from web server to Riak
&gt;&gt;
&gt;&gt; I think availability is similar for the two options.
&gt;&gt;
&gt;&gt; The web server response time is the primary metric I want to optimize.
&gt;&gt;  Most web server requests will cause several requests to Riak.
&gt;&gt;
&gt;&gt; What other factors should I take into account?  What measurements could I
&gt;&gt; make to help me decide between the architectures?  Are there other
&gt;&gt; architectures I should consider? Should I add memcached? Does anyone have
&gt;&gt; any experiences they could share in deploying such systems?
&gt;&gt;
&gt;&gt; Thanks.
&gt;&gt; \\_\\_
&gt;&gt; Eamonn

&gt;
