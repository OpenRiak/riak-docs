---
title: "RE: Newbie question 3/3"
description: ""
project: community
lastmod: 2012-01-09T23:05:57-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06200"
mailinglist_parent_id: "msg06190"
author_name: "Erik Søe Sørensen"
project_section: "mailinglistitem"
sent_date: 2012-01-09T23:05:57-08:00
---


One thing to be aware of, in a multi-cluster setup such as you apparently 
(will) have, is that cluster2cluster synchronization gives no ordering 
guarantees:
Updates at one cluster on two different keys may arrive at the other cluster in 
any order.
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
From: riak-users-boun...@lists.basho.com [riak-users-boun...@lists.basho.com] 
On Behalf Of Ryan Zezeski [rzeze...@basho.com]
Sent: 09 January 2012 23:54
To: John DeTreville
Cc: riak-users@lists.basho.com
Subject: Re: Newbie question 3/3

John,

As you already seem to understand, Riak doesn't provide a way to make multiple 
ops atomic. Part of the reason is because Riak's main focus thus far has been 
availability. Distributed transactions would work, but at the cost of 
availability. I think a flaw with the redo log approach is that you need to 
serialize all operations to A & B through \\_one\\_ client to keep from reading an 
inconsistent state.

A much simpler option, if you can bend your data, is to combine A and B into 
one object.

-Ryan

On Mon, Jan 9, 2012 at 12:33 AM, John DeTreville 
&gt; wrote:
(An earlier post seems not to have gone through. My apologies in the eventual 
case of a duplicate.)

I'm thinking of using Riak to replace a large Oracle system, and I'm trying to 
understand its guarantees. I have a few introductory questions; this is the 
third of three.

I would like to do two updates atomically, but of course I cannot. I imagine I 
could construct my own redo log, and perform a sequence of operations something 
like:

 write redo log entry (timestamp, A's update, B's update) to redo log
 update A
 update B
 delete redo log entry from redo log

Asynchronously, I could read dangling entries from the redo log and repeat 
them, deleting them upon success. (Let's imagine for simplicity that the 
updates are idempotent and commutative.) This seems doable, but it's not 
pretty. Is this the best I can do? Or should I think about the problem 
differently?

(BTW, I believe that secondary indexes won't help me.)

Cheers,
John

