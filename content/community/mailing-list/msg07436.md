---
title: "Re: How do I improve Level DB performance?"
description: ""
project: community
lastmod: 2012-05-11T09:20:29-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07436"
mailinglist_parent_id: "msg07434"
author_name: "Tim Haines"
project_section: "mailinglistitem"
sent_date: 2012-05-11T09:20:29-07:00
---


On Fri, May 11, 2012 at 9:13 AM, Ryan Zezeski  wrote:

&gt;
&gt;
&gt; On Thu, May 10, 2012 at 11:14 PM, Tim Haines  wrote:
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; With the adjusted ring size and settings, and adjusted to only do puts
&gt;&gt; (so no missed reads), my cluster is doing about 400 puts per second:
&gt;&gt; http://twitpic.com/9jnhlm/full
&gt;&gt;
&gt;
&gt; Actually, every put (put from a riak API level) does a read on the backend
&gt; [1]. This is needed to merge contents from the two objects [2].
&gt;
&gt; Like Dave already mentioned the key generation strategy along with
&gt; leveldb's degrading performance on not-found means your benchmark will just
&gt; get worse the longer it runs.
&gt;
&gt; Are you testing an actual use case here? Do you envision 100M objects
&gt; being written in a constant stream? Will your objects have a median size
&gt; of 1000 bytes? Basho bench also provides a pareto key generator which uses
&gt; a fraction of the key space most of the time. I'm not sure it matches your
&gt; use case but thought I'd mention it is there.
&gt;
&gt;
Hi Ryan,

Thanks. Greg just mentioned the reads on puts too. I'd changed the config
to 250 bytes (matching about what I store for a tweet), and reran it
overnight, and observed performance drop from 400 puts/s to 250 puts/s.
 Right now my use case has me constantly writing about 200 new tweets per
second, so unless I'm missing something, this throughput measurement is a
realistic indicator for me.

Tim.
