---
title: "Re: 'not found' after join"
description: ""
project: community
lastmod: 2011-05-03T02:30:20-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg03198"
mailinglist_parent_id: "msg03195"
author_name: "Nico Meyer"
project_section: "mailinglistitem"
sent_date: 2011-05-03T02:30:20-07:00
---


Hi everyone,

I just want to note that I observed similar behaviour with a somewhat
larger clusters of 10 or so nodes. I first noticed that handoff activity
after node join (or leave for that matter) involved a lot more
partitions than I would have expected. By comparing the old and the new
ring file, I found out that more than 80 percent of partitions had to be
moved to another node.
My naive expectation was that joining a node to a cluster of size X
would result in roughly ring\\_creation\\_size/(X+1) partitions to be handed
off, which would also be the minimum if one expects a balanced cluster
afterwards.
Furthermore it would in theory be possible to move partitions in such a
way that at least one partition from each preflist stays on the same
node. Maybe for X&gt;N it should even be possible to guarantee this for a
basic quorum of each preflist, eliminating the notfound problem
completely, but I am not sure about that.

I may be able to provide some ring files to analyze this behaviour if
someone from basho is interested.

Cheer Nico

Am Montag, den 02.05.2011, 23:14 -0400 schrieb Ryan Zezeski:
&gt; Greg,
&gt; 
&gt; 
&gt; Your expectations are fair, just because you added a node doesn't mean
&gt; Riak should return notfounds. Unfortunately, we aren't quite there
&gt; yet. This is a side effect of how Riak currently implements handoff
&gt; in that it immediately updates/gossips the ring causing
&gt; many partitions to handoff immediately. If a request comes in that
&gt; relies on these partitions then it will get a notfound and perform
&gt; read repair. You're situation is multiplied by the fact that you are
&gt; going from 3 nodes to 4. More vnode shuffling occurs because of the
&gt; small cluster size.
&gt; 
&gt; 
&gt; We're well aware of this and have it on our radar for improvement in a
&gt; future release.
&gt; 
&gt; 
&gt; All this said, you data will be eventually consistent. That is, all
&gt; your data will eventually be handed off and things will work as
&gt; normal. It's only during the handoff that you \\_may\\_ encounter
&gt; notfounds. In this case it would be best to add a new node to your
&gt; cluster at lowest load times and if you can spare additional hardware
&gt; a few more nodes to start with is an even easier option.
&gt; 
&gt; 
&gt; -Ryan
&gt; 
&gt; On Mon, May 2, 2011 at 9:48 PM, Greg Nelson 
&gt; wrote:
&gt; Hello riak users! 
&gt; 
&gt; 
&gt; I have a 4 node cluster that started out as 3 nodes.
&gt; ring\\_creation\\_size = 2048, target\\_n\\_val is default (4), and
&gt; all buckets have n\\_val = 3.
&gt; 
&gt; 
&gt; When I joined the 4th node, for a few minutes some GETs were
&gt; returning 'not found' for data that was already in riak.
&gt; Eventually the data was returned, due to read repair I would
&gt; assume. Is this expected? It seems that 'not found' and read
&gt; repairs should only happen when something goes wrong, like a
&gt; node goes down. Not when adding a node to the cluster, which
&gt; is supposed to be part of normal operation!
&gt; 
&gt; 
&gt; Any help or insight is appreciated!
&gt; 
&gt; 
&gt; Greg
&gt; 
 
&gt; 
&gt; 

