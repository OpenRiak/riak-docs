---
title: "Re: How to change existing data from one back-end to another"
description: ""
project: community
lastmod: 2011-12-22T18:34:40-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06045"
mailinglist_parent_id: "msg06004"
author_name: "Ryan Zezeski"
project_section: "mailinglistitem"
sent_date: 2011-12-22T18:34:40-08:00
---


Markus,

You're correct in that backup/restore currently doesn't work with search.
 You could still use that method but would have to reindex everything which
would require list keys. In our next minor version method #2 will get
better but it will require you to upgrade. Another method is to write some
code to directly convert one backend's data to another. Then you would
take each node down one at a time, run custom code to convert, switch
backends in config file, then restart node.

-Ryan

On Mon, Dec 19, 2011 at 8:59 PM, Markus Silpala  wrote:

&gt; Ryan,
&gt;
&gt; That's actually quite a relief that Riak doesn't automagically convert;
&gt; that would be been a frightening volume of work to keep so well hidden!
&gt;
&gt; For that Option #1 when you describe doing a "restore," are you referring
&gt; to the "riak-admin backup" and "riak-admin restore"? The reason I ask is
&gt; that we've been avoiding the use of riak-admin backup because (IIRC) it
&gt; didn't properly back up search index files (or something along those
&gt; lines). Has that issue been resolved now to where we can and should rely on
&gt; riak-admin to do our backups even if we use riak-search?
&gt;
&gt; (Or did I just pick up the wrong pipe this morning before remembering that
&gt; issue with the old riaksearch-admin?)
&gt;
&gt; Thanks again,
&gt;
&gt; -Markus
&gt;
&gt; On Mon, Dec 12, 2011 at 4:29 PM, Ryan Zezeski  wrote:
&gt;
&gt;&gt; Markus,
&gt;&gt;
&gt;&gt; Riak will \\_not\\_ automatically convert the data for you. If you change
&gt;&gt; the backend and bounce the node that node will no longer see the data and
&gt;&gt; it has no notion of converting data from another backend. Remember, you
&gt;&gt; are simply changing a value in the config file. Riak is not aware that you
&gt;&gt; were once using another backend and that your intention is to migrate the
&gt;&gt; data. Riak does not pretend to be smart in that regard and that's probably
&gt;&gt; a good thing as some people may change backends with the intention of \\_not\\_
&gt;&gt; migrating data. What would happen is that the one node would be using a new
&gt;&gt; backend with no data while the other nodes would still be using the old
&gt;&gt; backend with it's current data. As data is read Riak would notice the
&gt;&gt; missing data on the new backend and performed read repair. You could take
&gt;&gt; advantage of this and "migrate" data by performing a streaming list keys +
&gt;&gt; GET to read repair all data. However, down that road lies madness.
&gt;&gt;
&gt;&gt; I see two ways to go about this:
&gt;&gt;
&gt;&gt; 1) Do a rolling backup/stop/change config/start/restore.
&gt;&gt;
&gt;&gt; 2) Join new nodes using new backend, let claim and handoffs move data
&gt;&gt; over, then leave nodes using old backend.
&gt;&gt;
&gt;&gt; I like the first method because it doesn't require join/leave which can
&gt;&gt; cause massive partition shifts with the current default claim algorithm.
&gt;&gt; The second method is easier to execute but requires at least one
&gt;&gt; additional machine and use of the new claim algorithm.
&gt;&gt;
&gt;&gt; There is an outstanding pull request for 2i/multi back-end support [1].
&gt;&gt;
&gt;&gt; -Ryan
&gt;&gt;
&gt;&gt; [1]: https://github.com/basho/riak\\_kv/pull/258
&gt;&gt;
&gt;&gt; On Mon, Dec 12, 2011 at 12:19 PM, Markus Silpala wrote:
&gt;&gt;
&gt;&gt;&gt; Greetings again.
&gt;&gt;&gt;
&gt;&gt;&gt; Another likely-quick question after my weekend of doco-diving: is there
&gt;&gt;&gt; any trick or are there any steps needed to change an existing cluster from
&gt;&gt;&gt; one back-end to another? Judging by the wiki page for the Multi 
&gt;&gt;&gt; back-end it
&gt;&gt;&gt; would appear that one just changes the app.config or PUTs a change to
&gt;&gt;&gt; bucket properties, bounces the node, and riak converts all existing data
&gt;&gt;&gt; automatically. Is it really that simple?
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt;&gt; Are there any considerations around rolling updates vs taking downtime
&gt;&gt;&gt; to update the whole cluster? Any concern about large data sets during the
&gt;&gt;&gt; conversion? Is the node available during the conversion? Any gotchas around
&gt;&gt;&gt; when 2i actually becomes usable in the updated bucket?
&gt;&gt;&gt;
&gt;&gt;&gt; Okayâ€”only the first question was likely to be quick. :-)
&gt;&gt;&gt;
&gt;&gt;&gt; For us it's really unfortunate that we can't use 2i through a Multi
&gt;&gt;&gt; back-end. We don't use either today. We may want to use Multi to cause
&gt;&gt;&gt; certain buckets to expire their data sooner than the rest; but we very
&gt;&gt;&gt; likely want to adopt 2i for certain cases where buckets are related and
&gt;&gt;&gt; other cases where a simple equality- or range-based search will be needed.
&gt;&gt;&gt; Choosing between the two is a real bummer.
&gt;&gt;&gt;
&gt;&gt;&gt; Is 2i support through Multi in the plan for future releases?
&gt;&gt;&gt;
&gt;&gt;&gt; Thanks again,
&gt;&gt;&gt;
&gt;&gt;&gt; -Markus
&gt;&gt;&gt;

&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;
