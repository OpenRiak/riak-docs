---
title: "Deciphering Key Filter Errors"
description: ""
project: community
lastmod: 2011-03-02T22:55:20-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg02531"
author_name: "Jason J. W. Williams"
project_section: "mailinglistitem"
sent_date: 2011-03-02T22:55:20-08:00
---


Hi,

I'm experimenting using key filters to implement indexes. My approach
is for each data key in bucket A, to create a new empty key in a
dedicated index bucket where the original key name and value of the
indexed field is encoded in the key name for a new index key.

Data key looks like this:

Bucket - riak\\_perf\\_test
Key - ccode\\_ : {"redeemed\\_count": 23 }

For each data key created, an index key is created:

Bucket - idx=redeemed\\_count=ccode
Key - ccode/23

(in both keys 23 changes on a per-key basis based on what
"redeemed\\_count" is set to)


My goal is to be able to do a key filtered Map Reduce job on
idx=redeemed\\_count=ccode that generates a list of all data key names
with a redeemed\\_count &lt; 50.

The job (using curl) is here: https://gist.github.com/852451

It errors out almost immediately in sasl-error.log
(https://gist.github.com/852450), but the request doesn't immediately
error out to the client. The only error the client sees is an eventual
timeout error.

So my question is, what is the error in sasl-error.log telling me is
wrong with my job construction? And also, why is there only a timeout
error generated to the client instead of a map\\_reduce\\_error as I've
seen for non-key filtered jobs?

Thank you in advance for any help. I greatly appreciate it.

-J

