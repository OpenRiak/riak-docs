---
title: "Re: Riak Search"
description: ""
project: community
lastmod: 2012-10-16T05:49:44-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08934"
mailinglist_parent_id: "msg08933"
author_name: "Pavel Kogan"
project_section: "mailinglistitem"
sent_date: 2012-10-16T05:49:44-07:00
---


Thanks a lot.

On Tue, Oct 16, 2012 at 2:44 PM, Ryan Zezeski  wrote:

&gt;
&gt;
&gt; On Sun, Oct 14, 2012 at 12:33 AM, Pavel Kogan wrote:
&gt;&gt;
&gt;&gt;
&gt;&gt; 1) Is search enabling has any impact on read latency/throughput?
&gt;&gt;
&gt;
&gt; If you are reading and searching at the same time there is a good chance
&gt; it will. It will cause more disk seeks.
&gt;
&gt;
&gt;&gt; 2) Is search enabling has any impact on RAM usage?
&gt;&gt;
&gt;
&gt; Yes, the index engine behind Riak Search makes heavy usage of Erlang ETS
&gt; tables. Each partition has an in-memory buffer as well as an in-memory
&gt; offset table for every segment. It also uses a temporary ETS table for
&gt; every write to store posting data. The ETS system limit can even become an
&gt; issue in overload scenarios.
&gt;
&gt;
&gt;&gt; 3) In production we have no search enabled. What is the best way to
&gt;&gt; enable search without stop production? I thought about something like:
&gt;&gt; 1) Enable search node after node.
&gt;&gt;
&gt;
&gt; You could change the app env dynamically but that's only half the problem.
&gt; The other half is then starting the Riak Search application. I think
&gt; application:start(merge\\_index) followed by application:start(riak\\_search)
&gt; should work but I'm not 100% sure and this has not been tested. You'll
&gt; also want to make sure to edit all app.configs so that it is persistent.
&gt;
&gt;
&gt;&gt;
&gt; 2) Execute some night script that runs on all keys and overwrite them
&gt;&gt; back
&gt;&gt; with proper mime type.
&gt;&gt;
&gt;
&gt; Yes, you'll want to install the commit hook on the buckets you wish to
&gt; index. Then you'll want to do a streaming list-keys or bucket map-reduce
&gt; and re-write the data.
&gt;
&gt;
&gt;&gt;
&gt; 4) If we see that search overhead is something we can't handle, is there
&gt;&gt; simple
&gt;&gt; way to disable it without stop production?
&gt;&gt;
&gt;
&gt; I think the best course of action in this case would be to disable the
&gt; commit hook. But you would have to keep track of anything written during
&gt; this time and re-write it after re-installing the hook. If you don't then
&gt; you'll have to re-index everything because you don't know what you missed.
&gt;
&gt; 5) In what case we would need repair? It is said - on replica loss, but if
&gt;&gt; I understand
&gt;&gt; correct we have 3 replicas on different nodes don't we? If it happens
&gt;&gt; how difficult and
&gt;&gt; long would it be for large cluster (about 100 nodes)?
&gt;&gt;
&gt;
&gt; Repair is on a per partition basis. Number of nodes doesn't come into
&gt; play. Repair is very specific in that it requires the adjacent partitions
&gt; to be in a good, convergent state. If they aren't then repair isn't much
&gt; help.
&gt;
&gt; A lot of these entropy issues go away in Yokozuna. Repairing indexes is
&gt; done automatically, in the background, in an efficient manner. There is no
&gt; need to re-write data or run manual repair commands.
&gt;
&gt; -Z
&gt;
