---
title: "Re: Throughput issue contd. On Joyend Riak Smartmachine"
description: ""
project: community
lastmod: 2012-06-27T04:06:15-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07807"
mailinglist_parent_id: "msg07806"
author_name: "Yousuf Fauzan"
project_section: "mailinglistitem"
sent_date: 2012-06-27T04:06:15-07:00
---


I did use basho bench on my clusters. It should throughput of around 150

On Wed, Jun 27, 2012 at 4:24 PM, Russell Brown wrote:

&gt;
&gt; On 27 Jun 2012, at 11:50, Yousuf Fauzan wrote:
&gt;
&gt; Its not about the difference in throughput in the two approaches I took.
&gt; Rather, the issue is that even 200 writes/sec is a bit on the lower side.
&gt; I could be doing something wrong with the configuration because people are
&gt; reporting throughputs of 2-3k ops/sec
&gt;
&gt; If anyone here could guide me in setting up a cluster which would give
&gt; such kind of throughput.
&gt;
&gt;
&gt; To get the kind of throughput I use multiple threads / workers. Have you
&gt; looked at basho\\_bench[1], it is a simple, reliable tool to benchmark Riak
&gt; clusters?
&gt;
&gt; Cheers
&gt;
&gt; Russell
&gt;
&gt; [1] Basho Bench - https://github.com/basho/basho\\_bench and
&gt; http://wiki.basho.com/Benchmarking.html
&gt;
&gt;
&gt; Thanks,
&gt; Yousuf
&gt;
&gt; On Wed, Jun 27, 2012 at 4:02 PM, Eric Anderson wrote:
&gt;
&gt;&gt; On Jun 27, 2012, at 5:13 AM, Yousuf Fauzan 
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt; Hi,
&gt;&gt;
&gt;&gt; I setup a 3 machine riak SM cluster. Each machine used 4GB Ram and riak
&gt;&gt; OpenSource SmartMachine Image.
&gt;&gt;
&gt;&gt; Afterwards I tried loading data by following two methods
&gt;&gt; 1. Bash script
&gt;&gt; #!/bin/bash
&gt;&gt; echo $(date)
&gt;&gt; for (( c=1; c&lt;=1000; c++ ))
&gt;&gt; do
&gt;&gt; curl -s -d 'this is a test' -H "Content-Type: text/plain"
&gt;&gt; http://127.0.0.1:8098/buckets/test/keys
&gt;&gt; done
&gt;&gt; echo $(date)
&gt;&gt;
&gt;&gt; 2. Python Riak Client
&gt;&gt; c=riak.RiakClient("10.112.2.185")
&gt;&gt; b=c.bucket("test")
&gt;&gt; for i in xrange(10000):o=b.new(str(i), str(i)).store()
&gt;&gt;
&gt;&gt; For case 1, throughput was 25 writes/sec
&gt;&gt; For case 2, throughput was 200 writes/sec
&gt;&gt;
&gt;&gt; Maybe I am making a fundamental mistake somewhere. I tried the above two
&gt;&gt; scripts on EC2 clusters too and still got the same performance.
&gt;&gt;
&gt;&gt; Please, someone help
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; The major difference between these two is the first is executing a
&gt;&gt; binary, which has to basically create everything (connection, payload, etc)
&gt;&gt; every time through the loop. The second does not - it creates the client
&gt;&gt; once, then iterates over it keeping the same client and presumably the same
&gt;&gt; connection as well. That makes a huge difference.
&gt;&gt;
&gt;&gt; I would not use curl to do performance testing. What you probably want
&gt;&gt; is something like your python script that will work on many
&gt;&gt; threads/processes at once (or fire them up many times).
&gt;&gt;
&gt;&gt;
&gt;&gt; Eric Anderson
&gt;&gt; Co-Founder
&gt;&gt; CopperEgg
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt;

