---
title: "Re: mr_queue gone wild"
description: ""
project: community
lastmod: 2011-07-12T18:56:45-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg03998"
mailinglist_parent_id: "msg03936"
author_name: "Sylvain Niles"
project_section: "mailinglistitem"
sent_date: 2011-07-12T18:56:45-07:00
---


Thanks again for all the pointers. After much digging I found the
issue. We have UTF8 validation on the most data we put into riak (our
events bucket), but weren't validating UTF8 on some objects that are
linked to by many other objects (group bucket). Consequently some
malformed UTF8 (that displays fine via console, it's only spidermonkey
that has a problem) causes spidermonkey to die a horrible death when
it pulls an object that has a bad link. Does anyone have some example
code for returning a list of keys that have a common link? In this
case we only had one-way links.
Example:

Object1 ---link---&gt; BadUTF8.Object
Object2 ---link---&gt; BadUTF8.Object

I'll have to do this via the erlang client as doing it in Javascript
crashes every time :(

Any ideas?

PS: Is there any plan to make bad UTF8 not a riak-killer? This is the
second time it's bitten us and all of the examples we've seen don't
cause ruby or erlang any problems, only spidermonkey.

Bad UTF8: &lt;&lt;"Afro-Belly Boogie® Fitness and Wellness-1800400"&gt;&gt;


-Sylvain


On Tue, Jul 5, 2011 at 12:37 PM, Bryan Fink  wrote:
&gt; On Thu, Jun 30, 2011 at 4:52 PM, Sylvain Niles  
&gt; wrote:
&gt;&gt; Is there a way to list the m/r jobs in the queue in case there's
&gt;&gt; something else going on? Is there a reason they never get removed?
&gt;
&gt; Hi, Sylvain.  As Aphyr noted, the mr\\_queue is a bitcask.  Because
&gt; bitcask is append-only storage, its size alone does not give a good
&gt; indication of the active dataset.  More specifically, unless you have
&gt; tweaked your bitcask parameters, you can expect the mr\\_queue directory
&gt; to grow to at least 2GB before purging unused data.  This is normal
&gt; and expected.
&gt;
&gt; A few things worth noting:
&gt;
&gt;  - The mr\\_queue is only used for Javascript MapReduce phases.  Erlang
&gt;   phases never touch it.  This is because there are a limited number
&gt;   of Javascript VMs available on a node, and all vnodes compete for
&gt;   them.  The mr\\_queue provides a place to offload the backlog of
&gt;   pending requeusts for Javascript interpreters, rather than keeping
&gt;   them in memory.
&gt;
&gt;  - To check the depth of the mr\\_queue, connect to any Riak node's
&gt;   console (bin/riak attach), and call
&gt;   riak\\_kv\\_map\\_master:queue\\_depth/0.  It should show you the active
&gt;   depth of the mr\\_queue on each node in the cluster:
&gt;
&gt;   $ bin/riak attach
&gt;   (dev1@127.0.0.1)&gt; riak\\_kv\\_map\\_master:queue\\_depth().
&gt;   [{'dev1@127.0.0.1',0},
&gt;    {'dev2@127.0.0.1',0},
&gt;    {'dev3@127.0.0.1',0},
&gt;    {'dev4@127.0.0.1',0}]
&gt;
&gt;   A result like the above means there are no pending map requests
&gt;   waiting.  A result like the following means there are 242 map
&gt;   requests waiting on the dev1 node, 128 on dev2, etc.:
&gt;
&gt;   [{'dev1@127.0.0.1',242},
&gt;    {'dev2@127.0.0.1',128},
&gt;    {'dev3@127.0.0.1',212},
&gt;    {'dev4@127.0.0.1',230}]
&gt;
&gt;   These numbers may be slightly confusing because a single logical
&gt;   map phase gets split into a separate map request for each vnode.
&gt;   So, you may have only one MapReduce request outstanding, but see
&gt;   numbers greater than 1 in this output.
&gt;
&gt; Hope this helps,
&gt;
&gt; Bryan Fink
&gt; Senior Software Developer,
&gt; Basho Technologies
&gt;

