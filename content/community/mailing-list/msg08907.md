---
title: "Re: Riak Search"
description: ""
project: community
lastmod: 2012-10-13T21:33:55-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08907"
mailinglist_parent_id: "msg08906"
author_name: "Pavel Kogan"
project_section: "mailinglistitem"
sent_date: 2012-10-13T21:33:55-07:00
---


Hi Ryan,

Thanks for your reply. I have few more questions:

1) Is search enabling has any impact on read latency/throughput?
2) Is search enabling has any impact on RAM usage?
3) In production we have no search enabled. What is the best way to
 enable search without stop production? I thought about something like:
 1) Enable search node after node.
 2) Execute some night script that runs on all keys and overwrite them
back
 with proper mime type.
4) If we see that search overhead is something we can't handle, is there
simple
 way to disable it without stop production?
5) In what case we would need repair? It is said - on replica loss, but if
I understand
 correct we have 3 replicas on different nodes don't we? If it happens
how difficult and
 long would it be for large cluster (about 100 nodes)?

Thanks,
 Pavel


On Sun, Oct 14, 2012 at 5:03 AM, Ryan Zezeski  wrote:

&gt; Pavel,
&gt;
&gt; On Sat, Oct 13, 2012 at 12:59 AM, Pavel Kogan wrote:
&gt;
&gt;
&gt;&gt; Those limitations leaves us a single option of Riak Search and I have a
&gt;&gt; few questions about it.
&gt;&gt;
&gt;
&gt; I'm working on a new solution, named Yokozuna, that integrates Riak and
&gt; Solr. It's not currently part of Riak but my goal is to make it so.
&gt;
&gt; https://github.com/rzezeski/yokozuna
&gt;
&gt;
&gt;&gt; 1) We saw, that after enabling search option and adding search
&gt;&gt; precommit hook, store speed (our tests were
&gt;&gt; done on single test node) became x10 slower. Is it normal?
&gt;&gt;
&gt;
&gt; Degradation of throughput after enabling Riak Search is normal. Riak
&gt; Search does a lot of work during index time. It has to analyze the data
&gt; and each indexed document has a good chance of causing writes to every node
&gt; in the cluster because of term-based partitioning.
&gt;
&gt;
&gt;&gt; 2) If we have dedicated node in cluster for search (which would not be
&gt;&gt; used for KV store/get operations) would
&gt;&gt; it do some impact of general cluster performance?
&gt;&gt;
&gt;
&gt; You cannot dedicate a node for Riak Search. Every node is required to
&gt; participate in KV. Every node must have Riak Search enabled for search to
&gt; work.
&gt;
&gt;
&gt;&gt; 3) For 1M keys in cluster search runs very fast. How it would scale for
&gt;&gt; 100M (or even much more keys)?
&gt;&gt; How it would scale with number of nodes in cluster?
&gt;&gt;
&gt;
&gt; This depends on the query. A single-term query with a reasonable result
&gt; set typically has a latency of a disk seek plus a few milliseconds. This
&gt; is the benefit of term-based partitioning, at query time. A boolean query
&gt; containing one large result set, even if the others are small, can bite you
&gt; because of sub-optimal logic in the intersection code. A range query can
&gt; produce latency variance because it requires connecting to a covering set
&gt; of vnodes.
&gt;
&gt; Scaling out will not lower the absolute latency for single-term queries,
&gt; since it queries one node, but it can potentially reduce concurrent query
&gt; contention thus reducing latency variance and improving throughput.
&gt;
&gt; Scaling out may hurt range queries as it will require more nodes to
&gt; participate in coverage. TCP incast could become an issue with enough load.
&gt;
&gt; -Z
&gt;
