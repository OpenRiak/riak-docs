---
title: "Re: Storage of time-series data"
description: ""
project: community
lastmod: 2010-05-18T20:01:12-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg00415"
mailinglist_parent_id: "msg00414"
author_name: "Sean Cribbs"
project_section: "mailinglistitem"
sent_date: 2010-05-18T20:01:12-07:00
---


Buckets are essentially free if you are not changing their properties from the 
defaults (which you can set globally in app.config). Keep in mind the options 
I presented are not the only ones, just points of departure for your own schema 
design.

Sean Cribbs 
Developer Advocate
Basho Technologies, Inc.
http://basho.com/

On May 18, 2010, at 8:03 PM, Joel Pitt wrote:

&gt; Thanks Sean. Looks like 3 might be the best plan.
&gt; 
&gt; And, pre/post-commit hooks... cool! I didn't see those - that's
&gt; something I've been looking for (since I'd prefer to keep that kind of
&gt; stuff happening on the data nodes rather than in the client/app
&gt; itself).
&gt; 
&gt; One further question, is there any limitation to how the number of
&gt; buckets can scale? If you're recommending using them to box data by
&gt; minute I'm guessing that # buckets can increase without worry, but is
&gt; this still the case if say I started binning into buckets by second?
&gt; 
&gt; J
&gt; 
&gt; On Wed, May 19, 2010 at 1:53 AM, Sean Cribbs  wrote:
&gt;&gt; Joel,
&gt;&gt; 
&gt;&gt; Riak's only query mechanism aside from simple key retrieval is map-reduce. 
&gt;&gt; However, there are a number of strategies you could take, depending on what 
&gt;&gt; you want to query. I don't know the requirements of your application, but 
&gt;&gt; here are some options:
&gt;&gt; 
&gt;&gt; 1) Store the data either keyed on the timestamp, or as separate objects 
&gt;&gt; linked from a timestamp object.
&gt;&gt; 2) Create buckets for each time-window you want to track. For example, if I 
&gt;&gt; wanted to box data by minute, I'd make bucket names that look like: 
&gt;&gt; 2010-05-18T09.46. Then if I want all the data from that minute, I'd run a 
&gt;&gt; map-reduce query with that bucket name as the inputs.
&gt;&gt; 3) Create your own secondary indexes with a post-commit hook or code in your 
&gt;&gt; application for year, month, day, etc. The secondary index would be, like 
&gt;&gt; #1, keys that only contain links to the actual data.
&gt;&gt; 
&gt;&gt; With any of these options (which are by no means exhaustive), your 
&gt;&gt; map-reduce query will need to sort the data in a reduce phase if you require 
&gt;&gt; chronological ordering. Also, if you're building your own indexes in 
&gt;&gt; separate buckets, depending on the write throughput of your application, you 
&gt;&gt; might want to build in some sort of conflict resolution and turn on 
&gt;&gt; allow\\_mult so that concurrent updates are not lost.
&gt;&gt; 
&gt;&gt; Sean Cribbs 
&gt;&gt; Developer Advocate
&gt;&gt; Basho Technologies, Inc.
&gt;&gt; http://basho.com/
&gt;&gt; 
&gt;&gt; On May 17, 2010, at 8:31 PM, Joel Pitt wrote:
&gt;&gt; 
&gt;&gt;&gt; Hi,
&gt;&gt;&gt; 
&gt;&gt;&gt; I'm trying to work out the best way of storing temporal data in Riak.
&gt;&gt;&gt; 
&gt;&gt;&gt; I've been investigating several NoSQL solutions and originally started
&gt;&gt;&gt; out using CouchDB, however I want to move to a db that scales more
&gt;&gt;&gt; gradually (CouchDB scales, but you really have to set up the
&gt;&gt;&gt; architecture before-hand and I'd prefer to be able to build a cluster
&gt;&gt;&gt; a node at a time)
&gt;&gt;&gt; 
&gt;&gt;&gt; In CouchDB, I use a multi-level key in a map-reduce view to create an
&gt;&gt;&gt; index by time. Each reduce level corresponds to year, month, day,
&gt;&gt;&gt; time... so I can easily get aggregate data for say a month.
&gt;&gt;&gt; 
&gt;&gt;&gt; In addition to Riak I'm investigating Cassandra. In Cassandra the way
&gt;&gt;&gt; to store time series is by making the column keys timestamps and
&gt;&gt;&gt; sorting columns by TimeUUID. This allows one to do slices across a
&gt;&gt;&gt; range of time. This isn't exactly the same as what I have in CouchDB,
&gt;&gt;&gt; but by consensus it seems to be the way to store a time index.
&gt;&gt;&gt; 
&gt;&gt;&gt; Any suggestions for working with or creating time indexes in Riak?
&gt;&gt;&gt; 
&gt;&gt;&gt; Ideally I'd be able to query documents with a time range to either get
&gt;&gt;&gt; the documents, or to calculate aggregate statistics using a map-reduce
&gt;&gt;&gt; task.
&gt;&gt;&gt; 
&gt;&gt;&gt; Any information appreciated :-)
&gt;&gt;&gt; 
&gt;&gt;&gt; Joel Pitt, PhD | http://ferrouswheel.me | +64 21 101 7308
&gt;&gt;&gt; NetEmpathy Co-founder | http://netempathy.com
&gt;&gt;&gt; OpenCog Developer | http://opencog.org
&gt;&gt;&gt; Board member, Humanity+ | http://humanityplus.org
&gt;&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
