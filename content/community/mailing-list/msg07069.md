---
title: "Re: riak_core question when a node dies"
description: ""
project: community
lastmod: 2012-03-28T10:09:27-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07069"
mailinglist_parent_id: "msg07068"
author_name: "Jon Brisbin"
project_section: "mailinglistitem"
sent_date: 2012-03-28T10:09:27-07:00
---


I'm using get\\_primary\\_apl to get my preflist but the problem is how to handle a 
failure of trying to dispatch to a node that is just now going down and hasn't 
had time to notify the caller yet. I don't want to loose the web request 
currently in progress. Maybe I need to get a list of indexes to possibly 
dispatch to and iterate over them, stopping at the first one that doesn't blow 
up.

Sent from my iPhone

On Mar 28, 2012, at 12:00 PM, Sean Cribbs  wrote:

&gt; Jon,
&gt; 
&gt; Generally I would use the riak\\_core\\_apl module to calculate the preflist for 
&gt; your request. It takes into account node visibility and service availability. 
&gt; Use riak\\_core\\_node\\_watcher:service\\_up to announce that your app is available 
&gt; after registering with riak\\_core.
&gt; 
&gt; When doing some "split brain" testing/simulation for gen\\_leader we would do 
&gt; something like the following on a node we wanted to partition:
&gt; 
&gt; 1&gt; erlang:set\\_cookie(node(), riak2).
&gt; 2&gt; erlang:disconnect\\_node('dev3@127.0.0.1'), 
&gt; erlang:disconnect\\_node('dev4@127.0.0.1').
&gt; Basically, set the cookie so it can't connect to the other nodes, then 
&gt; manually disconnect. That might help you simulate node-outage.
&gt; 
&gt; On Wed, Mar 28, 2012 at 12:49 PM, Jon Brisbin  wrote:
&gt; I'm testing the example code that dispatches a web request from misultin into 
&gt; a riak\\_core ring of vnodes. It works fantastic when all nodes are up! :)
&gt; 
&gt; Doing "ab -k -c 200 -n 10000 http://localhost:3000/" yields a none-to-shabby 
&gt; performance (dispatching at random into all available vnodes on two separate 
&gt; riak\\_core processes):
&gt; 
&gt; Concurrency Level: 200
&gt; Time taken for tests: 1.446 seconds
&gt; Complete requests: 10000
&gt; Failed requests: 0
&gt; Write errors: 0
&gt; Keep-Alive requests: 10000
&gt; Total transferred: 1600480 bytes
&gt; HTML transferred: 120036 bytes
&gt; Requests per second: 6914.04 [#/sec] (mean)
&gt; Time per request: 28.927 [ms] (mean)
&gt; Time per request: 0.145 [ms] (mean, across all concurrent requests)
&gt; Transfer rate: 1080.64 [Kbytes/sec] received
&gt; 
&gt; Connection Times (ms)
&gt; min mean[+/-sd] median max
&gt; Connect: 0 0 1.0 0 12
&gt; Processing: 4 28 9.8 27 78
&gt; Waiting: 4 28 9.8 27 78
&gt; Total: 4 28 10.1 27 83
&gt; 
&gt; Percentage of the requests served within a certain time (ms)
&gt; 50% 27
&gt; 66% 31
&gt; 75% 34
&gt; 80% 36
&gt; 90% 41
&gt; 95% 47
&gt; 98% 53
&gt; 99% 58
&gt; 100% 83 (longest request)
&gt; 
&gt; If I were really zealous, I'd set up haproxy to load balance between these 
&gt; two misultin servers and get double failover.
&gt; 
&gt; I'm trying to catch the situation of going into the console of one of my 
&gt; nodes and hitting "CTL-C" to kill that process. I'm not sure what the best 
&gt; way is to handle this. Check before I dispatch to make sure the node is up? 
&gt; Keep a watch of some other kind that, when it sees that node go down and if 
&gt; it's trying to dispatch to that node, it tries to find another one?
&gt; 
&gt; Essentially, I'm trying to prevent misultin from completely bailing on the 
&gt; request because the sync\\_spawn\\_command blows up trying to do a 
&gt; gen\\_server:call to a non-existent node. I'd like to retry to dispatch to a 
&gt; different node if one happens to have crashed while I'm serving requests (I 
&gt; don't want to loose a request, essentially).
&gt; 
&gt; Thanks!
&gt; 
&gt; Jon Brisbin
&gt; http://about.me/jonbrisbin
&gt; 
&gt; 
&gt; 
 
&gt; 
&gt; 
&gt; 
&gt; -- 
&gt; Sean Cribbs 
&gt; Software Engineer
&gt; Basho Technologies, Inc.
&gt; http://basho.com/
&gt; 
