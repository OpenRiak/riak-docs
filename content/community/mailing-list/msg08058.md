---
title: "Re: How to store data"
description: ""
project: community
lastmod: 2012-07-25T07:35:34-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg08058"
mailinglist_parent_id: "msg08056"
author_name: "Andres Jaan Tack"
project_section: "mailinglistitem"
sent_date: 2012-07-25T07:35:34-07:00
---


Is that a realistic strategy for low latency requirements? Imagine this
were some web service, and people generate this query at some reasonable
frequency.

(not that I know what Andrew is looking for, exactly)

2012/7/25 Yousuf Fauzan 

&gt; Since 500 is not that big a number, I think you can run that many M/Rs
&gt; with each emitting only records having "time" greater than specified. Input
&gt; would be {index, &lt;&lt;"bucket"&gt;&gt;, &lt;&lt;"from\\_bin"&gt;&gt;, &lt;&lt;"from\\_field\\_value"&gt;&gt;}
&gt;
&gt; If you decide to split the data into separate buckets based on "from"
&gt; field, input would be {index, &lt;&lt;"from\\_field\\_value"&gt;&gt;, &lt;&lt;"time\\_bin"&gt;&gt;,
&gt; &lt;&lt;"time\\_low"&gt;&gt;, &lt;&lt;"time\\_high"&gt;&gt;}
&gt;
&gt;
&gt; --
&gt; Yousuf
&gt;
&gt; On Wed, Jul 25, 2012 at 6:35 PM, Andrew Kondratovich &lt;
&gt; andrew.kondratov...@gmail.com&gt; wrote:
&gt;
&gt;&gt; Hello, Yousuf.
&gt;&gt;
&gt;&gt; Thanks for your reply.
&gt;&gt;
&gt;&gt; We have several millions of items. It's about 10 000 of unique 'from'
&gt;&gt; fields (about 1000 items for each). Usually, we need to get items for about
&gt;&gt; 500 'from' identifiers with 'time' limit (about 5% of items is
&gt;&gt; corresponding).
&gt;&gt;
&gt;&gt; On Wed, Jul 25, 2012 at 1:02 PM, Yousuf Fauzan wrote:
&gt;&gt;
&gt;&gt;&gt; Hi Andrew,
&gt;&gt;&gt;
&gt;&gt;&gt; First of all, the correct answer to your question is the proverbial "it
&gt;&gt;&gt; depends". Having said that, here is what I could do in your case
&gt;&gt;&gt;
&gt;&gt;&gt; 1. If there are enough data points with the same "from" field, I will
&gt;&gt;&gt; make it a bucket and then index on time.
&gt;&gt;&gt; 2. If the above is not true, I will index on "from" and "time" field.
&gt;&gt;&gt; a. If number of records where "time" is greater than the one your
&gt;&gt;&gt; require is small, I will run a map/reduce with the initial input as those
&gt;&gt;&gt; records.
&gt;&gt;&gt; b. If number of records having a particular "from" is small, I will
&gt;&gt;&gt; do the above with the initial input as records having that "from" field.
&gt;&gt;&gt; This could be a problem as Riak only supports range and exact queries so if
&gt;&gt;&gt; you want to query multiple identifiers, you will have to run multiple
&gt;&gt;&gt; queries.
&gt;&gt;&gt; In both the above cases, I will use secondary indexes to get the
&gt;&gt;&gt; initial records.
&gt;&gt;&gt; Note that we are using M/R as Riak does not support querying by
&gt;&gt;&gt; multiple indexes.
&gt;&gt;&gt;
&gt;&gt;&gt; What I would also suggest is to partition your data into different
&gt;&gt;&gt; buckets. You will need to understand the queries that you will be
&gt;&gt;&gt; supporting and partition it accordingly.
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; Yousuf
&gt;&gt;&gt;
&gt;&gt;&gt; On Wed, Jul 25, 2012 at 2:50 PM, Andrew Kondratovich &lt;
&gt;&gt;&gt; andrew.kondratov...@gmail.com&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Good afternoon.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I am considering several storage solutions for my project, and now I
&gt;&gt;&gt;&gt; look at Riak.
&gt;&gt;&gt;&gt; We work with the following pattern of data:
&gt;&gt;&gt;&gt; {
&gt;&gt;&gt;&gt; time: unixtime
&gt;&gt;&gt;&gt; from: int
&gt;&gt;&gt;&gt; data: binary
&gt;&gt;&gt;&gt; ...
&gt;&gt;&gt;&gt; }
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; The amount of data is about several millions items for now, but it's
&gt;&gt;&gt;&gt; growing. It is necessary to handle the folloring requests: for a list of
&gt;&gt;&gt;&gt; identifiers (about 500 items) return all records where id = from and time
&gt;&gt;&gt;&gt; greater than a certain value.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; How to store such data and to effectively handle such requests with the
&gt;&gt;&gt;&gt; Riak?
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Thanks.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; --
&gt;&gt;&gt;&gt; Andrew Kondratovich
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt;&gt;&gt; riak-users mailing list
&gt;&gt;&gt;&gt; riak-users@lists.basho.com
&gt;&gt;&gt;&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; Andrew Kondratovich
&gt;&gt;
&gt;&gt;
&gt;
&gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt; riak-users mailing list
&gt; riak-users@lists.basho.com
&gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;
&gt;
\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
riak-users mailing list
riak-users@lists.basho.com
http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com

