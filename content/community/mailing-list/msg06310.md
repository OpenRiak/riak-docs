---
title: "Re: Pending transfers when joining 1.0.3 node to 1.0.0 cluster"
description: ""
project: community
lastmod: 2012-01-18T13:46:35-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg06310"
mailinglist_parent_id: "msg06309"
author_name: "Aphyr"
project_section: "mailinglistitem"
sent_date: 2012-01-18T13:46:35-08:00
---


https://github.com/basho/riak/blob/riak-1.0.2/RELEASE-NOTES.org

If partition transfer is blocked awaiting [] (as opposed to [kv\\_vnode] or 
whatever), There's a snippet in there that might be helpful.

--Kyle

On Jan 18, 2012, at 1:43 PM, Fredrik Lindström wrote:

&gt; After some digging I found a suggestion from Joseph Blomstedt in an earlier 
&gt; mail thread 
&gt; http://lists.basho.com/pipermail/riak-users\\_lists.basho.com/2012-January/007116.html
&gt; 
&gt; in the riak console:
&gt; riak\\_core\\_ring\\_manager:force\\_update().
&gt; riak\\_core\\_vnode\\_manager:force\\_handoffs().
&gt; 
&gt; The symptoms would appear to be the same although the cluster referenced in 
&gt; the mail thread does not appear to have search enabled,
&gt; as far as I can tell from the log snippets. The mail thread doesn't really 
&gt; specify which node to run the commands on so I tried both the new node and 
&gt; the current claimant of the cluster.
&gt; 
&gt; Sadly the suggested steps did not produce any kind of ownership handoff.
&gt; 
&gt; Any helpful ideas would be much appreciated :)
&gt; 
&gt; /F
&gt; 
&gt; 
&gt; From: riak-users-boun...@lists.basho.com [riak-users-boun...@lists.basho.com] 
&gt; on behalf of Fredrik Lindström [fredrik.lindst...@qbranch.se]
&gt; Sent: Wednesday, January 18, 2012 4:00 PM
&gt; To: riak-users@lists.basho.com
&gt; Subject: Pending transfers when joining 1.0.3 node to 1.0.0 cluster
&gt; 
&gt; Hi everyone,
&gt; when we try to join a 1.0.3 node to an existing 1.0.0 (3 node) cluster the 
&gt; ownership transfer doesn't appear to take place. I'm guessing that we're 
&gt; making some stupid little mistake but we can't figure it out at the moment. 
&gt; Anyone run into something similar?
&gt; 
&gt; Riak Search is enabled on the original nodes in the cluster as well as the 
&gt; new node.
&gt; Ring size is set to 128
&gt; 
&gt; The various logfiles do not appear to contain any errors or warnings
&gt; 
&gt; Output from riak-admin member\\_status
&gt; ================================= Membership 
&gt; ==================================
&gt; Status Ring Pending Node
&gt; -------------------------------------------------------------------------------
&gt; valid 33.6% 25.0% 'qbkp...@qbkpx01.ad.qnet.local'
&gt; valid 33.6% 25.0% 'qbkp...@qbkpx02.ad.qnet.local'
&gt; valid 32.8% 25.0% 'qbkp...@qbkpx03.ad.qnet.local'
&gt; valid 0.0% 25.0% 't...@qbkpxadmin01.ad.qnet.local'
&gt; -------------------------------------------------------------------------------
&gt; 
&gt; Output from riak-admin ring\\_status
&gt; See attached file
&gt; 
&gt; Output from riak-admin transfers
&gt; 't...@qbkpxadmin01.ad.qnet.local' waiting to handoff 10 partitions
&gt; 'qbkp...@qbkpx03.ad.qnet.local' waiting to handoff 62 partitions
&gt; 'qbkp...@qbkpx01.ad.qnet.local' waiting to handoff 63 partitions
&gt; 
&gt; 
&gt; /F
&gt; 
&gt; 

