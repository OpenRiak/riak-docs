---
title: "Re: RiakSearch Benchmark Test Invitation."
description: ""
project: community
lastmod: 2010-10-30T02:43:32-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg01409"
mailinglist_parent_id: "msg01393"
author_name: "Prometheus WillSurvive"
project_section: "mailinglistitem"
sent_date: 2010-10-30T02:43:32-07:00
---


Hi,

I have first benchmark results :

Test Data : http://rapidshare.com/files/427591191/wikipedia350.tar.gz 
350K doc from wikipedia. Ready to index by riaksearch (search-cmd solr 
index ..xml)
Cluster : 1x2core , 1x2core , 1x6 core each has 8 gig ram. Gig Network
Nginx reverse proxy in a sperate machine.


Indexing time around : 10 min for 20K doc
 
Avarage qps : 3700 ms . and min qps is around 2200 ms 

Is there anyone that make this test ? I expected better results from 
riaksearch but may be I make some mistakes in the test i dont know.

In our projects it is important to have qps below the 900 ms . 

Waiting your test results guy.. come on.

On Oct 28, 2010, at 7:02 PM, Rusty Klophaus wrote:

&gt; Hi folks,
&gt; 
&gt; Very happy to see the excitement around Riak Search. Just a quick note on 
&gt; benchmarking approach. For best results, make sure to spread the indexing 
&gt; load across multiple machines in the cluster, rather than firing all requests 
&gt; on a single node. Otherwise, you will become CPU bound on that node. Load 
&gt; balancing in a round-robin fashion is fine.
&gt; 
&gt; To make this easier, you may want to bypass the command line interface and 
&gt; post to Solr directly. In curl, it looks like this:
&gt; 
&gt; curl -X POST -H text/xml --data-binary @datafile.xml 
&gt; http://hostname:8098/solr/myindex/update
&gt; 
&gt; (Change the name of the datafile, hostname, and index appropriately.)
&gt; 
&gt; Best,
&gt; Rusty
&gt; 
&gt; On Thu, Oct 28, 2010 at 6:46 AM, Prometheus WillSurvive 
&gt;  wrote:
&gt; Hi Guys,
&gt; 
&gt; I just put the wikipedia riaksearch solr index ready XMLs to the: 
&gt; 
&gt; http://rapidshare.com/files/427591191/wikipedia350.tar.gz 
&gt; 
&gt; you can download from there. 
&gt; 
&gt; there is also a small keyword list for benchmark test.
&gt; 
&gt; We can put bigger documents later ie 3 million wikipedia doc. 
&gt; 
&gt; Let us know your test results. I used Apache Jmeter to send 10 clients 
&gt; queering to the clusters (3 machine)
&gt; 
&gt; Best Regards
&gt; 
&gt; PrometheusWillSurvive
&gt; 
&gt; On Oct 28, 2010, at 12:28 PM, Neville Burnell wrote:
&gt; 
&gt;&gt; Put it on S3
&gt;&gt; 
&gt;&gt; On 28 October 2010 20:20, francisco treacy  
&gt;&gt; wrote:
&gt;&gt; Very good idea!
&gt;&gt; 
&gt;&gt; 2010/10/28 Prometheus WillSurvive :
&gt;&gt; &gt; Hi All,
&gt;&gt; &gt; We have prepare wikipedia database output ready to submit RiakSearch. It is
&gt;&gt; &gt; XML and described format for solr submit. Each file has 20.000 Document and
&gt;&gt; &gt; totaly 15 xml files. Each file around 44 MB.
&gt;&gt; &gt; You can submit all XML 's = bin/search-cmd solr wikipedia
&gt;&gt; &gt; /wikipedia/content-xml-out/wikipedia\\_1.xml
&gt;&gt; &gt; So you only need to submit this files to the riaksearch and than make a
&gt;&gt; &gt; benchmark test/tune and share your experience.
&gt;&gt; &gt; I would like to ask Riak Admin guys is there any place that I can share
&gt;&gt; &gt; these files for public access to start collaborative tests ?
&gt;&gt; &gt; Second phase I can put 3 million wikipedia XML sets to ready to submit
&gt;&gt; &gt; riaksearch. So All we have some common benchmark and tuning parameters.
&gt;&gt; &gt; I hope this will help the riaksearch community to better understanding its
&gt;&gt; &gt; capability.
&gt;&gt; &gt; Best Regards
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; &gt; \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_
&gt;&gt; &gt; riak-users mailing list
&gt;&gt; &gt; riak-users@lists.basho.com
&gt;&gt; &gt; http://lists.basho.com/mailman/listinfo/riak-users\\_lists.basho.com
&gt;&gt; &gt;
&gt;&gt; &gt;
&gt;&gt; 
&gt;&gt; 
&gt; 
&gt; 
 
&gt; 

