---
title: "Re: advice on debugging OOM?"
description: ""
project: community
lastmod: 2012-04-23T11:05:53-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07291"
mailinglist_parent_id: "msg07290"
author_name: "Swinney, Austin"
project_section: "mailinglistitem"
sent_date: 2012-04-23T11:05:53-07:00
---


Ouchâ€¦

This presentation has some good info about OOM, swapiness, (and other stuff)
http://www.scribd.com/doc/53197944/Linux-and-H-W-optimizations-for-MySQL

But as it points out, OOM-proofing your process would probably lead to system 
death anyway. And if you set a memory usage limit for the process you are 
probably in the same place with a dead node.

On Apr 23, 2012, at 1:49 PM, Michael Radford wrote:

Yesterday three of four riak nodes in my cluster died due to running
out of memory. Unfortunately, the beam processes were killed by the
kernel oom-killer, so they didn't have a chance to write an
erl\\_crash.dump.

I'm wondering if anyone has any advice on figuring out what the
culprit might be, if this happens again, or any ways that queries
could easily cause sudden increases in memory use.

My only "nonstandard" usages (apart from normal read/write/delete) are:
1. a list-keys operation, interspersed with reads, for creating a backup
2. search queries feeding into riak\\_kv\\_mapreduce:reduce\\_identity, to
get lists of keys matching a query
3. multiple-key lookups, implemented by feeding lists of keys into
this map function:

map\\_key\\_data\\_object\\_value({error, notfound}, KeyData, \\_Arg) -&gt;
 [{KeyData, not\\_found}];
map\\_key\\_data\\_object\\_value(RiakObject, KeyData, \\_Arg) -&gt;
 [{KeyData, riak\\_object:get\\_value(RiakObject)}].

An additional wrinkle is that I'm doing all this via erlang rpc to
functions that invoke the native erlang client, to work around
performance issues with map/reduce via the protobufs api. But the code
for that is very simple, no loops or anything like that which would
even have the potential for unbounded memory use.

Is there any additional logging I could turn on, or any other ideas
besides periodically collecting memory usage stats and hoping to catch
something before it crashes the node?

Also, I am very tempted to enable heart in /etc/riak/vm.args, since
(a) it's clearly possible for this to happen again, and (b) the
failure seemed to cascade from one node to the next. As of last
August, the advice from this list was not to enable heart, because of
the potential to get stuck in a tight restart loop. But I don't see
how that is necessarily worse than not attempting to restart at all.

Thanks,
Mike

