---
title: "Re: slow mapred_search key lookups for single terms"
description: ""
project: community
lastmod: 2012-04-05T12:51:56-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07153"
mailinglist_parent_id: "msg07133"
author_name: "Bryan Fink"
project_section: "mailinglistitem"
sent_date: 2012-04-05T12:51:56-07:00
---


On Wed, Apr 4, 2012 at 11:28 AM, Michael Radford  wrote:
&gt; Aha, I just noticed that the native erlang client is still using
&gt; luke\\_flow to implement its map-reduce, rather than riak\\_pipe.  On some
&gt; level, this must be the reason for the differing behavior...either a
&gt; bug in riak\\_pipe, or a bug in the usage of riak\\_pipe somewhere in the
&gt; chain?

Maybe not "bug", but "naïveté", I think, is a pretty good bet.

https://github.com/basho/riak\\_kv/blob/master/src/riak\\_kv\\_mrc\\_pipe.erl#L551-L593

This is a behavior that we changed for list\\_keys just before 1.0 and
for 2i in 1.1. The implementation is naïve: have a query send all
results to this process, which then enqueues them one at a time in the
pipe.

Switching to a model where this queueing is done in parallel (as in
riak\\_kv\\_pipe\\_listkeys and …\\_index) reduces time dramatically, because
there's no need to hold up enqueuing an input on node X while an input
is being enqueued on node Y. The system is fluid enough that such
serialization often means that each stage of the pipeline is
processing ~1 input at a time, in aggregate, instead of ~($Partitions)
inputs at a time.

This \\*might\\* be the wrong intuition for Search, since there is
funneling happening to process the query anyway, but it's likely a
good place to start.

-Bryan

