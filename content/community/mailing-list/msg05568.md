---
title: "Re: Is Riak suitable for a short-term scatter/gather sort of data	store?"
description: ""
project: community
lastmod: 2011-11-12T17:41:36-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg05568"
mailinglist_parent_id: "msg05567"
author_name: "Gordon Tillman"
project_section: "mailinglistitem"
sent_date: 2011-11-12T17:41:36-08:00
---


Keith you are pretty close!

Everything could go into one bucket, not really an issue. About this:

&gt; 
&gt; This I don't know how to do based on my reading of the docs. Something like:
&gt; 
&gt; get /buckets/mydata/index/device\\_bin/FF345678912
&gt; 
&gt; which would return a list of .... what, device-timestamp compound keys? And 
&gt; then would I feed a potentially huge list of "bucket/key" pairs into a 
&gt; gigantic javascript query for the map-reduce phase?


You wouldn't do a get on it, you would initiate a map-reduce operation by 
issuing a POST to the /mapred endpoint. You can see an example here: 
http://wiki.basho.com/Secondary-Indexes.html Look for the section titled 
"Exact Match Query".

You just need a simple map-phase function that emits only the objects whose 
timestamp is in the desired range. It's a lot faster than you think because 
the map function executes on all nodes in the cluster simultaneously.

And for best performance you would use a map function written in Erlang rather 
than JavaScript because there is some extra overhead using JavaScript that you 
don't have when using an Erlang function.

I do believe that you can use Riak very well to handle what your application 
requires.

Give me a shout off-list if you you like and I'll put together a working 
example to get you started.

--gordon


On Nov 12, 2011, at 17:43 , Keith Irwin wrote:

&gt; On Nov 12, 2011, at 2:32 PM, Gordon Tillman wrote:
&gt; 
&gt;&gt; Keith I have an idea that might work for you. This is a bit vague but I 
&gt;&gt; would be glad to put together a more concrete example if you like.
&gt; 
&gt; Okay, thanks! Not sure I understand everything, though.
&gt; 
&gt;&gt; Use secondary indexes to tag each entry with the device id.
&gt; 
&gt; I get the tagging part, but I'm not sure what the bucket and key being tagged 
&gt; would look like. Are you taking a single bucket for all data?
&gt; 
&gt; put /buckets/mydata/keys/-
&gt; x-riak-index-device\\_bin: FF06541287AB
&gt; 
&gt; Something like that?
&gt; 
&gt;&gt; You can then find all of the entries for a given device by using the the 
&gt;&gt; secondary index to feed into a simple map phase operation that returns only 
&gt;&gt; the entries that you want; i.e., those that are in a given time range.
&gt; 
&gt; This I don't know how to do based on my reading of the docs. Something like:
&gt; 
&gt; get /buckets/mydata/index/device\\_bin/FF345678912
&gt; 
&gt; which would return a list of .... what, device-timestamp compound keys? And 
&gt; then would I feed a potentially huge list of "bucket/key" pairs into a 
&gt; gigantic javascript query for the map-reduce phase?
&gt; 
&gt;&gt; In addition, to easily find all of the registered device ids easily you can 
&gt;&gt; create one entry for each device. The key can be most anything (even the 
&gt;&gt; device id if you encode it properly -- hash it), and you could tag each of 
&gt;&gt; those entries with a secondary index whose field is something like "type" or 
&gt;&gt; whatever and whose value is "deviceid". The value for each entry could be 
&gt;&gt; just a simple text/plain value whose contents is just the device id of the 
&gt;&gt; registered device.
&gt; 
&gt; Okay, I think I get this:
&gt; 
&gt; When a device comes in, just do something like:
&gt; 
&gt; put /buckets/devices/
&gt; x-riak-index-type\\_bin: "device"
&gt; 
&gt; When I want a list of device IDs, I can:
&gt; 
&gt; get /buckets/devices/index/type\\_bin/device
&gt; 
&gt; and get them all, right? This is more efficient than the various list 
&gt; functions? That makes sense to me.
&gt; 
&gt; I guess I'll have to try a few examples and see what happens. What you're 
&gt; telling me is that what I want to do is possible, or is at least not pressing 
&gt; against Riak's particular trade-offs too much. Or at least I hope that's what 
&gt; you're telling me. ;)
&gt; 
&gt; Keith
&gt; 
&gt; 
&gt;&gt; 
&gt;&gt; --gordon
&gt;&gt; 
&gt;&gt; On Nov 12, 2011, at 16:19 , Keith Irwin wrote:
&gt;&gt; 
&gt;&gt;&gt; Folks--
&gt;&gt;&gt; 
&gt;&gt;&gt; (Apologies up front for the length of this.)
&gt;&gt;&gt; 
&gt;&gt;&gt; I'm wondering if you can let me know if Riak is a good fit for a simple 
&gt;&gt;&gt; not-quite-key-value scenario described below. MongoDB or (say) Postgresql 
&gt;&gt;&gt; seem a more natural fit conceptually, but I really, really like Riak's 
&gt;&gt;&gt; distribution strategy.
&gt;&gt;&gt; 
&gt;&gt;&gt; ## context
&gt;&gt;&gt; 
&gt;&gt;&gt; The basic overview is this: 
&gt;&gt;&gt; 
&gt;&gt;&gt; 50K devices push data once a second to web services which need to store 
&gt;&gt;&gt; that data in short-term storage (Riak). Once an hour, a sweeper needs to 
&gt;&gt;&gt; take an hour's worth of data per device (if there is any) and ship it off 
&gt;&gt;&gt; to long term storage, then delete it from short-term storage. Ideally, 
&gt;&gt;&gt; there'd only ever be slightly more than 1 hour's worth of data still in 
&gt;&gt;&gt; short-term storage for any given device. The goal is to write down the data 
&gt;&gt;&gt; as simply and safely as possible, with little or no processing on that data.
&gt;&gt;&gt; 
&gt;&gt;&gt; Each second's worth of data is:
&gt;&gt;&gt; 
&gt;&gt;&gt; \\* A device identifier
&gt;&gt;&gt; \\* A timestamp (epoch seconds, integer) for the slice of time the data 
&gt;&gt;&gt; represents
&gt;&gt;&gt; \\* An opaque blob of binary data (2 to 4k)
&gt;&gt;&gt; 
&gt;&gt;&gt; Once an hour, I'd like to do something like:
&gt;&gt;&gt; 
&gt;&gt;&gt; \\* For each device:
&gt;&gt;&gt; \\* Find (and concat) all the data between time1 and time2 (an hour).
&gt;&gt;&gt; \\* Move that data to long-term storage (not Riak) as a single blob.
&gt;&gt;&gt; \\* Delete that data from Riak.
&gt;&gt;&gt; 
&gt;&gt;&gt; For an SQL db, this is a really simple problem, conceptually. You can have 
&gt;&gt;&gt; a table with three columns: device-id, timestamp, blob. You can index the 
&gt;&gt;&gt; first two columns and roll up the data easily enough and then delete it via 
&gt;&gt;&gt; single SQL statements (or buffer as needed). The harder part is 
&gt;&gt;&gt; partitioning, replication, etc, etc.
&gt;&gt;&gt; 
&gt;&gt;&gt; For MongoDB, it's also fairly simple. Just use a document with the same 
&gt;&gt;&gt; device-id, timestamp and binary-array data (as JSON), make sure indexes are 
&gt;&gt;&gt; declared, and query/delete just as in SQL. MongoDB provides sharding, 
&gt;&gt;&gt; replica-sets, recovery, etc. Set up, while less complicated than an RDBMS, 
&gt;&gt;&gt; still seems way more complicated than necessary.
&gt;&gt;&gt; 
&gt;&gt;&gt; These solutions also provide sorting (which, while nice, isn't a 
&gt;&gt;&gt; requirement for my case).
&gt;&gt;&gt; 
&gt;&gt;&gt; ## question
&gt;&gt;&gt; 
&gt;&gt;&gt; I've been reading the Riak docs, and I'm just not sure if this simple 
&gt;&gt;&gt; "queryable" case can really fit all that well. I'm not so concerned about 
&gt;&gt;&gt; having to send 50K "deletes" to delete data. I'm more concerned about being 
&gt;&gt;&gt; able to find it. Given what I've written above, I may be blocked 
&gt;&gt;&gt; conceptually by the above index/query mentality such that I'm just not 
&gt;&gt;&gt; seeing the Riak way of doing things.
&gt;&gt;&gt; 
&gt;&gt;&gt; Anyway, I can "tag" (via the secondary index feature) each blob of data 
&gt;&gt;&gt; with the device-id and the timestamp. I could then do a range query similar 
&gt;&gt;&gt; to:
&gt;&gt;&gt; 
&gt;&gt;&gt; GET /buckets/devices/index/timestamp/start/end
&gt;&gt;&gt; 
&gt;&gt;&gt; However, this doesn't allow me to group based on device-id. I could create 
&gt;&gt;&gt; a separate bucket for every device, such that I could do:
&gt;&gt;&gt; 
&gt;&gt;&gt; GET /buckets/device-id/index/timestamp/start/end
&gt;&gt;&gt; 
&gt;&gt;&gt; but if I do this, how can I get a list of the device-ids I need so that I 
&gt;&gt;&gt; can create that specific URL? The docs say listing buckets and keys is 
&gt;&gt;&gt; problematic.
&gt;&gt;&gt; 
&gt;&gt;&gt; Might be that Riak just isn't a good case for this sort of thing, 
&gt;&gt;&gt; especially given I want to use it for short-term transient data, and that's 
&gt;&gt;&gt; fine. But I wanted to ask you all just to make sure that I'm not missing 
&gt;&gt;&gt; something somewhere.
&gt;&gt;&gt; 
&gt;&gt;&gt; For instance, might link walking help? How about a map/reduce to find a 
&gt;&gt;&gt; unique list of device-ids within a given time-horizon, and a streaming map 
&gt;&gt;&gt; job to gather the data for export? Does that seem pretty reasonable?
&gt;&gt;&gt; 
&gt;&gt;&gt; Thanks!
&gt;&gt;&gt; 
&gt;&gt;&gt; Keith

&gt;&gt; 
&gt; 
&gt; 

