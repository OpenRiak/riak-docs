---
title: "Re: Possible handoff stalls"
description: ""
project: community
lastmod: 2012-03-20T16:26:17-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07009"
mailinglist_parent_id: "msg07008"
author_name: "Michael Clemmons"
project_section: "mailinglistitem"
sent_date: 2012-03-20T16:26:17-07:00
---


Jon,
Thanks so much. Yes beam.swp was maxing cpu and memory on the 1 node. I
managed to get it to exit and now its a 3 node cluster. I'll take your
advice on changing the handoff.

On Tue, Mar 20, 2012 at 3:57 PM, Jon Meredith  wrote:

&gt; Hi Michael,
&gt;
&gt; When you say 'Only thing node is failing', do you mean the hardware is
&gt; failing (drives etc) or a problem with Riak itself? If it's a riak problem
&gt; sharing the error messages from the logs would be helpful.
&gt;
&gt; The fix will be included in the next point release, but we haven't set a
&gt; date for that yet. The files for packaging Riak are included with the
&gt; distribution but you'll need to get erlang set up and built as well to be
&gt; able to build it (make package, you'll have to set a few variables our
&gt; build system uses), but I'd recommend holding off until we do an official
&gt; version.
&gt;
&gt; If you'd like to increase the amount of handoff you can add
&gt; {handoff\\_concurrency, 4} to the riak\\_core section of app.config which will
&gt; take effect next restarts or you could attach to the riak console (riak
&gt; attach) and run
&gt;
&gt; rpc:multicall(riak\\_core\\_handoff\\_manager, set\\_concurrency, [4], 5000).
&gt;
&gt; (the dot is important), then ^D to disconnect.
&gt;
&gt; The handoff concurrency value was reduced from 4 to 1 for the 1.0.3
&gt; release around concerns that users building larger clusters would overwhelm
&gt; new nodes when they were added as the concurrency value applied to outbound
&gt; handoff. For 1.1 we've changed things so that the concurrency value
&gt; applied to inbound and outbound so it is safer to set it higher.
&gt;
&gt; As part of the pull request above we've also changed the logging slightly
&gt; to avoid printing out handoff starting messages until handoff succeeds. In
&gt; 1.1.0/1.1.1 when handoff concurrency is exceeded you may see repeats of
&gt; 'Starting handoff' messages if the destination node denies the transfer due
&gt; to hitting the limit.
&gt;
&gt; Cheers, Jon.
&gt;
&gt;
&gt; On Tue, Mar 20, 2012 at 4:28 PM, Michael Clemmons  &gt; wrote:
&gt;
&gt;&gt; [apologies for the delay on this email sent to armon only first]
&gt;&gt;
&gt;&gt; I'm having similar issues on a testing cluster for 1.1.1rc1. I'm having
&gt;&gt; 1 out of 4 nodes failing multiple times and not restarting well, there are
&gt;&gt; like 100 pending transfers. Only thing node is failing. I've stopped
&gt;&gt; pointing traffic at the nodes and have attempted to remove this machine
&gt;&gt; from the cluster.
&gt;&gt; Its slowly leaving but is moving very slowly for not much data, the
&gt;&gt; metadata is important and loosing any would be a significant time
&gt;&gt; consumer(but obviously not vital since we used a day old build).
&gt;&gt; What the likely hood that pull request will make it into a deb build in
&gt;&gt; the near future or will the make file generate a deb?
&gt;&gt; -Michael
&gt;&gt;
&gt;&gt;
&gt;&gt; On Mon, Mar 19, 2012 at 11:40 AM, Armon Dadgar wrote:
&gt;&gt;
&gt;&gt;&gt; Okay, good to know this is a known issue. I attached the
&gt;&gt;&gt; logs for the last time this occurred in my original email.
&gt;&gt;&gt;
&gt;&gt;&gt; I'll try to capture this information if the problem occurs again.
&gt;&gt;&gt; Thanks.
&gt;&gt;&gt;
&gt;&gt;&gt; Best Regards,
&gt;&gt;&gt;
&gt;&gt;&gt; Armon Dadgar
&gt;&gt;&gt;
&gt;&gt;&gt; On Mar 19, 2012, at 11:36 AM, Jon Meredith wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Hi Armon,
&gt;&gt;&gt;
&gt;&gt;&gt; We've recently patched an issue that affects handoffs here
&gt;&gt;&gt; https://github.com/basho/riak\\_core/pull/153
&gt;&gt;&gt;
&gt;&gt;&gt; If the issue repeats for you, as well as the logs it would be very
&gt;&gt;&gt; useful if you could follow the instructions from the pull request above ro
&gt;&gt;&gt; the 'riak\\_core\\_handoff\\_manager:status().' command against all nodes.
&gt;&gt;&gt;
&gt;&gt;&gt; The pull request works around an issue where it looks like the kernel
&gt;&gt;&gt; has closed a socket (no evidence of it any longer with netstat/ss) but the
&gt;&gt;&gt; erlang process is still stuck in an receive call from it (gen\\_tcp:recv/2 to
&gt;&gt;&gt; be more precise).
&gt;&gt;&gt;
&gt;&gt;&gt; Please let us know if you hit it again.
&gt;&gt;&gt;
&gt;&gt;&gt; Best, Jon.
&gt;&gt;&gt;
&gt;&gt;&gt; On Mon, Mar 19, 2012 at 12:10 PM, Armon Dadgar 
&gt;&gt;&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I wanted to ping the mailing list and see if anybody else has
&gt;&gt;&gt;&gt; encountered
&gt;&gt;&gt;&gt; stalls in the partition handoffs on Riak 1.1. We added a new node to
&gt;&gt;&gt;&gt; our cluster
&gt;&gt;&gt;&gt; last Friday, but noticed that the partition handoffs appear to have
&gt;&gt;&gt;&gt; stopped
&gt;&gt;&gt;&gt; after about 7-8 hours.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Most of the handoffs completed, and the only handoffs that remained
&gt;&gt;&gt;&gt; were from node 3 to node 2.
&gt;&gt;&gt;&gt; The ring claimant (node 1), indicated that node 3 was unreachable (via
&gt;&gt;&gt;&gt; ring\\_status).
&gt;&gt;&gt;&gt; However, Riak control did not indicate that node 3 was unreachable, and
&gt;&gt;&gt;&gt; in fact it was
&gt;&gt;&gt;&gt; actually live and continuing to serve request.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; To resolve this, I tried to just restart node 3. I ran "riak stop"
&gt;&gt;&gt;&gt; multiple times, but this did
&gt;&gt;&gt;&gt; not actually seem to do anything (The node was continuing to run and
&gt;&gt;&gt;&gt; serve requests).
&gt;&gt;&gt;&gt; Next, I attached to the node and ran "init:stop()." This started to
&gt;&gt;&gt;&gt; shut down various
&gt;&gt;&gt;&gt; sub-systems, but the node was still running. Sending a SIGTERM
&gt;&gt;&gt;&gt; signal to the beam vm
&gt;&gt;&gt;&gt; finally killed it. Restarting the node with "riak start" worked as
&gt;&gt;&gt;&gt; expected,
&gt;&gt;&gt;&gt; and the node promptly resumed the handoffs, and finished in a few hours.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I'm not sure exactly what the issue was, but something seemed to cause a
&gt;&gt;&gt;&gt; stalling of the handoffs.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I've attached the contents of our console.log, erlang.log, error.log
&gt;&gt;&gt;&gt; and crash.log
&gt;&gt;&gt;&gt; from the relevant times if that is useful.
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Best Regards,
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; Armon Dadgar
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; Jon Meredith
&gt;&gt;&gt; Platform Engineering Manager
&gt;&gt;&gt; Basho Technologies, Inc.
&gt;&gt;&gt; jmered...@basho.com
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;

&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt;
&gt;&gt; --
&gt;&gt; -Michael
&gt;&gt;
&gt;&gt;
&gt;
&gt;
&gt; --
&gt; Jon Meredith
&gt; Platform Engineering Manager
&gt; Basho Technologies, Inc.
&gt; jmered...@basho.com
&gt;
&gt;


-- 
-Michael
