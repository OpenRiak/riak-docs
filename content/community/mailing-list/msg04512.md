---
title: "Re: innostore performance tuning"
description: ""
project: community
lastmod: 2011-08-30T09:53:16-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg04512"
mailinglist_parent_id: "msg04509"
author_name: "Jonathan Langevin"
project_section: "mailinglistitem"
sent_date: 2011-08-30T09:53:16-07:00
---


So, essentially, creation of new keys/objects is much slower than an update
to already existing keys/objects?
Just want to make sure I'm following your description properly.
\\*

 
 Jonathan Langevin
Systems Administrator
Loom Inc.
Wilmington, NC: (910) 241-0433 - jlange...@loomlearning.com -
www.loomlearning.com - Skype: intel352
\\*


On Tue, Aug 30, 2011 at 12:30 PM, Kresten Krab Thorup wrote:

&gt; If you can do the inserts in sorted (ascending) key order, then innostore
&gt; will be significantly faster.
&gt;
&gt; Kresten
&gt;
&gt;
&gt; Mobile: + 45 2343 4626 | Skype: krestenkrabthorup | Twitter: @drkrab
&gt; Trifork A/S | Margrethepladsen 4 | DK- 8000 Aarhus C | Phone : +45
&gt; 8732 8787 | www.trifork.com
&gt;
&gt; Trifork organizes the world class conference on software development: GOTO
&gt; Aarhus - check it out!
&gt;
&gt;
&gt;
&gt; On Aug 30, 2011, at 6:14 PM, David Koblas wrote:
&gt;
&gt; &gt; I'm currently working on importing a very large dataset (800M) into Riak
&gt; and running into some serious performance problems. Hopefully this is just
&gt; configuration issues and nothing deeper...
&gt; &gt;
&gt; &gt; Hardware -
&gt; &gt; \\* 8 proc box
&gt; &gt; \\* 32 Gb ram
&gt; &gt; \\* 5TB disk - RAID10
&gt; &gt;
&gt; &gt; Have a cluster of 4 for these boxes all running riak - riak configuration
&gt; options that are different from stock:
&gt; &gt;
&gt; &gt; \\* Listening on all IP address "0.0.0.0"
&gt; &gt; \\* {storage\\_backend, riak\\_kv\\_innostore\\_backend},
&gt; &gt; \\* innostore section - {buffer\\_pool\\_size, 17179869184}, %% 16GB
&gt; &gt; \\* innostore section - {flush\\_method, "O\\_DIRECT"}
&gt; &gt;
&gt; &gt; What I see is that the performance of my import script runs at about
&gt; 200...300 keys per/second for keys that it's seen recently (e.g. re-runs)
&gt; then drops to 20ish keys per/sec for new keys.
&gt; &gt; STATS: 1000 keys handled in 3 seconds 250.75 keys/sec
&gt; &gt; STATS: 1000 keys handled in 3 seconds 258.20 keys/sec
&gt; &gt; STATS: 1000 keys handled in 4 seconds 240.11 keys/sec
&gt; &gt; STATS: 1000 keys handled in 5 seconds 177.63 keys/sec
&gt; &gt; STATS: 1000 keys handled in 4 seconds 246.26 keys/sec
&gt; &gt; STATS: 1000 keys handled in 5 seconds 184.79 keys/sec
&gt; &gt; STATS: 1000 keys handled in 5 seconds 195.95 keys/sec
&gt; &gt; STATS: 1000 keys handled in 47 seconds 21.02 keys/sec
&gt; &gt; STATS: 1000 keys handled in 44 seconds 22.63 keys/sec
&gt; &gt; STATS: 1000 keys handled in 42 seconds 23.64 keys/sec
&gt; &gt; STATS: 1000 keys handled in 43 seconds 22.88 keys/sec
&gt; &gt; STATS: 1000 keys handled in 45 seconds 22.12 keys/sec
&gt; &gt; STATS: 1000 keys handled in 43 seconds 22.83 keys/sec
&gt; &gt; STATS: 1000 keys handled in 43 seconds 23.11 keys/sec
&gt; &gt; Of course with 800M records to import a performance of 20 keys/sec is not
&gt; useful, plus as time goes on having an insert rate at that level is going to
&gt; be problematic.
&gt; &gt;
&gt; &gt; Questions -
&gt; &gt; Is there additional things to change for imports and datasets on this
&gt; scale?
&gt; &gt; Is there a way to get additional debugging to see where the performance
&gt; issues are?
&gt; &gt;
&gt; &gt; Thanks,

