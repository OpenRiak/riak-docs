---
title: "Re: Same MR query, different results every run..........."
description: ""
project: community
lastmod: 2013-01-08T00:20:43-08:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg09759"
mailinglist_parent_id: "msg09753"
author_name: "Christian Dahlqvist"
project_section: "mailinglistitem"
sent_date: 2013-01-08T00:20:43-08:00
---


Hi David,

Is it always the same entry that is missing from the result set? If so, does 
the issue go away if you issue a read request for the record(s) causing 
problems (resulting in read-repair)?

If this is the case, the cause of the problem might be explained by how 
MapReduce works in Riak.

In Riak, map phases are sent to a covering set of vnodes, and are executed 
where the data resides. When data is read in order to be passed in to the map 
phase, only the data stored on that vnode is considered (effectively a read 
with R=1 - not the default R value specified for the bucket). If all vnodes do 
not have the same version of the data, I believe it is possible the results may 
vary slightly between runs if the covering sets differ.

Best regards,

Christian

On 7 Jan 2013, at 23:33, David Montgomery  wrote:

&gt; Hi,
&gt; 
&gt; i do have a reduce phase
&gt; 
&gt; 
&gt; On Tue, Jan 8, 2013 at 12:08 AM, Mridul Kashatria  
&gt; wrote:
&gt; Hi,
&gt; 
&gt; If I am correct, adding a reduce function should return the same number of 
&gt; items.
&gt; 
&gt; I'm a riak noob but I faced some similar issue while testing with a map 
&gt; function only. Adding a reduce fixed it.
&gt; 
&gt; I believe as the map fans out to multiple nodes, whichever node returns data 
&gt; first is written to output and not collected by a reduce stage.
&gt; 
&gt; Please correct me if I'm wrong.
&gt; 
&gt; Thanks
&gt; 
&gt; --
&gt; Mridul
&gt; 
&gt; 
&gt; 
&gt; On Sunday 06 January 2013 11:07 AM, David Montgomery wrote:
&gt;&gt; Hi,
&gt;&gt; 
&gt;&gt; Here is my my mapper...
&gt;&gt; 
&gt;&gt; query.map('''
&gt;&gt; function(value, keyData, arg) {
&gt;&gt; 
&gt;&gt; if(value.length == 0){
&gt;&gt; return [];
&gt;&gt; }else{
&gt;&gt; var data = Riak.mapValuesJson(value)[0];
&gt;&gt; var obj = {};
&gt;&gt; if(data['campaign\\_id']=='%s'){
&gt;&gt; try{
&gt;&gt; var alt\\_key = data['ckid'] + '||' + data['gid'] + '||' + 
&gt;&gt; data['ts\\_hms']; 
&gt;&gt; }
&gt;&gt; catch(err){
&gt;&gt; var alt\\_key = 'error';
&gt;&gt; }
&gt;&gt; obj[alt\\_key] = 1;
&gt;&gt; return [ obj ];
&gt;&gt; }else{
&gt;&gt; return [];
&gt;&gt; }
&gt;&gt; }
&gt;&gt; }''' % campaign\\_id)
&gt;&gt; 
&gt;&gt; When I run the the query repeatedly, over and over, about every 2 seconds I 
&gt;&gt; get the below. A few times I get 14 rows and a few times I get 13 then back 
&gt;&gt; to 14 etc. So.....why? There should be no variation. I have a three node 
&gt;&gt; cluster, two cores, 4 gigs or ram on ubuntu 12.06 using the latest riak.
&gt;&gt; 
&gt;&gt; 
&gt;&gt; TOTAL: 14
&gt;&gt; 3dc3f58f-faea-4751-94b5-8a9a076d4b3f||CAESEGYMM1Q34DV8Ev0i12IVKdY||2012-12-31
&gt;&gt; 08:36:21 1
&gt;&gt; b4d82fa0-5cd4-4813-a150-554ebca30f1f||CAESEM98NHldIIyAzY0CIUnKudw||2013-01-04
&gt;&gt; 06:18:37 1
&gt;&gt; 8743af22-a664-4b60-ac59-b79d52c12e9e||CAESEH2PIdEYXvk3Dsg2\\_vF6Qcc||2013-01-04
&gt;&gt; 09:13:30 1
&gt;&gt; cef36621-527c-4b7a-be6f-5842e13a1350||CAESEHsyPPSizUsT-j31I-nCLzQ||2013-01-05
&gt;&gt; 12:50:22 1
&gt;&gt; 663fb22d-c60d-46b7-8b5b-c9be103c2084||CAESEDtHYmtttm7DBCRpCSU9zYE||2013-01-04
&gt;&gt; 08:55:06 1
&gt;&gt; e2b6afda-b838-48d5-a449-7b568b9f6b04||CAESEBciJaIqccs2584wIgdsOqc||2013-01-04
&gt;&gt; 04:02:13 1
&gt;&gt; 66aa05fe-9c55-43b2-93ae-c8cb19d097d7||CAESEBuVyK-X\\_iNGaiiLhPsT0TE||2013-01-02
&gt;&gt; 01:29:38 1
&gt;&gt; 0969a7ca-4324-4118-9038-b6fc11f08a36||CAESENwCD1bw1VvtIamGBCUl\\_zk||2013-01-02
&gt;&gt; 00:55:01 1
&gt;&gt; f78b77f6-a08c-4f07-b982-7b2cdcefba4f||CAESEJiWNlcbRN7Sx9o2FB7fbaU||2012-12-29
&gt;&gt; 05:22:46 1
&gt;&gt; 8050e5a7-1583-459a-983f-55feaf0e2a6c||CAESED2NyW9XDEbiKb1UD4sTzvI||2013-01-05
&gt;&gt; 12:18:59 1
&gt;&gt; 58b84566-ad3a-4a3f-91bd-1c61986fbadb||CAESELQcGkigDvXrtRDgOlw9rX0||2013-01-04
&gt;&gt; 16:19:25 1
&gt;&gt; 0db77e8d-ed94-43cf-8860-b4e43dfa24aa||CAESECbwN7VY6o8om79mZ905GIA||2013-01-02
&gt;&gt; 16:15:34 1
&gt;&gt; 67e79552-7e06-44bd-9e95-87f7cb634de3||CAESEFA6fd\\_C1PBslKgOj6\\_BI28||2012-12-29
&gt;&gt; 05:23:11 1
&gt;&gt; ffc3c6ae-beee-4dfe-b41d-ec3a72bddf67||CAESEN\\_MAXs55jCPIwuyvfTZIZc||2012-12-28
&gt;&gt; 07:56:03 1
&gt;&gt; 
&gt;&gt; 
&gt;&gt; TOTAL: 13
&gt;&gt; b4d82fa0-5cd4-4813-a150-554ebca30f1f||CAESEM98NHldIIyAzY0CIUnKudw||2013-01-04
&gt;&gt; 06:18:37 1
&gt;&gt; 8743af22-a664-4b60-ac59-b79d52c12e9e||CAESEH2PIdEYXvk3Dsg2\\_vF6Qcc||2013-01-04
&gt;&gt; 09:13:30 1
&gt;&gt; cef36621-527c-4b7a-be6f-5842e13a1350||CAESEHsyPPSizUsT-j31I-nCLzQ||2013-01-05
&gt;&gt; 12:50:22 1
&gt;&gt; 663fb22d-c60d-46b7-8b5b-c9be103c2084||CAESEDtHYmtttm7DBCRpCSU9zYE||2013-01-04
&gt;&gt; 08:55:06 1
&gt;&gt; e2b6afda-b838-48d5-a449-7b568b9f6b04||CAESEBciJaIqccs2584wIgdsOqc||2013-01-04
&gt;&gt; 04:02:13 1
&gt;&gt; 66aa05fe-9c55-43b2-93ae-c8cb19d097d7||CAESEBuVyK-X\\_iNGaiiLhPsT0TE||2013-01-02
&gt;&gt; 01:29:38 1
&gt;&gt; 0969a7ca-4324-4118-9038-b6fc11f08a36||CAESENwCD1bw1VvtIamGBCUl\\_zk||2013-01-02
&gt;&gt; 00:55:01 1
&gt;&gt; f78b77f6-a08c-4f07-b982-7b2cdcefba4f||CAESEJiWNlcbRN7Sx9o2FB7fbaU||2012-12-29
&gt;&gt; 05:22:46 1
&gt;&gt; 8050e5a7-1583-459a-983f-55feaf0e2a6c||CAESED2NyW9XDEbiKb1UD4sTzvI||2013-01-05
&gt;&gt; 12:18:59 1
&gt;&gt; 58b84566-ad3a-4a3f-91bd-1c61986fbadb||CAESELQcGkigDvXrtRDgOlw9rX0||2013-01-04
&gt;&gt; 16:19:25 1
&gt;&gt; 3dc3f58f-faea-4751-94b5-8a9a076d4b3f||CAESEGYMM1Q34DV8Ev0i12IVKdY||2012-12-31
&gt;&gt; 08:36:21 1
&gt;&gt; 67e79552-7e06-44bd-9e95-87f7cb634de3||CAESEFA6fd\\_C1PBslKgOj6\\_BI28||2012-12-29
&gt;&gt; 05:23:11 1
&gt;&gt; 0db77e8d-ed94-43cf-8860-b4e43dfa24aa||CAESECbwN7VY6o8om79mZ905GIA||2013-01-02
&gt;&gt; 16:15:34 1
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt;&gt; 
&gt; 
&gt; 
 
&gt; 

