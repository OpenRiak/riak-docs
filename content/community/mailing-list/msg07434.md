---
title: "Re: How do I improve Level DB performance?"
description: ""
project: community
lastmod: 2012-05-11T09:13:49-07:00
sitemap:
  priority: 0.2
layout: mailinglistitem
mailinglist_id: "msg07434"
mailinglist_parent_id: "msg07431"
author_name: "Ryan Zezeski"
project_section: "mailinglistitem"
sent_date: 2012-05-11T09:13:49-07:00
---


On Thu, May 10, 2012 at 11:14 PM, Tim Haines  wrote:
&gt;
&gt;
&gt;
&gt; With the adjusted ring size and settings, and adjusted to only do puts (so
&gt; no missed reads), my cluster is doing about 400 puts per second:
&gt; http://twitpic.com/9jnhlm/full
&gt;

Actually, every put (put from a riak API level) does a read on the backend
[1]. This is needed to merge contents from the two objects [2].

Like Dave already mentioned the key generation strategy along with
leveldb's degrading performance on not-found means your benchmark will just
get worse the longer it runs.

Are you testing an actual use case here? Do you envision 100M objects
being written in a constant stream? Will your objects have a median size
of 1000 bytes? Basho bench also provides a pareto key generator which uses
a fraction of the key space most of the time. I'm not sure it matches your
use case but thought I'd mention it is there.

-Z

[1]: https://github.com/basho/riak\\_kv/blob/1.1.2/src/riak\\_kv\\_vnode.erl#L669

[2]: https://github.com/basho/riak\\_kv/blob/1.1.2/src/riak\\_kv\\_vnode.erl#L686
